// $ANTLR 3.4 org/apache/hadoop/hive/ql/parse/HiveParser.g 2017-07-25 10:01:44

package org.apache.hadoop.hive.ql.parse;

import java.util.Arrays;
import java.util.Collection;
import java.util.HashMap;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hive.conf.HiveConf;


import org.antlr.runtime.*;
import java.util.Stack;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.util.HashMap;

import org.antlr.runtime.tree.*;


/**
   Licensed to the Apache Software Foundation (ASF) under one or more 
   contributor license agreements.  See the NOTICE file distributed with 
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with 
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
*/
@SuppressWarnings({"all", "warnings", "unchecked"})
public class HiveParser extends Parser {
    public static final String[] tokenNames = new String[] {
        "<invalid>", "<EOR>", "<DOWN>", "<UP>", "AMPERSAND", "BITWISEOR", "BITWISEXOR", "BigintLiteral", "ByteLengthLiteral", "COLON", "COMMA", "COMMENT", "CONCATENATE", "CharSetLiteral", "CharSetName", "DIV", "DIVIDE", "DOLLAR", "DOT", "DecimalLiteral", "Digit", "EQUAL", "EQUAL_NS", "Exponent", "GREATERTHAN", "GREATERTHANOREQUALTO", "HexDigit", "Identifier", "KW_ABORT", "KW_ADD", "KW_ADMIN", "KW_AFTER", "KW_ALL", "KW_ALTER", "KW_ANALYZE", "KW_AND", "KW_ARCHIVE", "KW_ARRAY", "KW_AS", "KW_ASC", "KW_AUTHORIZATION", "KW_AUTOCOMMIT", "KW_BEFORE", "KW_BETWEEN", "KW_BIGINT", "KW_BINARY", "KW_BOOLEAN", "KW_BOTH", "KW_BUCKET", "KW_BUCKETS", "KW_BY", "KW_CACHE", "KW_CASCADE", "KW_CASE", "KW_CAST", "KW_CHANGE", "KW_CHAR", "KW_CLUSTER", "KW_CLUSTERED", "KW_CLUSTERSTATUS", "KW_COLLECTION", "KW_COLUMN", "KW_COLUMNS", "KW_COMMENT", "KW_COMMIT", "KW_COMPACT", "KW_COMPACTIONS", "KW_COMPUTE", "KW_CONCATENATE", "KW_CONF", "KW_CONSTRAINT", "KW_CONTINUE", "KW_CREATE", "KW_CROSS", "KW_CUBE", "KW_CURRENT", "KW_CURRENT_DATE", "KW_CURRENT_TIMESTAMP", "KW_CURSOR", "KW_DATA", "KW_DATABASE", "KW_DATABASES", "KW_DATE", "KW_DATETIME", "KW_DAY", "KW_DBPROPERTIES", "KW_DECIMAL", "KW_DEFERRED", "KW_DEFINED", "KW_DELETE", "KW_DELIMITED", "KW_DEPENDENCY", "KW_DESC", "KW_DESCRIBE", "KW_DIRECTORIES", "KW_DIRECTORY", "KW_DISABLE", "KW_DISTINCT", "KW_DISTRIBUTE", "KW_DOUBLE", "KW_DOW", "KW_DROP", "KW_DUMP", "KW_ELEM_TYPE", "KW_ELSE", "KW_ENABLE", "KW_END", "KW_ESCAPED", "KW_EXCEPT", "KW_EXCHANGE", "KW_EXCLUSIVE", "KW_EXISTS", "KW_EXPLAIN", "KW_EXPORT", "KW_EXTENDED", "KW_EXTERNAL", "KW_EXTRACT", "KW_FALSE", "KW_FETCH", "KW_FIELDS", "KW_FILE", "KW_FILEFORMAT", "KW_FIRST", "KW_FLOAT", "KW_FLOOR", "KW_FOLLOWING", "KW_FOR", "KW_FOREIGN", "KW_FORMAT", "KW_FORMATTED", "KW_FROM", "KW_FULL", "KW_FUNCTION", "KW_FUNCTIONS", "KW_GRANT", "KW_GROUP", "KW_GROUPING", "KW_HAVING", "KW_HOUR", "KW_IDXPROPERTIES", "KW_IF", "KW_IMPORT", "KW_IN", "KW_INDEX", "KW_INDEXES", "KW_INNER", "KW_INPATH", "KW_INPUTDRIVER", "KW_INPUTFORMAT", "KW_INSERT", "KW_INT", "KW_INTERSECT", "KW_INTERVAL", "KW_INTO", "KW_IS", "KW_ISOLATION", "KW_ITEMS", "KW_JAR", "KW_JOIN", "KW_KEY", "KW_KEYS", "KW_KEY_TYPE", "KW_LAST", "KW_LATERAL", "KW_LEFT", "KW_LESS", "KW_LEVEL", "KW_LIKE", "KW_LIMIT", "KW_LINES", "KW_LOAD", "KW_LOCAL", "KW_LOCATION", "KW_LOCK", "KW_LOCKS", "KW_LOGICAL", "KW_LONG", "KW_MACRO", "KW_MAP", "KW_MAPJOIN", "KW_MATCHED", "KW_MATERIALIZED", "KW_MERGE", "KW_METADATA", "KW_MINUS", "KW_MINUTE", "KW_MONTH", "KW_MORE", "KW_MSCK", "KW_NONE", "KW_NORELY", "KW_NOSCAN", "KW_NOT", "KW_NOVALIDATE", "KW_NULL", "KW_NULLS", "KW_OF", "KW_OFFSET", "KW_ON", "KW_ONLY", "KW_OPTION", "KW_OR", "KW_ORDER", "KW_OUT", "KW_OUTER", "KW_OUTPUTDRIVER", "KW_OUTPUTFORMAT", "KW_OVER", "KW_OVERWRITE", "KW_OWNER", "KW_PARTIALSCAN", "KW_PARTITION", "KW_PARTITIONED", "KW_PARTITIONS", "KW_PERCENT", "KW_PLUS", "KW_PRECEDING", "KW_PRECISION", "KW_PRESERVE", "KW_PRETTY", "KW_PRIMARY", "KW_PRINCIPALS", "KW_PROCEDURE", "KW_PURGE", "KW_QUARTER", "KW_RANGE", "KW_READ", "KW_READS", "KW_REBUILD", "KW_RECORDREADER", "KW_RECORDWRITER", "KW_REDUCE", "KW_REFERENCES", "KW_REGEXP", "KW_RELOAD", "KW_RELY", "KW_RENAME", "KW_REPAIR", "KW_REPL", "KW_REPLACE", "KW_REPLICATION", "KW_RESTRICT", "KW_REVOKE", "KW_REWRITE", "KW_RIGHT", "KW_RLIKE", "KW_ROLE", "KW_ROLES", "KW_ROLLBACK", "KW_ROLLUP", "KW_ROW", "KW_ROWS", "KW_SCHEMA", "KW_SCHEMAS", "KW_SECOND", "KW_SELECT", "KW_SEMI", "KW_SERDE", "KW_SERDEPROPERTIES", "KW_SERVER", "KW_SET", "KW_SETS", "KW_SHARED", "KW_SHOW", "KW_SHOW_DATABASE", "KW_SKEWED", "KW_SMALLINT", "KW_SNAPSHOT", "KW_SORT", "KW_SORTED", "KW_SSL", "KW_START", "KW_STATISTICS", "KW_STATUS", "KW_STORED", "KW_STREAMTABLE", "KW_STRING", "KW_STRUCT", "KW_TABLE", "KW_TABLES", "KW_TABLESAMPLE", "KW_TBLPROPERTIES", "KW_TEMPORARY", "KW_TERMINATED", "KW_THEN", "KW_TIMESTAMP", "KW_TINYINT", "KW_TO", "KW_TOUCH", "KW_TRANSACTION", "KW_TRANSACTIONS", "KW_TRANSFORM", "KW_TRIGGER", "KW_TRUE", "KW_TRUNCATE", "KW_UNARCHIVE", "KW_UNBOUNDED", "KW_UNDO", "KW_UNION", "KW_UNIONTYPE", "KW_UNIQUEJOIN", "KW_UNLOCK", "KW_UNSET", "KW_UNSIGNED", "KW_UPDATE", "KW_URI", "KW_USE", "KW_USER", "KW_USING", "KW_UTC", "KW_UTCTIMESTAMP", "KW_VALIDATE", "KW_VALUES", "KW_VALUE_TYPE", "KW_VARCHAR", "KW_VIEW", "KW_VIEWS", "KW_WEEK", "KW_WHEN", "KW_WHERE", "KW_WHILE", "KW_WINDOW", "KW_WITH", "KW_WORK", "KW_WRITE", "KW_YEAR", "LCURLY", "LESSTHAN", "LESSTHANOREQUALTO", "LPAREN", "LSQUARE", "Letter", "MINUS", "MOD", "NOTEQUAL", "Number", "PLUS", "QUESTION", "QuotedIdentifier", "RCURLY", "RPAREN", "RSQUARE", "RegexComponent", "SEMICOLON", "STAR", "SmallintLiteral", "StringLiteral", "TILDE", "TinyintLiteral", "WS", "KW_BATCH", "KW_DAYOFWEEK", "KW_HOLD_DDLTIME", "KW_IGNORE", "KW_NO_DROP", "KW_OFFLINE", "KW_PROTECTION", "KW_READONLY", "TOK_ABORT_TRANSACTIONS", "TOK_ADMIN_OPTION_FOR", "TOK_ALIASLIST", "TOK_ALLCOLREF", "TOK_ALTERDATABASE_OWNER", "TOK_ALTERDATABASE_PROPERTIES", "TOK_ALTERINDEX_PROPERTIES", "TOK_ALTERINDEX_REBUILD", "TOK_ALTERTABLE", "TOK_ALTERTABLE_ADDCOLS", "TOK_ALTERTABLE_ADDCONSTRAINT", "TOK_ALTERTABLE_ADDPARTS", "TOK_ALTERTABLE_ARCHIVE", "TOK_ALTERTABLE_BUCKETS", "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION", "TOK_ALTERTABLE_CLUSTER_SORT", "TOK_ALTERTABLE_COMPACT", "TOK_ALTERTABLE_DROPCONSTRAINT", "TOK_ALTERTABLE_DROPPARTS", "TOK_ALTERTABLE_DROPPROPERTIES", "TOK_ALTERTABLE_EXCHANGEPARTITION", "TOK_ALTERTABLE_FILEFORMAT", "TOK_ALTERTABLE_LOCATION", "TOK_ALTERTABLE_MERGEFILES", "TOK_ALTERTABLE_PARTCOLTYPE", "TOK_ALTERTABLE_PROPERTIES", "TOK_ALTERTABLE_RENAME", "TOK_ALTERTABLE_RENAMECOL", "TOK_ALTERTABLE_RENAMEPART", "TOK_ALTERTABLE_REPLACECOLS", "TOK_ALTERTABLE_SERDEPROPERTIES", "TOK_ALTERTABLE_SERIALIZER", "TOK_ALTERTABLE_SKEWED", "TOK_ALTERTABLE_SKEWED_LOCATION", "TOK_ALTERTABLE_TOUCH", "TOK_ALTERTABLE_UNARCHIVE", "TOK_ALTERTABLE_UPDATECOLSTATS", "TOK_ALTERTABLE_UPDATESTATS", "TOK_ALTERVIEW", "TOK_ALTERVIEW_ADDPARTS", "TOK_ALTERVIEW_DROPPARTS", "TOK_ALTERVIEW_DROPPROPERTIES", "TOK_ALTERVIEW_PROPERTIES", "TOK_ALTERVIEW_RENAME", "TOK_ANALYZE", "TOK_ANONYMOUS", "TOK_ARCHIVE", "TOK_BIGINT", "TOK_BINARY", "TOK_BOOLEAN", "TOK_CACHE_METADATA", "TOK_CASCADE", "TOK_CHAR", "TOK_CHARSETLITERAL", "TOK_CLUSTERBY", "TOK_COLTYPELIST", "TOK_COL_NAME", "TOK_COMMIT", "TOK_CREATEDATABASE", "TOK_CREATEFUNCTION", "TOK_CREATEINDEX", "TOK_CREATEINDEX_INDEXTBLNAME", "TOK_CREATEMACRO", "TOK_CREATEROLE", "TOK_CREATETABLE", "TOK_CREATEVIEW", "TOK_CROSSJOIN", "TOK_CTE", "TOK_CUBE_GROUPBY", "TOK_DATABASECOMMENT", "TOK_DATABASELOCATION", "TOK_DATABASEPROPERTIES", "TOK_DATE", "TOK_DATELITERAL", "TOK_DATETIME", "TOK_DBPROPLIST", "TOK_DB_TYPE", "TOK_DECIMAL", "TOK_DEFERRED_REBUILDINDEX", "TOK_DELETE", "TOK_DELETE_FROM", "TOK_DESCDATABASE", "TOK_DESCFUNCTION", "TOK_DESCTABLE", "TOK_DESTINATION", "TOK_DIR", "TOK_DISABLE", "TOK_DISTRIBUTEBY", "TOK_DOUBLE", "TOK_DROPDATABASE", "TOK_DROPFUNCTION", "TOK_DROPINDEX", "TOK_DROPMACRO", "TOK_DROPROLE", "TOK_DROPTABLE", "TOK_DROPVIEW", "TOK_ENABLE", "TOK_EXCEPTALL", "TOK_EXCEPTDISTINCT", "TOK_EXPLAIN", "TOK_EXPLAIN_SQ_REWRITE", "TOK_EXPLIST", "TOK_EXPORT", "TOK_FALSE", "TOK_FILE", "TOK_FILEFORMAT_GENERIC", "TOK_FLOAT", "TOK_FOREIGN_KEY", "TOK_FROM", "TOK_FULLOUTERJOIN", "TOK_FUNCTION", "TOK_FUNCTIONDI", "TOK_FUNCTIONSTAR", "TOK_GRANT", "TOK_GRANT_OPTION_FOR", "TOK_GRANT_ROLE", "TOK_GRANT_WITH_ADMIN_OPTION", "TOK_GRANT_WITH_OPTION", "TOK_GROUP", "TOK_GROUPBY", "TOK_GROUPING_SETS", "TOK_GROUPING_SETS_EXPRESSION", "TOK_HAVING", "TOK_HINT", "TOK_HINTARGLIST", "TOK_HINTLIST", "TOK_IFEXISTS", "TOK_IFNOTEXISTS", "TOK_IMPORT", "TOK_INDEXCOMMENT", "TOK_INDEXPROPERTIES", "TOK_INDEXPROPLIST", "TOK_INSERT", "TOK_INSERT_INTO", "TOK_INT", "TOK_INTERSECTALL", "TOK_INTERSECTDISTINCT", "TOK_INTERVAL_DAY_LITERAL", "TOK_INTERVAL_DAY_TIME", "TOK_INTERVAL_DAY_TIME_LITERAL", "TOK_INTERVAL_HOUR_LITERAL", "TOK_INTERVAL_MINUTE_LITERAL", "TOK_INTERVAL_MONTH_LITERAL", "TOK_INTERVAL_SECOND_LITERAL", "TOK_INTERVAL_YEAR_LITERAL", "TOK_INTERVAL_YEAR_MONTH", "TOK_INTERVAL_YEAR_MONTH_LITERAL", "TOK_ISNOTNULL", "TOK_ISNULL", "TOK_ISOLATION_LEVEL", "TOK_ISOLATION_SNAPSHOT", "TOK_JAR", "TOK_JOIN", "TOK_LATERAL_VIEW", "TOK_LATERAL_VIEW_OUTER", "TOK_LEFTOUTERJOIN", "TOK_LEFTSEMIJOIN", "TOK_LENGTH", "TOK_LIKETABLE", "TOK_LIMIT", "TOK_LIST", "TOK_LOAD", "TOK_LOCKDB", "TOK_LOCKTABLE", "TOK_MAP", "TOK_MAPJOIN", "TOK_MATCHED", "TOK_MERGE", "TOK_METADATA", "TOK_MSCK", "TOK_NORELY", "TOK_NOT_CLUSTERED", "TOK_NOT_MATCHED", "TOK_NOT_SORTED", "TOK_NOVALIDATE", "TOK_NO_DROP", "TOK_NULL", "TOK_NULLS_FIRST", "TOK_NULLS_LAST", "TOK_OFFLINE", "TOK_OFFSET", "TOK_OP_ADD", "TOK_OP_AND", "TOK_OP_BITAND", "TOK_OP_BITNOT", "TOK_OP_BITOR", "TOK_OP_BITXOR", "TOK_OP_DIV", "TOK_OP_EQ", "TOK_OP_GE", "TOK_OP_GT", "TOK_OP_LE", "TOK_OP_LIKE", "TOK_OP_LT", "TOK_OP_MOD", "TOK_OP_MUL", "TOK_OP_NE", "TOK_OP_NOT", "TOK_OP_OR", "TOK_OP_SUB", "TOK_ORDERBY", "TOK_ORREPLACE", "TOK_PARTITIONINGSPEC", "TOK_PARTITIONLOCATION", "TOK_PARTSPEC", "TOK_PARTVAL", "TOK_PERCENT", "TOK_PRIMARY_KEY", "TOK_PRINCIPAL_NAME", "TOK_PRIVILEGE", "TOK_PRIVILEGE_LIST", "TOK_PRIV_ALL", "TOK_PRIV_ALTER_DATA", "TOK_PRIV_ALTER_METADATA", "TOK_PRIV_CREATE", "TOK_PRIV_DELETE", "TOK_PRIV_DROP", "TOK_PRIV_INDEX", "TOK_PRIV_INSERT", "TOK_PRIV_LOCK", "TOK_PRIV_OBJECT", "TOK_PRIV_OBJECT_COL", "TOK_PRIV_SELECT", "TOK_PRIV_SHOW_DATABASE", "TOK_PTBLFUNCTION", "TOK_QUERY", "TOK_READONLY", "TOK_RECORDREADER", "TOK_RECORDWRITER", "TOK_RELOADFUNCTION", "TOK_RELY", "TOK_REPLICATION", "TOK_REPL_DUMP", "TOK_REPL_LOAD", "TOK_REPL_STATUS", "TOK_RESOURCE_ALL", "TOK_RESOURCE_LIST", "TOK_RESOURCE_URI", "TOK_RESTRICT", "TOK_REVOKE", "TOK_REVOKE_ROLE", "TOK_RIGHTOUTERJOIN", "TOK_ROLE", "TOK_ROLLBACK", "TOK_ROLLUP_GROUPBY", "TOK_ROWCOUNT", "TOK_SELECT", "TOK_SELECTDI", "TOK_SELEXPR", "TOK_SERDE", "TOK_SERDENAME", "TOK_SERDEPROPS", "TOK_SERVER_TYPE", "TOK_SETCOLREF", "TOK_SET_AUTOCOMMIT", "TOK_SET_COLUMNS_CLAUSE", "TOK_SHOWCOLUMNS", "TOK_SHOWCONF", "TOK_SHOWDATABASES", "TOK_SHOWDBLOCKS", "TOK_SHOWFUNCTIONS", "TOK_SHOWINDEXES", "TOK_SHOWLOCKS", "TOK_SHOWPARTITIONS", "TOK_SHOWTABLES", "TOK_SHOW_COMPACTIONS", "TOK_SHOW_CREATEDATABASE", "TOK_SHOW_CREATETABLE", "TOK_SHOW_GRANT", "TOK_SHOW_ROLES", "TOK_SHOW_ROLE_GRANT", "TOK_SHOW_ROLE_PRINCIPALS", "TOK_SHOW_SET_ROLE", "TOK_SHOW_TABLESTATUS", "TOK_SHOW_TBLPROPERTIES", "TOK_SHOW_TRANSACTIONS", "TOK_SKEWED_LOCATIONS", "TOK_SKEWED_LOCATION_LIST", "TOK_SKEWED_LOCATION_MAP", "TOK_SMALLINT", "TOK_SORTBY", "TOK_START_TRANSACTION", "TOK_STORAGEHANDLER", "TOK_STOREDASDIRS", "TOK_STREAMTABLE", "TOK_STRING", "TOK_STRINGLITERALSEQUENCE", "TOK_STRUCT", "TOK_SUBQUERY", "TOK_SUBQUERY_EXPR", "TOK_SUBQUERY_OP", "TOK_SUBQUERY_OP_NOTEXISTS", "TOK_SUBQUERY_OP_NOTIN", "TOK_SWITCHDATABASE", "TOK_TAB", "TOK_TABALIAS", "TOK_TABCOL", "TOK_TABCOLLIST", "TOK_TABCOLNAME", "TOK_TABCOLVALUE", "TOK_TABCOLVALUES", "TOK_TABCOLVALUE_PAIR", "TOK_TABLEBUCKETSAMPLE", "TOK_TABLECOMMENT", "TOK_TABLEFILEFORMAT", "TOK_TABLELOCATION", "TOK_TABLEPARTCOLS", "TOK_TABLEPROPERTIES", "TOK_TABLEPROPERTY", "TOK_TABLEPROPLIST", "TOK_TABLEROWFORMAT", "TOK_TABLEROWFORMATCOLLITEMS", "TOK_TABLEROWFORMATFIELD", "TOK_TABLEROWFORMATLINES", "TOK_TABLEROWFORMATMAPKEYS", "TOK_TABLEROWFORMATNULL", "TOK_TABLESERIALIZER", "TOK_TABLESKEWED", "TOK_TABLESPLITSAMPLE", "TOK_TABLE_OR_COL", "TOK_TABLE_PARTITION", "TOK_TABLE_TYPE", "TOK_TABNAME", "TOK_TABREF", "TOK_TABSORTCOLNAMEASC", "TOK_TABSORTCOLNAMEDESC", "TOK_TABSRC", "TOK_TABTYPE", "TOK_TEMPORARY", "TOK_TIMESTAMP", "TOK_TIMESTAMPLITERAL", "TOK_TINYINT", "TOK_TMP_FILE", "TOK_TO", "TOK_TRANSFORM", "TOK_TRUE", "TOK_TRUNCATETABLE", "TOK_TXN_ACCESS_MODE", "TOK_TXN_READ_ONLY", "TOK_TXN_READ_WRITE", "TOK_UNIONALL", "TOK_UNIONDISTINCT", "TOK_UNIONTYPE", "TOK_UNIQUEJOIN", "TOK_UNLOCKDB", "TOK_UNLOCKTABLE", "TOK_UPDATE", "TOK_UPDATE_TABLE", "TOK_URI_TYPE", "TOK_USER", "TOK_USERSCRIPTCOLNAMES", "TOK_USERSCRIPTCOLSCHEMA", "TOK_VALIDATE", "TOK_VALUES_TABLE", "TOK_VALUE_ROW", "TOK_VARCHAR", "TOK_VIEWPARTCOLS", "TOK_VIRTUAL_TABLE", "TOK_VIRTUAL_TABREF", "TOK_WHERE", "TOK_WINDOWDEF", "TOK_WINDOWRANGE", "TOK_WINDOWSPEC", "TOK_WINDOWVALUES", "1035"
    };

    public static final int EOF=-1;
    public static final int AMPERSAND=4;
    public static final int BITWISEOR=5;
    public static final int BITWISEXOR=6;
    public static final int BigintLiteral=7;
    public static final int ByteLengthLiteral=8;
    public static final int COLON=9;
    public static final int COMMA=10;
    public static final int COMMENT=11;
    public static final int CONCATENATE=12;
    public static final int CharSetLiteral=13;
    public static final int CharSetName=14;
    public static final int DIV=15;
    public static final int DIVIDE=16;
    public static final int DOLLAR=17;
    public static final int DOT=18;
    public static final int DecimalLiteral=19;
    public static final int Digit=20;
    public static final int EQUAL=21;
    public static final int EQUAL_NS=22;
    public static final int Exponent=23;
    public static final int GREATERTHAN=24;
    public static final int GREATERTHANOREQUALTO=25;
    public static final int HexDigit=26;
    public static final int Identifier=27;
    public static final int KW_ABORT=28;
    public static final int KW_ADD=29;
    public static final int KW_ADMIN=30;
    public static final int KW_AFTER=31;
    public static final int KW_ALL=32;
    public static final int KW_ALTER=33;
    public static final int KW_ANALYZE=34;
    public static final int KW_AND=35;
    public static final int KW_ARCHIVE=36;
    public static final int KW_ARRAY=37;
    public static final int KW_AS=38;
    public static final int KW_ASC=39;
    public static final int KW_AUTHORIZATION=40;
    public static final int KW_AUTOCOMMIT=41;
    public static final int KW_BEFORE=42;
    public static final int KW_BETWEEN=43;
    public static final int KW_BIGINT=44;
    public static final int KW_BINARY=45;
    public static final int KW_BOOLEAN=46;
    public static final int KW_BOTH=47;
    public static final int KW_BUCKET=48;
    public static final int KW_BUCKETS=49;
    public static final int KW_BY=50;
    public static final int KW_CACHE=51;
    public static final int KW_CASCADE=52;
    public static final int KW_CASE=53;
    public static final int KW_CAST=54;
    public static final int KW_CHANGE=55;
    public static final int KW_CHAR=56;
    public static final int KW_CLUSTER=57;
    public static final int KW_CLUSTERED=58;
    public static final int KW_CLUSTERSTATUS=59;
    public static final int KW_COLLECTION=60;
    public static final int KW_COLUMN=61;
    public static final int KW_COLUMNS=62;
    public static final int KW_COMMENT=63;
    public static final int KW_COMMIT=64;
    public static final int KW_COMPACT=65;
    public static final int KW_COMPACTIONS=66;
    public static final int KW_COMPUTE=67;
    public static final int KW_CONCATENATE=68;
    public static final int KW_CONF=69;
    public static final int KW_CONSTRAINT=70;
    public static final int KW_CONTINUE=71;
    public static final int KW_CREATE=72;
    public static final int KW_CROSS=73;
    public static final int KW_CUBE=74;
    public static final int KW_CURRENT=75;
    public static final int KW_CURRENT_DATE=76;
    public static final int KW_CURRENT_TIMESTAMP=77;
    public static final int KW_CURSOR=78;
    public static final int KW_DATA=79;
    public static final int KW_DATABASE=80;
    public static final int KW_DATABASES=81;
    public static final int KW_DATE=82;
    public static final int KW_DATETIME=83;
    public static final int KW_DAY=84;
    public static final int KW_DBPROPERTIES=85;
    public static final int KW_DECIMAL=86;
    public static final int KW_DEFERRED=87;
    public static final int KW_DEFINED=88;
    public static final int KW_DELETE=89;
    public static final int KW_DELIMITED=90;
    public static final int KW_DEPENDENCY=91;
    public static final int KW_DESC=92;
    public static final int KW_DESCRIBE=93;
    public static final int KW_DIRECTORIES=94;
    public static final int KW_DIRECTORY=95;
    public static final int KW_DISABLE=96;
    public static final int KW_DISTINCT=97;
    public static final int KW_DISTRIBUTE=98;
    public static final int KW_DOUBLE=99;
    public static final int KW_DOW=100;
    public static final int KW_DROP=101;
    public static final int KW_DUMP=102;
    public static final int KW_ELEM_TYPE=103;
    public static final int KW_ELSE=104;
    public static final int KW_ENABLE=105;
    public static final int KW_END=106;
    public static final int KW_ESCAPED=107;
    public static final int KW_EXCEPT=108;
    public static final int KW_EXCHANGE=109;
    public static final int KW_EXCLUSIVE=110;
    public static final int KW_EXISTS=111;
    public static final int KW_EXPLAIN=112;
    public static final int KW_EXPORT=113;
    public static final int KW_EXTENDED=114;
    public static final int KW_EXTERNAL=115;
    public static final int KW_EXTRACT=116;
    public static final int KW_FALSE=117;
    public static final int KW_FETCH=118;
    public static final int KW_FIELDS=119;
    public static final int KW_FILE=120;
    public static final int KW_FILEFORMAT=121;
    public static final int KW_FIRST=122;
    public static final int KW_FLOAT=123;
    public static final int KW_FLOOR=124;
    public static final int KW_FOLLOWING=125;
    public static final int KW_FOR=126;
    public static final int KW_FOREIGN=127;
    public static final int KW_FORMAT=128;
    public static final int KW_FORMATTED=129;
    public static final int KW_FROM=130;
    public static final int KW_FULL=131;
    public static final int KW_FUNCTION=132;
    public static final int KW_FUNCTIONS=133;
    public static final int KW_GRANT=134;
    public static final int KW_GROUP=135;
    public static final int KW_GROUPING=136;
    public static final int KW_HAVING=137;
    public static final int KW_HOUR=138;
    public static final int KW_IDXPROPERTIES=139;
    public static final int KW_IF=140;
    public static final int KW_IMPORT=141;
    public static final int KW_IN=142;
    public static final int KW_INDEX=143;
    public static final int KW_INDEXES=144;
    public static final int KW_INNER=145;
    public static final int KW_INPATH=146;
    public static final int KW_INPUTDRIVER=147;
    public static final int KW_INPUTFORMAT=148;
    public static final int KW_INSERT=149;
    public static final int KW_INT=150;
    public static final int KW_INTERSECT=151;
    public static final int KW_INTERVAL=152;
    public static final int KW_INTO=153;
    public static final int KW_IS=154;
    public static final int KW_ISOLATION=155;
    public static final int KW_ITEMS=156;
    public static final int KW_JAR=157;
    public static final int KW_JOIN=158;
    public static final int KW_KEY=159;
    public static final int KW_KEYS=160;
    public static final int KW_KEY_TYPE=161;
    public static final int KW_LAST=162;
    public static final int KW_LATERAL=163;
    public static final int KW_LEFT=164;
    public static final int KW_LESS=165;
    public static final int KW_LEVEL=166;
    public static final int KW_LIKE=167;
    public static final int KW_LIMIT=168;
    public static final int KW_LINES=169;
    public static final int KW_LOAD=170;
    public static final int KW_LOCAL=171;
    public static final int KW_LOCATION=172;
    public static final int KW_LOCK=173;
    public static final int KW_LOCKS=174;
    public static final int KW_LOGICAL=175;
    public static final int KW_LONG=176;
    public static final int KW_MACRO=177;
    public static final int KW_MAP=178;
    public static final int KW_MAPJOIN=179;
    public static final int KW_MATCHED=180;
    public static final int KW_MATERIALIZED=181;
    public static final int KW_MERGE=182;
    public static final int KW_METADATA=183;
    public static final int KW_MINUS=184;
    public static final int KW_MINUTE=185;
    public static final int KW_MONTH=186;
    public static final int KW_MORE=187;
    public static final int KW_MSCK=188;
    public static final int KW_NONE=189;
    public static final int KW_NORELY=190;
    public static final int KW_NOSCAN=191;
    public static final int KW_NOT=192;
    public static final int KW_NOVALIDATE=193;
    public static final int KW_NULL=194;
    public static final int KW_NULLS=195;
    public static final int KW_OF=196;
    public static final int KW_OFFSET=197;
    public static final int KW_ON=198;
    public static final int KW_ONLY=199;
    public static final int KW_OPTION=200;
    public static final int KW_OR=201;
    public static final int KW_ORDER=202;
    public static final int KW_OUT=203;
    public static final int KW_OUTER=204;
    public static final int KW_OUTPUTDRIVER=205;
    public static final int KW_OUTPUTFORMAT=206;
    public static final int KW_OVER=207;
    public static final int KW_OVERWRITE=208;
    public static final int KW_OWNER=209;
    public static final int KW_PARTIALSCAN=210;
    public static final int KW_PARTITION=211;
    public static final int KW_PARTITIONED=212;
    public static final int KW_PARTITIONS=213;
    public static final int KW_PERCENT=214;
    public static final int KW_PLUS=215;
    public static final int KW_PRECEDING=216;
    public static final int KW_PRECISION=217;
    public static final int KW_PRESERVE=218;
    public static final int KW_PRETTY=219;
    public static final int KW_PRIMARY=220;
    public static final int KW_PRINCIPALS=221;
    public static final int KW_PROCEDURE=222;
    public static final int KW_PURGE=223;
    public static final int KW_QUARTER=224;
    public static final int KW_RANGE=225;
    public static final int KW_READ=226;
    public static final int KW_READS=227;
    public static final int KW_REBUILD=228;
    public static final int KW_RECORDREADER=229;
    public static final int KW_RECORDWRITER=230;
    public static final int KW_REDUCE=231;
    public static final int KW_REFERENCES=232;
    public static final int KW_REGEXP=233;
    public static final int KW_RELOAD=234;
    public static final int KW_RELY=235;
    public static final int KW_RENAME=236;
    public static final int KW_REPAIR=237;
    public static final int KW_REPL=238;
    public static final int KW_REPLACE=239;
    public static final int KW_REPLICATION=240;
    public static final int KW_RESTRICT=241;
    public static final int KW_REVOKE=242;
    public static final int KW_REWRITE=243;
    public static final int KW_RIGHT=244;
    public static final int KW_RLIKE=245;
    public static final int KW_ROLE=246;
    public static final int KW_ROLES=247;
    public static final int KW_ROLLBACK=248;
    public static final int KW_ROLLUP=249;
    public static final int KW_ROW=250;
    public static final int KW_ROWS=251;
    public static final int KW_SCHEMA=252;
    public static final int KW_SCHEMAS=253;
    public static final int KW_SECOND=254;
    public static final int KW_SELECT=255;
    public static final int KW_SEMI=256;
    public static final int KW_SERDE=257;
    public static final int KW_SERDEPROPERTIES=258;
    public static final int KW_SERVER=259;
    public static final int KW_SET=260;
    public static final int KW_SETS=261;
    public static final int KW_SHARED=262;
    public static final int KW_SHOW=263;
    public static final int KW_SHOW_DATABASE=264;
    public static final int KW_SKEWED=265;
    public static final int KW_SMALLINT=266;
    public static final int KW_SNAPSHOT=267;
    public static final int KW_SORT=268;
    public static final int KW_SORTED=269;
    public static final int KW_SSL=270;
    public static final int KW_START=271;
    public static final int KW_STATISTICS=272;
    public static final int KW_STATUS=273;
    public static final int KW_STORED=274;
    public static final int KW_STREAMTABLE=275;
    public static final int KW_STRING=276;
    public static final int KW_STRUCT=277;
    public static final int KW_TABLE=278;
    public static final int KW_TABLES=279;
    public static final int KW_TABLESAMPLE=280;
    public static final int KW_TBLPROPERTIES=281;
    public static final int KW_TEMPORARY=282;
    public static final int KW_TERMINATED=283;
    public static final int KW_THEN=284;
    public static final int KW_TIMESTAMP=285;
    public static final int KW_TINYINT=286;
    public static final int KW_TO=287;
    public static final int KW_TOUCH=288;
    public static final int KW_TRANSACTION=289;
    public static final int KW_TRANSACTIONS=290;
    public static final int KW_TRANSFORM=291;
    public static final int KW_TRIGGER=292;
    public static final int KW_TRUE=293;
    public static final int KW_TRUNCATE=294;
    public static final int KW_UNARCHIVE=295;
    public static final int KW_UNBOUNDED=296;
    public static final int KW_UNDO=297;
    public static final int KW_UNION=298;
    public static final int KW_UNIONTYPE=299;
    public static final int KW_UNIQUEJOIN=300;
    public static final int KW_UNLOCK=301;
    public static final int KW_UNSET=302;
    public static final int KW_UNSIGNED=303;
    public static final int KW_UPDATE=304;
    public static final int KW_URI=305;
    public static final int KW_USE=306;
    public static final int KW_USER=307;
    public static final int KW_USING=308;
    public static final int KW_UTC=309;
    public static final int KW_UTCTIMESTAMP=310;
    public static final int KW_VALIDATE=311;
    public static final int KW_VALUES=312;
    public static final int KW_VALUE_TYPE=313;
    public static final int KW_VARCHAR=314;
    public static final int KW_VIEW=315;
    public static final int KW_VIEWS=316;
    public static final int KW_WEEK=317;
    public static final int KW_WHEN=318;
    public static final int KW_WHERE=319;
    public static final int KW_WHILE=320;
    public static final int KW_WINDOW=321;
    public static final int KW_WITH=322;
    public static final int KW_WORK=323;
    public static final int KW_WRITE=324;
    public static final int KW_YEAR=325;
    public static final int LCURLY=326;
    public static final int LESSTHAN=327;
    public static final int LESSTHANOREQUALTO=328;
    public static final int LPAREN=329;
    public static final int LSQUARE=330;
    public static final int Letter=331;
    public static final int MINUS=332;
    public static final int MOD=333;
    public static final int NOTEQUAL=334;
    public static final int Number=335;
    public static final int PLUS=336;
    public static final int QUESTION=337;
    public static final int QuotedIdentifier=338;
    public static final int RCURLY=339;
    public static final int RPAREN=340;
    public static final int RSQUARE=341;
    public static final int RegexComponent=342;
    public static final int SEMICOLON=343;
    public static final int STAR=344;
    public static final int SmallintLiteral=345;
    public static final int StringLiteral=346;
    public static final int TILDE=347;
    public static final int TinyintLiteral=348;
    public static final int WS=349;
    public static final int KW_BATCH=382;
    public static final int KW_DAYOFWEEK=421;
    public static final int KW_HOLD_DDLTIME=471;
    public static final int KW_IGNORE=475;
    public static final int KW_NO_DROP=525;
    public static final int KW_OFFLINE=529;
    public static final int KW_PROTECTION=553;
    public static final int KW_READONLY=558;
    public static final int TOK_ABORT_TRANSACTIONS=671;
    public static final int TOK_ADMIN_OPTION_FOR=672;
    public static final int TOK_ALIASLIST=673;
    public static final int TOK_ALLCOLREF=674;
    public static final int TOK_ALTERDATABASE_OWNER=675;
    public static final int TOK_ALTERDATABASE_PROPERTIES=676;
    public static final int TOK_ALTERINDEX_PROPERTIES=677;
    public static final int TOK_ALTERINDEX_REBUILD=678;
    public static final int TOK_ALTERTABLE=679;
    public static final int TOK_ALTERTABLE_ADDCOLS=680;
    public static final int TOK_ALTERTABLE_ADDCONSTRAINT=681;
    public static final int TOK_ALTERTABLE_ADDPARTS=682;
    public static final int TOK_ALTERTABLE_ARCHIVE=683;
    public static final int TOK_ALTERTABLE_BUCKETS=684;
    public static final int TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION=685;
    public static final int TOK_ALTERTABLE_CLUSTER_SORT=686;
    public static final int TOK_ALTERTABLE_COMPACT=687;
    public static final int TOK_ALTERTABLE_DROPCONSTRAINT=688;
    public static final int TOK_ALTERTABLE_DROPPARTS=689;
    public static final int TOK_ALTERTABLE_DROPPROPERTIES=690;
    public static final int TOK_ALTERTABLE_EXCHANGEPARTITION=691;
    public static final int TOK_ALTERTABLE_FILEFORMAT=692;
    public static final int TOK_ALTERTABLE_LOCATION=693;
    public static final int TOK_ALTERTABLE_MERGEFILES=694;
    public static final int TOK_ALTERTABLE_PARTCOLTYPE=695;
    public static final int TOK_ALTERTABLE_PROPERTIES=696;
    public static final int TOK_ALTERTABLE_RENAME=697;
    public static final int TOK_ALTERTABLE_RENAMECOL=698;
    public static final int TOK_ALTERTABLE_RENAMEPART=699;
    public static final int TOK_ALTERTABLE_REPLACECOLS=700;
    public static final int TOK_ALTERTABLE_SERDEPROPERTIES=701;
    public static final int TOK_ALTERTABLE_SERIALIZER=702;
    public static final int TOK_ALTERTABLE_SKEWED=703;
    public static final int TOK_ALTERTABLE_SKEWED_LOCATION=704;
    public static final int TOK_ALTERTABLE_TOUCH=705;
    public static final int TOK_ALTERTABLE_UNARCHIVE=706;
    public static final int TOK_ALTERTABLE_UPDATECOLSTATS=707;
    public static final int TOK_ALTERTABLE_UPDATESTATS=708;
    public static final int TOK_ALTERVIEW=709;
    public static final int TOK_ALTERVIEW_ADDPARTS=710;
    public static final int TOK_ALTERVIEW_DROPPARTS=711;
    public static final int TOK_ALTERVIEW_DROPPROPERTIES=712;
    public static final int TOK_ALTERVIEW_PROPERTIES=713;
    public static final int TOK_ALTERVIEW_RENAME=714;
    public static final int TOK_ANALYZE=715;
    public static final int TOK_ANONYMOUS=716;
    public static final int TOK_ARCHIVE=717;
    public static final int TOK_BIGINT=718;
    public static final int TOK_BINARY=719;
    public static final int TOK_BOOLEAN=720;
    public static final int TOK_CACHE_METADATA=721;
    public static final int TOK_CASCADE=722;
    public static final int TOK_CHAR=723;
    public static final int TOK_CHARSETLITERAL=724;
    public static final int TOK_CLUSTERBY=725;
    public static final int TOK_COLTYPELIST=726;
    public static final int TOK_COL_NAME=727;
    public static final int TOK_COMMIT=728;
    public static final int TOK_CREATEDATABASE=729;
    public static final int TOK_CREATEFUNCTION=730;
    public static final int TOK_CREATEINDEX=731;
    public static final int TOK_CREATEINDEX_INDEXTBLNAME=732;
    public static final int TOK_CREATEMACRO=733;
    public static final int TOK_CREATEROLE=734;
    public static final int TOK_CREATETABLE=735;
    public static final int TOK_CREATEVIEW=736;
    public static final int TOK_CROSSJOIN=737;
    public static final int TOK_CTE=738;
    public static final int TOK_CUBE_GROUPBY=739;
    public static final int TOK_DATABASECOMMENT=740;
    public static final int TOK_DATABASELOCATION=741;
    public static final int TOK_DATABASEPROPERTIES=742;
    public static final int TOK_DATE=743;
    public static final int TOK_DATELITERAL=744;
    public static final int TOK_DATETIME=745;
    public static final int TOK_DBPROPLIST=746;
    public static final int TOK_DB_TYPE=747;
    public static final int TOK_DECIMAL=748;
    public static final int TOK_DEFERRED_REBUILDINDEX=749;
    public static final int TOK_DELETE=750;
    public static final int TOK_DELETE_FROM=751;
    public static final int TOK_DESCDATABASE=752;
    public static final int TOK_DESCFUNCTION=753;
    public static final int TOK_DESCTABLE=754;
    public static final int TOK_DESTINATION=755;
    public static final int TOK_DIR=756;
    public static final int TOK_DISABLE=757;
    public static final int TOK_DISTRIBUTEBY=758;
    public static final int TOK_DOUBLE=759;
    public static final int TOK_DROPDATABASE=760;
    public static final int TOK_DROPFUNCTION=761;
    public static final int TOK_DROPINDEX=762;
    public static final int TOK_DROPMACRO=763;
    public static final int TOK_DROPROLE=764;
    public static final int TOK_DROPTABLE=765;
    public static final int TOK_DROPVIEW=766;
    public static final int TOK_ENABLE=767;
    public static final int TOK_EXCEPTALL=768;
    public static final int TOK_EXCEPTDISTINCT=769;
    public static final int TOK_EXPLAIN=770;
    public static final int TOK_EXPLAIN_SQ_REWRITE=771;
    public static final int TOK_EXPLIST=772;
    public static final int TOK_EXPORT=773;
    public static final int TOK_FALSE=774;
    public static final int TOK_FILE=775;
    public static final int TOK_FILEFORMAT_GENERIC=776;
    public static final int TOK_FLOAT=777;
    public static final int TOK_FOREIGN_KEY=778;
    public static final int TOK_FROM=779;
    public static final int TOK_FULLOUTERJOIN=780;
    public static final int TOK_FUNCTION=781;
    public static final int TOK_FUNCTIONDI=782;
    public static final int TOK_FUNCTIONSTAR=783;
    public static final int TOK_GRANT=784;
    public static final int TOK_GRANT_OPTION_FOR=785;
    public static final int TOK_GRANT_ROLE=786;
    public static final int TOK_GRANT_WITH_ADMIN_OPTION=787;
    public static final int TOK_GRANT_WITH_OPTION=788;
    public static final int TOK_GROUP=789;
    public static final int TOK_GROUPBY=790;
    public static final int TOK_GROUPING_SETS=791;
    public static final int TOK_GROUPING_SETS_EXPRESSION=792;
    public static final int TOK_HAVING=793;
    public static final int TOK_HINT=794;
    public static final int TOK_HINTARGLIST=795;
    public static final int TOK_HINTLIST=796;
    public static final int TOK_IFEXISTS=797;
    public static final int TOK_IFNOTEXISTS=798;
    public static final int TOK_IMPORT=799;
    public static final int TOK_INDEXCOMMENT=800;
    public static final int TOK_INDEXPROPERTIES=801;
    public static final int TOK_INDEXPROPLIST=802;
    public static final int TOK_INSERT=803;
    public static final int TOK_INSERT_INTO=804;
    public static final int TOK_INT=805;
    public static final int TOK_INTERSECTALL=806;
    public static final int TOK_INTERSECTDISTINCT=807;
    public static final int TOK_INTERVAL_DAY_LITERAL=808;
    public static final int TOK_INTERVAL_DAY_TIME=809;
    public static final int TOK_INTERVAL_DAY_TIME_LITERAL=810;
    public static final int TOK_INTERVAL_HOUR_LITERAL=811;
    public static final int TOK_INTERVAL_MINUTE_LITERAL=812;
    public static final int TOK_INTERVAL_MONTH_LITERAL=813;
    public static final int TOK_INTERVAL_SECOND_LITERAL=814;
    public static final int TOK_INTERVAL_YEAR_LITERAL=815;
    public static final int TOK_INTERVAL_YEAR_MONTH=816;
    public static final int TOK_INTERVAL_YEAR_MONTH_LITERAL=817;
    public static final int TOK_ISNOTNULL=818;
    public static final int TOK_ISNULL=819;
    public static final int TOK_ISOLATION_LEVEL=820;
    public static final int TOK_ISOLATION_SNAPSHOT=821;
    public static final int TOK_JAR=822;
    public static final int TOK_JOIN=823;
    public static final int TOK_LATERAL_VIEW=824;
    public static final int TOK_LATERAL_VIEW_OUTER=825;
    public static final int TOK_LEFTOUTERJOIN=826;
    public static final int TOK_LEFTSEMIJOIN=827;
    public static final int TOK_LENGTH=828;
    public static final int TOK_LIKETABLE=829;
    public static final int TOK_LIMIT=830;
    public static final int TOK_LIST=831;
    public static final int TOK_LOAD=832;
    public static final int TOK_LOCKDB=833;
    public static final int TOK_LOCKTABLE=834;
    public static final int TOK_MAP=835;
    public static final int TOK_MAPJOIN=836;
    public static final int TOK_MATCHED=837;
    public static final int TOK_MERGE=838;
    public static final int TOK_METADATA=839;
    public static final int TOK_MSCK=840;
    public static final int TOK_NORELY=841;
    public static final int TOK_NOT_CLUSTERED=842;
    public static final int TOK_NOT_MATCHED=843;
    public static final int TOK_NOT_SORTED=844;
    public static final int TOK_NOVALIDATE=845;
    public static final int TOK_NO_DROP=846;
    public static final int TOK_NULL=847;
    public static final int TOK_NULLS_FIRST=848;
    public static final int TOK_NULLS_LAST=849;
    public static final int TOK_OFFLINE=850;
    public static final int TOK_OFFSET=851;
    public static final int TOK_OP_ADD=852;
    public static final int TOK_OP_AND=853;
    public static final int TOK_OP_BITAND=854;
    public static final int TOK_OP_BITNOT=855;
    public static final int TOK_OP_BITOR=856;
    public static final int TOK_OP_BITXOR=857;
    public static final int TOK_OP_DIV=858;
    public static final int TOK_OP_EQ=859;
    public static final int TOK_OP_GE=860;
    public static final int TOK_OP_GT=861;
    public static final int TOK_OP_LE=862;
    public static final int TOK_OP_LIKE=863;
    public static final int TOK_OP_LT=864;
    public static final int TOK_OP_MOD=865;
    public static final int TOK_OP_MUL=866;
    public static final int TOK_OP_NE=867;
    public static final int TOK_OP_NOT=868;
    public static final int TOK_OP_OR=869;
    public static final int TOK_OP_SUB=870;
    public static final int TOK_ORDERBY=871;
    public static final int TOK_ORREPLACE=872;
    public static final int TOK_PARTITIONINGSPEC=873;
    public static final int TOK_PARTITIONLOCATION=874;
    public static final int TOK_PARTSPEC=875;
    public static final int TOK_PARTVAL=876;
    public static final int TOK_PERCENT=877;
    public static final int TOK_PRIMARY_KEY=878;
    public static final int TOK_PRINCIPAL_NAME=879;
    public static final int TOK_PRIVILEGE=880;
    public static final int TOK_PRIVILEGE_LIST=881;
    public static final int TOK_PRIV_ALL=882;
    public static final int TOK_PRIV_ALTER_DATA=883;
    public static final int TOK_PRIV_ALTER_METADATA=884;
    public static final int TOK_PRIV_CREATE=885;
    public static final int TOK_PRIV_DELETE=886;
    public static final int TOK_PRIV_DROP=887;
    public static final int TOK_PRIV_INDEX=888;
    public static final int TOK_PRIV_INSERT=889;
    public static final int TOK_PRIV_LOCK=890;
    public static final int TOK_PRIV_OBJECT=891;
    public static final int TOK_PRIV_OBJECT_COL=892;
    public static final int TOK_PRIV_SELECT=893;
    public static final int TOK_PRIV_SHOW_DATABASE=894;
    public static final int TOK_PTBLFUNCTION=895;
    public static final int TOK_QUERY=896;
    public static final int TOK_READONLY=897;
    public static final int TOK_RECORDREADER=898;
    public static final int TOK_RECORDWRITER=899;
    public static final int TOK_RELOADFUNCTION=900;
    public static final int TOK_RELY=901;
    public static final int TOK_REPLICATION=902;
    public static final int TOK_REPL_DUMP=903;
    public static final int TOK_REPL_LOAD=904;
    public static final int TOK_REPL_STATUS=905;
    public static final int TOK_RESOURCE_ALL=906;
    public static final int TOK_RESOURCE_LIST=907;
    public static final int TOK_RESOURCE_URI=908;
    public static final int TOK_RESTRICT=909;
    public static final int TOK_REVOKE=910;
    public static final int TOK_REVOKE_ROLE=911;
    public static final int TOK_RIGHTOUTERJOIN=912;
    public static final int TOK_ROLE=913;
    public static final int TOK_ROLLBACK=914;
    public static final int TOK_ROLLUP_GROUPBY=915;
    public static final int TOK_ROWCOUNT=916;
    public static final int TOK_SELECT=917;
    public static final int TOK_SELECTDI=918;
    public static final int TOK_SELEXPR=919;
    public static final int TOK_SERDE=920;
    public static final int TOK_SERDENAME=921;
    public static final int TOK_SERDEPROPS=922;
    public static final int TOK_SERVER_TYPE=923;
    public static final int TOK_SETCOLREF=924;
    public static final int TOK_SET_AUTOCOMMIT=925;
    public static final int TOK_SET_COLUMNS_CLAUSE=926;
    public static final int TOK_SHOWCOLUMNS=927;
    public static final int TOK_SHOWCONF=928;
    public static final int TOK_SHOWDATABASES=929;
    public static final int TOK_SHOWDBLOCKS=930;
    public static final int TOK_SHOWFUNCTIONS=931;
    public static final int TOK_SHOWINDEXES=932;
    public static final int TOK_SHOWLOCKS=933;
    public static final int TOK_SHOWPARTITIONS=934;
    public static final int TOK_SHOWTABLES=935;
    public static final int TOK_SHOW_COMPACTIONS=936;
    public static final int TOK_SHOW_CREATEDATABASE=937;
    public static final int TOK_SHOW_CREATETABLE=938;
    public static final int TOK_SHOW_GRANT=939;
    public static final int TOK_SHOW_ROLES=940;
    public static final int TOK_SHOW_ROLE_GRANT=941;
    public static final int TOK_SHOW_ROLE_PRINCIPALS=942;
    public static final int TOK_SHOW_SET_ROLE=943;
    public static final int TOK_SHOW_TABLESTATUS=944;
    public static final int TOK_SHOW_TBLPROPERTIES=945;
    public static final int TOK_SHOW_TRANSACTIONS=946;
    public static final int TOK_SKEWED_LOCATIONS=947;
    public static final int TOK_SKEWED_LOCATION_LIST=948;
    public static final int TOK_SKEWED_LOCATION_MAP=949;
    public static final int TOK_SMALLINT=950;
    public static final int TOK_SORTBY=951;
    public static final int TOK_START_TRANSACTION=952;
    public static final int TOK_STORAGEHANDLER=953;
    public static final int TOK_STOREDASDIRS=954;
    public static final int TOK_STREAMTABLE=955;
    public static final int TOK_STRING=956;
    public static final int TOK_STRINGLITERALSEQUENCE=957;
    public static final int TOK_STRUCT=958;
    public static final int TOK_SUBQUERY=959;
    public static final int TOK_SUBQUERY_EXPR=960;
    public static final int TOK_SUBQUERY_OP=961;
    public static final int TOK_SUBQUERY_OP_NOTEXISTS=962;
    public static final int TOK_SUBQUERY_OP_NOTIN=963;
    public static final int TOK_SWITCHDATABASE=964;
    public static final int TOK_TAB=965;
    public static final int TOK_TABALIAS=966;
    public static final int TOK_TABCOL=967;
    public static final int TOK_TABCOLLIST=968;
    public static final int TOK_TABCOLNAME=969;
    public static final int TOK_TABCOLVALUE=970;
    public static final int TOK_TABCOLVALUES=971;
    public static final int TOK_TABCOLVALUE_PAIR=972;
    public static final int TOK_TABLEBUCKETSAMPLE=973;
    public static final int TOK_TABLECOMMENT=974;
    public static final int TOK_TABLEFILEFORMAT=975;
    public static final int TOK_TABLELOCATION=976;
    public static final int TOK_TABLEPARTCOLS=977;
    public static final int TOK_TABLEPROPERTIES=978;
    public static final int TOK_TABLEPROPERTY=979;
    public static final int TOK_TABLEPROPLIST=980;
    public static final int TOK_TABLEROWFORMAT=981;
    public static final int TOK_TABLEROWFORMATCOLLITEMS=982;
    public static final int TOK_TABLEROWFORMATFIELD=983;
    public static final int TOK_TABLEROWFORMATLINES=984;
    public static final int TOK_TABLEROWFORMATMAPKEYS=985;
    public static final int TOK_TABLEROWFORMATNULL=986;
    public static final int TOK_TABLESERIALIZER=987;
    public static final int TOK_TABLESKEWED=988;
    public static final int TOK_TABLESPLITSAMPLE=989;
    public static final int TOK_TABLE_OR_COL=990;
    public static final int TOK_TABLE_PARTITION=991;
    public static final int TOK_TABLE_TYPE=992;
    public static final int TOK_TABNAME=993;
    public static final int TOK_TABREF=994;
    public static final int TOK_TABSORTCOLNAMEASC=995;
    public static final int TOK_TABSORTCOLNAMEDESC=996;
    public static final int TOK_TABSRC=997;
    public static final int TOK_TABTYPE=998;
    public static final int TOK_TEMPORARY=999;
    public static final int TOK_TIMESTAMP=1000;
    public static final int TOK_TIMESTAMPLITERAL=1001;
    public static final int TOK_TINYINT=1002;
    public static final int TOK_TMP_FILE=1003;
    public static final int TOK_TO=1004;
    public static final int TOK_TRANSFORM=1005;
    public static final int TOK_TRUE=1006;
    public static final int TOK_TRUNCATETABLE=1007;
    public static final int TOK_TXN_ACCESS_MODE=1008;
    public static final int TOK_TXN_READ_ONLY=1009;
    public static final int TOK_TXN_READ_WRITE=1010;
    public static final int TOK_UNIONALL=1011;
    public static final int TOK_UNIONDISTINCT=1012;
    public static final int TOK_UNIONTYPE=1013;
    public static final int TOK_UNIQUEJOIN=1014;
    public static final int TOK_UNLOCKDB=1015;
    public static final int TOK_UNLOCKTABLE=1016;
    public static final int TOK_UPDATE=1017;
    public static final int TOK_UPDATE_TABLE=1018;
    public static final int TOK_URI_TYPE=1019;
    public static final int TOK_USER=1020;
    public static final int TOK_USERSCRIPTCOLNAMES=1021;
    public static final int TOK_USERSCRIPTCOLSCHEMA=1022;
    public static final int TOK_VALIDATE=1023;
    public static final int TOK_VALUES_TABLE=1024;
    public static final int TOK_VALUE_ROW=1025;
    public static final int TOK_VARCHAR=1026;
    public static final int TOK_VIEWPARTCOLS=1027;
    public static final int TOK_VIRTUAL_TABLE=1028;
    public static final int TOK_VIRTUAL_TABREF=1029;
    public static final int TOK_WHERE=1030;
    public static final int TOK_WINDOWDEF=1031;
    public static final int TOK_WINDOWRANGE=1032;
    public static final int TOK_WINDOWSPEC=1033;
    public static final int TOK_WINDOWVALUES=1034;

    // delegates
    public HiveParser_SelectClauseParser gSelectClauseParser;
    public HiveParser_FromClauseParser gFromClauseParser;
    public HiveParser_IdentifiersParser gIdentifiersParser;
    public Parser[] getDelegates() {
        return new Parser[] {gSelectClauseParser, gFromClauseParser, gIdentifiersParser};
    }

    // delegators


    public HiveParser(TokenStream input) {
        this(input, new RecognizerSharedState());
    }
    public HiveParser(TokenStream input, RecognizerSharedState state) {
        super(input, state);
        gSelectClauseParser = new HiveParser_SelectClauseParser(input, state, this);
        gFromClauseParser = new HiveParser_FromClauseParser(input, state, this);
        gIdentifiersParser = new HiveParser_IdentifiersParser(input, state, this);
    }

protected TreeAdaptor adaptor = new CommonTreeAdaptor();

public void setTreeAdaptor(TreeAdaptor adaptor) {
    this.adaptor = adaptor;
    gSelectClauseParser.setTreeAdaptor(this.adaptor);gFromClauseParser.setTreeAdaptor(this.adaptor);gIdentifiersParser.setTreeAdaptor(this.adaptor);
}
public TreeAdaptor getTreeAdaptor() {
    return adaptor;
}
    public String[] getTokenNames() { return HiveParser.tokenNames; }
    public String getGrammarFileName() { return "org/apache/hadoop/hive/ql/parse/HiveParser.g"; }


      ArrayList<ParseError> errors = new ArrayList<ParseError>();
      Stack msgs = new Stack<String>();

      private static HashMap<String, String> xlateMap;
      static {
        //this is used to support auto completion in CLI
        xlateMap = new HashMap<String, String>();

        // Keywords
        xlateMap.put("KW_TRUE", "TRUE");
        xlateMap.put("KW_FALSE", "FALSE");
        xlateMap.put("KW_ALL", "ALL");
        xlateMap.put("KW_NONE", "NONE");
        xlateMap.put("KW_AND", "AND");
        xlateMap.put("KW_OR", "OR");
        xlateMap.put("KW_NOT", "NOT");
        xlateMap.put("KW_LIKE", "LIKE");

        xlateMap.put("KW_ASC", "ASC");
        xlateMap.put("KW_DESC", "DESC");
        xlateMap.put("KW_NULLS", "NULLS");
        xlateMap.put("KW_LAST", "LAST");
        xlateMap.put("KW_ORDER", "ORDER");
        xlateMap.put("KW_BY", "BY");
        xlateMap.put("KW_GROUP", "GROUP");
        xlateMap.put("KW_WHERE", "WHERE");
        xlateMap.put("KW_FROM", "FROM");
        xlateMap.put("KW_AS", "AS");
        xlateMap.put("KW_SELECT", "SELECT");
        xlateMap.put("KW_DISTINCT", "DISTINCT");
        xlateMap.put("KW_INSERT", "INSERT");
        xlateMap.put("KW_OVERWRITE", "OVERWRITE");
        xlateMap.put("KW_OUTER", "OUTER");
        xlateMap.put("KW_JOIN", "JOIN");
        xlateMap.put("KW_LEFT", "LEFT");
        xlateMap.put("KW_RIGHT", "RIGHT");
        xlateMap.put("KW_FULL", "FULL");
        xlateMap.put("KW_ON", "ON");
        xlateMap.put("KW_PARTITION", "PARTITION");
        xlateMap.put("KW_PARTITIONS", "PARTITIONS");
        xlateMap.put("KW_TABLE", "TABLE");
        xlateMap.put("KW_TABLES", "TABLES");
        xlateMap.put("KW_TBLPROPERTIES", "TBLPROPERTIES");
        xlateMap.put("KW_SHOW", "SHOW");
        xlateMap.put("KW_MSCK", "MSCK");
        xlateMap.put("KW_DIRECTORY", "DIRECTORY");
        xlateMap.put("KW_LOCAL", "LOCAL");
        xlateMap.put("KW_TRANSFORM", "TRANSFORM");
        xlateMap.put("KW_USING", "USING");
        xlateMap.put("KW_CLUSTER", "CLUSTER");
        xlateMap.put("KW_DISTRIBUTE", "DISTRIBUTE");
        xlateMap.put("KW_SORT", "SORT");
        xlateMap.put("KW_UNION", "UNION");
        xlateMap.put("KW_INTERSECT", "INTERSECT");
        xlateMap.put("KW_EXCEPT", "EXCEPT");
        xlateMap.put("KW_LOAD", "LOAD");
        xlateMap.put("KW_DATA", "DATA");
        xlateMap.put("KW_INPATH", "INPATH");
        xlateMap.put("KW_IS", "IS");
        xlateMap.put("KW_NULL", "NULL");
        xlateMap.put("KW_CREATE", "CREATE");
        xlateMap.put("KW_EXTERNAL", "EXTERNAL");
        xlateMap.put("KW_ALTER", "ALTER");
        xlateMap.put("KW_DESCRIBE", "DESCRIBE");
        xlateMap.put("KW_DROP", "DROP");
        xlateMap.put("KW_RENAME", "RENAME");
        xlateMap.put("KW_TO", "TO");
        xlateMap.put("KW_COMMENT", "COMMENT");
        xlateMap.put("KW_BOOLEAN", "BOOLEAN");
        xlateMap.put("KW_TINYINT", "TINYINT");
        xlateMap.put("KW_SMALLINT", "SMALLINT");
        xlateMap.put("KW_INT", "INT");
        xlateMap.put("KW_BIGINT", "BIGINT");
        xlateMap.put("KW_FLOAT", "FLOAT");
        xlateMap.put("KW_DOUBLE", "DOUBLE");
        xlateMap.put("KW_DATE", "DATE");
        xlateMap.put("KW_DATETIME", "DATETIME");
        xlateMap.put("KW_TIMESTAMP", "TIMESTAMP");
        xlateMap.put("KW_STRING", "STRING");
        xlateMap.put("KW_BINARY", "BINARY");
        xlateMap.put("KW_ARRAY", "ARRAY");
        xlateMap.put("KW_MAP", "MAP");
        xlateMap.put("KW_REDUCE", "REDUCE");
        xlateMap.put("KW_PARTITIONED", "PARTITIONED");
        xlateMap.put("KW_CLUSTERED", "CLUSTERED");
        xlateMap.put("KW_SORTED", "SORTED");
        xlateMap.put("KW_INTO", "INTO");
        xlateMap.put("KW_BUCKETS", "BUCKETS");
        xlateMap.put("KW_ROW", "ROW");
        xlateMap.put("KW_FORMAT", "FORMAT");
        xlateMap.put("KW_DELIMITED", "DELIMITED");
        xlateMap.put("KW_FIELDS", "FIELDS");
        xlateMap.put("KW_TERMINATED", "TERMINATED");
        xlateMap.put("KW_COLLECTION", "COLLECTION");
        xlateMap.put("KW_ITEMS", "ITEMS");
        xlateMap.put("KW_KEYS", "KEYS");
        xlateMap.put("KW_KEY_TYPE", "$KEY$");
        xlateMap.put("KW_LINES", "LINES");
        xlateMap.put("KW_STORED", "STORED");
        xlateMap.put("KW_SEQUENCEFILE", "SEQUENCEFILE");
        xlateMap.put("KW_TEXTFILE", "TEXTFILE");
        xlateMap.put("KW_INPUTFORMAT", "INPUTFORMAT");
        xlateMap.put("KW_OUTPUTFORMAT", "OUTPUTFORMAT");
        xlateMap.put("KW_LOCATION", "LOCATION");
        xlateMap.put("KW_TABLESAMPLE", "TABLESAMPLE");
        xlateMap.put("KW_BUCKET", "BUCKET");
        xlateMap.put("KW_OUT", "OUT");
        xlateMap.put("KW_OF", "OF");
        xlateMap.put("KW_CAST", "CAST");
        xlateMap.put("KW_ADD", "ADD");
        xlateMap.put("KW_REPLACE", "REPLACE");
        xlateMap.put("KW_COLUMNS", "COLUMNS");
        xlateMap.put("KW_RLIKE", "RLIKE");
        xlateMap.put("KW_REGEXP", "REGEXP");
        xlateMap.put("KW_TEMPORARY", "TEMPORARY");
        xlateMap.put("KW_FUNCTION", "FUNCTION");
        xlateMap.put("KW_EXPLAIN", "EXPLAIN");
        xlateMap.put("KW_EXTENDED", "EXTENDED");
        xlateMap.put("KW_SERDE", "SERDE");
        xlateMap.put("KW_WITH", "WITH");
        xlateMap.put("KW_SERDEPROPERTIES", "SERDEPROPERTIES");
        xlateMap.put("KW_LIMIT", "LIMIT");
        xlateMap.put("KW_OFFSET", "OFFSET");
        xlateMap.put("KW_SET", "SET");
        xlateMap.put("KW_PROPERTIES", "TBLPROPERTIES");
        xlateMap.put("KW_VALUE_TYPE", "$VALUE$");
        xlateMap.put("KW_ELEM_TYPE", "$ELEM$");
        xlateMap.put("KW_DEFINED", "DEFINED");
        xlateMap.put("KW_SUBQUERY", "SUBQUERY");
        xlateMap.put("KW_REWRITE", "REWRITE");
        xlateMap.put("KW_UPDATE", "UPDATE");
        xlateMap.put("KW_VALUES", "VALUES");
        xlateMap.put("KW_PURGE", "PURGE");
        xlateMap.put("KW_PRIMARY", "PRIMARY");
        xlateMap.put("KW_FOREIGN", "FOREIGN");
        xlateMap.put("KW_KEY", "KEY");
        xlateMap.put("KW_REFERENCES", "REFERENCES");
        xlateMap.put("KW_CONSTRAINT", "CONSTRAINT");
        xlateMap.put("KW_ENABLE", "ENABLE");
        xlateMap.put("KW_DISABLE", "DISABLE");
        xlateMap.put("KW_VALIDATE", "VALIDATE");
        xlateMap.put("KW_NOVALIDATE", "NOVALIDATE");
        xlateMap.put("KW_RELY", "RELY");
        xlateMap.put("KW_NORELY", "NORELY");
        xlateMap.put("KW_ABORT", "ABORT");
        xlateMap.put("KW_TRANSACTIONS", "TRANSACTIONS");

        // Operators
        xlateMap.put("DOT", ".");
        xlateMap.put("COLON", ":");
        xlateMap.put("COMMA", ",");
        xlateMap.put("SEMICOLON", ");");

        xlateMap.put("LPAREN", "(");
        xlateMap.put("RPAREN", ")");
        xlateMap.put("LSQUARE", "[");
        xlateMap.put("RSQUARE", "]");

        xlateMap.put("EQUAL", "=");
        xlateMap.put("NOTEQUAL", "<>");
        xlateMap.put("EQUAL_NS", "<=>");
        xlateMap.put("LESSTHANOREQUALTO", "<=");
        xlateMap.put("LESSTHAN", "<");
        xlateMap.put("GREATERTHANOREQUALTO", ">=");
        xlateMap.put("GREATERTHAN", ">");

        xlateMap.put("DIVIDE", "/");
        xlateMap.put("PLUS", "+");
        xlateMap.put("MINUS", "-");
        xlateMap.put("STAR", "*");
        xlateMap.put("MOD", "%");

        xlateMap.put("AMPERSAND", "&");
        xlateMap.put("TILDE", "~");
        xlateMap.put("BITWISEOR", "|");
        xlateMap.put("BITWISEXOR", "^");
        xlateMap.put("CharSetLiteral", "\\'");
      }

      public static Collection<String> getKeywords() {
        return xlateMap.values();
      }

      private static String xlate(String name) {

        String ret = xlateMap.get(name);
        if (ret == null) {
          ret = name;
        }

        return ret;
      }

      @Override
      public Object recoverFromMismatchedSet(IntStream input,
          RecognitionException re, BitSet follow) throws RecognitionException {
        throw re;
      }

      @Override
      public void displayRecognitionError(String[] tokenNames,
          RecognitionException e) {
        errors.add(new ParseError(this, e, tokenNames));
      }

      @Override
      public String getErrorHeader(RecognitionException e) {
        String header = null;
        if (e.charPositionInLine < 0 && input.LT(-1) != null) {
          Token t = input.LT(-1);
          header = "line " + t.getLine() + ":" + t.getCharPositionInLine();
        } else {
          header = super.getErrorHeader(e);
        }

        return header;
      }
      
      @Override
      public String getErrorMessage(RecognitionException e, String[] tokenNames) {
        String msg = null;

        // Translate the token names to something that the user can understand
        String[] xlateNames = new String[tokenNames.length];
        for (int i = 0; i < tokenNames.length; ++i) {
          xlateNames[i] = HiveParser.xlate(tokenNames[i]);
        }

        if (e instanceof NoViableAltException) {
          @SuppressWarnings("unused")
          NoViableAltException nvae = (NoViableAltException) e;
          // for development, can add
          // "decision=<<"+nvae.grammarDecisionDescription+">>"
          // and "(decision="+nvae.decisionNumber+") and
          // "state "+nvae.stateNumber
          msg = "cannot recognize input near"
                  + (input.LT(1) != null ? " " + getTokenErrorDisplay(input.LT(1)) : "")
                  + (input.LT(2) != null ? " " + getTokenErrorDisplay(input.LT(2)) : "")
                  + (input.LT(3) != null ? " " + getTokenErrorDisplay(input.LT(3)) : "");
        } else if (e instanceof MismatchedTokenException) {
          MismatchedTokenException mte = (MismatchedTokenException) e;
          msg = super.getErrorMessage(e, xlateNames) + (input.LT(-1) == null ? "":" near '" + input.LT(-1).getText()) + "'";
        } else if (e instanceof FailedPredicateException) {
          FailedPredicateException fpe = (FailedPredicateException) e;
          msg = "Failed to recognize predicate '" + fpe.token.getText() + "'. Failed rule: '" + fpe.ruleName + "'";
        } else {
          msg = super.getErrorMessage(e, xlateNames);
        }

        if (msgs.size() > 0) {
          msg = msg + " in " + msgs.peek();
        }
        return msg;
      }
      
      public void pushMsg(String msg, RecognizerSharedState state) {
        // ANTLR generated code does not wrap the @init code wit this backtracking check,
        //  even if the matching @after has it. If we have parser rules with that are doing
        // some lookahead with syntactic predicates this can cause the push() and pop() calls
        // to become unbalanced, so make sure both push/pop check the backtracking state.
        if (state.backtracking == 0) {
          msgs.push(msg);
        }
      }

      public void popMsg(RecognizerSharedState state) {
        if (state.backtracking == 0) {
          Object o = msgs.pop();
        }
      }

      // counter to generate unique union aliases
      private int aliasCounter;
      private String generateUnionAlias() {
        return "_u" + (++aliasCounter);
      }
      private char [] excludedCharForColumnName = {'.', ':'};
      private boolean containExcludedCharForCreateTableColumnName(String input) {
        for(char c : excludedCharForColumnName) {
          if(input.indexOf(c)>-1) {
            return true;
          }
        }
        return false;
      }
      private CommonTree throwSetOpException() throws RecognitionException {
        throw new FailedPredicateException(input, "orderByClause clusterByClause distributeByClause sortByClause limitClause can only be applied to the whole union.", "");
      }
      private CommonTree throwColumnNameException() throws RecognitionException {
        throw new FailedPredicateException(input, Arrays.toString(excludedCharForColumnName) + " can not be used in column name in create table statement.", "");
      }
      private Configuration hiveConf;
      public void setHiveConf(Configuration hiveConf) {
        this.hiveConf = hiveConf;
      }
      protected boolean useSQL11ReservedKeywordsForIdentifier() {
        if(hiveConf==null){
          return false;
        }
        return !HiveConf.getBoolVar(hiveConf, HiveConf.ConfVars.HIVE_SUPPORT_SQL11_RESERVED_KEYWORDS);
      }


    public static class statement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "statement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:721:1: statement : ( explainStatement EOF | execStatement EOF );
    public final HiveParser.statement_return statement() throws RecognitionException {
        HiveParser.statement_return retval = new HiveParser.statement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token EOF2=null;
        Token EOF4=null;
        HiveParser.explainStatement_return explainStatement1 =null;

        HiveParser.execStatement_return execStatement3 =null;


        ASTNode EOF2_tree=null;
        ASTNode EOF4_tree=null;

        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:722:2: ( explainStatement EOF | execStatement EOF )
            int alt1=2;
            switch ( input.LA(1) ) {
            case KW_EXPLAIN:
                {
                alt1=1;
                }
                break;
            case KW_ABORT:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_COMMIT:
            case KW_CREATE:
            case KW_DELETE:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DROP:
            case KW_EXPORT:
            case KW_FROM:
            case KW_GRANT:
            case KW_IMPORT:
            case KW_INSERT:
            case KW_LOAD:
            case KW_LOCK:
            case KW_MAP:
            case KW_MERGE:
            case KW_MSCK:
            case KW_REDUCE:
            case KW_RELOAD:
            case KW_REPL:
            case KW_REVOKE:
            case KW_ROLLBACK:
            case KW_SELECT:
            case KW_SET:
            case KW_SHOW:
            case KW_START:
            case KW_TRUNCATE:
            case KW_UNLOCK:
            case KW_UPDATE:
            case KW_USE:
            case KW_WITH:
            case LPAREN:
                {
                alt1=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 1, 0, input);

                throw nvae;

            }

            switch (alt1) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:722:4: explainStatement EOF
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_explainStatement_in_statement1175);
                    explainStatement1=explainStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, explainStatement1.getTree());

                    EOF2=(Token)match(input,EOF,FOLLOW_EOF_in_statement1177); if (state.failed) return retval;
                    if ( state.backtracking==0 ) {
                    EOF2_tree = 
                    (ASTNode)adaptor.create(EOF2)
                    ;
                    adaptor.addChild(root_0, EOF2_tree);
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:723:4: execStatement EOF
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_execStatement_in_statement1182);
                    execStatement3=execStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, execStatement3.getTree());

                    EOF4=(Token)match(input,EOF,FOLLOW_EOF_in_statement1184); if (state.failed) return retval;
                    if ( state.backtracking==0 ) {
                    EOF4_tree = 
                    (ASTNode)adaptor.create(EOF4)
                    ;
                    adaptor.addChild(root_0, EOF4_tree);
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "statement"


    public static class explainStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "explainStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:726:1: explainStatement : KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) ) ;
    public final HiveParser.explainStatement_return explainStatement() throws RecognitionException {
        HiveParser.explainStatement_return retval = new HiveParser.explainStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_EXPLAIN5=null;
        Token KW_REWRITE8=null;
        HiveParser.explainOption_return explainOption6 =null;

        HiveParser.execStatement_return execStatement7 =null;

        HiveParser.queryStatementExpression_return queryStatementExpression9 =null;


        ASTNode KW_EXPLAIN5_tree=null;
        ASTNode KW_REWRITE8_tree=null;
        RewriteRuleTokenStream stream_KW_REWRITE=new RewriteRuleTokenStream(adaptor,"token KW_REWRITE");
        RewriteRuleTokenStream stream_KW_EXPLAIN=new RewriteRuleTokenStream(adaptor,"token KW_EXPLAIN");
        RewriteRuleSubtreeStream stream_queryStatementExpression=new RewriteRuleSubtreeStream(adaptor,"rule queryStatementExpression");
        RewriteRuleSubtreeStream stream_explainOption=new RewriteRuleSubtreeStream(adaptor,"rule explainOption");
        RewriteRuleSubtreeStream stream_execStatement=new RewriteRuleSubtreeStream(adaptor,"rule execStatement");
         pushMsg("explain statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:729:2: ( KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:729:4: KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) )
            {
            KW_EXPLAIN5=(Token)match(input,KW_EXPLAIN,FOLLOW_KW_EXPLAIN_in_explainStatement1205); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_EXPLAIN.add(KW_EXPLAIN5);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:729:15: ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) )
            int alt3=2;
            switch ( input.LA(1) ) {
            case KW_ABORT:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_AUTHORIZATION:
            case KW_COMMIT:
            case KW_CREATE:
            case KW_DELETE:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DROP:
            case KW_EXPORT:
            case KW_EXTENDED:
            case KW_FORMATTED:
            case KW_FROM:
            case KW_GRANT:
            case KW_IMPORT:
            case KW_INSERT:
            case KW_LOAD:
            case KW_LOCK:
            case KW_LOGICAL:
            case KW_MAP:
            case KW_MERGE:
            case KW_MSCK:
            case KW_REDUCE:
            case KW_RELOAD:
            case KW_REPL:
            case KW_REVOKE:
            case KW_ROLLBACK:
            case KW_SELECT:
            case KW_SET:
            case KW_SHOW:
            case KW_START:
            case KW_TRUNCATE:
            case KW_UNLOCK:
            case KW_UPDATE:
            case KW_USE:
            case KW_WITH:
            case LPAREN:
                {
                alt3=1;
                }
                break;
            case KW_REWRITE:
                {
                alt3=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 3, 0, input);

                throw nvae;

            }

            switch (alt3) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:730:6: ( explainOption )* execStatement
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:730:6: ( explainOption )*
                    loop2:
                    do {
                        int alt2=2;
                        alt2 = dfa2.predict(input);
                        switch (alt2) {
                    	case 1 :
                    	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:730:6: explainOption
                    	    {
                    	    pushFollow(FOLLOW_explainOption_in_explainStatement1214);
                    	    explainOption6=explainOption();

                    	    state._fsp--;
                    	    if (state.failed) return retval;
                    	    if ( state.backtracking==0 ) stream_explainOption.add(explainOption6.getTree());

                    	    }
                    	    break;

                    	default :
                    	    break loop2;
                        }
                    } while (true);


                    pushFollow(FOLLOW_execStatement_in_explainStatement1217);
                    execStatement7=execStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_execStatement.add(execStatement7.getTree());

                    // AST REWRITE
                    // elements: execStatement, explainOption
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 730:35: -> ^( TOK_EXPLAIN execStatement ( explainOption )* )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:730:38: ^( TOK_EXPLAIN execStatement ( explainOption )* )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_EXPLAIN, "TOK_EXPLAIN")
                        , root_1);

                        adaptor.addChild(root_1, stream_execStatement.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:730:66: ( explainOption )*
                        while ( stream_explainOption.hasNext() ) {
                            adaptor.addChild(root_1, stream_explainOption.nextTree());

                        }
                        stream_explainOption.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:732:9: KW_REWRITE queryStatementExpression
                    {
                    KW_REWRITE8=(Token)match(input,KW_REWRITE,FOLLOW_KW_REWRITE_in_explainStatement1248); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_REWRITE.add(KW_REWRITE8);


                    pushFollow(FOLLOW_queryStatementExpression_in_explainStatement1250);
                    queryStatementExpression9=queryStatementExpression();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_queryStatementExpression.add(queryStatementExpression9.getTree());

                    // AST REWRITE
                    // elements: queryStatementExpression
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 732:45: -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:732:48: ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_EXPLAIN_SQ_REWRITE, "TOK_EXPLAIN_SQ_REWRITE")
                        , root_1);

                        adaptor.addChild(root_1, stream_queryStatementExpression.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }


            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "explainStatement"


    public static class explainOption_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "explainOption"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:735:1: explainOption : ( KW_EXTENDED | KW_FORMATTED | KW_DEPENDENCY | KW_LOGICAL | KW_AUTHORIZATION | KW_ANALYZE );
    public final HiveParser.explainOption_return explainOption() throws RecognitionException {
        HiveParser.explainOption_return retval = new HiveParser.explainOption_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token set10=null;

        ASTNode set10_tree=null;

         msgs.push("explain option"); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:738:5: ( KW_EXTENDED | KW_FORMATTED | KW_DEPENDENCY | KW_LOGICAL | KW_AUTHORIZATION | KW_ANALYZE )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:
            {
            root_0 = (ASTNode)adaptor.nil();


            set10=(Token)input.LT(1);

            if ( input.LA(1)==KW_ANALYZE||input.LA(1)==KW_AUTHORIZATION||input.LA(1)==KW_DEPENDENCY||input.LA(1)==KW_EXTENDED||input.LA(1)==KW_FORMATTED||input.LA(1)==KW_LOGICAL ) {
                input.consume();
                if ( state.backtracking==0 ) adaptor.addChild(root_0, 
                (ASTNode)adaptor.create(set10)
                );
                state.errorRecovery=false;
                state.failed=false;
            }
            else {
                if (state.backtracking>0) {state.failed=true; return retval;}
                MismatchedSetException mse = new MismatchedSetException(null,input);
                throw mse;
            }


            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { msgs.pop(); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "explainOption"


    public static class execStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "execStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:741:1: execStatement : ( queryStatementExpression | loadStatement | exportStatement | importStatement | replDumpStatement | replLoadStatement | replStatusStatement | ddlStatement | deleteStatement | updateStatement | sqlTransactionStatement | mergeStatement );
    public final HiveParser.execStatement_return execStatement() throws RecognitionException {
        HiveParser.execStatement_return retval = new HiveParser.execStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.queryStatementExpression_return queryStatementExpression11 =null;

        HiveParser.loadStatement_return loadStatement12 =null;

        HiveParser.exportStatement_return exportStatement13 =null;

        HiveParser.importStatement_return importStatement14 =null;

        HiveParser.replDumpStatement_return replDumpStatement15 =null;

        HiveParser.replLoadStatement_return replLoadStatement16 =null;

        HiveParser.replStatusStatement_return replStatusStatement17 =null;

        HiveParser.ddlStatement_return ddlStatement18 =null;

        HiveParser.deleteStatement_return deleteStatement19 =null;

        HiveParser.updateStatement_return updateStatement20 =null;

        HiveParser.sqlTransactionStatement_return sqlTransactionStatement21 =null;

        HiveParser.mergeStatement_return mergeStatement22 =null;



         pushMsg("statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:744:5: ( queryStatementExpression | loadStatement | exportStatement | importStatement | replDumpStatement | replLoadStatement | replStatusStatement | ddlStatement | deleteStatement | updateStatement | sqlTransactionStatement | mergeStatement )
            int alt4=12;
            switch ( input.LA(1) ) {
            case KW_FROM:
            case KW_INSERT:
            case KW_MAP:
            case KW_REDUCE:
            case KW_SELECT:
            case KW_WITH:
            case LPAREN:
                {
                alt4=1;
                }
                break;
            case KW_LOAD:
                {
                alt4=2;
                }
                break;
            case KW_EXPORT:
                {
                alt4=3;
                }
                break;
            case KW_IMPORT:
                {
                alt4=4;
                }
                break;
            case KW_REPL:
                {
                switch ( input.LA(2) ) {
                case KW_DUMP:
                    {
                    alt4=5;
                    }
                    break;
                case KW_LOAD:
                    {
                    alt4=6;
                    }
                    break;
                case KW_STATUS:
                    {
                    alt4=7;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 4, 11, input);

                    throw nvae;

                }

                }
                break;
            case KW_ABORT:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_CREATE:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DROP:
            case KW_GRANT:
            case KW_LOCK:
            case KW_MSCK:
            case KW_RELOAD:
            case KW_REVOKE:
            case KW_SHOW:
            case KW_TRUNCATE:
            case KW_UNLOCK:
            case KW_USE:
                {
                alt4=8;
                }
                break;
            case KW_SET:
                {
                switch ( input.LA(2) ) {
                case KW_ROLE:
                    {
                    alt4=8;
                    }
                    break;
                case KW_AUTOCOMMIT:
                    {
                    alt4=11;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 4, 27, input);

                    throw nvae;

                }

                }
                break;
            case KW_DELETE:
                {
                alt4=9;
                }
                break;
            case KW_UPDATE:
                {
                alt4=10;
                }
                break;
            case KW_COMMIT:
            case KW_ROLLBACK:
            case KW_START:
                {
                alt4=11;
                }
                break;
            case KW_MERGE:
                {
                alt4=12;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 4, 0, input);

                throw nvae;

            }

            switch (alt4) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:744:7: queryStatementExpression
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_queryStatementExpression_in_execStatement1320);
                    queryStatementExpression11=queryStatementExpression();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, queryStatementExpression11.getTree());

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:745:7: loadStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_loadStatement_in_execStatement1328);
                    loadStatement12=loadStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, loadStatement12.getTree());

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:746:7: exportStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_exportStatement_in_execStatement1336);
                    exportStatement13=exportStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, exportStatement13.getTree());

                    }
                    break;
                case 4 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:747:7: importStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_importStatement_in_execStatement1344);
                    importStatement14=importStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, importStatement14.getTree());

                    }
                    break;
                case 5 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:748:7: replDumpStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_replDumpStatement_in_execStatement1352);
                    replDumpStatement15=replDumpStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, replDumpStatement15.getTree());

                    }
                    break;
                case 6 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:749:7: replLoadStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_replLoadStatement_in_execStatement1360);
                    replLoadStatement16=replLoadStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, replLoadStatement16.getTree());

                    }
                    break;
                case 7 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:750:7: replStatusStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_replStatusStatement_in_execStatement1368);
                    replStatusStatement17=replStatusStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, replStatusStatement17.getTree());

                    }
                    break;
                case 8 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:751:7: ddlStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_ddlStatement_in_execStatement1376);
                    ddlStatement18=ddlStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, ddlStatement18.getTree());

                    }
                    break;
                case 9 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:752:7: deleteStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_deleteStatement_in_execStatement1384);
                    deleteStatement19=deleteStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, deleteStatement19.getTree());

                    }
                    break;
                case 10 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:753:7: updateStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_updateStatement_in_execStatement1392);
                    updateStatement20=updateStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, updateStatement20.getTree());

                    }
                    break;
                case 11 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:754:7: sqlTransactionStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_sqlTransactionStatement_in_execStatement1400);
                    sqlTransactionStatement21=sqlTransactionStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, sqlTransactionStatement21.getTree());

                    }
                    break;
                case 12 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:755:7: mergeStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_mergeStatement_in_execStatement1408);
                    mergeStatement22=mergeStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, mergeStatement22.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "execStatement"


    public static class loadStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "loadStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:758:1: loadStatement : KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ) ;
    public final HiveParser.loadStatement_return loadStatement() throws RecognitionException {
        HiveParser.loadStatement_return retval = new HiveParser.loadStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token islocal=null;
        Token path=null;
        Token isoverwrite=null;
        Token KW_LOAD23=null;
        Token KW_DATA24=null;
        Token KW_INPATH25=null;
        Token KW_INTO26=null;
        Token KW_TABLE27=null;
        HiveParser_IdentifiersParser.tableOrPartition_return tab =null;


        ASTNode islocal_tree=null;
        ASTNode path_tree=null;
        ASTNode isoverwrite_tree=null;
        ASTNode KW_LOAD23_tree=null;
        ASTNode KW_DATA24_tree=null;
        ASTNode KW_INPATH25_tree=null;
        ASTNode KW_INTO26_tree=null;
        ASTNode KW_TABLE27_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
        RewriteRuleTokenStream stream_KW_INPATH=new RewriteRuleTokenStream(adaptor,"token KW_INPATH");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_KW_OVERWRITE=new RewriteRuleTokenStream(adaptor,"token KW_OVERWRITE");
        RewriteRuleTokenStream stream_KW_LOAD=new RewriteRuleTokenStream(adaptor,"token KW_LOAD");
        RewriteRuleTokenStream stream_KW_DATA=new RewriteRuleTokenStream(adaptor,"token KW_DATA");
        RewriteRuleTokenStream stream_KW_LOCAL=new RewriteRuleTokenStream(adaptor,"token KW_LOCAL");
        RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
         pushMsg("load statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:761:5: ( KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:761:7: KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition )
            {
            KW_LOAD23=(Token)match(input,KW_LOAD,FOLLOW_KW_LOAD_in_loadStatement1435); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_LOAD.add(KW_LOAD23);


            KW_DATA24=(Token)match(input,KW_DATA,FOLLOW_KW_DATA_in_loadStatement1437); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DATA.add(KW_DATA24);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:761:23: (islocal= KW_LOCAL )?
            int alt5=2;
            switch ( input.LA(1) ) {
                case KW_LOCAL:
                    {
                    alt5=1;
                    }
                    break;
            }

            switch (alt5) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:761:24: islocal= KW_LOCAL
                    {
                    islocal=(Token)match(input,KW_LOCAL,FOLLOW_KW_LOCAL_in_loadStatement1442); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_LOCAL.add(islocal);


                    }
                    break;

            }


            KW_INPATH25=(Token)match(input,KW_INPATH,FOLLOW_KW_INPATH_in_loadStatement1446); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_INPATH.add(KW_INPATH25);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:761:53: (path= StringLiteral )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:761:54: path= StringLiteral
            {
            path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_loadStatement1451); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(path);


            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:761:74: (isoverwrite= KW_OVERWRITE )?
            int alt6=2;
            switch ( input.LA(1) ) {
                case KW_OVERWRITE:
                    {
                    alt6=1;
                    }
                    break;
            }

            switch (alt6) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:761:75: isoverwrite= KW_OVERWRITE
                    {
                    isoverwrite=(Token)match(input,KW_OVERWRITE,FOLLOW_KW_OVERWRITE_in_loadStatement1457); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_OVERWRITE.add(isoverwrite);


                    }
                    break;

            }


            KW_INTO26=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_loadStatement1461); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO26);


            KW_TABLE27=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_loadStatement1463); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE27);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:761:119: (tab= tableOrPartition )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:761:120: tab= tableOrPartition
            {
            pushFollow(FOLLOW_tableOrPartition_in_loadStatement1468);
            tab=tableOrPartition();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableOrPartition.add(tab.getTree());

            }


            // AST REWRITE
            // elements: tab, isoverwrite, islocal, path
            // token labels: islocal, path, isoverwrite
            // rule labels: tab, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_islocal=new RewriteRuleTokenStream(adaptor,"token islocal",islocal);
            RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
            RewriteRuleTokenStream stream_isoverwrite=new RewriteRuleTokenStream(adaptor,"token isoverwrite",isoverwrite);
            RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 762:5: -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:762:8: ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_LOAD, "TOK_LOAD")
                , root_1);

                adaptor.addChild(root_1, stream_path.nextNode());

                adaptor.addChild(root_1, stream_tab.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:762:31: ( $islocal)?
                if ( stream_islocal.hasNext() ) {
                    adaptor.addChild(root_1, stream_islocal.nextNode());

                }
                stream_islocal.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:762:41: ( $isoverwrite)?
                if ( stream_isoverwrite.hasNext() ) {
                    adaptor.addChild(root_1, stream_isoverwrite.nextNode());

                }
                stream_isoverwrite.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "loadStatement"


    public static class replicationClause_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "replicationClause"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:765:1: replicationClause : KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? ) ;
    public final HiveParser.replicationClause_return replicationClause() throws RecognitionException {
        HiveParser.replicationClause_return retval = new HiveParser.replicationClause_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token isMetadataOnly=null;
        Token replId=null;
        Token KW_FOR28=null;
        Token KW_REPLICATION29=null;
        Token LPAREN30=null;
        Token RPAREN31=null;

        ASTNode isMetadataOnly_tree=null;
        ASTNode replId_tree=null;
        ASTNode KW_FOR28_tree=null;
        ASTNode KW_REPLICATION29_tree=null;
        ASTNode LPAREN30_tree=null;
        ASTNode RPAREN31_tree=null;
        RewriteRuleTokenStream stream_KW_REPLICATION=new RewriteRuleTokenStream(adaptor,"token KW_REPLICATION");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_METADATA=new RewriteRuleTokenStream(adaptor,"token KW_METADATA");

         pushMsg("replication clause", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:768:5: ( KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:768:7: KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN
            {
            KW_FOR28=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_replicationClause1520); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR28);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:768:14: (isMetadataOnly= KW_METADATA )?
            int alt7=2;
            switch ( input.LA(1) ) {
                case KW_METADATA:
                    {
                    alt7=1;
                    }
                    break;
            }

            switch (alt7) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:768:15: isMetadataOnly= KW_METADATA
                    {
                    isMetadataOnly=(Token)match(input,KW_METADATA,FOLLOW_KW_METADATA_in_replicationClause1525); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_METADATA.add(isMetadataOnly);


                    }
                    break;

            }


            KW_REPLICATION29=(Token)match(input,KW_REPLICATION,FOLLOW_KW_REPLICATION_in_replicationClause1529); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_REPLICATION.add(KW_REPLICATION29);


            LPAREN30=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_replicationClause1531); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN30);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:768:66: (replId= StringLiteral )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:768:67: replId= StringLiteral
            {
            replId=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_replicationClause1536); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(replId);


            }


            RPAREN31=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_replicationClause1539); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN31);


            // AST REWRITE
            // elements: replId, isMetadataOnly
            // token labels: replId, isMetadataOnly
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_replId=new RewriteRuleTokenStream(adaptor,"token replId",replId);
            RewriteRuleTokenStream stream_isMetadataOnly=new RewriteRuleTokenStream(adaptor,"token isMetadataOnly",isMetadataOnly);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 769:5: -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:769:8: ^( TOK_REPLICATION $replId ( $isMetadataOnly)? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_REPLICATION, "TOK_REPLICATION")
                , root_1);

                adaptor.addChild(root_1, stream_replId.nextNode());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:769:35: ( $isMetadataOnly)?
                if ( stream_isMetadataOnly.hasNext() ) {
                    adaptor.addChild(root_1, stream_isMetadataOnly.nextNode());

                }
                stream_isMetadataOnly.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "replicationClause"


    public static class exportStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "exportStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:772:1: exportStatement : KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )? -> ^( TOK_EXPORT $tab $path ( replicationClause )? ) ;
    public final HiveParser.exportStatement_return exportStatement() throws RecognitionException {
        HiveParser.exportStatement_return retval = new HiveParser.exportStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token path=null;
        Token KW_EXPORT32=null;
        Token KW_TABLE33=null;
        Token KW_TO34=null;
        HiveParser_IdentifiersParser.tableOrPartition_return tab =null;

        HiveParser.replicationClause_return replicationClause35 =null;


        ASTNode path_tree=null;
        ASTNode KW_EXPORT32_tree=null;
        ASTNode KW_TABLE33_tree=null;
        ASTNode KW_TO34_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
        RewriteRuleTokenStream stream_KW_EXPORT=new RewriteRuleTokenStream(adaptor,"token KW_EXPORT");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
        RewriteRuleSubtreeStream stream_replicationClause=new RewriteRuleSubtreeStream(adaptor,"rule replicationClause");
         pushMsg("export statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:775:5: ( KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )? -> ^( TOK_EXPORT $tab $path ( replicationClause )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:775:7: KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )?
            {
            KW_EXPORT32=(Token)match(input,KW_EXPORT,FOLLOW_KW_EXPORT_in_exportStatement1583); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_EXPORT.add(KW_EXPORT32);


            KW_TABLE33=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_exportStatement1591); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE33);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:776:16: (tab= tableOrPartition )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:776:17: tab= tableOrPartition
            {
            pushFollow(FOLLOW_tableOrPartition_in_exportStatement1596);
            tab=tableOrPartition();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableOrPartition.add(tab.getTree());

            }


            KW_TO34=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_exportStatement1605); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO34);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:777:13: (path= StringLiteral )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:777:14: path= StringLiteral
            {
            path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_exportStatement1610); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(path);


            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:778:7: ( replicationClause )?
            int alt8=2;
            switch ( input.LA(1) ) {
                case KW_FOR:
                    {
                    alt8=1;
                    }
                    break;
            }

            switch (alt8) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:778:7: replicationClause
                    {
                    pushFollow(FOLLOW_replicationClause_in_exportStatement1619);
                    replicationClause35=replicationClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_replicationClause.add(replicationClause35.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: path, tab, replicationClause
            // token labels: path
            // rule labels: tab, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
            RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 779:5: -> ^( TOK_EXPORT $tab $path ( replicationClause )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:779:8: ^( TOK_EXPORT $tab $path ( replicationClause )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_EXPORT, "TOK_EXPORT")
                , root_1);

                adaptor.addChild(root_1, stream_tab.nextTree());

                adaptor.addChild(root_1, stream_path.nextNode());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:779:32: ( replicationClause )?
                if ( stream_replicationClause.hasNext() ) {
                    adaptor.addChild(root_1, stream_replicationClause.nextTree());

                }
                stream_replicationClause.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "exportStatement"


    public static class importStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "importStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:782:1: importStatement : KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( tableLocation )? -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? ) ;
    public final HiveParser.importStatement_return importStatement() throws RecognitionException {
        HiveParser.importStatement_return retval = new HiveParser.importStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token ext=null;
        Token path=null;
        Token KW_IMPORT36=null;
        Token KW_TABLE37=null;
        Token KW_FROM38=null;
        HiveParser_IdentifiersParser.tableOrPartition_return tab =null;

        HiveParser.tableLocation_return tableLocation39 =null;


        ASTNode ext_tree=null;
        ASTNode path_tree=null;
        ASTNode KW_IMPORT36_tree=null;
        ASTNode KW_TABLE37_tree=null;
        ASTNode KW_FROM38_tree=null;
        RewriteRuleTokenStream stream_KW_EXTERNAL=new RewriteRuleTokenStream(adaptor,"token KW_EXTERNAL");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_KW_IMPORT=new RewriteRuleTokenStream(adaptor,"token KW_IMPORT");
        RewriteRuleSubtreeStream stream_tableLocation=new RewriteRuleSubtreeStream(adaptor,"rule tableLocation");
        RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
         pushMsg("import statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:785:8: ( KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( tableLocation )? -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:785:10: KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( tableLocation )?
            {
            KW_IMPORT36=(Token)match(input,KW_IMPORT,FOLLOW_KW_IMPORT_in_importStatement1669); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_IMPORT.add(KW_IMPORT36);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:786:10: ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )?
            int alt10=2;
            switch ( input.LA(1) ) {
                case KW_EXTERNAL:
                case KW_TABLE:
                    {
                    alt10=1;
                    }
                    break;
            }

            switch (alt10) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:786:11: (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition )
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:786:11: (ext= KW_EXTERNAL )?
                    int alt9=2;
                    switch ( input.LA(1) ) {
                        case KW_EXTERNAL:
                            {
                            alt9=1;
                            }
                            break;
                    }

                    switch (alt9) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:786:12: ext= KW_EXTERNAL
                            {
                            ext=(Token)match(input,KW_EXTERNAL,FOLLOW_KW_EXTERNAL_in_importStatement1684); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_EXTERNAL.add(ext);


                            }
                            break;

                    }


                    KW_TABLE37=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_importStatement1688); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE37);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:786:39: (tab= tableOrPartition )
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:786:40: tab= tableOrPartition
                    {
                    pushFollow(FOLLOW_tableOrPartition_in_importStatement1693);
                    tab=tableOrPartition();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableOrPartition.add(tab.getTree());

                    }


                    }
                    break;

            }


            KW_FROM38=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_importStatement1707); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM38);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:787:18: (path= StringLiteral )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:787:19: path= StringLiteral
            {
            path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_importStatement1712); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(path);


            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:788:10: ( tableLocation )?
            int alt11=2;
            switch ( input.LA(1) ) {
                case KW_LOCATION:
                    {
                    alt11=1;
                    }
                    break;
            }

            switch (alt11) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:788:10: tableLocation
                    {
                    pushFollow(FOLLOW_tableLocation_in_importStatement1724);
                    tableLocation39=tableLocation();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableLocation.add(tableLocation39.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: path, tableLocation, tab, ext
            // token labels: ext, path
            // rule labels: tab, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_ext=new RewriteRuleTokenStream(adaptor,"token ext",ext);
            RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
            RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 789:5: -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:789:8: ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_IMPORT, "TOK_IMPORT")
                , root_1);

                adaptor.addChild(root_1, stream_path.nextNode());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:789:28: ( $tab)?
                if ( stream_tab.hasNext() ) {
                    adaptor.addChild(root_1, stream_tab.nextTree());

                }
                stream_tab.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:789:34: ( $ext)?
                if ( stream_ext.hasNext() ) {
                    adaptor.addChild(root_1, stream_ext.nextNode());

                }
                stream_ext.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:789:39: ( tableLocation )?
                if ( stream_tableLocation.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableLocation.nextTree());

                }
                stream_tableLocation.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "importStatement"


    public static class replDumpStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "replDumpStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:792:1: replDumpStatement : KW_REPL KW_DUMP (dbName= identifier ) ( DOT tblName= identifier )? ( KW_FROM (eventId= Number ) ( KW_TO (rangeEnd= Number ) )? ( KW_LIMIT (batchSize= Number ) )? )? -> ^( TOK_REPL_DUMP $dbName ( $tblName)? ( ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? ) )? ) ;
    public final HiveParser.replDumpStatement_return replDumpStatement() throws RecognitionException {
        HiveParser.replDumpStatement_return retval = new HiveParser.replDumpStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token eventId=null;
        Token rangeEnd=null;
        Token batchSize=null;
        Token KW_REPL40=null;
        Token KW_DUMP41=null;
        Token DOT42=null;
        Token KW_FROM43=null;
        Token KW_TO44=null;
        Token KW_LIMIT45=null;
        HiveParser_IdentifiersParser.identifier_return dbName =null;

        HiveParser_IdentifiersParser.identifier_return tblName =null;


        ASTNode eventId_tree=null;
        ASTNode rangeEnd_tree=null;
        ASTNode batchSize_tree=null;
        ASTNode KW_REPL40_tree=null;
        ASTNode KW_DUMP41_tree=null;
        ASTNode DOT42_tree=null;
        ASTNode KW_FROM43_tree=null;
        ASTNode KW_TO44_tree=null;
        ASTNode KW_LIMIT45_tree=null;
        RewriteRuleTokenStream stream_KW_DUMP=new RewriteRuleTokenStream(adaptor,"token KW_DUMP");
        RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
        RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
        RewriteRuleTokenStream stream_KW_REPL=new RewriteRuleTokenStream(adaptor,"token KW_REPL");
        RewriteRuleTokenStream stream_DOT=new RewriteRuleTokenStream(adaptor,"token DOT");
        RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
        RewriteRuleTokenStream stream_KW_LIMIT=new RewriteRuleTokenStream(adaptor,"token KW_LIMIT");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         pushMsg("replication dump statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:795:7: ( KW_REPL KW_DUMP (dbName= identifier ) ( DOT tblName= identifier )? ( KW_FROM (eventId= Number ) ( KW_TO (rangeEnd= Number ) )? ( KW_LIMIT (batchSize= Number ) )? )? -> ^( TOK_REPL_DUMP $dbName ( $tblName)? ( ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? ) )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:795:9: KW_REPL KW_DUMP (dbName= identifier ) ( DOT tblName= identifier )? ( KW_FROM (eventId= Number ) ( KW_TO (rangeEnd= Number ) )? ( KW_LIMIT (batchSize= Number ) )? )?
            {
            KW_REPL40=(Token)match(input,KW_REPL,FOLLOW_KW_REPL_in_replDumpStatement1778); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_REPL.add(KW_REPL40);


            KW_DUMP41=(Token)match(input,KW_DUMP,FOLLOW_KW_DUMP_in_replDumpStatement1780); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DUMP.add(KW_DUMP41);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:796:9: (dbName= identifier )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:796:10: dbName= identifier
            {
            pushFollow(FOLLOW_identifier_in_replDumpStatement1793);
            dbName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:796:29: ( DOT tblName= identifier )?
            int alt12=2;
            switch ( input.LA(1) ) {
                case DOT:
                    {
                    alt12=1;
                    }
                    break;
            }

            switch (alt12) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:796:30: DOT tblName= identifier
                    {
                    DOT42=(Token)match(input,DOT,FOLLOW_DOT_in_replDumpStatement1797); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_DOT.add(DOT42);


                    pushFollow(FOLLOW_identifier_in_replDumpStatement1801);
                    tblName=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_identifier.add(tblName.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:797:9: ( KW_FROM (eventId= Number ) ( KW_TO (rangeEnd= Number ) )? ( KW_LIMIT (batchSize= Number ) )? )?
            int alt15=2;
            switch ( input.LA(1) ) {
                case KW_FROM:
                    {
                    alt15=1;
                    }
                    break;
            }

            switch (alt15) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:797:10: KW_FROM (eventId= Number ) ( KW_TO (rangeEnd= Number ) )? ( KW_LIMIT (batchSize= Number ) )?
                    {
                    KW_FROM43=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_replDumpStatement1814); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM43);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:797:18: (eventId= Number )
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:797:19: eventId= Number
                    {
                    eventId=(Token)match(input,Number,FOLLOW_Number_in_replDumpStatement1819); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_Number.add(eventId);


                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:798:11: ( KW_TO (rangeEnd= Number ) )?
                    int alt13=2;
                    switch ( input.LA(1) ) {
                        case KW_TO:
                            {
                            alt13=1;
                            }
                            break;
                    }

                    switch (alt13) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:798:12: KW_TO (rangeEnd= Number )
                            {
                            KW_TO44=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_replDumpStatement1833); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO44);


                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:798:18: (rangeEnd= Number )
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:798:19: rangeEnd= Number
                            {
                            rangeEnd=(Token)match(input,Number,FOLLOW_Number_in_replDumpStatement1838); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_Number.add(rangeEnd);


                            }


                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:799:11: ( KW_LIMIT (batchSize= Number ) )?
                    int alt14=2;
                    switch ( input.LA(1) ) {
                        case KW_LIMIT:
                            {
                            alt14=1;
                            }
                            break;
                    }

                    switch (alt14) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:799:12: KW_LIMIT (batchSize= Number )
                            {
                            KW_LIMIT45=(Token)match(input,KW_LIMIT,FOLLOW_KW_LIMIT_in_replDumpStatement1854); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_LIMIT.add(KW_LIMIT45);


                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:799:21: (batchSize= Number )
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:799:22: batchSize= Number
                            {
                            batchSize=(Token)match(input,Number,FOLLOW_Number_in_replDumpStatement1859); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_Number.add(batchSize);


                            }


                            }
                            break;

                    }


                    }
                    break;

            }


            // AST REWRITE
            // elements: dbName, tblName, rangeEnd, batchSize, eventId
            // token labels: eventId, batchSize, rangeEnd
            // rule labels: dbName, tblName, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_eventId=new RewriteRuleTokenStream(adaptor,"token eventId",eventId);
            RewriteRuleTokenStream stream_batchSize=new RewriteRuleTokenStream(adaptor,"token batchSize",batchSize);
            RewriteRuleTokenStream stream_rangeEnd=new RewriteRuleTokenStream(adaptor,"token rangeEnd",rangeEnd);
            RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.tree:null);
            RewriteRuleSubtreeStream stream_tblName=new RewriteRuleSubtreeStream(adaptor,"rule tblName",tblName!=null?tblName.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 801:5: -> ^( TOK_REPL_DUMP $dbName ( $tblName)? ( ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? ) )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:801:8: ^( TOK_REPL_DUMP $dbName ( $tblName)? ( ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? ) )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_REPL_DUMP, "TOK_REPL_DUMP")
                , root_1);

                adaptor.addChild(root_1, stream_dbName.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:801:33: ( $tblName)?
                if ( stream_tblName.hasNext() ) {
                    adaptor.addChild(root_1, stream_tblName.nextTree());

                }
                stream_tblName.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:801:42: ( ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? ) )?
                if ( stream_rangeEnd.hasNext()||stream_batchSize.hasNext()||stream_eventId.hasNext() ) {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:801:42: ^( TOK_FROM $eventId ( TOK_TO $rangeEnd)? ( TOK_LIMIT $batchSize)? )
                    {
                    ASTNode root_2 = (ASTNode)adaptor.nil();
                    root_2 = (ASTNode)adaptor.becomeRoot(
                    (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM")
                    , root_2);

                    adaptor.addChild(root_2, stream_eventId.nextNode());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:801:62: ( TOK_TO $rangeEnd)?
                    if ( stream_rangeEnd.hasNext() ) {
                        adaptor.addChild(root_2, 
                        (ASTNode)adaptor.create(TOK_TO, "TOK_TO")
                        );

                        adaptor.addChild(root_2, stream_rangeEnd.nextNode());

                    }
                    stream_rangeEnd.reset();

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:801:82: ( TOK_LIMIT $batchSize)?
                    if ( stream_batchSize.hasNext() ) {
                        adaptor.addChild(root_2, 
                        (ASTNode)adaptor.create(TOK_LIMIT, "TOK_LIMIT")
                        );

                        adaptor.addChild(root_2, stream_batchSize.nextNode());

                    }
                    stream_batchSize.reset();

                    adaptor.addChild(root_1, root_2);
                    }

                }
                stream_rangeEnd.reset();
                stream_batchSize.reset();
                stream_eventId.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "replDumpStatement"


    public static class replLoadStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "replLoadStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:804:1: replLoadStatement : KW_REPL KW_LOAD ( (dbName= identifier ) ( DOT tblName= identifier )? )? KW_FROM (path= StringLiteral ) -> ^( TOK_REPL_LOAD $path ( $dbName)? ( $tblName)? ) ;
    public final HiveParser.replLoadStatement_return replLoadStatement() throws RecognitionException {
        HiveParser.replLoadStatement_return retval = new HiveParser.replLoadStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token path=null;
        Token KW_REPL46=null;
        Token KW_LOAD47=null;
        Token DOT48=null;
        Token KW_FROM49=null;
        HiveParser_IdentifiersParser.identifier_return dbName =null;

        HiveParser_IdentifiersParser.identifier_return tblName =null;


        ASTNode path_tree=null;
        ASTNode KW_REPL46_tree=null;
        ASTNode KW_LOAD47_tree=null;
        ASTNode DOT48_tree=null;
        ASTNode KW_FROM49_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_REPL=new RewriteRuleTokenStream(adaptor,"token KW_REPL");
        RewriteRuleTokenStream stream_DOT=new RewriteRuleTokenStream(adaptor,"token DOT");
        RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
        RewriteRuleTokenStream stream_KW_LOAD=new RewriteRuleTokenStream(adaptor,"token KW_LOAD");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         pushMsg("replication load statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:807:7: ( KW_REPL KW_LOAD ( (dbName= identifier ) ( DOT tblName= identifier )? )? KW_FROM (path= StringLiteral ) -> ^( TOK_REPL_LOAD $path ( $dbName)? ( $tblName)? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:807:9: KW_REPL KW_LOAD ( (dbName= identifier ) ( DOT tblName= identifier )? )? KW_FROM (path= StringLiteral )
            {
            KW_REPL46=(Token)match(input,KW_REPL,FOLLOW_KW_REPL_in_replLoadStatement1944); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_REPL.add(KW_REPL46);


            KW_LOAD47=(Token)match(input,KW_LOAD,FOLLOW_KW_LOAD_in_replLoadStatement1946); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_LOAD.add(KW_LOAD47);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:808:9: ( (dbName= identifier ) ( DOT tblName= identifier )? )?
            int alt17=2;
            switch ( input.LA(1) ) {
                case Identifier:
                case KW_ABORT:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_AUTOCOMMIT:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CACHE:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONSTRAINT:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURRENT_DATE:
                case KW_CURRENT_TIMESTAMP:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DAY:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DOW:
                case KW_DROP:
                case KW_DUMP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FOREIGN:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOUR:
                case KW_IDXPROPERTIES:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ISOLATION:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEY:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LAST:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LEVEL:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATCHED:
                case KW_MATERIALIZED:
                case KW_MERGE:
                case KW_METADATA:
                case KW_MINUTE:
                case KW_MONTH:
                case KW_MSCK:
                case KW_NONE:
                case KW_NORELY:
                case KW_NOSCAN:
                case KW_NOVALIDATE:
                case KW_NULL:
                case KW_NULLS:
                case KW_OF:
                case KW_OFFSET:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRIMARY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PURGE:
                case KW_QUARTER:
                case KW_RANGE:
                case KW_READ:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REFERENCES:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RELY:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPL:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SECOND:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SNAPSHOT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STATUS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTION:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALIDATE:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_VIEWS:
                case KW_WEEK:
                case KW_WHILE:
                case KW_WITH:
                case KW_WORK:
                case KW_WRITE:
                case KW_YEAR:
                case KW_BATCH:
                case KW_DAYOFWEEK:
                case KW_HOLD_DDLTIME:
                case KW_IGNORE:
                case KW_NO_DROP:
                case KW_OFFLINE:
                case KW_PROTECTION:
                case KW_READONLY:
                    {
                    alt17=1;
                    }
                    break;
            }

            switch (alt17) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:808:10: (dbName= identifier ) ( DOT tblName= identifier )?
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:808:10: (dbName= identifier )
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:808:11: dbName= identifier
                    {
                    pushFollow(FOLLOW_identifier_in_replLoadStatement1960);
                    dbName=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:808:30: ( DOT tblName= identifier )?
                    int alt16=2;
                    switch ( input.LA(1) ) {
                        case DOT:
                            {
                            alt16=1;
                            }
                            break;
                    }

                    switch (alt16) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:808:31: DOT tblName= identifier
                            {
                            DOT48=(Token)match(input,DOT,FOLLOW_DOT_in_replLoadStatement1964); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_DOT.add(DOT48);


                            pushFollow(FOLLOW_identifier_in_replLoadStatement1968);
                            tblName=identifier();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_identifier.add(tblName.getTree());

                            }
                            break;

                    }


                    }
                    break;

            }


            KW_FROM49=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_replLoadStatement1982); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM49);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:809:17: (path= StringLiteral )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:809:18: path= StringLiteral
            {
            path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_replLoadStatement1987); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(path);


            }


            // AST REWRITE
            // elements: dbName, tblName, path
            // token labels: path
            // rule labels: dbName, tblName, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
            RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.tree:null);
            RewriteRuleSubtreeStream stream_tblName=new RewriteRuleSubtreeStream(adaptor,"rule tblName",tblName!=null?tblName.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 810:7: -> ^( TOK_REPL_LOAD $path ( $dbName)? ( $tblName)? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:810:10: ^( TOK_REPL_LOAD $path ( $dbName)? ( $tblName)? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_REPL_LOAD, "TOK_REPL_LOAD")
                , root_1);

                adaptor.addChild(root_1, stream_path.nextNode());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:810:33: ( $dbName)?
                if ( stream_dbName.hasNext() ) {
                    adaptor.addChild(root_1, stream_dbName.nextTree());

                }
                stream_dbName.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:810:42: ( $tblName)?
                if ( stream_tblName.hasNext() ) {
                    adaptor.addChild(root_1, stream_tblName.nextTree());

                }
                stream_tblName.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "replLoadStatement"


    public static class replStatusStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "replStatusStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:813:1: replStatusStatement : KW_REPL KW_STATUS (dbName= identifier ) ( DOT tblName= identifier )? -> ^( TOK_REPL_STATUS $dbName ( $tblName)? ) ;
    public final HiveParser.replStatusStatement_return replStatusStatement() throws RecognitionException {
        HiveParser.replStatusStatement_return retval = new HiveParser.replStatusStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_REPL50=null;
        Token KW_STATUS51=null;
        Token DOT52=null;
        HiveParser_IdentifiersParser.identifier_return dbName =null;

        HiveParser_IdentifiersParser.identifier_return tblName =null;


        ASTNode KW_REPL50_tree=null;
        ASTNode KW_STATUS51_tree=null;
        ASTNode DOT52_tree=null;
        RewriteRuleTokenStream stream_KW_STATUS=new RewriteRuleTokenStream(adaptor,"token KW_STATUS");
        RewriteRuleTokenStream stream_KW_REPL=new RewriteRuleTokenStream(adaptor,"token KW_REPL");
        RewriteRuleTokenStream stream_DOT=new RewriteRuleTokenStream(adaptor,"token DOT");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         pushMsg("replication load statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:816:7: ( KW_REPL KW_STATUS (dbName= identifier ) ( DOT tblName= identifier )? -> ^( TOK_REPL_STATUS $dbName ( $tblName)? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:816:9: KW_REPL KW_STATUS (dbName= identifier ) ( DOT tblName= identifier )?
            {
            KW_REPL50=(Token)match(input,KW_REPL,FOLLOW_KW_REPL_in_replStatusStatement2042); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_REPL.add(KW_REPL50);


            KW_STATUS51=(Token)match(input,KW_STATUS,FOLLOW_KW_STATUS_in_replStatusStatement2044); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_STATUS.add(KW_STATUS51);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:817:9: (dbName= identifier )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:817:10: dbName= identifier
            {
            pushFollow(FOLLOW_identifier_in_replStatusStatement2057);
            dbName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:817:29: ( DOT tblName= identifier )?
            int alt18=2;
            switch ( input.LA(1) ) {
                case DOT:
                    {
                    alt18=1;
                    }
                    break;
            }

            switch (alt18) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:817:30: DOT tblName= identifier
                    {
                    DOT52=(Token)match(input,DOT,FOLLOW_DOT_in_replStatusStatement2061); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_DOT.add(DOT52);


                    pushFollow(FOLLOW_identifier_in_replStatusStatement2065);
                    tblName=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_identifier.add(tblName.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: dbName, tblName
            // token labels: 
            // rule labels: dbName, tblName, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.tree:null);
            RewriteRuleSubtreeStream stream_tblName=new RewriteRuleSubtreeStream(adaptor,"rule tblName",tblName!=null?tblName.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 818:7: -> ^( TOK_REPL_STATUS $dbName ( $tblName)? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:818:10: ^( TOK_REPL_STATUS $dbName ( $tblName)? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_REPL_STATUS, "TOK_REPL_STATUS")
                , root_1);

                adaptor.addChild(root_1, stream_dbName.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:818:37: ( $tblName)?
                if ( stream_tblName.hasNext() ) {
                    adaptor.addChild(root_1, stream_tblName.nextTree());

                }
                stream_tblName.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "replStatusStatement"


    public static class ddlStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "ddlStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:821:1: ddlStatement : ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | dropViewStatement | createFunctionStatement | createMacroStatement | createIndexStatement | dropIndexStatement | dropFunctionStatement | reloadFunctionStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | ( grantPrivileges )=> grantPrivileges | ( revokePrivileges )=> revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole | abortTransactionStatement );
    public final HiveParser.ddlStatement_return ddlStatement() throws RecognitionException {
        HiveParser.ddlStatement_return retval = new HiveParser.ddlStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.createDatabaseStatement_return createDatabaseStatement53 =null;

        HiveParser.switchDatabaseStatement_return switchDatabaseStatement54 =null;

        HiveParser.dropDatabaseStatement_return dropDatabaseStatement55 =null;

        HiveParser.createTableStatement_return createTableStatement56 =null;

        HiveParser.dropTableStatement_return dropTableStatement57 =null;

        HiveParser.truncateTableStatement_return truncateTableStatement58 =null;

        HiveParser.alterStatement_return alterStatement59 =null;

        HiveParser.descStatement_return descStatement60 =null;

        HiveParser.showStatement_return showStatement61 =null;

        HiveParser.metastoreCheck_return metastoreCheck62 =null;

        HiveParser.createViewStatement_return createViewStatement63 =null;

        HiveParser.dropViewStatement_return dropViewStatement64 =null;

        HiveParser.createFunctionStatement_return createFunctionStatement65 =null;

        HiveParser.createMacroStatement_return createMacroStatement66 =null;

        HiveParser.createIndexStatement_return createIndexStatement67 =null;

        HiveParser.dropIndexStatement_return dropIndexStatement68 =null;

        HiveParser.dropFunctionStatement_return dropFunctionStatement69 =null;

        HiveParser.reloadFunctionStatement_return reloadFunctionStatement70 =null;

        HiveParser.dropMacroStatement_return dropMacroStatement71 =null;

        HiveParser.analyzeStatement_return analyzeStatement72 =null;

        HiveParser.lockStatement_return lockStatement73 =null;

        HiveParser.unlockStatement_return unlockStatement74 =null;

        HiveParser.lockDatabase_return lockDatabase75 =null;

        HiveParser.unlockDatabase_return unlockDatabase76 =null;

        HiveParser.createRoleStatement_return createRoleStatement77 =null;

        HiveParser.dropRoleStatement_return dropRoleStatement78 =null;

        HiveParser.grantPrivileges_return grantPrivileges79 =null;

        HiveParser.revokePrivileges_return revokePrivileges80 =null;

        HiveParser.showGrants_return showGrants81 =null;

        HiveParser.showRoleGrants_return showRoleGrants82 =null;

        HiveParser.showRolePrincipals_return showRolePrincipals83 =null;

        HiveParser.showRoles_return showRoles84 =null;

        HiveParser.grantRole_return grantRole85 =null;

        HiveParser.revokeRole_return revokeRole86 =null;

        HiveParser.setRole_return setRole87 =null;

        HiveParser.showCurrentRole_return showCurrentRole88 =null;

        HiveParser.abortTransactionStatement_return abortTransactionStatement89 =null;



         pushMsg("ddl statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:824:5: ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | dropViewStatement | createFunctionStatement | createMacroStatement | createIndexStatement | dropIndexStatement | dropFunctionStatement | reloadFunctionStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | ( grantPrivileges )=> grantPrivileges | ( revokePrivileges )=> revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole | abortTransactionStatement )
            int alt19=37;
            alt19 = dfa19.predict(input);
            switch (alt19) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:824:7: createDatabaseStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_createDatabaseStatement_in_ddlStatement2115);
                    createDatabaseStatement53=createDatabaseStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, createDatabaseStatement53.getTree());

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:7: switchDatabaseStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_switchDatabaseStatement_in_ddlStatement2123);
                    switchDatabaseStatement54=switchDatabaseStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, switchDatabaseStatement54.getTree());

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:826:7: dropDatabaseStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_dropDatabaseStatement_in_ddlStatement2131);
                    dropDatabaseStatement55=dropDatabaseStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, dropDatabaseStatement55.getTree());

                    }
                    break;
                case 4 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:827:7: createTableStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_createTableStatement_in_ddlStatement2139);
                    createTableStatement56=createTableStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, createTableStatement56.getTree());

                    }
                    break;
                case 5 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:828:7: dropTableStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_dropTableStatement_in_ddlStatement2147);
                    dropTableStatement57=dropTableStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, dropTableStatement57.getTree());

                    }
                    break;
                case 6 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:829:7: truncateTableStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_truncateTableStatement_in_ddlStatement2155);
                    truncateTableStatement58=truncateTableStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, truncateTableStatement58.getTree());

                    }
                    break;
                case 7 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:830:7: alterStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatement_in_ddlStatement2163);
                    alterStatement59=alterStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatement59.getTree());

                    }
                    break;
                case 8 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:831:7: descStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_descStatement_in_ddlStatement2171);
                    descStatement60=descStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, descStatement60.getTree());

                    }
                    break;
                case 9 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:832:7: showStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_showStatement_in_ddlStatement2179);
                    showStatement61=showStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, showStatement61.getTree());

                    }
                    break;
                case 10 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:833:7: metastoreCheck
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_metastoreCheck_in_ddlStatement2187);
                    metastoreCheck62=metastoreCheck();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, metastoreCheck62.getTree());

                    }
                    break;
                case 11 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:834:7: createViewStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_createViewStatement_in_ddlStatement2195);
                    createViewStatement63=createViewStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, createViewStatement63.getTree());

                    }
                    break;
                case 12 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:835:7: dropViewStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_dropViewStatement_in_ddlStatement2203);
                    dropViewStatement64=dropViewStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, dropViewStatement64.getTree());

                    }
                    break;
                case 13 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:836:7: createFunctionStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_createFunctionStatement_in_ddlStatement2211);
                    createFunctionStatement65=createFunctionStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, createFunctionStatement65.getTree());

                    }
                    break;
                case 14 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:837:7: createMacroStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_createMacroStatement_in_ddlStatement2219);
                    createMacroStatement66=createMacroStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, createMacroStatement66.getTree());

                    }
                    break;
                case 15 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:838:7: createIndexStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_createIndexStatement_in_ddlStatement2227);
                    createIndexStatement67=createIndexStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, createIndexStatement67.getTree());

                    }
                    break;
                case 16 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:7: dropIndexStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_dropIndexStatement_in_ddlStatement2235);
                    dropIndexStatement68=dropIndexStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, dropIndexStatement68.getTree());

                    }
                    break;
                case 17 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:840:7: dropFunctionStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_dropFunctionStatement_in_ddlStatement2243);
                    dropFunctionStatement69=dropFunctionStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, dropFunctionStatement69.getTree());

                    }
                    break;
                case 18 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:841:7: reloadFunctionStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_reloadFunctionStatement_in_ddlStatement2251);
                    reloadFunctionStatement70=reloadFunctionStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, reloadFunctionStatement70.getTree());

                    }
                    break;
                case 19 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:842:7: dropMacroStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_dropMacroStatement_in_ddlStatement2259);
                    dropMacroStatement71=dropMacroStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, dropMacroStatement71.getTree());

                    }
                    break;
                case 20 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:843:7: analyzeStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_analyzeStatement_in_ddlStatement2267);
                    analyzeStatement72=analyzeStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, analyzeStatement72.getTree());

                    }
                    break;
                case 21 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:844:7: lockStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_lockStatement_in_ddlStatement2275);
                    lockStatement73=lockStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, lockStatement73.getTree());

                    }
                    break;
                case 22 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:845:7: unlockStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_unlockStatement_in_ddlStatement2283);
                    unlockStatement74=unlockStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, unlockStatement74.getTree());

                    }
                    break;
                case 23 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:846:7: lockDatabase
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_lockDatabase_in_ddlStatement2291);
                    lockDatabase75=lockDatabase();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, lockDatabase75.getTree());

                    }
                    break;
                case 24 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:847:7: unlockDatabase
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_unlockDatabase_in_ddlStatement2299);
                    unlockDatabase76=unlockDatabase();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, unlockDatabase76.getTree());

                    }
                    break;
                case 25 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:848:7: createRoleStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_createRoleStatement_in_ddlStatement2307);
                    createRoleStatement77=createRoleStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, createRoleStatement77.getTree());

                    }
                    break;
                case 26 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:849:7: dropRoleStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_dropRoleStatement_in_ddlStatement2315);
                    dropRoleStatement78=dropRoleStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, dropRoleStatement78.getTree());

                    }
                    break;
                case 27 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:850:7: ( grantPrivileges )=> grantPrivileges
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_grantPrivileges_in_ddlStatement2329);
                    grantPrivileges79=grantPrivileges();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, grantPrivileges79.getTree());

                    }
                    break;
                case 28 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:851:7: ( revokePrivileges )=> revokePrivileges
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_revokePrivileges_in_ddlStatement2343);
                    revokePrivileges80=revokePrivileges();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, revokePrivileges80.getTree());

                    }
                    break;
                case 29 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:852:7: showGrants
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_showGrants_in_ddlStatement2351);
                    showGrants81=showGrants();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, showGrants81.getTree());

                    }
                    break;
                case 30 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:853:7: showRoleGrants
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_showRoleGrants_in_ddlStatement2359);
                    showRoleGrants82=showRoleGrants();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, showRoleGrants82.getTree());

                    }
                    break;
                case 31 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:854:7: showRolePrincipals
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_showRolePrincipals_in_ddlStatement2367);
                    showRolePrincipals83=showRolePrincipals();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, showRolePrincipals83.getTree());

                    }
                    break;
                case 32 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:855:7: showRoles
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_showRoles_in_ddlStatement2375);
                    showRoles84=showRoles();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, showRoles84.getTree());

                    }
                    break;
                case 33 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:856:7: grantRole
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_grantRole_in_ddlStatement2383);
                    grantRole85=grantRole();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, grantRole85.getTree());

                    }
                    break;
                case 34 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:857:7: revokeRole
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_revokeRole_in_ddlStatement2391);
                    revokeRole86=revokeRole();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, revokeRole86.getTree());

                    }
                    break;
                case 35 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:858:7: setRole
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_setRole_in_ddlStatement2399);
                    setRole87=setRole();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, setRole87.getTree());

                    }
                    break;
                case 36 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:859:7: showCurrentRole
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_showCurrentRole_in_ddlStatement2407);
                    showCurrentRole88=showCurrentRole();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, showCurrentRole88.getTree());

                    }
                    break;
                case 37 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:860:7: abortTransactionStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_abortTransactionStatement_in_ddlStatement2415);
                    abortTransactionStatement89=abortTransactionStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, abortTransactionStatement89.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "ddlStatement"


    public static class ifExists_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "ifExists"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:863:1: ifExists : KW_IF KW_EXISTS -> ^( TOK_IFEXISTS ) ;
    public final HiveParser.ifExists_return ifExists() throws RecognitionException {
        HiveParser.ifExists_return retval = new HiveParser.ifExists_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_IF90=null;
        Token KW_EXISTS91=null;

        ASTNode KW_IF90_tree=null;
        ASTNode KW_EXISTS91_tree=null;
        RewriteRuleTokenStream stream_KW_EXISTS=new RewriteRuleTokenStream(adaptor,"token KW_EXISTS");
        RewriteRuleTokenStream stream_KW_IF=new RewriteRuleTokenStream(adaptor,"token KW_IF");

         pushMsg("if exists clause", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:866:5: ( KW_IF KW_EXISTS -> ^( TOK_IFEXISTS ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:866:7: KW_IF KW_EXISTS
            {
            KW_IF90=(Token)match(input,KW_IF,FOLLOW_KW_IF_in_ifExists2442); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_IF.add(KW_IF90);


            KW_EXISTS91=(Token)match(input,KW_EXISTS,FOLLOW_KW_EXISTS_in_ifExists2444); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_EXISTS.add(KW_EXISTS91);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 867:5: -> ^( TOK_IFEXISTS )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:867:8: ^( TOK_IFEXISTS )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_IFEXISTS, "TOK_IFEXISTS")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "ifExists"


    public static class restrictOrCascade_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "restrictOrCascade"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:870:1: restrictOrCascade : ( KW_RESTRICT -> ^( TOK_RESTRICT ) | KW_CASCADE -> ^( TOK_CASCADE ) );
    public final HiveParser.restrictOrCascade_return restrictOrCascade() throws RecognitionException {
        HiveParser.restrictOrCascade_return retval = new HiveParser.restrictOrCascade_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_RESTRICT92=null;
        Token KW_CASCADE93=null;

        ASTNode KW_RESTRICT92_tree=null;
        ASTNode KW_CASCADE93_tree=null;
        RewriteRuleTokenStream stream_KW_CASCADE=new RewriteRuleTokenStream(adaptor,"token KW_CASCADE");
        RewriteRuleTokenStream stream_KW_RESTRICT=new RewriteRuleTokenStream(adaptor,"token KW_RESTRICT");

         pushMsg("restrict or cascade clause", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:873:5: ( KW_RESTRICT -> ^( TOK_RESTRICT ) | KW_CASCADE -> ^( TOK_CASCADE ) )
            int alt20=2;
            switch ( input.LA(1) ) {
            case KW_RESTRICT:
                {
                alt20=1;
                }
                break;
            case KW_CASCADE:
                {
                alt20=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 20, 0, input);

                throw nvae;

            }

            switch (alt20) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:873:7: KW_RESTRICT
                    {
                    KW_RESTRICT92=(Token)match(input,KW_RESTRICT,FOLLOW_KW_RESTRICT_in_restrictOrCascade2481); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_RESTRICT.add(KW_RESTRICT92);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 874:5: -> ^( TOK_RESTRICT )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:874:8: ^( TOK_RESTRICT )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_RESTRICT, "TOK_RESTRICT")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:875:7: KW_CASCADE
                    {
                    KW_CASCADE93=(Token)match(input,KW_CASCADE,FOLLOW_KW_CASCADE_in_restrictOrCascade2499); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_CASCADE.add(KW_CASCADE93);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 876:5: -> ^( TOK_CASCADE )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:876:8: ^( TOK_CASCADE )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_CASCADE, "TOK_CASCADE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "restrictOrCascade"


    public static class ifNotExists_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "ifNotExists"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:879:1: ifNotExists : KW_IF KW_NOT KW_EXISTS -> ^( TOK_IFNOTEXISTS ) ;
    public final HiveParser.ifNotExists_return ifNotExists() throws RecognitionException {
        HiveParser.ifNotExists_return retval = new HiveParser.ifNotExists_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_IF94=null;
        Token KW_NOT95=null;
        Token KW_EXISTS96=null;

        ASTNode KW_IF94_tree=null;
        ASTNode KW_NOT95_tree=null;
        ASTNode KW_EXISTS96_tree=null;
        RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
        RewriteRuleTokenStream stream_KW_EXISTS=new RewriteRuleTokenStream(adaptor,"token KW_EXISTS");
        RewriteRuleTokenStream stream_KW_IF=new RewriteRuleTokenStream(adaptor,"token KW_IF");

         pushMsg("if not exists clause", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:882:5: ( KW_IF KW_NOT KW_EXISTS -> ^( TOK_IFNOTEXISTS ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:882:7: KW_IF KW_NOT KW_EXISTS
            {
            KW_IF94=(Token)match(input,KW_IF,FOLLOW_KW_IF_in_ifNotExists2536); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_IF.add(KW_IF94);


            KW_NOT95=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_ifNotExists2538); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT95);


            KW_EXISTS96=(Token)match(input,KW_EXISTS,FOLLOW_KW_EXISTS_in_ifNotExists2540); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_EXISTS.add(KW_EXISTS96);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 883:5: -> ^( TOK_IFNOTEXISTS )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:883:8: ^( TOK_IFNOTEXISTS )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_IFNOTEXISTS, "TOK_IFNOTEXISTS")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "ifNotExists"


    public static class storedAsDirs_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "storedAsDirs"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:886:1: storedAsDirs : KW_STORED KW_AS KW_DIRECTORIES -> ^( TOK_STOREDASDIRS ) ;
    public final HiveParser.storedAsDirs_return storedAsDirs() throws RecognitionException {
        HiveParser.storedAsDirs_return retval = new HiveParser.storedAsDirs_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_STORED97=null;
        Token KW_AS98=null;
        Token KW_DIRECTORIES99=null;

        ASTNode KW_STORED97_tree=null;
        ASTNode KW_AS98_tree=null;
        ASTNode KW_DIRECTORIES99_tree=null;
        RewriteRuleTokenStream stream_KW_DIRECTORIES=new RewriteRuleTokenStream(adaptor,"token KW_DIRECTORIES");
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleTokenStream stream_KW_STORED=new RewriteRuleTokenStream(adaptor,"token KW_STORED");

         pushMsg("stored as directories", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:889:5: ( KW_STORED KW_AS KW_DIRECTORIES -> ^( TOK_STOREDASDIRS ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:889:7: KW_STORED KW_AS KW_DIRECTORIES
            {
            KW_STORED97=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_storedAsDirs2577); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED97);


            KW_AS98=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_storedAsDirs2579); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS98);


            KW_DIRECTORIES99=(Token)match(input,KW_DIRECTORIES,FOLLOW_KW_DIRECTORIES_in_storedAsDirs2581); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DIRECTORIES.add(KW_DIRECTORIES99);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 890:5: -> ^( TOK_STOREDASDIRS )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:890:8: ^( TOK_STOREDASDIRS )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_STOREDASDIRS, "TOK_STOREDASDIRS")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "storedAsDirs"


    public static class orReplace_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "orReplace"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:893:1: orReplace : KW_OR KW_REPLACE -> ^( TOK_ORREPLACE ) ;
    public final HiveParser.orReplace_return orReplace() throws RecognitionException {
        HiveParser.orReplace_return retval = new HiveParser.orReplace_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_OR100=null;
        Token KW_REPLACE101=null;

        ASTNode KW_OR100_tree=null;
        ASTNode KW_REPLACE101_tree=null;
        RewriteRuleTokenStream stream_KW_REPLACE=new RewriteRuleTokenStream(adaptor,"token KW_REPLACE");
        RewriteRuleTokenStream stream_KW_OR=new RewriteRuleTokenStream(adaptor,"token KW_OR");

         pushMsg("or replace clause", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:896:5: ( KW_OR KW_REPLACE -> ^( TOK_ORREPLACE ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:896:7: KW_OR KW_REPLACE
            {
            KW_OR100=(Token)match(input,KW_OR,FOLLOW_KW_OR_in_orReplace2618); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_OR.add(KW_OR100);


            KW_REPLACE101=(Token)match(input,KW_REPLACE,FOLLOW_KW_REPLACE_in_orReplace2620); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_REPLACE.add(KW_REPLACE101);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 897:5: -> ^( TOK_ORREPLACE )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:897:8: ^( TOK_ORREPLACE )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ORREPLACE, "TOK_ORREPLACE")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "orReplace"


    public static class createDatabaseStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "createDatabaseStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:900:1: createDatabaseStatement : KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( dbLocation )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )? -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( databaseComment )? ( $dbprops)? ) ;
    public final HiveParser.createDatabaseStatement_return createDatabaseStatement() throws RecognitionException {
        HiveParser.createDatabaseStatement_return retval = new HiveParser.createDatabaseStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_CREATE102=null;
        Token KW_DATABASE103=null;
        Token KW_SCHEMA104=null;
        Token KW_WITH108=null;
        Token KW_DBPROPERTIES109=null;
        HiveParser_IdentifiersParser.identifier_return name =null;

        HiveParser.dbProperties_return dbprops =null;

        HiveParser.ifNotExists_return ifNotExists105 =null;

        HiveParser.databaseComment_return databaseComment106 =null;

        HiveParser.dbLocation_return dbLocation107 =null;


        ASTNode KW_CREATE102_tree=null;
        ASTNode KW_DATABASE103_tree=null;
        ASTNode KW_SCHEMA104_tree=null;
        ASTNode KW_WITH108_tree=null;
        ASTNode KW_DBPROPERTIES109_tree=null;
        RewriteRuleTokenStream stream_KW_DBPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_DBPROPERTIES");
        RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_dbProperties=new RewriteRuleSubtreeStream(adaptor,"rule dbProperties");
        RewriteRuleSubtreeStream stream_databaseComment=new RewriteRuleSubtreeStream(adaptor,"rule databaseComment");
        RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
        RewriteRuleSubtreeStream stream_dbLocation=new RewriteRuleSubtreeStream(adaptor,"rule dbLocation");
         pushMsg("create database statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:903:5: ( KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( dbLocation )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )? -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( databaseComment )? ( $dbprops)? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:903:7: KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( dbLocation )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )?
            {
            KW_CREATE102=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createDatabaseStatement2657); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE102);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:903:17: ( KW_DATABASE | KW_SCHEMA )
            int alt21=2;
            switch ( input.LA(1) ) {
            case KW_DATABASE:
                {
                alt21=1;
                }
                break;
            case KW_SCHEMA:
                {
                alt21=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 21, 0, input);

                throw nvae;

            }

            switch (alt21) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:903:18: KW_DATABASE
                    {
                    KW_DATABASE103=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_createDatabaseStatement2660); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE103);


                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:903:30: KW_SCHEMA
                    {
                    KW_SCHEMA104=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_createDatabaseStatement2662); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA104);


                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:904:9: ( ifNotExists )?
            int alt22=2;
            switch ( input.LA(1) ) {
                case KW_IF:
                    {
                    alt22=1;
                    }
                    break;
            }

            switch (alt22) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:904:9: ifNotExists
                    {
                    pushFollow(FOLLOW_ifNotExists_in_createDatabaseStatement2673);
                    ifNotExists105=ifNotExists();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists105.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_identifier_in_createDatabaseStatement2686);
            name=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(name.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:906:9: ( databaseComment )?
            int alt23=2;
            switch ( input.LA(1) ) {
                case KW_COMMENT:
                    {
                    alt23=1;
                    }
                    break;
            }

            switch (alt23) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:906:9: databaseComment
                    {
                    pushFollow(FOLLOW_databaseComment_in_createDatabaseStatement2696);
                    databaseComment106=databaseComment();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_databaseComment.add(databaseComment106.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:907:9: ( dbLocation )?
            int alt24=2;
            switch ( input.LA(1) ) {
                case KW_LOCATION:
                    {
                    alt24=1;
                    }
                    break;
            }

            switch (alt24) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:907:9: dbLocation
                    {
                    pushFollow(FOLLOW_dbLocation_in_createDatabaseStatement2707);
                    dbLocation107=dbLocation();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_dbLocation.add(dbLocation107.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:908:9: ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )?
            int alt25=2;
            switch ( input.LA(1) ) {
                case KW_WITH:
                    {
                    alt25=1;
                    }
                    break;
            }

            switch (alt25) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:908:10: KW_WITH KW_DBPROPERTIES dbprops= dbProperties
                    {
                    KW_WITH108=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_createDatabaseStatement2719); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH108);


                    KW_DBPROPERTIES109=(Token)match(input,KW_DBPROPERTIES,FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement2721); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_DBPROPERTIES.add(KW_DBPROPERTIES109);


                    pushFollow(FOLLOW_dbProperties_in_createDatabaseStatement2725);
                    dbprops=dbProperties();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_dbProperties.add(dbprops.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: dbLocation, name, databaseComment, ifNotExists, dbprops
            // token labels: 
            // rule labels: name, dbprops, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);
            RewriteRuleSubtreeStream stream_dbprops=new RewriteRuleSubtreeStream(adaptor,"rule dbprops",dbprops!=null?dbprops.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 909:5: -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( databaseComment )? ( $dbprops)? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:909:8: ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( databaseComment )? ( $dbprops)? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_CREATEDATABASE, "TOK_CREATEDATABASE")
                , root_1);

                adaptor.addChild(root_1, stream_name.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:909:35: ( ifNotExists )?
                if ( stream_ifNotExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifNotExists.nextTree());

                }
                stream_ifNotExists.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:909:48: ( dbLocation )?
                if ( stream_dbLocation.hasNext() ) {
                    adaptor.addChild(root_1, stream_dbLocation.nextTree());

                }
                stream_dbLocation.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:909:60: ( databaseComment )?
                if ( stream_databaseComment.hasNext() ) {
                    adaptor.addChild(root_1, stream_databaseComment.nextTree());

                }
                stream_databaseComment.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:909:78: ( $dbprops)?
                if ( stream_dbprops.hasNext() ) {
                    adaptor.addChild(root_1, stream_dbprops.nextTree());

                }
                stream_dbprops.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "createDatabaseStatement"


    public static class dbLocation_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dbLocation"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:912:1: dbLocation : KW_LOCATION locn= StringLiteral -> ^( TOK_DATABASELOCATION $locn) ;
    public final HiveParser.dbLocation_return dbLocation() throws RecognitionException {
        HiveParser.dbLocation_return retval = new HiveParser.dbLocation_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token locn=null;
        Token KW_LOCATION110=null;

        ASTNode locn_tree=null;
        ASTNode KW_LOCATION110_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");

         pushMsg("database location specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:915:5: ( KW_LOCATION locn= StringLiteral -> ^( TOK_DATABASELOCATION $locn) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:916:7: KW_LOCATION locn= StringLiteral
            {
            KW_LOCATION110=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_dbLocation2786); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION110);


            locn=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_dbLocation2790); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(locn);


            // AST REWRITE
            // elements: locn
            // token labels: locn
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_locn=new RewriteRuleTokenStream(adaptor,"token locn",locn);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 916:38: -> ^( TOK_DATABASELOCATION $locn)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:916:41: ^( TOK_DATABASELOCATION $locn)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DATABASELOCATION, "TOK_DATABASELOCATION")
                , root_1);

                adaptor.addChild(root_1, stream_locn.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dbLocation"


    public static class dbProperties_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dbProperties"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:919:1: dbProperties : LPAREN dbPropertiesList RPAREN -> ^( TOK_DATABASEPROPERTIES dbPropertiesList ) ;
    public final HiveParser.dbProperties_return dbProperties() throws RecognitionException {
        HiveParser.dbProperties_return retval = new HiveParser.dbProperties_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token LPAREN111=null;
        Token RPAREN113=null;
        HiveParser.dbPropertiesList_return dbPropertiesList112 =null;


        ASTNode LPAREN111_tree=null;
        ASTNode RPAREN113_tree=null;
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleSubtreeStream stream_dbPropertiesList=new RewriteRuleSubtreeStream(adaptor,"rule dbPropertiesList");
         pushMsg("dbproperties", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:922:5: ( LPAREN dbPropertiesList RPAREN -> ^( TOK_DATABASEPROPERTIES dbPropertiesList ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:923:7: LPAREN dbPropertiesList RPAREN
            {
            LPAREN111=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_dbProperties2832); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN111);


            pushFollow(FOLLOW_dbPropertiesList_in_dbProperties2834);
            dbPropertiesList112=dbPropertiesList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_dbPropertiesList.add(dbPropertiesList112.getTree());

            RPAREN113=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_dbProperties2836); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN113);


            // AST REWRITE
            // elements: dbPropertiesList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 923:38: -> ^( TOK_DATABASEPROPERTIES dbPropertiesList )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:923:41: ^( TOK_DATABASEPROPERTIES dbPropertiesList )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DATABASEPROPERTIES, "TOK_DATABASEPROPERTIES")
                , root_1);

                adaptor.addChild(root_1, stream_dbPropertiesList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dbProperties"


    public static class dbPropertiesList_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dbPropertiesList"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:926:1: dbPropertiesList : keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_DBPROPLIST ( keyValueProperty )+ ) ;
    public final HiveParser.dbPropertiesList_return dbPropertiesList() throws RecognitionException {
        HiveParser.dbPropertiesList_return retval = new HiveParser.dbPropertiesList_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token COMMA115=null;
        HiveParser.keyValueProperty_return keyValueProperty114 =null;

        HiveParser.keyValueProperty_return keyValueProperty116 =null;


        ASTNode COMMA115_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_keyValueProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyValueProperty");
         pushMsg("database properties list", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:929:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_DBPROPLIST ( keyValueProperty )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:930:7: keyValueProperty ( COMMA keyValueProperty )*
            {
            pushFollow(FOLLOW_keyValueProperty_in_dbPropertiesList2877);
            keyValueProperty114=keyValueProperty();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty114.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:930:24: ( COMMA keyValueProperty )*
            loop26:
            do {
                int alt26=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt26=1;
                    }
                    break;

                }

                switch (alt26) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:930:25: COMMA keyValueProperty
            	    {
            	    COMMA115=(Token)match(input,COMMA,FOLLOW_COMMA_in_dbPropertiesList2880); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA115);


            	    pushFollow(FOLLOW_keyValueProperty_in_dbPropertiesList2882);
            	    keyValueProperty116=keyValueProperty();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty116.getTree());

            	    }
            	    break;

            	default :
            	    break loop26;
                }
            } while (true);


            // AST REWRITE
            // elements: keyValueProperty
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 930:50: -> ^( TOK_DBPROPLIST ( keyValueProperty )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:930:53: ^( TOK_DBPROPLIST ( keyValueProperty )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DBPROPLIST, "TOK_DBPROPLIST")
                , root_1);

                if ( !(stream_keyValueProperty.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_keyValueProperty.hasNext() ) {
                    adaptor.addChild(root_1, stream_keyValueProperty.nextTree());

                }
                stream_keyValueProperty.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dbPropertiesList"


    public static class switchDatabaseStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "switchDatabaseStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:934:1: switchDatabaseStatement : KW_USE identifier -> ^( TOK_SWITCHDATABASE identifier ) ;
    public final HiveParser.switchDatabaseStatement_return switchDatabaseStatement() throws RecognitionException {
        HiveParser.switchDatabaseStatement_return retval = new HiveParser.switchDatabaseStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_USE117=null;
        HiveParser_IdentifiersParser.identifier_return identifier118 =null;


        ASTNode KW_USE117_tree=null;
        RewriteRuleTokenStream stream_KW_USE=new RewriteRuleTokenStream(adaptor,"token KW_USE");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         pushMsg("switch database statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:937:5: ( KW_USE identifier -> ^( TOK_SWITCHDATABASE identifier ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:937:7: KW_USE identifier
            {
            KW_USE117=(Token)match(input,KW_USE,FOLLOW_KW_USE_in_switchDatabaseStatement2921); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_USE.add(KW_USE117);


            pushFollow(FOLLOW_identifier_in_switchDatabaseStatement2923);
            identifier118=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(identifier118.getTree());

            // AST REWRITE
            // elements: identifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 938:5: -> ^( TOK_SWITCHDATABASE identifier )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:938:8: ^( TOK_SWITCHDATABASE identifier )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SWITCHDATABASE, "TOK_SWITCHDATABASE")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "switchDatabaseStatement"


    public static class dropDatabaseStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dropDatabaseStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:941:1: dropDatabaseStatement : KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )? -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? ) ;
    public final HiveParser.dropDatabaseStatement_return dropDatabaseStatement() throws RecognitionException {
        HiveParser.dropDatabaseStatement_return retval = new HiveParser.dropDatabaseStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_DROP119=null;
        Token KW_DATABASE120=null;
        Token KW_SCHEMA121=null;
        HiveParser.ifExists_return ifExists122 =null;

        HiveParser_IdentifiersParser.identifier_return identifier123 =null;

        HiveParser.restrictOrCascade_return restrictOrCascade124 =null;


        ASTNode KW_DROP119_tree=null;
        ASTNode KW_DATABASE120_tree=null;
        ASTNode KW_SCHEMA121_tree=null;
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
        RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
        RewriteRuleSubtreeStream stream_restrictOrCascade=new RewriteRuleSubtreeStream(adaptor,"rule restrictOrCascade");
         pushMsg("drop database statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:944:5: ( KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )? -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:944:7: KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )?
            {
            KW_DROP119=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropDatabaseStatement2962); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP119);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:944:15: ( KW_DATABASE | KW_SCHEMA )
            int alt27=2;
            switch ( input.LA(1) ) {
            case KW_DATABASE:
                {
                alt27=1;
                }
                break;
            case KW_SCHEMA:
                {
                alt27=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 27, 0, input);

                throw nvae;

            }

            switch (alt27) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:944:16: KW_DATABASE
                    {
                    KW_DATABASE120=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_dropDatabaseStatement2965); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE120);


                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:944:28: KW_SCHEMA
                    {
                    KW_SCHEMA121=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_dropDatabaseStatement2967); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA121);


                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:944:39: ( ifExists )?
            int alt28=2;
            switch ( input.LA(1) ) {
                case KW_IF:
                    {
                    alt28=1;
                    }
                    break;
            }

            switch (alt28) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:944:39: ifExists
                    {
                    pushFollow(FOLLOW_ifExists_in_dropDatabaseStatement2970);
                    ifExists122=ifExists();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_ifExists.add(ifExists122.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_identifier_in_dropDatabaseStatement2973);
            identifier123=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(identifier123.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:944:60: ( restrictOrCascade )?
            int alt29=2;
            switch ( input.LA(1) ) {
                case KW_CASCADE:
                case KW_RESTRICT:
                    {
                    alt29=1;
                    }
                    break;
            }

            switch (alt29) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:944:60: restrictOrCascade
                    {
                    pushFollow(FOLLOW_restrictOrCascade_in_dropDatabaseStatement2975);
                    restrictOrCascade124=restrictOrCascade();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_restrictOrCascade.add(restrictOrCascade124.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: ifExists, restrictOrCascade, identifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 945:5: -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:945:8: ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DROPDATABASE, "TOK_DROPDATABASE")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:945:38: ( ifExists )?
                if ( stream_ifExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifExists.nextTree());

                }
                stream_ifExists.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:945:48: ( restrictOrCascade )?
                if ( stream_restrictOrCascade.hasNext() ) {
                    adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());

                }
                stream_restrictOrCascade.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dropDatabaseStatement"


    public static class databaseComment_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "databaseComment"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:948:1: databaseComment : KW_COMMENT comment= StringLiteral -> ^( TOK_DATABASECOMMENT $comment) ;
    public final HiveParser.databaseComment_return databaseComment() throws RecognitionException {
        HiveParser.databaseComment_return retval = new HiveParser.databaseComment_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token comment=null;
        Token KW_COMMENT125=null;

        ASTNode comment_tree=null;
        ASTNode KW_COMMENT125_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");

         pushMsg("database's comment", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:951:5: ( KW_COMMENT comment= StringLiteral -> ^( TOK_DATABASECOMMENT $comment) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:951:7: KW_COMMENT comment= StringLiteral
            {
            KW_COMMENT125=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_databaseComment3021); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT125);


            comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_databaseComment3025); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(comment);


            // AST REWRITE
            // elements: comment
            // token labels: comment
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 952:5: -> ^( TOK_DATABASECOMMENT $comment)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:952:8: ^( TOK_DATABASECOMMENT $comment)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DATABASECOMMENT, "TOK_DATABASECOMMENT")
                , root_1);

                adaptor.addChild(root_1, stream_comment.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "databaseComment"


    public static class createTableStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "createTableStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:955:1: createTableStatement : KW_CREATE (temp= KW_TEMPORARY )? (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeOrPKOrFKList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? ) -> ^( TOK_CREATETABLE $name ( $temp)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeOrPKOrFKList )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? ) ;
    public final HiveParser.createTableStatement_return createTableStatement() throws RecognitionException {
        HiveParser.createTableStatement_return retval = new HiveParser.createTableStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token temp=null;
        Token ext=null;
        Token like=null;
        Token KW_CREATE126=null;
        Token KW_TABLE127=null;
        Token LPAREN133=null;
        Token RPAREN135=null;
        Token KW_AS144=null;
        HiveParser_FromClauseParser.tableName_return name =null;

        HiveParser_FromClauseParser.tableName_return likeName =null;

        HiveParser.ifNotExists_return ifNotExists128 =null;

        HiveParser.tableRowFormat_return tableRowFormat129 =null;

        HiveParser.tableFileFormat_return tableFileFormat130 =null;

        HiveParser.tableLocation_return tableLocation131 =null;

        HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed132 =null;

        HiveParser.columnNameTypeOrPKOrFKList_return columnNameTypeOrPKOrFKList134 =null;

        HiveParser.tableComment_return tableComment136 =null;

        HiveParser.tablePartition_return tablePartition137 =null;

        HiveParser.tableBuckets_return tableBuckets138 =null;

        HiveParser.tableSkewed_return tableSkewed139 =null;

        HiveParser.tableRowFormat_return tableRowFormat140 =null;

        HiveParser.tableFileFormat_return tableFileFormat141 =null;

        HiveParser.tableLocation_return tableLocation142 =null;

        HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed143 =null;

        HiveParser.selectStatementWithCTE_return selectStatementWithCTE145 =null;


        ASTNode temp_tree=null;
        ASTNode ext_tree=null;
        ASTNode like_tree=null;
        ASTNode KW_CREATE126_tree=null;
        ASTNode KW_TABLE127_tree=null;
        ASTNode LPAREN133_tree=null;
        ASTNode RPAREN135_tree=null;
        ASTNode KW_AS144_tree=null;
        RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_KW_EXTERNAL=new RewriteRuleTokenStream(adaptor,"token KW_EXTERNAL");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleTokenStream stream_KW_LIKE=new RewriteRuleTokenStream(adaptor,"token KW_LIKE");
        RewriteRuleSubtreeStream stream_tableRowFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormat");
        RewriteRuleSubtreeStream stream_selectStatementWithCTE=new RewriteRuleSubtreeStream(adaptor,"rule selectStatementWithCTE");
        RewriteRuleSubtreeStream stream_tableLocation=new RewriteRuleSubtreeStream(adaptor,"rule tableLocation");
        RewriteRuleSubtreeStream stream_columnNameTypeOrPKOrFKList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeOrPKOrFKList");
        RewriteRuleSubtreeStream stream_tableSkewed=new RewriteRuleSubtreeStream(adaptor,"rule tableSkewed");
        RewriteRuleSubtreeStream stream_tablePropertiesPrefixed=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesPrefixed");
        RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
        RewriteRuleSubtreeStream stream_tableFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableFileFormat");
        RewriteRuleSubtreeStream stream_tableComment=new RewriteRuleSubtreeStream(adaptor,"rule tableComment");
        RewriteRuleSubtreeStream stream_tablePartition=new RewriteRuleSubtreeStream(adaptor,"rule tablePartition");
        RewriteRuleSubtreeStream stream_tableBuckets=new RewriteRuleSubtreeStream(adaptor,"rule tableBuckets");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("create table statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:958:5: ( KW_CREATE (temp= KW_TEMPORARY )? (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeOrPKOrFKList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? ) -> ^( TOK_CREATETABLE $name ( $temp)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeOrPKOrFKList )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:958:7: KW_CREATE (temp= KW_TEMPORARY )? (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeOrPKOrFKList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? )
            {
            KW_CREATE126=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createTableStatement3065); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE126);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:958:17: (temp= KW_TEMPORARY )?
            int alt30=2;
            switch ( input.LA(1) ) {
                case KW_TEMPORARY:
                    {
                    alt30=1;
                    }
                    break;
            }

            switch (alt30) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:958:18: temp= KW_TEMPORARY
                    {
                    temp=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_createTableStatement3070); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(temp);


                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:958:38: (ext= KW_EXTERNAL )?
            int alt31=2;
            switch ( input.LA(1) ) {
                case KW_EXTERNAL:
                    {
                    alt31=1;
                    }
                    break;
            }

            switch (alt31) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:958:39: ext= KW_EXTERNAL
                    {
                    ext=(Token)match(input,KW_EXTERNAL,FOLLOW_KW_EXTERNAL_in_createTableStatement3077); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_EXTERNAL.add(ext);


                    }
                    break;

            }


            KW_TABLE127=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_createTableStatement3081); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE127);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:958:66: ( ifNotExists )?
            int alt32=2;
            switch ( input.LA(1) ) {
                case KW_IF:
                    {
                    alt32=1;
                    }
                    break;
            }

            switch (alt32) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:958:66: ifNotExists
                    {
                    pushFollow(FOLLOW_ifNotExists_in_createTableStatement3083);
                    ifNotExists128=ifNotExists();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists128.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_tableName_in_createTableStatement3088);
            name=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(name.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:959:7: (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeOrPKOrFKList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? )
            int alt47=2;
            switch ( input.LA(1) ) {
            case KW_LIKE:
                {
                alt47=1;
                }
                break;
            case EOF:
            case KW_AS:
            case KW_CLUSTERED:
            case KW_COMMENT:
            case KW_LOCATION:
            case KW_PARTITIONED:
            case KW_ROW:
            case KW_SKEWED:
            case KW_STORED:
            case KW_TBLPROPERTIES:
            case LPAREN:
                {
                alt47=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 47, 0, input);

                throw nvae;

            }

            switch (alt47) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:959:10: like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )?
                    {
                    like=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_createTableStatement3101); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_LIKE.add(like);


                    pushFollow(FOLLOW_tableName_in_createTableStatement3105);
                    likeName=tableName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableName.add(likeName.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:960:10: ( tableRowFormat )?
                    int alt33=2;
                    switch ( input.LA(1) ) {
                        case KW_ROW:
                            {
                            alt33=1;
                            }
                            break;
                    }

                    switch (alt33) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:960:10: tableRowFormat
                            {
                            pushFollow(FOLLOW_tableRowFormat_in_createTableStatement3116);
                            tableRowFormat129=tableRowFormat();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tableRowFormat.add(tableRowFormat129.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:961:10: ( tableFileFormat )?
                    int alt34=2;
                    switch ( input.LA(1) ) {
                        case KW_STORED:
                            {
                            alt34=1;
                            }
                            break;
                    }

                    switch (alt34) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:961:10: tableFileFormat
                            {
                            pushFollow(FOLLOW_tableFileFormat_in_createTableStatement3128);
                            tableFileFormat130=tableFileFormat();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tableFileFormat.add(tableFileFormat130.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:962:10: ( tableLocation )?
                    int alt35=2;
                    switch ( input.LA(1) ) {
                        case KW_LOCATION:
                            {
                            alt35=1;
                            }
                            break;
                    }

                    switch (alt35) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:962:10: tableLocation
                            {
                            pushFollow(FOLLOW_tableLocation_in_createTableStatement3140);
                            tableLocation131=tableLocation();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tableLocation.add(tableLocation131.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:963:10: ( tablePropertiesPrefixed )?
                    int alt36=2;
                    switch ( input.LA(1) ) {
                        case KW_TBLPROPERTIES:
                            {
                            alt36=1;
                            }
                            break;
                    }

                    switch (alt36) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:963:10: tablePropertiesPrefixed
                            {
                            pushFollow(FOLLOW_tablePropertiesPrefixed_in_createTableStatement3152);
                            tablePropertiesPrefixed132=tablePropertiesPrefixed();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed132.getTree());

                            }
                            break;

                    }


                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:964:10: ( LPAREN columnNameTypeOrPKOrFKList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )?
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:964:10: ( LPAREN columnNameTypeOrPKOrFKList RPAREN )?
                    int alt37=2;
                    switch ( input.LA(1) ) {
                        case LPAREN:
                            {
                            alt37=1;
                            }
                            break;
                    }

                    switch (alt37) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:964:11: LPAREN columnNameTypeOrPKOrFKList RPAREN
                            {
                            LPAREN133=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createTableStatement3165); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN133);


                            pushFollow(FOLLOW_columnNameTypeOrPKOrFKList_in_createTableStatement3167);
                            columnNameTypeOrPKOrFKList134=columnNameTypeOrPKOrFKList();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_columnNameTypeOrPKOrFKList.add(columnNameTypeOrPKOrFKList134.getTree());

                            RPAREN135=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createTableStatement3169); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN135);


                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:965:10: ( tableComment )?
                    int alt38=2;
                    switch ( input.LA(1) ) {
                        case KW_COMMENT:
                            {
                            alt38=1;
                            }
                            break;
                    }

                    switch (alt38) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:965:10: tableComment
                            {
                            pushFollow(FOLLOW_tableComment_in_createTableStatement3182);
                            tableComment136=tableComment();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tableComment.add(tableComment136.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:966:10: ( tablePartition )?
                    int alt39=2;
                    switch ( input.LA(1) ) {
                        case KW_PARTITIONED:
                            {
                            alt39=1;
                            }
                            break;
                    }

                    switch (alt39) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:966:10: tablePartition
                            {
                            pushFollow(FOLLOW_tablePartition_in_createTableStatement3194);
                            tablePartition137=tablePartition();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tablePartition.add(tablePartition137.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:967:10: ( tableBuckets )?
                    int alt40=2;
                    switch ( input.LA(1) ) {
                        case KW_CLUSTERED:
                            {
                            alt40=1;
                            }
                            break;
                    }

                    switch (alt40) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:967:10: tableBuckets
                            {
                            pushFollow(FOLLOW_tableBuckets_in_createTableStatement3206);
                            tableBuckets138=tableBuckets();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tableBuckets.add(tableBuckets138.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:968:10: ( tableSkewed )?
                    int alt41=2;
                    switch ( input.LA(1) ) {
                        case KW_SKEWED:
                            {
                            alt41=1;
                            }
                            break;
                    }

                    switch (alt41) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:968:10: tableSkewed
                            {
                            pushFollow(FOLLOW_tableSkewed_in_createTableStatement3218);
                            tableSkewed139=tableSkewed();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tableSkewed.add(tableSkewed139.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:969:10: ( tableRowFormat )?
                    int alt42=2;
                    switch ( input.LA(1) ) {
                        case KW_ROW:
                            {
                            alt42=1;
                            }
                            break;
                    }

                    switch (alt42) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:969:10: tableRowFormat
                            {
                            pushFollow(FOLLOW_tableRowFormat_in_createTableStatement3230);
                            tableRowFormat140=tableRowFormat();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tableRowFormat.add(tableRowFormat140.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:970:10: ( tableFileFormat )?
                    int alt43=2;
                    switch ( input.LA(1) ) {
                        case KW_STORED:
                            {
                            alt43=1;
                            }
                            break;
                    }

                    switch (alt43) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:970:10: tableFileFormat
                            {
                            pushFollow(FOLLOW_tableFileFormat_in_createTableStatement3242);
                            tableFileFormat141=tableFileFormat();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tableFileFormat.add(tableFileFormat141.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:971:10: ( tableLocation )?
                    int alt44=2;
                    switch ( input.LA(1) ) {
                        case KW_LOCATION:
                            {
                            alt44=1;
                            }
                            break;
                    }

                    switch (alt44) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:971:10: tableLocation
                            {
                            pushFollow(FOLLOW_tableLocation_in_createTableStatement3254);
                            tableLocation142=tableLocation();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tableLocation.add(tableLocation142.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:972:10: ( tablePropertiesPrefixed )?
                    int alt45=2;
                    switch ( input.LA(1) ) {
                        case KW_TBLPROPERTIES:
                            {
                            alt45=1;
                            }
                            break;
                    }

                    switch (alt45) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:972:10: tablePropertiesPrefixed
                            {
                            pushFollow(FOLLOW_tablePropertiesPrefixed_in_createTableStatement3266);
                            tablePropertiesPrefixed143=tablePropertiesPrefixed();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed143.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:973:10: ( KW_AS selectStatementWithCTE )?
                    int alt46=2;
                    switch ( input.LA(1) ) {
                        case KW_AS:
                            {
                            alt46=1;
                            }
                            break;
                    }

                    switch (alt46) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:973:11: KW_AS selectStatementWithCTE
                            {
                            KW_AS144=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createTableStatement3279); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS144);


                            pushFollow(FOLLOW_selectStatementWithCTE_in_createTableStatement3281);
                            selectStatementWithCTE145=selectStatementWithCTE();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_selectStatementWithCTE.add(selectStatementWithCTE145.getTree());

                            }
                            break;

                    }


                    }
                    break;

            }


            // AST REWRITE
            // elements: selectStatementWithCTE, tableLocation, ext, tableFileFormat, likeName, tableRowFormat, ifNotExists, tableComment, tablePartition, name, tableBuckets, temp, tablePropertiesPrefixed, columnNameTypeOrPKOrFKList, tableSkewed
            // token labels: ext, temp
            // rule labels: likeName, name, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_ext=new RewriteRuleTokenStream(adaptor,"token ext",ext);
            RewriteRuleTokenStream stream_temp=new RewriteRuleTokenStream(adaptor,"token temp",temp);
            RewriteRuleSubtreeStream stream_likeName=new RewriteRuleSubtreeStream(adaptor,"rule likeName",likeName!=null?likeName.tree:null);
            RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 975:5: -> ^( TOK_CREATETABLE $name ( $temp)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeOrPKOrFKList )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:975:8: ^( TOK_CREATETABLE $name ( $temp)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeOrPKOrFKList )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_CREATETABLE, "TOK_CREATETABLE")
                , root_1);

                adaptor.addChild(root_1, stream_name.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:975:33: ( $temp)?
                if ( stream_temp.hasNext() ) {
                    adaptor.addChild(root_1, stream_temp.nextNode());

                }
                stream_temp.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:975:40: ( $ext)?
                if ( stream_ext.hasNext() ) {
                    adaptor.addChild(root_1, stream_ext.nextNode());

                }
                stream_ext.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:975:45: ( ifNotExists )?
                if ( stream_ifNotExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifNotExists.nextTree());

                }
                stream_ifNotExists.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:976:10: ^( TOK_LIKETABLE ( $likeName)? )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_LIKETABLE, "TOK_LIKETABLE")
                , root_2);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:976:27: ( $likeName)?
                if ( stream_likeName.hasNext() ) {
                    adaptor.addChild(root_2, stream_likeName.nextTree());

                }
                stream_likeName.reset();

                adaptor.addChild(root_1, root_2);
                }

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:977:10: ( columnNameTypeOrPKOrFKList )?
                if ( stream_columnNameTypeOrPKOrFKList.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameTypeOrPKOrFKList.nextTree());

                }
                stream_columnNameTypeOrPKOrFKList.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:978:10: ( tableComment )?
                if ( stream_tableComment.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableComment.nextTree());

                }
                stream_tableComment.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:979:10: ( tablePartition )?
                if ( stream_tablePartition.hasNext() ) {
                    adaptor.addChild(root_1, stream_tablePartition.nextTree());

                }
                stream_tablePartition.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:980:10: ( tableBuckets )?
                if ( stream_tableBuckets.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableBuckets.nextTree());

                }
                stream_tableBuckets.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:981:10: ( tableSkewed )?
                if ( stream_tableSkewed.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableSkewed.nextTree());

                }
                stream_tableSkewed.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:982:10: ( tableRowFormat )?
                if ( stream_tableRowFormat.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableRowFormat.nextTree());

                }
                stream_tableRowFormat.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:983:10: ( tableFileFormat )?
                if ( stream_tableFileFormat.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableFileFormat.nextTree());

                }
                stream_tableFileFormat.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:984:10: ( tableLocation )?
                if ( stream_tableLocation.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableLocation.nextTree());

                }
                stream_tableLocation.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:985:10: ( tablePropertiesPrefixed )?
                if ( stream_tablePropertiesPrefixed.hasNext() ) {
                    adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());

                }
                stream_tablePropertiesPrefixed.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:986:10: ( selectStatementWithCTE )?
                if ( stream_selectStatementWithCTE.hasNext() ) {
                    adaptor.addChild(root_1, stream_selectStatementWithCTE.nextTree());

                }
                stream_selectStatementWithCTE.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "createTableStatement"


    public static class truncateTableStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "truncateTableStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:990:1: truncateTableStatement : KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ) ;
    public final HiveParser.truncateTableStatement_return truncateTableStatement() throws RecognitionException {
        HiveParser.truncateTableStatement_return retval = new HiveParser.truncateTableStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_TRUNCATE146=null;
        Token KW_TABLE147=null;
        Token KW_COLUMNS149=null;
        Token LPAREN150=null;
        Token RPAREN152=null;
        HiveParser.tablePartitionPrefix_return tablePartitionPrefix148 =null;

        HiveParser.columnNameList_return columnNameList151 =null;


        ASTNode KW_TRUNCATE146_tree=null;
        ASTNode KW_TABLE147_tree=null;
        ASTNode KW_COLUMNS149_tree=null;
        ASTNode LPAREN150_tree=null;
        ASTNode RPAREN152_tree=null;
        RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_KW_TRUNCATE=new RewriteRuleTokenStream(adaptor,"token KW_TRUNCATE");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleSubtreeStream stream_tablePartitionPrefix=new RewriteRuleSubtreeStream(adaptor,"rule tablePartitionPrefix");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
         pushMsg("truncate table statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:993:5: ( KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:993:7: KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )?
            {
            KW_TRUNCATE146=(Token)match(input,KW_TRUNCATE,FOLLOW_KW_TRUNCATE_in_truncateTableStatement3488); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TRUNCATE.add(KW_TRUNCATE146);


            KW_TABLE147=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_truncateTableStatement3490); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE147);


            pushFollow(FOLLOW_tablePartitionPrefix_in_truncateTableStatement3492);
            tablePartitionPrefix148=tablePartitionPrefix();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tablePartitionPrefix.add(tablePartitionPrefix148.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:993:49: ( KW_COLUMNS LPAREN columnNameList RPAREN )?
            int alt48=2;
            switch ( input.LA(1) ) {
                case KW_COLUMNS:
                    {
                    alt48=1;
                    }
                    break;
            }

            switch (alt48) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:993:50: KW_COLUMNS LPAREN columnNameList RPAREN
                    {
                    KW_COLUMNS149=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_truncateTableStatement3495); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS149);


                    LPAREN150=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_truncateTableStatement3497); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN150);


                    pushFollow(FOLLOW_columnNameList_in_truncateTableStatement3499);
                    columnNameList151=columnNameList();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_columnNameList.add(columnNameList151.getTree());

                    RPAREN152=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_truncateTableStatement3501); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN152);


                    }
                    break;

            }


            // AST REWRITE
            // elements: tablePartitionPrefix, columnNameList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 993:92: -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:993:95: ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TRUNCATETABLE, "TOK_TRUNCATETABLE")
                , root_1);

                adaptor.addChild(root_1, stream_tablePartitionPrefix.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:993:136: ( columnNameList )?
                if ( stream_columnNameList.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameList.nextTree());

                }
                stream_columnNameList.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "truncateTableStatement"


    public static class createIndexStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "createIndexStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:995:1: createIndexStatement : KW_CREATE KW_INDEX indexName= identifier KW_ON KW_TABLE tab= tableName LPAREN indexedCols= columnNameList RPAREN KW_AS typeName= StringLiteral ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( indexComment )? -> ^( TOK_CREATEINDEX $indexName $typeName $tab $indexedCols ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( indexComment )? ) ;
    public final HiveParser.createIndexStatement_return createIndexStatement() throws RecognitionException {
        HiveParser.createIndexStatement_return retval = new HiveParser.createIndexStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token typeName=null;
        Token KW_CREATE153=null;
        Token KW_INDEX154=null;
        Token KW_ON155=null;
        Token KW_TABLE156=null;
        Token LPAREN157=null;
        Token RPAREN158=null;
        Token KW_AS159=null;
        HiveParser_IdentifiersParser.identifier_return indexName =null;

        HiveParser_FromClauseParser.tableName_return tab =null;

        HiveParser.columnNameList_return indexedCols =null;

        HiveParser.autoRebuild_return autoRebuild160 =null;

        HiveParser.indexPropertiesPrefixed_return indexPropertiesPrefixed161 =null;

        HiveParser.indexTblName_return indexTblName162 =null;

        HiveParser.tableRowFormat_return tableRowFormat163 =null;

        HiveParser.tableFileFormat_return tableFileFormat164 =null;

        HiveParser.tableLocation_return tableLocation165 =null;

        HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed166 =null;

        HiveParser.indexComment_return indexComment167 =null;


        ASTNode typeName_tree=null;
        ASTNode KW_CREATE153_tree=null;
        ASTNode KW_INDEX154_tree=null;
        ASTNode KW_ON155_tree=null;
        ASTNode KW_TABLE156_tree=null;
        ASTNode LPAREN157_tree=null;
        ASTNode RPAREN158_tree=null;
        ASTNode KW_AS159_tree=null;
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_KW_INDEX=new RewriteRuleTokenStream(adaptor,"token KW_INDEX");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleSubtreeStream stream_tableRowFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormat");
        RewriteRuleSubtreeStream stream_indexComment=new RewriteRuleSubtreeStream(adaptor,"rule indexComment");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_tableLocation=new RewriteRuleSubtreeStream(adaptor,"rule tableLocation");
        RewriteRuleSubtreeStream stream_tablePropertiesPrefixed=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesPrefixed");
        RewriteRuleSubtreeStream stream_tableFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableFileFormat");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
        RewriteRuleSubtreeStream stream_indexTblName=new RewriteRuleSubtreeStream(adaptor,"rule indexTblName");
        RewriteRuleSubtreeStream stream_autoRebuild=new RewriteRuleSubtreeStream(adaptor,"rule autoRebuild");
        RewriteRuleSubtreeStream stream_indexPropertiesPrefixed=new RewriteRuleSubtreeStream(adaptor,"rule indexPropertiesPrefixed");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("create index statement", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:998:5: ( KW_CREATE KW_INDEX indexName= identifier KW_ON KW_TABLE tab= tableName LPAREN indexedCols= columnNameList RPAREN KW_AS typeName= StringLiteral ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( indexComment )? -> ^( TOK_CREATEINDEX $indexName $typeName $tab $indexedCols ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( indexComment )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:998:7: KW_CREATE KW_INDEX indexName= identifier KW_ON KW_TABLE tab= tableName LPAREN indexedCols= columnNameList RPAREN KW_AS typeName= StringLiteral ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( indexComment )?
            {
            KW_CREATE153=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createIndexStatement3536); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE153);


            KW_INDEX154=(Token)match(input,KW_INDEX,FOLLOW_KW_INDEX_in_createIndexStatement3538); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_INDEX.add(KW_INDEX154);


            pushFollow(FOLLOW_identifier_in_createIndexStatement3542);
            indexName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(indexName.getTree());

            KW_ON155=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_createIndexStatement3550); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON155);


            KW_TABLE156=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_createIndexStatement3552); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE156);


            pushFollow(FOLLOW_tableName_in_createIndexStatement3556);
            tab=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(tab.getTree());

            LPAREN157=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createIndexStatement3558); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN157);


            pushFollow(FOLLOW_columnNameList_in_createIndexStatement3562);
            indexedCols=columnNameList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnNameList.add(indexedCols.getTree());

            RPAREN158=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createIndexStatement3564); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN158);


            KW_AS159=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createIndexStatement3572); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS159);


            typeName=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_createIndexStatement3576); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(typeName);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1001:7: ( autoRebuild )?
            int alt49=2;
            switch ( input.LA(1) ) {
                case KW_WITH:
                    {
                    alt49=1;
                    }
                    break;
            }

            switch (alt49) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1001:7: autoRebuild
                    {
                    pushFollow(FOLLOW_autoRebuild_in_createIndexStatement3584);
                    autoRebuild160=autoRebuild();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_autoRebuild.add(autoRebuild160.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1002:7: ( indexPropertiesPrefixed )?
            int alt50=2;
            switch ( input.LA(1) ) {
                case KW_IDXPROPERTIES:
                    {
                    alt50=1;
                    }
                    break;
            }

            switch (alt50) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1002:7: indexPropertiesPrefixed
                    {
                    pushFollow(FOLLOW_indexPropertiesPrefixed_in_createIndexStatement3593);
                    indexPropertiesPrefixed161=indexPropertiesPrefixed();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_indexPropertiesPrefixed.add(indexPropertiesPrefixed161.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1003:7: ( indexTblName )?
            int alt51=2;
            switch ( input.LA(1) ) {
                case KW_IN:
                    {
                    alt51=1;
                    }
                    break;
            }

            switch (alt51) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1003:7: indexTblName
                    {
                    pushFollow(FOLLOW_indexTblName_in_createIndexStatement3602);
                    indexTblName162=indexTblName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_indexTblName.add(indexTblName162.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1004:7: ( tableRowFormat )?
            int alt52=2;
            switch ( input.LA(1) ) {
                case KW_ROW:
                    {
                    alt52=1;
                    }
                    break;
            }

            switch (alt52) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1004:7: tableRowFormat
                    {
                    pushFollow(FOLLOW_tableRowFormat_in_createIndexStatement3611);
                    tableRowFormat163=tableRowFormat();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableRowFormat.add(tableRowFormat163.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1005:7: ( tableFileFormat )?
            int alt53=2;
            switch ( input.LA(1) ) {
                case KW_STORED:
                    {
                    alt53=1;
                    }
                    break;
            }

            switch (alt53) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1005:7: tableFileFormat
                    {
                    pushFollow(FOLLOW_tableFileFormat_in_createIndexStatement3620);
                    tableFileFormat164=tableFileFormat();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableFileFormat.add(tableFileFormat164.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1006:7: ( tableLocation )?
            int alt54=2;
            switch ( input.LA(1) ) {
                case KW_LOCATION:
                    {
                    alt54=1;
                    }
                    break;
            }

            switch (alt54) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1006:7: tableLocation
                    {
                    pushFollow(FOLLOW_tableLocation_in_createIndexStatement3629);
                    tableLocation165=tableLocation();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableLocation.add(tableLocation165.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1007:7: ( tablePropertiesPrefixed )?
            int alt55=2;
            switch ( input.LA(1) ) {
                case KW_TBLPROPERTIES:
                    {
                    alt55=1;
                    }
                    break;
            }

            switch (alt55) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1007:7: tablePropertiesPrefixed
                    {
                    pushFollow(FOLLOW_tablePropertiesPrefixed_in_createIndexStatement3638);
                    tablePropertiesPrefixed166=tablePropertiesPrefixed();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed166.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1008:7: ( indexComment )?
            int alt56=2;
            switch ( input.LA(1) ) {
                case KW_COMMENT:
                    {
                    alt56=1;
                    }
                    break;
            }

            switch (alt56) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1008:7: indexComment
                    {
                    pushFollow(FOLLOW_indexComment_in_createIndexStatement3647);
                    indexComment167=indexComment();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_indexComment.add(indexComment167.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: indexedCols, indexPropertiesPrefixed, tableRowFormat, tableLocation, tablePropertiesPrefixed, tab, autoRebuild, tableFileFormat, indexTblName, indexName, indexComment, typeName
            // token labels: typeName
            // rule labels: indexedCols, tab, indexName, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_typeName=new RewriteRuleTokenStream(adaptor,"token typeName",typeName);
            RewriteRuleSubtreeStream stream_indexedCols=new RewriteRuleSubtreeStream(adaptor,"rule indexedCols",indexedCols!=null?indexedCols.tree:null);
            RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.tree:null);
            RewriteRuleSubtreeStream stream_indexName=new RewriteRuleSubtreeStream(adaptor,"rule indexName",indexName!=null?indexName.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1009:5: -> ^( TOK_CREATEINDEX $indexName $typeName $tab $indexedCols ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( indexComment )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1009:7: ^( TOK_CREATEINDEX $indexName $typeName $tab $indexedCols ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( indexComment )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_CREATEINDEX, "TOK_CREATEINDEX")
                , root_1);

                adaptor.addChild(root_1, stream_indexName.nextTree());

                adaptor.addChild(root_1, stream_typeName.nextNode());

                adaptor.addChild(root_1, stream_tab.nextTree());

                adaptor.addChild(root_1, stream_indexedCols.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1010:9: ( autoRebuild )?
                if ( stream_autoRebuild.hasNext() ) {
                    adaptor.addChild(root_1, stream_autoRebuild.nextTree());

                }
                stream_autoRebuild.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1011:9: ( indexPropertiesPrefixed )?
                if ( stream_indexPropertiesPrefixed.hasNext() ) {
                    adaptor.addChild(root_1, stream_indexPropertiesPrefixed.nextTree());

                }
                stream_indexPropertiesPrefixed.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1012:9: ( indexTblName )?
                if ( stream_indexTblName.hasNext() ) {
                    adaptor.addChild(root_1, stream_indexTblName.nextTree());

                }
                stream_indexTblName.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1013:9: ( tableRowFormat )?
                if ( stream_tableRowFormat.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableRowFormat.nextTree());

                }
                stream_tableRowFormat.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1014:9: ( tableFileFormat )?
                if ( stream_tableFileFormat.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableFileFormat.nextTree());

                }
                stream_tableFileFormat.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1015:9: ( tableLocation )?
                if ( stream_tableLocation.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableLocation.nextTree());

                }
                stream_tableLocation.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1016:9: ( tablePropertiesPrefixed )?
                if ( stream_tablePropertiesPrefixed.hasNext() ) {
                    adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());

                }
                stream_tablePropertiesPrefixed.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1017:9: ( indexComment )?
                if ( stream_indexComment.hasNext() ) {
                    adaptor.addChild(root_1, stream_indexComment.nextTree());

                }
                stream_indexComment.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "createIndexStatement"


    public static class indexComment_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "indexComment"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1020:1: indexComment : KW_COMMENT comment= StringLiteral -> ^( TOK_INDEXCOMMENT $comment) ;
    public final HiveParser.indexComment_return indexComment() throws RecognitionException {
        HiveParser.indexComment_return retval = new HiveParser.indexComment_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token comment=null;
        Token KW_COMMENT168=null;

        ASTNode comment_tree=null;
        ASTNode KW_COMMENT168_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");

         pushMsg("comment on an index", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1023:9: ( KW_COMMENT comment= StringLiteral -> ^( TOK_INDEXCOMMENT $comment) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1024:17: KW_COMMENT comment= StringLiteral
            {
            KW_COMMENT168=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_indexComment3804); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT168);


            comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_indexComment3808); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(comment);


            // AST REWRITE
            // elements: comment
            // token labels: comment
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1024:51: -> ^( TOK_INDEXCOMMENT $comment)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1024:54: ^( TOK_INDEXCOMMENT $comment)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_INDEXCOMMENT, "TOK_INDEXCOMMENT")
                , root_1);

                adaptor.addChild(root_1, stream_comment.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "indexComment"


    public static class autoRebuild_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "autoRebuild"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1027:1: autoRebuild : KW_WITH KW_DEFERRED KW_REBUILD -> ^( TOK_DEFERRED_REBUILDINDEX ) ;
    public final HiveParser.autoRebuild_return autoRebuild() throws RecognitionException {
        HiveParser.autoRebuild_return retval = new HiveParser.autoRebuild_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_WITH169=null;
        Token KW_DEFERRED170=null;
        Token KW_REBUILD171=null;

        ASTNode KW_WITH169_tree=null;
        ASTNode KW_DEFERRED170_tree=null;
        ASTNode KW_REBUILD171_tree=null;
        RewriteRuleTokenStream stream_KW_REBUILD=new RewriteRuleTokenStream(adaptor,"token KW_REBUILD");
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleTokenStream stream_KW_DEFERRED=new RewriteRuleTokenStream(adaptor,"token KW_DEFERRED");

         pushMsg("auto rebuild index", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1030:5: ( KW_WITH KW_DEFERRED KW_REBUILD -> ^( TOK_DEFERRED_REBUILDINDEX ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1030:7: KW_WITH KW_DEFERRED KW_REBUILD
            {
            KW_WITH169=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_autoRebuild3849); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH169);


            KW_DEFERRED170=(Token)match(input,KW_DEFERRED,FOLLOW_KW_DEFERRED_in_autoRebuild3851); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DEFERRED.add(KW_DEFERRED170);


            KW_REBUILD171=(Token)match(input,KW_REBUILD,FOLLOW_KW_REBUILD_in_autoRebuild3853); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_REBUILD.add(KW_REBUILD171);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1031:5: -> ^( TOK_DEFERRED_REBUILDINDEX )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1031:7: ^( TOK_DEFERRED_REBUILDINDEX )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DEFERRED_REBUILDINDEX, "TOK_DEFERRED_REBUILDINDEX")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "autoRebuild"


    public static class indexTblName_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "indexTblName"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1034:1: indexTblName : KW_IN KW_TABLE indexTbl= tableName -> ^( TOK_CREATEINDEX_INDEXTBLNAME $indexTbl) ;
    public final HiveParser.indexTblName_return indexTblName() throws RecognitionException {
        HiveParser.indexTblName_return retval = new HiveParser.indexTblName_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_IN172=null;
        Token KW_TABLE173=null;
        HiveParser_FromClauseParser.tableName_return indexTbl =null;


        ASTNode KW_IN172_tree=null;
        ASTNode KW_TABLE173_tree=null;
        RewriteRuleTokenStream stream_KW_IN=new RewriteRuleTokenStream(adaptor,"token KW_IN");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("index table name", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1037:5: ( KW_IN KW_TABLE indexTbl= tableName -> ^( TOK_CREATEINDEX_INDEXTBLNAME $indexTbl) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1037:7: KW_IN KW_TABLE indexTbl= tableName
            {
            KW_IN172=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_indexTblName3889); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN172);


            KW_TABLE173=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_indexTblName3891); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE173);


            pushFollow(FOLLOW_tableName_in_indexTblName3895);
            indexTbl=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(indexTbl.getTree());

            // AST REWRITE
            // elements: indexTbl
            // token labels: 
            // rule labels: indexTbl, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_indexTbl=new RewriteRuleSubtreeStream(adaptor,"rule indexTbl",indexTbl!=null?indexTbl.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1038:5: -> ^( TOK_CREATEINDEX_INDEXTBLNAME $indexTbl)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1038:7: ^( TOK_CREATEINDEX_INDEXTBLNAME $indexTbl)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_CREATEINDEX_INDEXTBLNAME, "TOK_CREATEINDEX_INDEXTBLNAME")
                , root_1);

                adaptor.addChild(root_1, stream_indexTbl.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "indexTblName"


    public static class indexPropertiesPrefixed_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "indexPropertiesPrefixed"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1041:1: indexPropertiesPrefixed : KW_IDXPROPERTIES ! indexProperties ;
    public final HiveParser.indexPropertiesPrefixed_return indexPropertiesPrefixed() throws RecognitionException {
        HiveParser.indexPropertiesPrefixed_return retval = new HiveParser.indexPropertiesPrefixed_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_IDXPROPERTIES174=null;
        HiveParser.indexProperties_return indexProperties175 =null;


        ASTNode KW_IDXPROPERTIES174_tree=null;

         pushMsg("table properties with prefix", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1044:5: ( KW_IDXPROPERTIES ! indexProperties )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1045:9: KW_IDXPROPERTIES ! indexProperties
            {
            root_0 = (ASTNode)adaptor.nil();


            KW_IDXPROPERTIES174=(Token)match(input,KW_IDXPROPERTIES,FOLLOW_KW_IDXPROPERTIES_in_indexPropertiesPrefixed3942); if (state.failed) return retval;

            pushFollow(FOLLOW_indexProperties_in_indexPropertiesPrefixed3945);
            indexProperties175=indexProperties();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) adaptor.addChild(root_0, indexProperties175.getTree());

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "indexPropertiesPrefixed"


    public static class indexProperties_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "indexProperties"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1048:1: indexProperties : LPAREN indexPropertiesList RPAREN -> ^( TOK_INDEXPROPERTIES indexPropertiesList ) ;
    public final HiveParser.indexProperties_return indexProperties() throws RecognitionException {
        HiveParser.indexProperties_return retval = new HiveParser.indexProperties_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token LPAREN176=null;
        Token RPAREN178=null;
        HiveParser.indexPropertiesList_return indexPropertiesList177 =null;


        ASTNode LPAREN176_tree=null;
        ASTNode RPAREN178_tree=null;
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleSubtreeStream stream_indexPropertiesList=new RewriteRuleSubtreeStream(adaptor,"rule indexPropertiesList");
         pushMsg("index properties", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1051:5: ( LPAREN indexPropertiesList RPAREN -> ^( TOK_INDEXPROPERTIES indexPropertiesList ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1052:7: LPAREN indexPropertiesList RPAREN
            {
            LPAREN176=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_indexProperties3978); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN176);


            pushFollow(FOLLOW_indexPropertiesList_in_indexProperties3980);
            indexPropertiesList177=indexPropertiesList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_indexPropertiesList.add(indexPropertiesList177.getTree());

            RPAREN178=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_indexProperties3982); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN178);


            // AST REWRITE
            // elements: indexPropertiesList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1052:41: -> ^( TOK_INDEXPROPERTIES indexPropertiesList )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1052:44: ^( TOK_INDEXPROPERTIES indexPropertiesList )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_INDEXPROPERTIES, "TOK_INDEXPROPERTIES")
                , root_1);

                adaptor.addChild(root_1, stream_indexPropertiesList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "indexProperties"


    public static class indexPropertiesList_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "indexPropertiesList"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1055:1: indexPropertiesList : keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_INDEXPROPLIST ( keyValueProperty )+ ) ;
    public final HiveParser.indexPropertiesList_return indexPropertiesList() throws RecognitionException {
        HiveParser.indexPropertiesList_return retval = new HiveParser.indexPropertiesList_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token COMMA180=null;
        HiveParser.keyValueProperty_return keyValueProperty179 =null;

        HiveParser.keyValueProperty_return keyValueProperty181 =null;


        ASTNode COMMA180_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_keyValueProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyValueProperty");
         pushMsg("index properties list", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1058:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_INDEXPROPLIST ( keyValueProperty )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1059:7: keyValueProperty ( COMMA keyValueProperty )*
            {
            pushFollow(FOLLOW_keyValueProperty_in_indexPropertiesList4023);
            keyValueProperty179=keyValueProperty();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty179.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1059:24: ( COMMA keyValueProperty )*
            loop57:
            do {
                int alt57=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt57=1;
                    }
                    break;

                }

                switch (alt57) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1059:25: COMMA keyValueProperty
            	    {
            	    COMMA180=(Token)match(input,COMMA,FOLLOW_COMMA_in_indexPropertiesList4026); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA180);


            	    pushFollow(FOLLOW_keyValueProperty_in_indexPropertiesList4028);
            	    keyValueProperty181=keyValueProperty();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty181.getTree());

            	    }
            	    break;

            	default :
            	    break loop57;
                }
            } while (true);


            // AST REWRITE
            // elements: keyValueProperty
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1059:50: -> ^( TOK_INDEXPROPLIST ( keyValueProperty )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1059:53: ^( TOK_INDEXPROPLIST ( keyValueProperty )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_INDEXPROPLIST, "TOK_INDEXPROPLIST")
                , root_1);

                if ( !(stream_keyValueProperty.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_keyValueProperty.hasNext() ) {
                    adaptor.addChild(root_1, stream_keyValueProperty.nextTree());

                }
                stream_keyValueProperty.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "indexPropertiesList"


    public static class dropIndexStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dropIndexStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1062:1: dropIndexStatement : KW_DROP KW_INDEX ( ifExists )? indexName= identifier KW_ON tab= tableName -> ^( TOK_DROPINDEX $indexName $tab ( ifExists )? ) ;
    public final HiveParser.dropIndexStatement_return dropIndexStatement() throws RecognitionException {
        HiveParser.dropIndexStatement_return retval = new HiveParser.dropIndexStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_DROP182=null;
        Token KW_INDEX183=null;
        Token KW_ON185=null;
        HiveParser_IdentifiersParser.identifier_return indexName =null;

        HiveParser_FromClauseParser.tableName_return tab =null;

        HiveParser.ifExists_return ifExists184 =null;


        ASTNode KW_DROP182_tree=null;
        ASTNode KW_INDEX183_tree=null;
        ASTNode KW_ON185_tree=null;
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_INDEX=new RewriteRuleTokenStream(adaptor,"token KW_INDEX");
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("drop index statement", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1065:5: ( KW_DROP KW_INDEX ( ifExists )? indexName= identifier KW_ON tab= tableName -> ^( TOK_DROPINDEX $indexName $tab ( ifExists )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1065:7: KW_DROP KW_INDEX ( ifExists )? indexName= identifier KW_ON tab= tableName
            {
            KW_DROP182=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropIndexStatement4066); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP182);


            KW_INDEX183=(Token)match(input,KW_INDEX,FOLLOW_KW_INDEX_in_dropIndexStatement4068); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_INDEX.add(KW_INDEX183);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1065:24: ( ifExists )?
            int alt58=2;
            switch ( input.LA(1) ) {
                case KW_IF:
                    {
                    alt58=1;
                    }
                    break;
            }

            switch (alt58) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1065:24: ifExists
                    {
                    pushFollow(FOLLOW_ifExists_in_dropIndexStatement4070);
                    ifExists184=ifExists();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_ifExists.add(ifExists184.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_identifier_in_dropIndexStatement4075);
            indexName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(indexName.getTree());

            KW_ON185=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_dropIndexStatement4077); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON185);


            pushFollow(FOLLOW_tableName_in_dropIndexStatement4081);
            tab=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(tab.getTree());

            // AST REWRITE
            // elements: indexName, ifExists, tab
            // token labels: 
            // rule labels: tab, indexName, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.tree:null);
            RewriteRuleSubtreeStream stream_indexName=new RewriteRuleSubtreeStream(adaptor,"rule indexName",indexName!=null?indexName.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1066:5: -> ^( TOK_DROPINDEX $indexName $tab ( ifExists )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1066:7: ^( TOK_DROPINDEX $indexName $tab ( ifExists )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DROPINDEX, "TOK_DROPINDEX")
                , root_1);

                adaptor.addChild(root_1, stream_indexName.nextTree());

                adaptor.addChild(root_1, stream_tab.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1066:39: ( ifExists )?
                if ( stream_ifExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifExists.nextTree());

                }
                stream_ifExists.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dropIndexStatement"


    public static class dropTableStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dropTableStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1069:1: dropTableStatement : KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )? -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) ;
    public final HiveParser.dropTableStatement_return dropTableStatement() throws RecognitionException {
        HiveParser.dropTableStatement_return retval = new HiveParser.dropTableStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_DROP186=null;
        Token KW_TABLE187=null;
        Token KW_PURGE190=null;
        HiveParser.ifExists_return ifExists188 =null;

        HiveParser_FromClauseParser.tableName_return tableName189 =null;

        HiveParser.replicationClause_return replicationClause191 =null;


        ASTNode KW_DROP186_tree=null;
        ASTNode KW_TABLE187_tree=null;
        ASTNode KW_PURGE190_tree=null;
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_PURGE=new RewriteRuleTokenStream(adaptor,"token KW_PURGE");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
        RewriteRuleSubtreeStream stream_replicationClause=new RewriteRuleSubtreeStream(adaptor,"rule replicationClause");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("drop statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:5: ( KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )? -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:7: KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )?
            {
            KW_DROP186=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropTableStatement4126); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP186);


            KW_TABLE187=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_dropTableStatement4128); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE187);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:24: ( ifExists )?
            int alt59=2;
            switch ( input.LA(1) ) {
                case KW_IF:
                    {
                    alt59=1;
                    }
                    break;
            }

            switch (alt59) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:24: ifExists
                    {
                    pushFollow(FOLLOW_ifExists_in_dropTableStatement4130);
                    ifExists188=ifExists();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_ifExists.add(ifExists188.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_tableName_in_dropTableStatement4133);
            tableName189=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(tableName189.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:44: ( KW_PURGE )?
            int alt60=2;
            switch ( input.LA(1) ) {
                case KW_PURGE:
                    {
                    alt60=1;
                    }
                    break;
            }

            switch (alt60) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:44: KW_PURGE
                    {
                    KW_PURGE190=(Token)match(input,KW_PURGE,FOLLOW_KW_PURGE_in_dropTableStatement4135); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_PURGE.add(KW_PURGE190);


                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:54: ( replicationClause )?
            int alt61=2;
            switch ( input.LA(1) ) {
                case KW_FOR:
                    {
                    alt61=1;
                    }
                    break;
            }

            switch (alt61) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:54: replicationClause
                    {
                    pushFollow(FOLLOW_replicationClause_in_dropTableStatement4138);
                    replicationClause191=replicationClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_replicationClause.add(replicationClause191.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: KW_PURGE, replicationClause, ifExists, tableName
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1073:5: -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1073:8: ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DROPTABLE, "TOK_DROPTABLE")
                , root_1);

                adaptor.addChild(root_1, stream_tableName.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1073:34: ( ifExists )?
                if ( stream_ifExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifExists.nextTree());

                }
                stream_ifExists.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1073:44: ( KW_PURGE )?
                if ( stream_KW_PURGE.hasNext() ) {
                    adaptor.addChild(root_1, 
                    stream_KW_PURGE.nextNode()
                    );

                }
                stream_KW_PURGE.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1073:54: ( replicationClause )?
                if ( stream_replicationClause.hasNext() ) {
                    adaptor.addChild(root_1, stream_replicationClause.nextTree());

                }
                stream_replicationClause.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dropTableStatement"


    public static class alterStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1076:1: alterStatement : ( KW_ALTER KW_TABLE tableName alterTableStatementSuffix -> ^( TOK_ALTERTABLE tableName alterTableStatementSuffix ) | KW_ALTER KW_VIEW tableName ( KW_AS )? alterViewStatementSuffix -> ^( TOK_ALTERVIEW tableName alterViewStatementSuffix ) | KW_ALTER KW_INDEX alterIndexStatementSuffix -> alterIndexStatementSuffix | KW_ALTER ( KW_DATABASE | KW_SCHEMA ) alterDatabaseStatementSuffix -> alterDatabaseStatementSuffix );
    public final HiveParser.alterStatement_return alterStatement() throws RecognitionException {
        HiveParser.alterStatement_return retval = new HiveParser.alterStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_ALTER192=null;
        Token KW_TABLE193=null;
        Token KW_ALTER196=null;
        Token KW_VIEW197=null;
        Token KW_AS199=null;
        Token KW_ALTER201=null;
        Token KW_INDEX202=null;
        Token KW_ALTER204=null;
        Token KW_DATABASE205=null;
        Token KW_SCHEMA206=null;
        HiveParser_FromClauseParser.tableName_return tableName194 =null;

        HiveParser.alterTableStatementSuffix_return alterTableStatementSuffix195 =null;

        HiveParser_FromClauseParser.tableName_return tableName198 =null;

        HiveParser.alterViewStatementSuffix_return alterViewStatementSuffix200 =null;

        HiveParser.alterIndexStatementSuffix_return alterIndexStatementSuffix203 =null;

        HiveParser.alterDatabaseStatementSuffix_return alterDatabaseStatementSuffix207 =null;


        ASTNode KW_ALTER192_tree=null;
        ASTNode KW_TABLE193_tree=null;
        ASTNode KW_ALTER196_tree=null;
        ASTNode KW_VIEW197_tree=null;
        ASTNode KW_AS199_tree=null;
        ASTNode KW_ALTER201_tree=null;
        ASTNode KW_INDEX202_tree=null;
        ASTNode KW_ALTER204_tree=null;
        ASTNode KW_DATABASE205_tree=null;
        ASTNode KW_SCHEMA206_tree=null;
        RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
        RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
        RewriteRuleTokenStream stream_KW_INDEX=new RewriteRuleTokenStream(adaptor,"token KW_INDEX");
        RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
        RewriteRuleTokenStream stream_KW_ALTER=new RewriteRuleTokenStream(adaptor,"token KW_ALTER");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleSubtreeStream stream_alterTableStatementSuffix=new RewriteRuleSubtreeStream(adaptor,"rule alterTableStatementSuffix");
        RewriteRuleSubtreeStream stream_alterViewStatementSuffix=new RewriteRuleSubtreeStream(adaptor,"rule alterViewStatementSuffix");
        RewriteRuleSubtreeStream stream_alterDatabaseStatementSuffix=new RewriteRuleSubtreeStream(adaptor,"rule alterDatabaseStatementSuffix");
        RewriteRuleSubtreeStream stream_alterIndexStatementSuffix=new RewriteRuleSubtreeStream(adaptor,"rule alterIndexStatementSuffix");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("alter statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1079:5: ( KW_ALTER KW_TABLE tableName alterTableStatementSuffix -> ^( TOK_ALTERTABLE tableName alterTableStatementSuffix ) | KW_ALTER KW_VIEW tableName ( KW_AS )? alterViewStatementSuffix -> ^( TOK_ALTERVIEW tableName alterViewStatementSuffix ) | KW_ALTER KW_INDEX alterIndexStatementSuffix -> alterIndexStatementSuffix | KW_ALTER ( KW_DATABASE | KW_SCHEMA ) alterDatabaseStatementSuffix -> alterDatabaseStatementSuffix )
            int alt64=4;
            switch ( input.LA(1) ) {
            case KW_ALTER:
                {
                switch ( input.LA(2) ) {
                case KW_TABLE:
                    {
                    alt64=1;
                    }
                    break;
                case KW_VIEW:
                    {
                    alt64=2;
                    }
                    break;
                case KW_INDEX:
                    {
                    alt64=3;
                    }
                    break;
                case KW_DATABASE:
                case KW_SCHEMA:
                    {
                    alt64=4;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 64, 1, input);

                    throw nvae;

                }

                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 64, 0, input);

                throw nvae;

            }

            switch (alt64) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1079:7: KW_ALTER KW_TABLE tableName alterTableStatementSuffix
                    {
                    KW_ALTER192=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_alterStatement4187); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER192);


                    KW_TABLE193=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_alterStatement4189); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE193);


                    pushFollow(FOLLOW_tableName_in_alterStatement4191);
                    tableName194=tableName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableName.add(tableName194.getTree());

                    pushFollow(FOLLOW_alterTableStatementSuffix_in_alterStatement4193);
                    alterTableStatementSuffix195=alterTableStatementSuffix();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_alterTableStatementSuffix.add(alterTableStatementSuffix195.getTree());

                    // AST REWRITE
                    // elements: tableName, alterTableStatementSuffix
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1079:61: -> ^( TOK_ALTERTABLE tableName alterTableStatementSuffix )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1079:64: ^( TOK_ALTERTABLE tableName alterTableStatementSuffix )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERTABLE, "TOK_ALTERTABLE")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableName.nextTree());

                        adaptor.addChild(root_1, stream_alterTableStatementSuffix.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1080:7: KW_ALTER KW_VIEW tableName ( KW_AS )? alterViewStatementSuffix
                    {
                    KW_ALTER196=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_alterStatement4211); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER196);


                    KW_VIEW197=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_alterStatement4213); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW197);


                    pushFollow(FOLLOW_tableName_in_alterStatement4215);
                    tableName198=tableName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableName.add(tableName198.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1080:34: ( KW_AS )?
                    int alt62=2;
                    switch ( input.LA(1) ) {
                        case KW_AS:
                            {
                            alt62=1;
                            }
                            break;
                    }

                    switch (alt62) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1080:34: KW_AS
                            {
                            KW_AS199=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_alterStatement4217); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS199);


                            }
                            break;

                    }


                    pushFollow(FOLLOW_alterViewStatementSuffix_in_alterStatement4220);
                    alterViewStatementSuffix200=alterViewStatementSuffix();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_alterViewStatementSuffix.add(alterViewStatementSuffix200.getTree());

                    // AST REWRITE
                    // elements: alterViewStatementSuffix, tableName
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1080:66: -> ^( TOK_ALTERVIEW tableName alterViewStatementSuffix )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1080:69: ^( TOK_ALTERVIEW tableName alterViewStatementSuffix )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERVIEW, "TOK_ALTERVIEW")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableName.nextTree());

                        adaptor.addChild(root_1, stream_alterViewStatementSuffix.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1081:7: KW_ALTER KW_INDEX alterIndexStatementSuffix
                    {
                    KW_ALTER201=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_alterStatement4238); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER201);


                    KW_INDEX202=(Token)match(input,KW_INDEX,FOLLOW_KW_INDEX_in_alterStatement4240); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_INDEX.add(KW_INDEX202);


                    pushFollow(FOLLOW_alterIndexStatementSuffix_in_alterStatement4242);
                    alterIndexStatementSuffix203=alterIndexStatementSuffix();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_alterIndexStatementSuffix.add(alterIndexStatementSuffix203.getTree());

                    // AST REWRITE
                    // elements: alterIndexStatementSuffix
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1081:51: -> alterIndexStatementSuffix
                    {
                        adaptor.addChild(root_0, stream_alterIndexStatementSuffix.nextTree());

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 4 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1082:7: KW_ALTER ( KW_DATABASE | KW_SCHEMA ) alterDatabaseStatementSuffix
                    {
                    KW_ALTER204=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_alterStatement4254); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER204);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1082:16: ( KW_DATABASE | KW_SCHEMA )
                    int alt63=2;
                    switch ( input.LA(1) ) {
                    case KW_DATABASE:
                        {
                        alt63=1;
                        }
                        break;
                    case KW_SCHEMA:
                        {
                        alt63=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 63, 0, input);

                        throw nvae;

                    }

                    switch (alt63) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1082:17: KW_DATABASE
                            {
                            KW_DATABASE205=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_alterStatement4257); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE205);


                            }
                            break;
                        case 2 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1082:29: KW_SCHEMA
                            {
                            KW_SCHEMA206=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_alterStatement4259); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA206);


                            }
                            break;

                    }


                    pushFollow(FOLLOW_alterDatabaseStatementSuffix_in_alterStatement4262);
                    alterDatabaseStatementSuffix207=alterDatabaseStatementSuffix();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_alterDatabaseStatementSuffix.add(alterDatabaseStatementSuffix207.getTree());

                    // AST REWRITE
                    // elements: alterDatabaseStatementSuffix
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1082:69: -> alterDatabaseStatementSuffix
                    {
                        adaptor.addChild(root_0, stream_alterDatabaseStatementSuffix.nextTree());

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatement"


    public static class alterTableStatementSuffix_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterTableStatementSuffix"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1085:1: alterTableStatementSuffix : ( ( alterStatementSuffixRename[true] )=> alterStatementSuffixRename[true] | alterStatementSuffixDropPartitions[true] | alterStatementSuffixAddPartitions[true] | alterStatementSuffixTouch | alterStatementSuffixArchive | alterStatementSuffixUnArchive | alterStatementSuffixProperties | alterStatementSuffixSkewedby | alterStatementSuffixExchangePartition | alterStatementPartitionKeyType | alterStatementSuffixDropConstraint | alterStatementSuffixAddConstraint | ( partitionSpec )? alterTblPartitionStatementSuffix -> alterTblPartitionStatementSuffix ( partitionSpec )? );
    public final HiveParser.alterTableStatementSuffix_return alterTableStatementSuffix() throws RecognitionException {
        HiveParser.alterTableStatementSuffix_return retval = new HiveParser.alterTableStatementSuffix_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.alterStatementSuffixRename_return alterStatementSuffixRename208 =null;

        HiveParser.alterStatementSuffixDropPartitions_return alterStatementSuffixDropPartitions209 =null;

        HiveParser.alterStatementSuffixAddPartitions_return alterStatementSuffixAddPartitions210 =null;

        HiveParser.alterStatementSuffixTouch_return alterStatementSuffixTouch211 =null;

        HiveParser.alterStatementSuffixArchive_return alterStatementSuffixArchive212 =null;

        HiveParser.alterStatementSuffixUnArchive_return alterStatementSuffixUnArchive213 =null;

        HiveParser.alterStatementSuffixProperties_return alterStatementSuffixProperties214 =null;

        HiveParser.alterStatementSuffixSkewedby_return alterStatementSuffixSkewedby215 =null;

        HiveParser.alterStatementSuffixExchangePartition_return alterStatementSuffixExchangePartition216 =null;

        HiveParser.alterStatementPartitionKeyType_return alterStatementPartitionKeyType217 =null;

        HiveParser.alterStatementSuffixDropConstraint_return alterStatementSuffixDropConstraint218 =null;

        HiveParser.alterStatementSuffixAddConstraint_return alterStatementSuffixAddConstraint219 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec220 =null;

        HiveParser.alterTblPartitionStatementSuffix_return alterTblPartitionStatementSuffix221 =null;


        RewriteRuleSubtreeStream stream_alterTblPartitionStatementSuffix=new RewriteRuleSubtreeStream(adaptor,"rule alterTblPartitionStatementSuffix");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
         pushMsg("alter table statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1088:5: ( ( alterStatementSuffixRename[true] )=> alterStatementSuffixRename[true] | alterStatementSuffixDropPartitions[true] | alterStatementSuffixAddPartitions[true] | alterStatementSuffixTouch | alterStatementSuffixArchive | alterStatementSuffixUnArchive | alterStatementSuffixProperties | alterStatementSuffixSkewedby | alterStatementSuffixExchangePartition | alterStatementPartitionKeyType | alterStatementSuffixDropConstraint | alterStatementSuffixAddConstraint | ( partitionSpec )? alterTblPartitionStatementSuffix -> alterTblPartitionStatementSuffix ( partitionSpec )? )
            int alt66=13;
            switch ( input.LA(1) ) {
            case KW_RENAME:
                {
                switch ( input.LA(2) ) {
                case KW_TO:
                    {
                    int LA66_20 = input.LA(3);

                    if ( (LA66_20==Identifier) && (synpred3_HiveParser())) {
                        alt66=1;
                    }
                    else if ( ((LA66_20 >= KW_ABORT && LA66_20 <= KW_AFTER)||LA66_20==KW_ANALYZE||LA66_20==KW_ARCHIVE||LA66_20==KW_ASC||(LA66_20 >= KW_AUTOCOMMIT && LA66_20 <= KW_BEFORE)||(LA66_20 >= KW_BUCKET && LA66_20 <= KW_BUCKETS)||(LA66_20 >= KW_CACHE && LA66_20 <= KW_CASCADE)||LA66_20==KW_CHANGE||(LA66_20 >= KW_CLUSTER && LA66_20 <= KW_COLLECTION)||(LA66_20 >= KW_COLUMNS && LA66_20 <= KW_COMMENT)||(LA66_20 >= KW_COMPACT && LA66_20 <= KW_CONCATENATE)||LA66_20==KW_CONTINUE||LA66_20==KW_DATA||LA66_20==KW_DATABASES||(LA66_20 >= KW_DATETIME && LA66_20 <= KW_DBPROPERTIES)||(LA66_20 >= KW_DEFERRED && LA66_20 <= KW_DEFINED)||(LA66_20 >= KW_DELIMITED && LA66_20 <= KW_DESC)||(LA66_20 >= KW_DIRECTORIES && LA66_20 <= KW_DISABLE)||LA66_20==KW_DISTRIBUTE||LA66_20==KW_DOW||(LA66_20 >= KW_DUMP && LA66_20 <= KW_ELEM_TYPE)||LA66_20==KW_ENABLE||LA66_20==KW_ESCAPED||LA66_20==KW_EXCLUSIVE||(LA66_20 >= KW_EXPLAIN && LA66_20 <= KW_EXPORT)||(LA66_20 >= KW_FIELDS && LA66_20 <= KW_FIRST)||(LA66_20 >= KW_FORMAT && LA66_20 <= KW_FORMATTED)||LA66_20==KW_FUNCTIONS||(LA66_20 >= KW_HOUR && LA66_20 <= KW_IDXPROPERTIES)||(LA66_20 >= KW_INDEX && LA66_20 <= KW_INDEXES)||(LA66_20 >= KW_INPATH && LA66_20 <= KW_INPUTFORMAT)||(LA66_20 >= KW_ISOLATION && LA66_20 <= KW_JAR)||(LA66_20 >= KW_KEY && LA66_20 <= KW_LAST)||LA66_20==KW_LEVEL||(LA66_20 >= KW_LIMIT && LA66_20 <= KW_LOAD)||(LA66_20 >= KW_LOCATION && LA66_20 <= KW_LONG)||(LA66_20 >= KW_MAPJOIN && LA66_20 <= KW_METADATA)||(LA66_20 >= KW_MINUTE && LA66_20 <= KW_MONTH)||LA66_20==KW_MSCK||(LA66_20 >= KW_NORELY && LA66_20 <= KW_NOSCAN)||LA66_20==KW_NOVALIDATE||LA66_20==KW_NULLS||LA66_20==KW_OFFSET||LA66_20==KW_OPTION||(LA66_20 >= KW_OUTPUTDRIVER && LA66_20 <= KW_OUTPUTFORMAT)||(LA66_20 >= KW_OVERWRITE && LA66_20 <= KW_OWNER)||(LA66_20 >= KW_PARTITIONED && LA66_20 <= KW_PARTITIONS)||LA66_20==KW_PLUS||LA66_20==KW_PRETTY||LA66_20==KW_PRINCIPALS||(LA66_20 >= KW_PURGE && LA66_20 <= KW_QUARTER)||LA66_20==KW_READ||(LA66_20 >= KW_REBUILD && LA66_20 <= KW_RECORDWRITER)||(LA66_20 >= KW_RELOAD && LA66_20 <= KW_RESTRICT)||LA66_20==KW_REWRITE||(LA66_20 >= KW_ROLE && LA66_20 <= KW_ROLES)||(LA66_20 >= KW_SCHEMA && LA66_20 <= KW_SECOND)||(LA66_20 >= KW_SEMI && LA66_20 <= KW_SERVER)||(LA66_20 >= KW_SETS && LA66_20 <= KW_SKEWED)||(LA66_20 >= KW_SNAPSHOT && LA66_20 <= KW_SSL)||(LA66_20 >= KW_STATISTICS && LA66_20 <= KW_STRUCT)||LA66_20==KW_TABLES||(LA66_20 >= KW_TBLPROPERTIES && LA66_20 <= KW_TERMINATED)||LA66_20==KW_TINYINT||(LA66_20 >= KW_TOUCH && LA66_20 <= KW_TRANSACTIONS)||LA66_20==KW_UNARCHIVE||LA66_20==KW_UNDO||LA66_20==KW_UNIONTYPE||(LA66_20 >= KW_UNLOCK && LA66_20 <= KW_UNSIGNED)||(LA66_20 >= KW_URI && LA66_20 <= KW_USE)||(LA66_20 >= KW_UTC && LA66_20 <= KW_VALIDATE)||LA66_20==KW_VALUE_TYPE||(LA66_20 >= KW_VIEW && LA66_20 <= KW_WEEK)||LA66_20==KW_WHILE||(LA66_20 >= KW_WORK && LA66_20 <= KW_YEAR)||LA66_20==KW_BATCH||LA66_20==KW_DAYOFWEEK||LA66_20==KW_HOLD_DDLTIME||LA66_20==KW_IGNORE||LA66_20==KW_NO_DROP||LA66_20==KW_OFFLINE||LA66_20==KW_PROTECTION||LA66_20==KW_READONLY) && (synpred3_HiveParser())) {
                        alt66=1;
                    }
                    else if ( (LA66_20==KW_PARTITION) ) {
                        int LA66_42 = input.LA(4);

                        if ( (synpred3_HiveParser()) ) {
                            alt66=1;
                        }
                        else if ( (true) ) {
                            alt66=13;
                        }
                        else {
                            if (state.backtracking>0) {state.failed=true; return retval;}
                            NoViableAltException nvae =
                                new NoViableAltException("", 66, 42, input);

                            throw nvae;

                        }
                    }
                    else if ( ((LA66_20 >= KW_ALL && LA66_20 <= KW_ALTER)||(LA66_20 >= KW_ARRAY && LA66_20 <= KW_AS)||LA66_20==KW_AUTHORIZATION||(LA66_20 >= KW_BETWEEN && LA66_20 <= KW_BOTH)||LA66_20==KW_BY||LA66_20==KW_CONSTRAINT||LA66_20==KW_CREATE||LA66_20==KW_CUBE||(LA66_20 >= KW_CURRENT_DATE && LA66_20 <= KW_CURSOR)||LA66_20==KW_DATE||LA66_20==KW_DECIMAL||LA66_20==KW_DELETE||LA66_20==KW_DESCRIBE||LA66_20==KW_DOUBLE||LA66_20==KW_DROP||LA66_20==KW_EXISTS||LA66_20==KW_EXTERNAL||(LA66_20 >= KW_FALSE && LA66_20 <= KW_FETCH)||LA66_20==KW_FLOAT||(LA66_20 >= KW_FOR && LA66_20 <= KW_FOREIGN)||LA66_20==KW_FULL||(LA66_20 >= KW_GRANT && LA66_20 <= KW_GROUPING)||(LA66_20 >= KW_IMPORT && LA66_20 <= KW_IN)||LA66_20==KW_INNER||(LA66_20 >= KW_INSERT && LA66_20 <= KW_INTERSECT)||(LA66_20 >= KW_INTO && LA66_20 <= KW_IS)||(LA66_20 >= KW_LATERAL && LA66_20 <= KW_LEFT)||LA66_20==KW_LIKE||LA66_20==KW_LOCAL||LA66_20==KW_NONE||LA66_20==KW_NULL||LA66_20==KW_OF||(LA66_20 >= KW_ORDER && LA66_20 <= KW_OUTER)||LA66_20==KW_PERCENT||LA66_20==KW_PRIMARY||LA66_20==KW_PROCEDURE||LA66_20==KW_RANGE||LA66_20==KW_READS||(LA66_20 >= KW_REFERENCES && LA66_20 <= KW_REGEXP)||LA66_20==KW_REVOKE||(LA66_20 >= KW_RIGHT && LA66_20 <= KW_RLIKE)||(LA66_20 >= KW_ROLLUP && LA66_20 <= KW_ROWS)||LA66_20==KW_SET||LA66_20==KW_SMALLINT||LA66_20==KW_TABLE||LA66_20==KW_TIMESTAMP||LA66_20==KW_TO||(LA66_20 >= KW_TRIGGER && LA66_20 <= KW_TRUNCATE)||LA66_20==KW_UNION||LA66_20==KW_UPDATE||(LA66_20 >= KW_USER && LA66_20 <= KW_USING)||LA66_20==KW_VALUES||LA66_20==KW_WITH) && (synpred3_HiveParser())) {
                        alt66=1;
                    }
                    else {
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 66, 20, input);

                        throw nvae;

                    }
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 66, 1, input);

                    throw nvae;

                }

                }
                break;
            case KW_DROP:
                {
                switch ( input.LA(2) ) {
                case KW_CONSTRAINT:
                    {
                    alt66=11;
                    }
                    break;
                case KW_IF:
                case KW_PARTITION:
                    {
                    alt66=2;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 66, 2, input);

                    throw nvae;

                }

                }
                break;
            case KW_ADD:
                {
                switch ( input.LA(2) ) {
                case KW_IF:
                case KW_PARTITION:
                    {
                    alt66=3;
                    }
                    break;
                case KW_CONSTRAINT:
                    {
                    alt66=12;
                    }
                    break;
                case KW_COLUMNS:
                    {
                    alt66=13;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 66, 3, input);

                    throw nvae;

                }

                }
                break;
            case KW_TOUCH:
                {
                alt66=4;
                }
                break;
            case KW_ARCHIVE:
                {
                alt66=5;
                }
                break;
            case KW_UNARCHIVE:
                {
                alt66=6;
                }
                break;
            case KW_SET:
                {
                switch ( input.LA(2) ) {
                case KW_TBLPROPERTIES:
                    {
                    alt66=7;
                    }
                    break;
                case KW_FILEFORMAT:
                case KW_LOCATION:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SKEWED:
                    {
                    alt66=13;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 66, 7, input);

                    throw nvae;

                }

                }
                break;
            case KW_UNSET:
                {
                alt66=7;
                }
                break;
            case KW_SKEWED:
                {
                alt66=8;
                }
                break;
            case KW_NOT:
                {
                switch ( input.LA(2) ) {
                case KW_SKEWED:
                case KW_STORED:
                    {
                    alt66=8;
                    }
                    break;
                case KW_CLUSTERED:
                case KW_SORTED:
                    {
                    alt66=13;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 66, 10, input);

                    throw nvae;

                }

                }
                break;
            case KW_EXCHANGE:
                {
                alt66=9;
                }
                break;
            case KW_PARTITION:
                {
                switch ( input.LA(2) ) {
                case KW_COLUMN:
                    {
                    alt66=10;
                    }
                    break;
                case LPAREN:
                    {
                    alt66=13;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 66, 12, input);

                    throw nvae;

                }

                }
                break;
            case KW_CHANGE:
            case KW_CLUSTERED:
            case KW_COMPACT:
            case KW_CONCATENATE:
            case KW_INTO:
            case KW_REPLACE:
            case KW_UPDATE:
                {
                alt66=13;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 66, 0, input);

                throw nvae;

            }

            switch (alt66) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1088:7: ( alterStatementSuffixRename[true] )=> alterStatementSuffixRename[true]
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixRename_in_alterTableStatementSuffix4300);
                    alterStatementSuffixRename208=alterStatementSuffixRename(true);

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixRename208.getTree());

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1089:7: alterStatementSuffixDropPartitions[true]
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixDropPartitions_in_alterTableStatementSuffix4309);
                    alterStatementSuffixDropPartitions209=alterStatementSuffixDropPartitions(true);

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixDropPartitions209.getTree());

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1090:7: alterStatementSuffixAddPartitions[true]
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixAddPartitions_in_alterTableStatementSuffix4318);
                    alterStatementSuffixAddPartitions210=alterStatementSuffixAddPartitions(true);

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixAddPartitions210.getTree());

                    }
                    break;
                case 4 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1091:7: alterStatementSuffixTouch
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixTouch_in_alterTableStatementSuffix4327);
                    alterStatementSuffixTouch211=alterStatementSuffixTouch();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixTouch211.getTree());

                    }
                    break;
                case 5 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:7: alterStatementSuffixArchive
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixArchive_in_alterTableStatementSuffix4335);
                    alterStatementSuffixArchive212=alterStatementSuffixArchive();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixArchive212.getTree());

                    }
                    break;
                case 6 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1093:7: alterStatementSuffixUnArchive
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixUnArchive_in_alterTableStatementSuffix4343);
                    alterStatementSuffixUnArchive213=alterStatementSuffixUnArchive();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixUnArchive213.getTree());

                    }
                    break;
                case 7 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1094:7: alterStatementSuffixProperties
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixProperties_in_alterTableStatementSuffix4351);
                    alterStatementSuffixProperties214=alterStatementSuffixProperties();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixProperties214.getTree());

                    }
                    break;
                case 8 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1095:7: alterStatementSuffixSkewedby
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixSkewedby_in_alterTableStatementSuffix4359);
                    alterStatementSuffixSkewedby215=alterStatementSuffixSkewedby();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixSkewedby215.getTree());

                    }
                    break;
                case 9 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1096:7: alterStatementSuffixExchangePartition
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixExchangePartition_in_alterTableStatementSuffix4367);
                    alterStatementSuffixExchangePartition216=alterStatementSuffixExchangePartition();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixExchangePartition216.getTree());

                    }
                    break;
                case 10 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1097:7: alterStatementPartitionKeyType
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementPartitionKeyType_in_alterTableStatementSuffix4375);
                    alterStatementPartitionKeyType217=alterStatementPartitionKeyType();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementPartitionKeyType217.getTree());

                    }
                    break;
                case 11 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:7: alterStatementSuffixDropConstraint
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixDropConstraint_in_alterTableStatementSuffix4383);
                    alterStatementSuffixDropConstraint218=alterStatementSuffixDropConstraint();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixDropConstraint218.getTree());

                    }
                    break;
                case 12 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1099:7: alterStatementSuffixAddConstraint
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixAddConstraint_in_alterTableStatementSuffix4391);
                    alterStatementSuffixAddConstraint219=alterStatementSuffixAddConstraint();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixAddConstraint219.getTree());

                    }
                    break;
                case 13 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1100:7: ( partitionSpec )? alterTblPartitionStatementSuffix
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1100:7: ( partitionSpec )?
                    int alt65=2;
                    switch ( input.LA(1) ) {
                        case KW_PARTITION:
                            {
                            alt65=1;
                            }
                            break;
                    }

                    switch (alt65) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1100:7: partitionSpec
                            {
                            pushFollow(FOLLOW_partitionSpec_in_alterTableStatementSuffix4399);
                            partitionSpec220=partitionSpec();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec220.getTree());

                            }
                            break;

                    }


                    pushFollow(FOLLOW_alterTblPartitionStatementSuffix_in_alterTableStatementSuffix4402);
                    alterTblPartitionStatementSuffix221=alterTblPartitionStatementSuffix();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_alterTblPartitionStatementSuffix.add(alterTblPartitionStatementSuffix221.getTree());

                    // AST REWRITE
                    // elements: alterTblPartitionStatementSuffix, partitionSpec
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1100:55: -> alterTblPartitionStatementSuffix ( partitionSpec )?
                    {
                        adaptor.addChild(root_0, stream_alterTblPartitionStatementSuffix.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1100:91: ( partitionSpec )?
                        if ( stream_partitionSpec.hasNext() ) {
                            adaptor.addChild(root_0, stream_partitionSpec.nextTree());

                        }
                        stream_partitionSpec.reset();

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterTableStatementSuffix"


    public static class alterTblPartitionStatementSuffix_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterTblPartitionStatementSuffix"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1103:1: alterTblPartitionStatementSuffix : ( alterStatementSuffixFileFormat | alterStatementSuffixLocation | alterStatementSuffixMergeFiles | alterStatementSuffixSerdeProperties | alterStatementSuffixRenamePart | alterStatementSuffixBucketNum | alterTblPartitionStatementSuffixSkewedLocation | alterStatementSuffixClusterbySortby | alterStatementSuffixCompact | alterStatementSuffixUpdateStatsCol | alterStatementSuffixUpdateStats | alterStatementSuffixRenameCol | alterStatementSuffixAddCol );
    public final HiveParser.alterTblPartitionStatementSuffix_return alterTblPartitionStatementSuffix() throws RecognitionException {
        HiveParser.alterTblPartitionStatementSuffix_return retval = new HiveParser.alterTblPartitionStatementSuffix_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.alterStatementSuffixFileFormat_return alterStatementSuffixFileFormat222 =null;

        HiveParser.alterStatementSuffixLocation_return alterStatementSuffixLocation223 =null;

        HiveParser.alterStatementSuffixMergeFiles_return alterStatementSuffixMergeFiles224 =null;

        HiveParser.alterStatementSuffixSerdeProperties_return alterStatementSuffixSerdeProperties225 =null;

        HiveParser.alterStatementSuffixRenamePart_return alterStatementSuffixRenamePart226 =null;

        HiveParser.alterStatementSuffixBucketNum_return alterStatementSuffixBucketNum227 =null;

        HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return alterTblPartitionStatementSuffixSkewedLocation228 =null;

        HiveParser.alterStatementSuffixClusterbySortby_return alterStatementSuffixClusterbySortby229 =null;

        HiveParser.alterStatementSuffixCompact_return alterStatementSuffixCompact230 =null;

        HiveParser.alterStatementSuffixUpdateStatsCol_return alterStatementSuffixUpdateStatsCol231 =null;

        HiveParser.alterStatementSuffixUpdateStats_return alterStatementSuffixUpdateStats232 =null;

        HiveParser.alterStatementSuffixRenameCol_return alterStatementSuffixRenameCol233 =null;

        HiveParser.alterStatementSuffixAddCol_return alterStatementSuffixAddCol234 =null;



        pushMsg("alter table partition statement suffix", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1106:3: ( alterStatementSuffixFileFormat | alterStatementSuffixLocation | alterStatementSuffixMergeFiles | alterStatementSuffixSerdeProperties | alterStatementSuffixRenamePart | alterStatementSuffixBucketNum | alterTblPartitionStatementSuffixSkewedLocation | alterStatementSuffixClusterbySortby | alterStatementSuffixCompact | alterStatementSuffixUpdateStatsCol | alterStatementSuffixUpdateStats | alterStatementSuffixRenameCol | alterStatementSuffixAddCol )
            int alt67=13;
            switch ( input.LA(1) ) {
            case KW_SET:
                {
                switch ( input.LA(2) ) {
                case KW_FILEFORMAT:
                    {
                    alt67=1;
                    }
                    break;
                case KW_LOCATION:
                    {
                    alt67=2;
                    }
                    break;
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                    {
                    alt67=4;
                    }
                    break;
                case KW_SKEWED:
                    {
                    alt67=7;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 67, 1, input);

                    throw nvae;

                }

                }
                break;
            case KW_CONCATENATE:
                {
                alt67=3;
                }
                break;
            case KW_RENAME:
                {
                alt67=5;
                }
                break;
            case KW_INTO:
                {
                alt67=6;
                }
                break;
            case KW_CLUSTERED:
            case KW_NOT:
                {
                alt67=8;
                }
                break;
            case KW_COMPACT:
                {
                alt67=9;
                }
                break;
            case KW_UPDATE:
                {
                switch ( input.LA(2) ) {
                case KW_STATISTICS:
                    {
                    switch ( input.LA(3) ) {
                    case KW_FOR:
                        {
                        alt67=10;
                        }
                        break;
                    case KW_SET:
                        {
                        alt67=11;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 67, 17, input);

                        throw nvae;

                    }

                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 67, 8, input);

                    throw nvae;

                }

                }
                break;
            case KW_CHANGE:
                {
                alt67=12;
                }
                break;
            case KW_ADD:
            case KW_REPLACE:
                {
                alt67=13;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 67, 0, input);

                throw nvae;

            }

            switch (alt67) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1106:5: alterStatementSuffixFileFormat
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixFileFormat_in_alterTblPartitionStatementSuffix4434);
                    alterStatementSuffixFileFormat222=alterStatementSuffixFileFormat();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixFileFormat222.getTree());

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1107:5: alterStatementSuffixLocation
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixLocation_in_alterTblPartitionStatementSuffix4440);
                    alterStatementSuffixLocation223=alterStatementSuffixLocation();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixLocation223.getTree());

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1108:5: alterStatementSuffixMergeFiles
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixMergeFiles_in_alterTblPartitionStatementSuffix4446);
                    alterStatementSuffixMergeFiles224=alterStatementSuffixMergeFiles();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixMergeFiles224.getTree());

                    }
                    break;
                case 4 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1109:5: alterStatementSuffixSerdeProperties
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixSerdeProperties_in_alterTblPartitionStatementSuffix4452);
                    alterStatementSuffixSerdeProperties225=alterStatementSuffixSerdeProperties();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixSerdeProperties225.getTree());

                    }
                    break;
                case 5 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1110:5: alterStatementSuffixRenamePart
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixRenamePart_in_alterTblPartitionStatementSuffix4458);
                    alterStatementSuffixRenamePart226=alterStatementSuffixRenamePart();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixRenamePart226.getTree());

                    }
                    break;
                case 6 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1111:5: alterStatementSuffixBucketNum
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixBucketNum_in_alterTblPartitionStatementSuffix4464);
                    alterStatementSuffixBucketNum227=alterStatementSuffixBucketNum();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixBucketNum227.getTree());

                    }
                    break;
                case 7 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1112:5: alterTblPartitionStatementSuffixSkewedLocation
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterTblPartitionStatementSuffixSkewedLocation_in_alterTblPartitionStatementSuffix4470);
                    alterTblPartitionStatementSuffixSkewedLocation228=alterTblPartitionStatementSuffixSkewedLocation();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterTblPartitionStatementSuffixSkewedLocation228.getTree());

                    }
                    break;
                case 8 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1113:5: alterStatementSuffixClusterbySortby
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixClusterbySortby_in_alterTblPartitionStatementSuffix4476);
                    alterStatementSuffixClusterbySortby229=alterStatementSuffixClusterbySortby();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixClusterbySortby229.getTree());

                    }
                    break;
                case 9 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1114:5: alterStatementSuffixCompact
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixCompact_in_alterTblPartitionStatementSuffix4482);
                    alterStatementSuffixCompact230=alterStatementSuffixCompact();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixCompact230.getTree());

                    }
                    break;
                case 10 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1115:5: alterStatementSuffixUpdateStatsCol
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixUpdateStatsCol_in_alterTblPartitionStatementSuffix4488);
                    alterStatementSuffixUpdateStatsCol231=alterStatementSuffixUpdateStatsCol();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixUpdateStatsCol231.getTree());

                    }
                    break;
                case 11 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1116:5: alterStatementSuffixUpdateStats
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixUpdateStats_in_alterTblPartitionStatementSuffix4494);
                    alterStatementSuffixUpdateStats232=alterStatementSuffixUpdateStats();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixUpdateStats232.getTree());

                    }
                    break;
                case 12 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1117:5: alterStatementSuffixRenameCol
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixRenameCol_in_alterTblPartitionStatementSuffix4500);
                    alterStatementSuffixRenameCol233=alterStatementSuffixRenameCol();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixRenameCol233.getTree());

                    }
                    break;
                case 13 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1118:5: alterStatementSuffixAddCol
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixAddCol_in_alterTblPartitionStatementSuffix4506);
                    alterStatementSuffixAddCol234=alterStatementSuffixAddCol();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixAddCol234.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterTblPartitionStatementSuffix"


    public static class alterStatementPartitionKeyType_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementPartitionKeyType"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1121:1: alterStatementPartitionKeyType : KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN -> ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType ) ;
    public final HiveParser.alterStatementPartitionKeyType_return alterStatementPartitionKeyType() throws RecognitionException {
        HiveParser.alterStatementPartitionKeyType_return retval = new HiveParser.alterStatementPartitionKeyType_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_PARTITION235=null;
        Token KW_COLUMN236=null;
        Token LPAREN237=null;
        Token RPAREN239=null;
        HiveParser.columnNameType_return columnNameType238 =null;


        ASTNode KW_PARTITION235_tree=null;
        ASTNode KW_COLUMN236_tree=null;
        ASTNode LPAREN237_tree=null;
        ASTNode RPAREN239_tree=null;
        RewriteRuleTokenStream stream_KW_PARTITION=new RewriteRuleTokenStream(adaptor,"token KW_PARTITION");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_COLUMN=new RewriteRuleTokenStream(adaptor,"token KW_COLUMN");
        RewriteRuleSubtreeStream stream_columnNameType=new RewriteRuleSubtreeStream(adaptor,"rule columnNameType");
        msgs.push("alter partition key type"); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1124:2: ( KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN -> ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1124:4: KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN
            {
            KW_PARTITION235=(Token)match(input,KW_PARTITION,FOLLOW_KW_PARTITION_in_alterStatementPartitionKeyType4528); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_PARTITION.add(KW_PARTITION235);


            KW_COLUMN236=(Token)match(input,KW_COLUMN,FOLLOW_KW_COLUMN_in_alterStatementPartitionKeyType4530); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_COLUMN.add(KW_COLUMN236);


            LPAREN237=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_alterStatementPartitionKeyType4532); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN237);


            pushFollow(FOLLOW_columnNameType_in_alterStatementPartitionKeyType4534);
            columnNameType238=columnNameType();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnNameType.add(columnNameType238.getTree());

            RPAREN239=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_alterStatementPartitionKeyType4536); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN239);


            // AST REWRITE
            // elements: columnNameType
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1125:2: -> ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1125:5: ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_PARTCOLTYPE, "TOK_ALTERTABLE_PARTCOLTYPE")
                , root_1);

                adaptor.addChild(root_1, stream_columnNameType.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {msgs.pop();}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementPartitionKeyType"


    public static class alterViewStatementSuffix_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterViewStatementSuffix"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1128:1: alterViewStatementSuffix : ( alterViewSuffixProperties | alterStatementSuffixRename[false] | alterStatementSuffixAddPartitions[false] | alterStatementSuffixDropPartitions[false] | selectStatementWithCTE );
    public final HiveParser.alterViewStatementSuffix_return alterViewStatementSuffix() throws RecognitionException {
        HiveParser.alterViewStatementSuffix_return retval = new HiveParser.alterViewStatementSuffix_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.alterViewSuffixProperties_return alterViewSuffixProperties240 =null;

        HiveParser.alterStatementSuffixRename_return alterStatementSuffixRename241 =null;

        HiveParser.alterStatementSuffixAddPartitions_return alterStatementSuffixAddPartitions242 =null;

        HiveParser.alterStatementSuffixDropPartitions_return alterStatementSuffixDropPartitions243 =null;

        HiveParser.selectStatementWithCTE_return selectStatementWithCTE244 =null;



         pushMsg("alter view statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1131:5: ( alterViewSuffixProperties | alterStatementSuffixRename[false] | alterStatementSuffixAddPartitions[false] | alterStatementSuffixDropPartitions[false] | selectStatementWithCTE )
            int alt68=5;
            switch ( input.LA(1) ) {
            case KW_SET:
            case KW_UNSET:
                {
                alt68=1;
                }
                break;
            case KW_RENAME:
                {
                alt68=2;
                }
                break;
            case KW_ADD:
                {
                alt68=3;
                }
                break;
            case KW_DROP:
                {
                alt68=4;
                }
                break;
            case KW_MAP:
            case KW_REDUCE:
            case KW_SELECT:
            case KW_WITH:
            case LPAREN:
                {
                alt68=5;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 68, 0, input);

                throw nvae;

            }

            switch (alt68) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1131:7: alterViewSuffixProperties
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterViewSuffixProperties_in_alterViewStatementSuffix4569);
                    alterViewSuffixProperties240=alterViewSuffixProperties();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterViewSuffixProperties240.getTree());

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1132:7: alterStatementSuffixRename[false]
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixRename_in_alterViewStatementSuffix4577);
                    alterStatementSuffixRename241=alterStatementSuffixRename(false);

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixRename241.getTree());

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1133:7: alterStatementSuffixAddPartitions[false]
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixAddPartitions_in_alterViewStatementSuffix4586);
                    alterStatementSuffixAddPartitions242=alterStatementSuffixAddPartitions(false);

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixAddPartitions242.getTree());

                    }
                    break;
                case 4 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1134:7: alterStatementSuffixDropPartitions[false]
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixDropPartitions_in_alterViewStatementSuffix4595);
                    alterStatementSuffixDropPartitions243=alterStatementSuffixDropPartitions(false);

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatementSuffixDropPartitions243.getTree());

                    }
                    break;
                case 5 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1135:7: selectStatementWithCTE
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_selectStatementWithCTE_in_alterViewStatementSuffix4604);
                    selectStatementWithCTE244=selectStatementWithCTE();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, selectStatementWithCTE244.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterViewStatementSuffix"


    public static class alterIndexStatementSuffix_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterIndexStatementSuffix"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1138:1: alterIndexStatementSuffix : indexName= identifier KW_ON tableName ( partitionSpec )? ( KW_REBUILD -> ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? ) | KW_SET KW_IDXPROPERTIES indexProperties -> ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties ) ) ;
    public final HiveParser.alterIndexStatementSuffix_return alterIndexStatementSuffix() throws RecognitionException {
        HiveParser.alterIndexStatementSuffix_return retval = new HiveParser.alterIndexStatementSuffix_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_ON245=null;
        Token KW_REBUILD248=null;
        Token KW_SET249=null;
        Token KW_IDXPROPERTIES250=null;
        HiveParser_IdentifiersParser.identifier_return indexName =null;

        HiveParser_FromClauseParser.tableName_return tableName246 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec247 =null;

        HiveParser.indexProperties_return indexProperties251 =null;


        ASTNode KW_ON245_tree=null;
        ASTNode KW_REBUILD248_tree=null;
        ASTNode KW_SET249_tree=null;
        ASTNode KW_IDXPROPERTIES250_tree=null;
        RewriteRuleTokenStream stream_KW_IDXPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_IDXPROPERTIES");
        RewriteRuleTokenStream stream_KW_REBUILD=new RewriteRuleTokenStream(adaptor,"token KW_REBUILD");
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_indexProperties=new RewriteRuleSubtreeStream(adaptor,"rule indexProperties");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("alter index statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1141:5: (indexName= identifier KW_ON tableName ( partitionSpec )? ( KW_REBUILD -> ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? ) | KW_SET KW_IDXPROPERTIES indexProperties -> ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties ) ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1141:7: indexName= identifier KW_ON tableName ( partitionSpec )? ( KW_REBUILD -> ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? ) | KW_SET KW_IDXPROPERTIES indexProperties -> ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties ) )
            {
            pushFollow(FOLLOW_identifier_in_alterIndexStatementSuffix4633);
            indexName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(indexName.getTree());

            KW_ON245=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_alterIndexStatementSuffix4635); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON245);


            pushFollow(FOLLOW_tableName_in_alterIndexStatementSuffix4637);
            tableName246=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(tableName246.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1141:44: ( partitionSpec )?
            int alt69=2;
            switch ( input.LA(1) ) {
                case KW_PARTITION:
                    {
                    alt69=1;
                    }
                    break;
            }

            switch (alt69) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1141:44: partitionSpec
                    {
                    pushFollow(FOLLOW_partitionSpec_in_alterIndexStatementSuffix4639);
                    partitionSpec247=partitionSpec();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec247.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1142:5: ( KW_REBUILD -> ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? ) | KW_SET KW_IDXPROPERTIES indexProperties -> ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties ) )
            int alt70=2;
            switch ( input.LA(1) ) {
            case KW_REBUILD:
                {
                alt70=1;
                }
                break;
            case KW_SET:
                {
                alt70=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 70, 0, input);

                throw nvae;

            }

            switch (alt70) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1143:7: KW_REBUILD
                    {
                    KW_REBUILD248=(Token)match(input,KW_REBUILD,FOLLOW_KW_REBUILD_in_alterIndexStatementSuffix4654); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_REBUILD.add(KW_REBUILD248);


                    // AST REWRITE
                    // elements: tableName, indexName, partitionSpec
                    // token labels: 
                    // rule labels: indexName, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_indexName=new RewriteRuleSubtreeStream(adaptor,"rule indexName",indexName!=null?indexName.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1144:7: -> ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1144:9: ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERINDEX_REBUILD, "TOK_ALTERINDEX_REBUILD")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableName.nextTree());

                        adaptor.addChild(root_1, stream_indexName.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1144:55: ( partitionSpec )?
                        if ( stream_partitionSpec.hasNext() ) {
                            adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                        }
                        stream_partitionSpec.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1146:7: KW_SET KW_IDXPROPERTIES indexProperties
                    {
                    KW_SET249=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterIndexStatementSuffix4687); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET249);


                    KW_IDXPROPERTIES250=(Token)match(input,KW_IDXPROPERTIES,FOLLOW_KW_IDXPROPERTIES_in_alterIndexStatementSuffix4689); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_IDXPROPERTIES.add(KW_IDXPROPERTIES250);


                    pushFollow(FOLLOW_indexProperties_in_alterIndexStatementSuffix4697);
                    indexProperties251=indexProperties();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_indexProperties.add(indexProperties251.getTree());

                    // AST REWRITE
                    // elements: indexName, indexProperties, tableName
                    // token labels: 
                    // rule labels: indexName, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_indexName=new RewriteRuleSubtreeStream(adaptor,"rule indexName",indexName!=null?indexName.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1148:7: -> ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1148:9: ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERINDEX_PROPERTIES, "TOK_ALTERINDEX_PROPERTIES")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableName.nextTree());

                        adaptor.addChild(root_1, stream_indexName.nextTree());

                        adaptor.addChild(root_1, stream_indexProperties.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }


            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterIndexStatementSuffix"


    public static class alterDatabaseStatementSuffix_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterDatabaseStatementSuffix"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1152:1: alterDatabaseStatementSuffix : ( alterDatabaseSuffixProperties | alterDatabaseSuffixSetOwner );
    public final HiveParser.alterDatabaseStatementSuffix_return alterDatabaseStatementSuffix() throws RecognitionException {
        HiveParser.alterDatabaseStatementSuffix_return retval = new HiveParser.alterDatabaseStatementSuffix_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.alterDatabaseSuffixProperties_return alterDatabaseSuffixProperties252 =null;

        HiveParser.alterDatabaseSuffixSetOwner_return alterDatabaseSuffixSetOwner253 =null;



         pushMsg("alter database statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1155:5: ( alterDatabaseSuffixProperties | alterDatabaseSuffixSetOwner )
            int alt71=2;
            switch ( input.LA(1) ) {
            case Identifier:
                {
                switch ( input.LA(2) ) {
                case KW_SET:
                    {
                    switch ( input.LA(3) ) {
                    case KW_DBPROPERTIES:
                        {
                        alt71=1;
                        }
                        break;
                    case KW_OWNER:
                        {
                        alt71=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 71, 4, input);

                        throw nvae;

                    }

                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 71, 1, input);

                    throw nvae;

                }

                }
                break;
            case KW_ABORT:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ASC:
            case KW_AUTOCOMMIT:
            case KW_BEFORE:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_CACHE:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATETIME:
            case KW_DAY:
            case KW_DBPROPERTIES:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOW:
            case KW_DUMP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FUNCTIONS:
            case KW_HOUR:
            case KW_IDXPROPERTIES:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_ISOLATION:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEY:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LAST:
            case KW_LEVEL:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATCHED:
            case KW_MATERIALIZED:
            case KW_MERGE:
            case KW_METADATA:
            case KW_MINUTE:
            case KW_MONTH:
            case KW_MSCK:
            case KW_NORELY:
            case KW_NOSCAN:
            case KW_NOVALIDATE:
            case KW_NULLS:
            case KW_OFFSET:
            case KW_OPTION:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PURGE:
            case KW_QUARTER:
            case KW_READ:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_RELOAD:
            case KW_RELY:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPL:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REWRITE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SECOND:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SNAPSHOT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STATUS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TINYINT:
            case KW_TOUCH:
            case KW_TRANSACTION:
            case KW_TRANSACTIONS:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_URI:
            case KW_USE:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALIDATE:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_VIEWS:
            case KW_WEEK:
            case KW_WHILE:
            case KW_WORK:
            case KW_WRITE:
            case KW_YEAR:
            case KW_BATCH:
            case KW_DAYOFWEEK:
            case KW_HOLD_DDLTIME:
            case KW_IGNORE:
            case KW_NO_DROP:
            case KW_OFFLINE:
            case KW_PROTECTION:
            case KW_READONLY:
                {
                switch ( input.LA(2) ) {
                case KW_SET:
                    {
                    switch ( input.LA(3) ) {
                    case KW_DBPROPERTIES:
                        {
                        alt71=1;
                        }
                        break;
                    case KW_OWNER:
                        {
                        alt71=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 71, 5, input);

                        throw nvae;

                    }

                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 71, 2, input);

                    throw nvae;

                }

                }
                break;
            case KW_ALL:
            case KW_ALTER:
            case KW_ARRAY:
            case KW_AS:
            case KW_AUTHORIZATION:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BY:
            case KW_CONSTRAINT:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURRENT_DATE:
            case KW_CURRENT_TIMESTAMP:
            case KW_CURSOR:
            case KW_DATE:
            case KW_DECIMAL:
            case KW_DELETE:
            case KW_DESCRIBE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_EXISTS:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FOREIGN:
            case KW_FULL:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_IMPORT:
            case KW_IN:
            case KW_INNER:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIKE:
            case KW_LOCAL:
            case KW_NONE:
            case KW_NULL:
            case KW_OF:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_PARTITION:
            case KW_PERCENT:
            case KW_PRIMARY:
            case KW_PROCEDURE:
            case KW_RANGE:
            case KW_READS:
            case KW_REFERENCES:
            case KW_REGEXP:
            case KW_REVOKE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SET:
            case KW_SMALLINT:
            case KW_TABLE:
            case KW_TIMESTAMP:
            case KW_TO:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNION:
            case KW_UPDATE:
            case KW_USER:
            case KW_USING:
            case KW_VALUES:
            case KW_WITH:
                {
                switch ( input.LA(2) ) {
                case KW_SET:
                    {
                    switch ( input.LA(3) ) {
                    case KW_DBPROPERTIES:
                        {
                        alt71=1;
                        }
                        break;
                    case KW_OWNER:
                        {
                        alt71=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 71, 6, input);

                        throw nvae;

                    }

                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 71, 3, input);

                    throw nvae;

                }

                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 71, 0, input);

                throw nvae;

            }

            switch (alt71) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1155:7: alterDatabaseSuffixProperties
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterDatabaseSuffixProperties_in_alterDatabaseStatementSuffix4748);
                    alterDatabaseSuffixProperties252=alterDatabaseSuffixProperties();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterDatabaseSuffixProperties252.getTree());

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1156:7: alterDatabaseSuffixSetOwner
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_alterDatabaseSuffixSetOwner_in_alterDatabaseStatementSuffix4756);
                    alterDatabaseSuffixSetOwner253=alterDatabaseSuffixSetOwner();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, alterDatabaseSuffixSetOwner253.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterDatabaseStatementSuffix"


    public static class alterDatabaseSuffixProperties_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterDatabaseSuffixProperties"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1159:1: alterDatabaseSuffixProperties : name= identifier KW_SET KW_DBPROPERTIES dbProperties -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties ) ;
    public final HiveParser.alterDatabaseSuffixProperties_return alterDatabaseSuffixProperties() throws RecognitionException {
        HiveParser.alterDatabaseSuffixProperties_return retval = new HiveParser.alterDatabaseSuffixProperties_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_SET254=null;
        Token KW_DBPROPERTIES255=null;
        HiveParser_IdentifiersParser.identifier_return name =null;

        HiveParser.dbProperties_return dbProperties256 =null;


        ASTNode KW_SET254_tree=null;
        ASTNode KW_DBPROPERTIES255_tree=null;
        RewriteRuleTokenStream stream_KW_DBPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_DBPROPERTIES");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_dbProperties=new RewriteRuleSubtreeStream(adaptor,"rule dbProperties");
         pushMsg("alter database properties statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1162:5: (name= identifier KW_SET KW_DBPROPERTIES dbProperties -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1162:7: name= identifier KW_SET KW_DBPROPERTIES dbProperties
            {
            pushFollow(FOLLOW_identifier_in_alterDatabaseSuffixProperties4785);
            name=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(name.getTree());

            KW_SET254=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterDatabaseSuffixProperties4787); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET254);


            KW_DBPROPERTIES255=(Token)match(input,KW_DBPROPERTIES,FOLLOW_KW_DBPROPERTIES_in_alterDatabaseSuffixProperties4789); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DBPROPERTIES.add(KW_DBPROPERTIES255);


            pushFollow(FOLLOW_dbProperties_in_alterDatabaseSuffixProperties4791);
            dbProperties256=dbProperties();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_dbProperties.add(dbProperties256.getTree());

            // AST REWRITE
            // elements: name, dbProperties
            // token labels: 
            // rule labels: name, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1163:5: -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1163:8: ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERDATABASE_PROPERTIES, "TOK_ALTERDATABASE_PROPERTIES")
                , root_1);

                adaptor.addChild(root_1, stream_name.nextTree());

                adaptor.addChild(root_1, stream_dbProperties.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterDatabaseSuffixProperties"


    public static class alterDatabaseSuffixSetOwner_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterDatabaseSuffixSetOwner"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1166:1: alterDatabaseSuffixSetOwner : dbName= identifier KW_SET KW_OWNER principalName -> ^( TOK_ALTERDATABASE_OWNER $dbName principalName ) ;
    public final HiveParser.alterDatabaseSuffixSetOwner_return alterDatabaseSuffixSetOwner() throws RecognitionException {
        HiveParser.alterDatabaseSuffixSetOwner_return retval = new HiveParser.alterDatabaseSuffixSetOwner_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_SET257=null;
        Token KW_OWNER258=null;
        HiveParser_IdentifiersParser.identifier_return dbName =null;

        HiveParser.principalName_return principalName259 =null;


        ASTNode KW_SET257_tree=null;
        ASTNode KW_OWNER258_tree=null;
        RewriteRuleTokenStream stream_KW_OWNER=new RewriteRuleTokenStream(adaptor,"token KW_OWNER");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");
         pushMsg("alter database set owner", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1169:5: (dbName= identifier KW_SET KW_OWNER principalName -> ^( TOK_ALTERDATABASE_OWNER $dbName principalName ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1169:7: dbName= identifier KW_SET KW_OWNER principalName
            {
            pushFollow(FOLLOW_identifier_in_alterDatabaseSuffixSetOwner4835);
            dbName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());

            KW_SET257=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterDatabaseSuffixSetOwner4837); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET257);


            KW_OWNER258=(Token)match(input,KW_OWNER,FOLLOW_KW_OWNER_in_alterDatabaseSuffixSetOwner4839); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_OWNER.add(KW_OWNER258);


            pushFollow(FOLLOW_principalName_in_alterDatabaseSuffixSetOwner4841);
            principalName259=principalName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_principalName.add(principalName259.getTree());

            // AST REWRITE
            // elements: dbName, principalName
            // token labels: 
            // rule labels: dbName, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1170:5: -> ^( TOK_ALTERDATABASE_OWNER $dbName principalName )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1170:8: ^( TOK_ALTERDATABASE_OWNER $dbName principalName )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERDATABASE_OWNER, "TOK_ALTERDATABASE_OWNER")
                , root_1);

                adaptor.addChild(root_1, stream_dbName.nextTree());

                adaptor.addChild(root_1, stream_principalName.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterDatabaseSuffixSetOwner"


    public static class alterStatementSuffixRename_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixRename"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1173:1: alterStatementSuffixRename[boolean table] : KW_RENAME KW_TO tableName -> { table }? ^( TOK_ALTERTABLE_RENAME tableName ) -> ^( TOK_ALTERVIEW_RENAME tableName ) ;
    public final HiveParser.alterStatementSuffixRename_return alterStatementSuffixRename(boolean table) throws RecognitionException {
        HiveParser.alterStatementSuffixRename_return retval = new HiveParser.alterStatementSuffixRename_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_RENAME260=null;
        Token KW_TO261=null;
        HiveParser_FromClauseParser.tableName_return tableName262 =null;


        ASTNode KW_RENAME260_tree=null;
        ASTNode KW_TO261_tree=null;
        RewriteRuleTokenStream stream_KW_RENAME=new RewriteRuleTokenStream(adaptor,"token KW_RENAME");
        RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("rename statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1176:5: ( KW_RENAME KW_TO tableName -> { table }? ^( TOK_ALTERTABLE_RENAME tableName ) -> ^( TOK_ALTERVIEW_RENAME tableName ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1176:7: KW_RENAME KW_TO tableName
            {
            KW_RENAME260=(Token)match(input,KW_RENAME,FOLLOW_KW_RENAME_in_alterStatementSuffixRename4884); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_RENAME.add(KW_RENAME260);


            KW_TO261=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_alterStatementSuffixRename4886); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO261);


            pushFollow(FOLLOW_tableName_in_alterStatementSuffixRename4888);
            tableName262=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(tableName262.getTree());

            // AST REWRITE
            // elements: tableName, tableName
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1177:5: -> { table }? ^( TOK_ALTERTABLE_RENAME tableName )
            if ( table ) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:19: ^( TOK_ALTERTABLE_RENAME tableName )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_RENAME, "TOK_ALTERTABLE_RENAME")
                , root_1);

                adaptor.addChild(root_1, stream_tableName.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 1178:5: -> ^( TOK_ALTERVIEW_RENAME tableName )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1178:19: ^( TOK_ALTERVIEW_RENAME tableName )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERVIEW_RENAME, "TOK_ALTERVIEW_RENAME")
                , root_1);

                adaptor.addChild(root_1, stream_tableName.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixRename"


    public static class alterStatementSuffixAddCol_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixAddCol"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1181:1: alterStatementSuffixAddCol : (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN ( restrictOrCascade )? -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? ) -> ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? ) ;
    public final HiveParser.alterStatementSuffixAddCol_return alterStatementSuffixAddCol() throws RecognitionException {
        HiveParser.alterStatementSuffixAddCol_return retval = new HiveParser.alterStatementSuffixAddCol_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token add=null;
        Token replace=null;
        Token KW_COLUMNS263=null;
        Token LPAREN264=null;
        Token RPAREN266=null;
        HiveParser.columnNameTypeList_return columnNameTypeList265 =null;

        HiveParser.restrictOrCascade_return restrictOrCascade267 =null;


        ASTNode add_tree=null;
        ASTNode replace_tree=null;
        ASTNode KW_COLUMNS263_tree=null;
        ASTNode LPAREN264_tree=null;
        ASTNode RPAREN266_tree=null;
        RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_REPLACE=new RewriteRuleTokenStream(adaptor,"token KW_REPLACE");
        RewriteRuleTokenStream stream_KW_ADD=new RewriteRuleTokenStream(adaptor,"token KW_ADD");
        RewriteRuleSubtreeStream stream_columnNameTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeList");
        RewriteRuleSubtreeStream stream_restrictOrCascade=new RewriteRuleSubtreeStream(adaptor,"rule restrictOrCascade");
         pushMsg("add column statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1184:5: ( (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN ( restrictOrCascade )? -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? ) -> ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1184:7: (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN ( restrictOrCascade )?
            {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1184:7: (add= KW_ADD |replace= KW_REPLACE )
            int alt72=2;
            switch ( input.LA(1) ) {
            case KW_ADD:
                {
                alt72=1;
                }
                break;
            case KW_REPLACE:
                {
                alt72=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 72, 0, input);

                throw nvae;

            }

            switch (alt72) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1184:8: add= KW_ADD
                    {
                    add=(Token)match(input,KW_ADD,FOLLOW_KW_ADD_in_alterStatementSuffixAddCol4955); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ADD.add(add);


                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1184:21: replace= KW_REPLACE
                    {
                    replace=(Token)match(input,KW_REPLACE,FOLLOW_KW_REPLACE_in_alterStatementSuffixAddCol4961); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_REPLACE.add(replace);


                    }
                    break;

            }


            KW_COLUMNS263=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_alterStatementSuffixAddCol4964); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS263);


            LPAREN264=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_alterStatementSuffixAddCol4966); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN264);


            pushFollow(FOLLOW_columnNameTypeList_in_alterStatementSuffixAddCol4968);
            columnNameTypeList265=columnNameTypeList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnNameTypeList.add(columnNameTypeList265.getTree());

            RPAREN266=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_alterStatementSuffixAddCol4970); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN266);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1184:85: ( restrictOrCascade )?
            int alt73=2;
            switch ( input.LA(1) ) {
                case KW_CASCADE:
                case KW_RESTRICT:
                    {
                    alt73=1;
                    }
                    break;
            }

            switch (alt73) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1184:85: restrictOrCascade
                    {
                    pushFollow(FOLLOW_restrictOrCascade_in_alterStatementSuffixAddCol4972);
                    restrictOrCascade267=restrictOrCascade();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_restrictOrCascade.add(restrictOrCascade267.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: restrictOrCascade, columnNameTypeList, restrictOrCascade, columnNameTypeList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1185:5: -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? )
            if (add != null) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1185:24: ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_ADDCOLS, "TOK_ALTERTABLE_ADDCOLS")
                , root_1);

                adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1185:68: ( restrictOrCascade )?
                if ( stream_restrictOrCascade.hasNext() ) {
                    adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());

                }
                stream_restrictOrCascade.reset();

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 1186:5: -> ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1186:24: ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_REPLACECOLS, "TOK_ALTERTABLE_REPLACECOLS")
                , root_1);

                adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1186:72: ( restrictOrCascade )?
                if ( stream_restrictOrCascade.hasNext() ) {
                    adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());

                }
                stream_restrictOrCascade.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixAddCol"


    public static class alterStatementSuffixAddConstraint_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixAddConstraint"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1189:1: alterStatementSuffixAddConstraint : KW_ADD (fk= foreignKeyWithName | primaryKeyWithName ) -> {fk != null}? ^( TOK_ALTERTABLE_ADDCONSTRAINT foreignKeyWithName ) -> ^( TOK_ALTERTABLE_ADDCONSTRAINT primaryKeyWithName ) ;
    public final HiveParser.alterStatementSuffixAddConstraint_return alterStatementSuffixAddConstraint() throws RecognitionException {
        HiveParser.alterStatementSuffixAddConstraint_return retval = new HiveParser.alterStatementSuffixAddConstraint_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_ADD268=null;
        HiveParser.foreignKeyWithName_return fk =null;

        HiveParser.primaryKeyWithName_return primaryKeyWithName269 =null;


        ASTNode KW_ADD268_tree=null;
        RewriteRuleTokenStream stream_KW_ADD=new RewriteRuleTokenStream(adaptor,"token KW_ADD");
        RewriteRuleSubtreeStream stream_foreignKeyWithName=new RewriteRuleSubtreeStream(adaptor,"rule foreignKeyWithName");
        RewriteRuleSubtreeStream stream_primaryKeyWithName=new RewriteRuleSubtreeStream(adaptor,"rule primaryKeyWithName");
         pushMsg("add constraint statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:4: ( KW_ADD (fk= foreignKeyWithName | primaryKeyWithName ) -> {fk != null}? ^( TOK_ALTERTABLE_ADDCONSTRAINT foreignKeyWithName ) -> ^( TOK_ALTERTABLE_ADDCONSTRAINT primaryKeyWithName ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:7: KW_ADD (fk= foreignKeyWithName | primaryKeyWithName )
            {
            KW_ADD268=(Token)match(input,KW_ADD,FOLLOW_KW_ADD_in_alterStatementSuffixAddConstraint5048); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ADD.add(KW_ADD268);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:14: (fk= foreignKeyWithName | primaryKeyWithName )
            int alt74=2;
            switch ( input.LA(1) ) {
            case KW_CONSTRAINT:
                {
                switch ( input.LA(2) ) {
                case Identifier:
                    {
                    switch ( input.LA(3) ) {
                    case KW_FOREIGN:
                        {
                        alt74=1;
                        }
                        break;
                    case KW_PRIMARY:
                        {
                        alt74=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 74, 2, input);

                        throw nvae;

                    }

                    }
                    break;
                case KW_ABORT:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ASC:
                case KW_AUTOCOMMIT:
                case KW_BEFORE:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_CACHE:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATETIME:
                case KW_DAY:
                case KW_DBPROPERTIES:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOW:
                case KW_DUMP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FUNCTIONS:
                case KW_HOUR:
                case KW_IDXPROPERTIES:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_ISOLATION:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEY:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LAST:
                case KW_LEVEL:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATCHED:
                case KW_MATERIALIZED:
                case KW_MERGE:
                case KW_METADATA:
                case KW_MINUTE:
                case KW_MONTH:
                case KW_MSCK:
                case KW_NORELY:
                case KW_NOSCAN:
                case KW_NOVALIDATE:
                case KW_NULLS:
                case KW_OFFSET:
                case KW_OPTION:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PURGE:
                case KW_QUARTER:
                case KW_READ:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_RELOAD:
                case KW_RELY:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPL:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REWRITE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SECOND:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SNAPSHOT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STATUS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TINYINT:
                case KW_TOUCH:
                case KW_TRANSACTION:
                case KW_TRANSACTIONS:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_URI:
                case KW_USE:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALIDATE:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_VIEWS:
                case KW_WEEK:
                case KW_WHILE:
                case KW_WORK:
                case KW_WRITE:
                case KW_YEAR:
                case KW_BATCH:
                case KW_DAYOFWEEK:
                case KW_HOLD_DDLTIME:
                case KW_IGNORE:
                case KW_NO_DROP:
                case KW_OFFLINE:
                case KW_PROTECTION:
                case KW_READONLY:
                    {
                    switch ( input.LA(3) ) {
                    case KW_FOREIGN:
                        {
                        alt74=1;
                        }
                        break;
                    case KW_PRIMARY:
                        {
                        alt74=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 74, 3, input);

                        throw nvae;

                    }

                    }
                    break;
                case KW_ALL:
                case KW_ALTER:
                case KW_ARRAY:
                case KW_AS:
                case KW_AUTHORIZATION:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BY:
                case KW_CONSTRAINT:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURRENT_DATE:
                case KW_CURRENT_TIMESTAMP:
                case KW_CURSOR:
                case KW_DATE:
                case KW_DECIMAL:
                case KW_DELETE:
                case KW_DESCRIBE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_EXISTS:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FOREIGN:
                case KW_FULL:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_IMPORT:
                case KW_IN:
                case KW_INNER:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LOCAL:
                case KW_NONE:
                case KW_NULL:
                case KW_OF:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_PARTITION:
                case KW_PERCENT:
                case KW_PRIMARY:
                case KW_PROCEDURE:
                case KW_RANGE:
                case KW_READS:
                case KW_REFERENCES:
                case KW_REGEXP:
                case KW_REVOKE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SET:
                case KW_SMALLINT:
                case KW_TABLE:
                case KW_TIMESTAMP:
                case KW_TO:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNION:
                case KW_UPDATE:
                case KW_USER:
                case KW_USING:
                case KW_VALUES:
                case KW_WITH:
                    {
                    switch ( input.LA(3) ) {
                    case KW_FOREIGN:
                        {
                        alt74=1;
                        }
                        break;
                    case KW_PRIMARY:
                        {
                        alt74=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 74, 4, input);

                        throw nvae;

                    }

                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 74, 1, input);

                    throw nvae;

                }

                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 74, 0, input);

                throw nvae;

            }

            switch (alt74) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:15: fk= foreignKeyWithName
                    {
                    pushFollow(FOLLOW_foreignKeyWithName_in_alterStatementSuffixAddConstraint5053);
                    fk=foreignKeyWithName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_foreignKeyWithName.add(fk.getTree());

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:39: primaryKeyWithName
                    {
                    pushFollow(FOLLOW_primaryKeyWithName_in_alterStatementSuffixAddConstraint5057);
                    primaryKeyWithName269=primaryKeyWithName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_primaryKeyWithName.add(primaryKeyWithName269.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: primaryKeyWithName, foreignKeyWithName
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1193:4: -> {fk != null}? ^( TOK_ALTERTABLE_ADDCONSTRAINT foreignKeyWithName )
            if (fk != null) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1193:21: ^( TOK_ALTERTABLE_ADDCONSTRAINT foreignKeyWithName )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_ADDCONSTRAINT, "TOK_ALTERTABLE_ADDCONSTRAINT")
                , root_1);

                adaptor.addChild(root_1, stream_foreignKeyWithName.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 1194:4: -> ^( TOK_ALTERTABLE_ADDCONSTRAINT primaryKeyWithName )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1194:21: ^( TOK_ALTERTABLE_ADDCONSTRAINT primaryKeyWithName )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_ADDCONSTRAINT, "TOK_ALTERTABLE_ADDCONSTRAINT")
                , root_1);

                adaptor.addChild(root_1, stream_primaryKeyWithName.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixAddConstraint"


    public static class alterStatementSuffixDropConstraint_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixDropConstraint"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1197:1: alterStatementSuffixDropConstraint : KW_DROP KW_CONSTRAINT cName= identifier -> ^( TOK_ALTERTABLE_DROPCONSTRAINT $cName) ;
    public final HiveParser.alterStatementSuffixDropConstraint_return alterStatementSuffixDropConstraint() throws RecognitionException {
        HiveParser.alterStatementSuffixDropConstraint_return retval = new HiveParser.alterStatementSuffixDropConstraint_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_DROP270=null;
        Token KW_CONSTRAINT271=null;
        HiveParser_IdentifiersParser.identifier_return cName =null;


        ASTNode KW_DROP270_tree=null;
        ASTNode KW_CONSTRAINT271_tree=null;
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         pushMsg("drop constraint statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1200:4: ( KW_DROP KW_CONSTRAINT cName= identifier -> ^( TOK_ALTERTABLE_DROPCONSTRAINT $cName) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1200:6: KW_DROP KW_CONSTRAINT cName= identifier
            {
            KW_DROP270=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_alterStatementSuffixDropConstraint5121); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP270);


            KW_CONSTRAINT271=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_alterStatementSuffixDropConstraint5123); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT271);


            pushFollow(FOLLOW_identifier_in_alterStatementSuffixDropConstraint5127);
            cName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(cName.getTree());

            // AST REWRITE
            // elements: cName
            // token labels: 
            // rule labels: cName, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_cName=new RewriteRuleSubtreeStream(adaptor,"rule cName",cName!=null?cName.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1201:4: -> ^( TOK_ALTERTABLE_DROPCONSTRAINT $cName)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1201:6: ^( TOK_ALTERTABLE_DROPCONSTRAINT $cName)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_DROPCONSTRAINT, "TOK_ALTERTABLE_DROPCONSTRAINT")
                , root_1);

                adaptor.addChild(root_1, stream_cName.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixDropConstraint"


    public static class alterStatementSuffixRenameCol_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixRenameCol"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1204:1: alterStatementSuffixRenameCol : KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? -> ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterStatementChangeColPosition )? ( restrictOrCascade )? ) ;
    public final HiveParser.alterStatementSuffixRenameCol_return alterStatementSuffixRenameCol() throws RecognitionException {
        HiveParser.alterStatementSuffixRenameCol_return retval = new HiveParser.alterStatementSuffixRenameCol_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token comment=null;
        Token KW_CHANGE272=null;
        Token KW_COLUMN273=null;
        Token KW_COMMENT275=null;
        HiveParser_IdentifiersParser.identifier_return oldName =null;

        HiveParser_IdentifiersParser.identifier_return newName =null;

        HiveParser.colType_return colType274 =null;

        HiveParser.alterStatementChangeColPosition_return alterStatementChangeColPosition276 =null;

        HiveParser.restrictOrCascade_return restrictOrCascade277 =null;


        ASTNode comment_tree=null;
        ASTNode KW_CHANGE272_tree=null;
        ASTNode KW_COLUMN273_tree=null;
        ASTNode KW_COMMENT275_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
        RewriteRuleTokenStream stream_KW_COLUMN=new RewriteRuleTokenStream(adaptor,"token KW_COLUMN");
        RewriteRuleTokenStream stream_KW_CHANGE=new RewriteRuleTokenStream(adaptor,"token KW_CHANGE");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");
        RewriteRuleSubtreeStream stream_alterStatementChangeColPosition=new RewriteRuleSubtreeStream(adaptor,"rule alterStatementChangeColPosition");
        RewriteRuleSubtreeStream stream_restrictOrCascade=new RewriteRuleSubtreeStream(adaptor,"rule restrictOrCascade");
         pushMsg("rename column name", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1207:5: ( KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? -> ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterStatementChangeColPosition )? ( restrictOrCascade )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1207:7: KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? ( restrictOrCascade )?
            {
            KW_CHANGE272=(Token)match(input,KW_CHANGE,FOLLOW_KW_CHANGE_in_alterStatementSuffixRenameCol5164); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_CHANGE.add(KW_CHANGE272);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1207:17: ( KW_COLUMN )?
            int alt75=2;
            switch ( input.LA(1) ) {
                case KW_COLUMN:
                    {
                    alt75=1;
                    }
                    break;
            }

            switch (alt75) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1207:17: KW_COLUMN
                    {
                    KW_COLUMN273=(Token)match(input,KW_COLUMN,FOLLOW_KW_COLUMN_in_alterStatementSuffixRenameCol5166); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_COLUMN.add(KW_COLUMN273);


                    }
                    break;

            }


            pushFollow(FOLLOW_identifier_in_alterStatementSuffixRenameCol5171);
            oldName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(oldName.getTree());

            pushFollow(FOLLOW_identifier_in_alterStatementSuffixRenameCol5175);
            newName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(newName.getTree());

            pushFollow(FOLLOW_colType_in_alterStatementSuffixRenameCol5177);
            colType274=colType();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_colType.add(colType274.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1207:74: ( KW_COMMENT comment= StringLiteral )?
            int alt76=2;
            switch ( input.LA(1) ) {
                case KW_COMMENT:
                    {
                    alt76=1;
                    }
                    break;
            }

            switch (alt76) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1207:75: KW_COMMENT comment= StringLiteral
                    {
                    KW_COMMENT275=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_alterStatementSuffixRenameCol5180); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT275);


                    comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixRenameCol5184); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(comment);


                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1207:110: ( alterStatementChangeColPosition )?
            int alt77=2;
            switch ( input.LA(1) ) {
                case KW_AFTER:
                case KW_FIRST:
                    {
                    alt77=1;
                    }
                    break;
            }

            switch (alt77) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1207:110: alterStatementChangeColPosition
                    {
                    pushFollow(FOLLOW_alterStatementChangeColPosition_in_alterStatementSuffixRenameCol5188);
                    alterStatementChangeColPosition276=alterStatementChangeColPosition();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_alterStatementChangeColPosition.add(alterStatementChangeColPosition276.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1207:143: ( restrictOrCascade )?
            int alt78=2;
            switch ( input.LA(1) ) {
                case KW_CASCADE:
                case KW_RESTRICT:
                    {
                    alt78=1;
                    }
                    break;
            }

            switch (alt78) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1207:143: restrictOrCascade
                    {
                    pushFollow(FOLLOW_restrictOrCascade_in_alterStatementSuffixRenameCol5191);
                    restrictOrCascade277=restrictOrCascade();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_restrictOrCascade.add(restrictOrCascade277.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: comment, oldName, restrictOrCascade, alterStatementChangeColPosition, newName, colType
            // token labels: comment
            // rule labels: newName, oldName, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
            RewriteRuleSubtreeStream stream_newName=new RewriteRuleSubtreeStream(adaptor,"rule newName",newName!=null?newName.tree:null);
            RewriteRuleSubtreeStream stream_oldName=new RewriteRuleSubtreeStream(adaptor,"rule oldName",oldName!=null?oldName.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1208:5: -> ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterStatementChangeColPosition )? ( restrictOrCascade )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1208:7: ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterStatementChangeColPosition )? ( restrictOrCascade )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_RENAMECOL, "TOK_ALTERTABLE_RENAMECOL")
                , root_1);

                adaptor.addChild(root_1, stream_oldName.nextTree());

                adaptor.addChild(root_1, stream_newName.nextTree());

                adaptor.addChild(root_1, stream_colType.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1208:61: ( $comment)?
                if ( stream_comment.hasNext() ) {
                    adaptor.addChild(root_1, stream_comment.nextNode());

                }
                stream_comment.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1208:70: ( alterStatementChangeColPosition )?
                if ( stream_alterStatementChangeColPosition.hasNext() ) {
                    adaptor.addChild(root_1, stream_alterStatementChangeColPosition.nextTree());

                }
                stream_alterStatementChangeColPosition.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1208:103: ( restrictOrCascade )?
                if ( stream_restrictOrCascade.hasNext() ) {
                    adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());

                }
                stream_restrictOrCascade.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixRenameCol"


    public static class alterStatementSuffixUpdateStatsCol_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixUpdateStatsCol"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1211:1: alterStatementSuffixUpdateStatsCol : KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) ;
    public final HiveParser.alterStatementSuffixUpdateStatsCol_return alterStatementSuffixUpdateStatsCol() throws RecognitionException {
        HiveParser.alterStatementSuffixUpdateStatsCol_return retval = new HiveParser.alterStatementSuffixUpdateStatsCol_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token comment=null;
        Token KW_UPDATE278=null;
        Token KW_STATISTICS279=null;
        Token KW_FOR280=null;
        Token KW_COLUMN281=null;
        Token KW_SET282=null;
        Token KW_COMMENT284=null;
        HiveParser_IdentifiersParser.identifier_return colName =null;

        HiveParser.tableProperties_return tableProperties283 =null;


        ASTNode comment_tree=null;
        ASTNode KW_UPDATE278_tree=null;
        ASTNode KW_STATISTICS279_tree=null;
        ASTNode KW_FOR280_tree=null;
        ASTNode KW_COLUMN281_tree=null;
        ASTNode KW_SET282_tree=null;
        ASTNode KW_COMMENT284_tree=null;
        RewriteRuleTokenStream stream_KW_STATISTICS=new RewriteRuleTokenStream(adaptor,"token KW_STATISTICS");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
        RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
        RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
        RewriteRuleTokenStream stream_KW_COLUMN=new RewriteRuleTokenStream(adaptor,"token KW_COLUMN");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
         pushMsg("update column statistics", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1214:5: ( KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1214:7: KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )?
            {
            KW_UPDATE278=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateStatsCol5246); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE278);


            KW_STATISTICS279=(Token)match(input,KW_STATISTICS,FOLLOW_KW_STATISTICS_in_alterStatementSuffixUpdateStatsCol5248); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_STATISTICS.add(KW_STATISTICS279);


            KW_FOR280=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_alterStatementSuffixUpdateStatsCol5250); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR280);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1214:38: ( KW_COLUMN )?
            int alt79=2;
            switch ( input.LA(1) ) {
                case KW_COLUMN:
                    {
                    alt79=1;
                    }
                    break;
            }

            switch (alt79) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1214:38: KW_COLUMN
                    {
                    KW_COLUMN281=(Token)match(input,KW_COLUMN,FOLLOW_KW_COLUMN_in_alterStatementSuffixUpdateStatsCol5252); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_COLUMN.add(KW_COLUMN281);


                    }
                    break;

            }


            pushFollow(FOLLOW_identifier_in_alterStatementSuffixUpdateStatsCol5257);
            colName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());

            KW_SET282=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixUpdateStatsCol5259); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET282);


            pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixUpdateStatsCol5261);
            tableProperties283=tableProperties();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties283.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1214:91: ( KW_COMMENT comment= StringLiteral )?
            int alt80=2;
            switch ( input.LA(1) ) {
                case KW_COMMENT:
                    {
                    alt80=1;
                    }
                    break;
            }

            switch (alt80) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1214:92: KW_COMMENT comment= StringLiteral
                    {
                    KW_COMMENT284=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_alterStatementSuffixUpdateStatsCol5264); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT284);


                    comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixUpdateStatsCol5268); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(comment);


                    }
                    break;

            }


            // AST REWRITE
            // elements: tableProperties, comment, colName
            // token labels: comment
            // rule labels: colName, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
            RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1215:5: -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:7: ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_UPDATECOLSTATS, "TOK_ALTERTABLE_UPDATECOLSTATS")
                , root_1);

                adaptor.addChild(root_1, stream_colName.nextTree());

                adaptor.addChild(root_1, stream_tableProperties.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:65: ( $comment)?
                if ( stream_comment.hasNext() ) {
                    adaptor.addChild(root_1, stream_comment.nextNode());

                }
                stream_comment.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixUpdateStatsCol"


    public static class alterStatementSuffixUpdateStats_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixUpdateStats"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:1: alterStatementSuffixUpdateStats : KW_UPDATE KW_STATISTICS KW_SET tableProperties -> ^( TOK_ALTERTABLE_UPDATESTATS tableProperties ) ;
    public final HiveParser.alterStatementSuffixUpdateStats_return alterStatementSuffixUpdateStats() throws RecognitionException {
        HiveParser.alterStatementSuffixUpdateStats_return retval = new HiveParser.alterStatementSuffixUpdateStats_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_UPDATE285=null;
        Token KW_STATISTICS286=null;
        Token KW_SET287=null;
        HiveParser.tableProperties_return tableProperties288 =null;


        ASTNode KW_UPDATE285_tree=null;
        ASTNode KW_STATISTICS286_tree=null;
        ASTNode KW_SET287_tree=null;
        RewriteRuleTokenStream stream_KW_STATISTICS=new RewriteRuleTokenStream(adaptor,"token KW_STATISTICS");
        RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
         pushMsg("update basic statistics", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1221:5: ( KW_UPDATE KW_STATISTICS KW_SET tableProperties -> ^( TOK_ALTERTABLE_UPDATESTATS tableProperties ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1221:7: KW_UPDATE KW_STATISTICS KW_SET tableProperties
            {
            KW_UPDATE285=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateStats5315); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE285);


            KW_STATISTICS286=(Token)match(input,KW_STATISTICS,FOLLOW_KW_STATISTICS_in_alterStatementSuffixUpdateStats5317); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_STATISTICS.add(KW_STATISTICS286);


            KW_SET287=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixUpdateStats5319); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET287);


            pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixUpdateStats5321);
            tableProperties288=tableProperties();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties288.getTree());

            // AST REWRITE
            // elements: tableProperties
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1222:5: -> ^( TOK_ALTERTABLE_UPDATESTATS tableProperties )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1222:7: ^( TOK_ALTERTABLE_UPDATESTATS tableProperties )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_UPDATESTATS, "TOK_ALTERTABLE_UPDATESTATS")
                , root_1);

                adaptor.addChild(root_1, stream_tableProperties.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixUpdateStats"


    public static class alterStatementChangeColPosition_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementChangeColPosition"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1225:1: alterStatementChangeColPosition : (first= KW_FIRST | KW_AFTER afterCol= identifier -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION ) -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol) );
    public final HiveParser.alterStatementChangeColPosition_return alterStatementChangeColPosition() throws RecognitionException {
        HiveParser.alterStatementChangeColPosition_return retval = new HiveParser.alterStatementChangeColPosition_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token first=null;
        Token KW_AFTER289=null;
        HiveParser_IdentifiersParser.identifier_return afterCol =null;


        ASTNode first_tree=null;
        ASTNode KW_AFTER289_tree=null;
        RewriteRuleTokenStream stream_KW_AFTER=new RewriteRuleTokenStream(adaptor,"token KW_AFTER");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1226:5: (first= KW_FIRST | KW_AFTER afterCol= identifier -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION ) -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol) )
            int alt81=2;
            switch ( input.LA(1) ) {
            case KW_FIRST:
                {
                alt81=1;
                }
                break;
            case KW_AFTER:
                {
                alt81=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 81, 0, input);

                throw nvae;

            }

            switch (alt81) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1226:7: first= KW_FIRST
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    first=(Token)match(input,KW_FIRST,FOLLOW_KW_FIRST_in_alterStatementChangeColPosition5351); if (state.failed) return retval;
                    if ( state.backtracking==0 ) {
                    first_tree = 
                    (ASTNode)adaptor.create(first)
                    ;
                    adaptor.addChild(root_0, first_tree);
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1226:22: KW_AFTER afterCol= identifier
                    {
                    KW_AFTER289=(Token)match(input,KW_AFTER,FOLLOW_KW_AFTER_in_alterStatementChangeColPosition5353); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_AFTER.add(KW_AFTER289);


                    pushFollow(FOLLOW_identifier_in_alterStatementChangeColPosition5357);
                    afterCol=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_identifier.add(afterCol.getTree());

                    // AST REWRITE
                    // elements: afterCol
                    // token labels: 
                    // rule labels: afterCol, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_afterCol=new RewriteRuleSubtreeStream(adaptor,"rule afterCol",afterCol!=null?afterCol.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1227:5: -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION )
                    if (first != null) {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1227:25: ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION, "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }

                    else // 1228:5: -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol)
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1228:8: ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol)
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION, "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION")
                        , root_1);

                        adaptor.addChild(root_1, stream_afterCol.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementChangeColPosition"


    public static class alterStatementSuffixAddPartitions_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixAddPartitions"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:1: alterStatementSuffixAddPartitions[boolean table] : KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ -> { table }? ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) -> ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) ;
    public final HiveParser.alterStatementSuffixAddPartitions_return alterStatementSuffixAddPartitions(boolean table) throws RecognitionException {
        HiveParser.alterStatementSuffixAddPartitions_return retval = new HiveParser.alterStatementSuffixAddPartitions_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_ADD290=null;
        HiveParser.ifNotExists_return ifNotExists291 =null;

        HiveParser.alterStatementSuffixAddPartitionsElement_return alterStatementSuffixAddPartitionsElement292 =null;


        ASTNode KW_ADD290_tree=null;
        RewriteRuleTokenStream stream_KW_ADD=new RewriteRuleTokenStream(adaptor,"token KW_ADD");
        RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
        RewriteRuleSubtreeStream stream_alterStatementSuffixAddPartitionsElement=new RewriteRuleSubtreeStream(adaptor,"rule alterStatementSuffixAddPartitionsElement");
         pushMsg("add partition statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1234:5: ( KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ -> { table }? ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) -> ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1234:7: KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+
            {
            KW_ADD290=(Token)match(input,KW_ADD,FOLLOW_KW_ADD_in_alterStatementSuffixAddPartitions5410); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ADD.add(KW_ADD290);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1234:14: ( ifNotExists )?
            int alt82=2;
            switch ( input.LA(1) ) {
                case KW_IF:
                    {
                    alt82=1;
                    }
                    break;
            }

            switch (alt82) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1234:14: ifNotExists
                    {
                    pushFollow(FOLLOW_ifNotExists_in_alterStatementSuffixAddPartitions5412);
                    ifNotExists291=ifNotExists();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists291.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1234:27: ( alterStatementSuffixAddPartitionsElement )+
            int cnt83=0;
            loop83:
            do {
                int alt83=2;
                switch ( input.LA(1) ) {
                case KW_PARTITION:
                    {
                    alt83=1;
                    }
                    break;

                }

                switch (alt83) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1234:27: alterStatementSuffixAddPartitionsElement
            	    {
            	    pushFollow(FOLLOW_alterStatementSuffixAddPartitionsElement_in_alterStatementSuffixAddPartitions5415);
            	    alterStatementSuffixAddPartitionsElement292=alterStatementSuffixAddPartitionsElement();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_alterStatementSuffixAddPartitionsElement.add(alterStatementSuffixAddPartitionsElement292.getTree());

            	    }
            	    break;

            	default :
            	    if ( cnt83 >= 1 ) break loop83;
            	    if (state.backtracking>0) {state.failed=true; return retval;}
                        EarlyExitException eee =
                            new EarlyExitException(83, input);
                        throw eee;
                }
                cnt83++;
            } while (true);


            // AST REWRITE
            // elements: ifNotExists, ifNotExists, alterStatementSuffixAddPartitionsElement, alterStatementSuffixAddPartitionsElement
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1235:5: -> { table }? ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
            if ( table ) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:19: ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_ADDPARTS, "TOK_ALTERTABLE_ADDPARTS")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:45: ( ifNotExists )?
                if ( stream_ifNotExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifNotExists.nextTree());

                }
                stream_ifNotExists.reset();

                if ( !(stream_alterStatementSuffixAddPartitionsElement.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_alterStatementSuffixAddPartitionsElement.hasNext() ) {
                    adaptor.addChild(root_1, stream_alterStatementSuffixAddPartitionsElement.nextTree());

                }
                stream_alterStatementSuffixAddPartitionsElement.reset();

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 1236:5: -> ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1236:19: ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERVIEW_ADDPARTS, "TOK_ALTERVIEW_ADDPARTS")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1236:44: ( ifNotExists )?
                if ( stream_ifNotExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifNotExists.nextTree());

                }
                stream_ifNotExists.reset();

                if ( !(stream_alterStatementSuffixAddPartitionsElement.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_alterStatementSuffixAddPartitionsElement.hasNext() ) {
                    adaptor.addChild(root_1, stream_alterStatementSuffixAddPartitionsElement.nextTree());

                }
                stream_alterStatementSuffixAddPartitionsElement.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixAddPartitions"


    public static class alterStatementSuffixAddPartitionsElement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixAddPartitionsElement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1239:1: alterStatementSuffixAddPartitionsElement : partitionSpec ( partitionLocation )? ;
    public final HiveParser.alterStatementSuffixAddPartitionsElement_return alterStatementSuffixAddPartitionsElement() throws RecognitionException {
        HiveParser.alterStatementSuffixAddPartitionsElement_return retval = new HiveParser.alterStatementSuffixAddPartitionsElement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec293 =null;

        HiveParser.partitionLocation_return partitionLocation294 =null;



        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1240:5: ( partitionSpec ( partitionLocation )? )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1240:7: partitionSpec ( partitionLocation )?
            {
            root_0 = (ASTNode)adaptor.nil();


            pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixAddPartitionsElement5478);
            partitionSpec293=partitionSpec();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) adaptor.addChild(root_0, partitionSpec293.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1240:21: ( partitionLocation )?
            int alt84=2;
            switch ( input.LA(1) ) {
                case KW_LOCATION:
                    {
                    alt84=1;
                    }
                    break;
            }

            switch (alt84) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1240:21: partitionLocation
                    {
                    pushFollow(FOLLOW_partitionLocation_in_alterStatementSuffixAddPartitionsElement5480);
                    partitionLocation294=partitionLocation();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, partitionLocation294.getTree());

                    }
                    break;

            }


            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixAddPartitionsElement"


    public static class alterStatementSuffixTouch_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixTouch"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1243:1: alterStatementSuffixTouch : KW_TOUCH ( partitionSpec )* -> ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* ) ;
    public final HiveParser.alterStatementSuffixTouch_return alterStatementSuffixTouch() throws RecognitionException {
        HiveParser.alterStatementSuffixTouch_return retval = new HiveParser.alterStatementSuffixTouch_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_TOUCH295=null;
        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec296 =null;


        ASTNode KW_TOUCH295_tree=null;
        RewriteRuleTokenStream stream_KW_TOUCH=new RewriteRuleTokenStream(adaptor,"token KW_TOUCH");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
         pushMsg("touch statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1246:5: ( KW_TOUCH ( partitionSpec )* -> ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1246:7: KW_TOUCH ( partitionSpec )*
            {
            KW_TOUCH295=(Token)match(input,KW_TOUCH,FOLLOW_KW_TOUCH_in_alterStatementSuffixTouch5508); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TOUCH.add(KW_TOUCH295);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1246:16: ( partitionSpec )*
            loop85:
            do {
                int alt85=2;
                switch ( input.LA(1) ) {
                case KW_PARTITION:
                    {
                    alt85=1;
                    }
                    break;

                }

                switch (alt85) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1246:17: partitionSpec
            	    {
            	    pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixTouch5511);
            	    partitionSpec296=partitionSpec();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec296.getTree());

            	    }
            	    break;

            	default :
            	    break loop85;
                }
            } while (true);


            // AST REWRITE
            // elements: partitionSpec
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1247:5: -> ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1247:8: ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_TOUCH, "TOK_ALTERTABLE_TOUCH")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1247:31: ( partitionSpec )*
                while ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixTouch"


    public static class alterStatementSuffixArchive_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixArchive"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1250:1: alterStatementSuffixArchive : KW_ARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* ) ;
    public final HiveParser.alterStatementSuffixArchive_return alterStatementSuffixArchive() throws RecognitionException {
        HiveParser.alterStatementSuffixArchive_return retval = new HiveParser.alterStatementSuffixArchive_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_ARCHIVE297=null;
        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec298 =null;


        ASTNode KW_ARCHIVE297_tree=null;
        RewriteRuleTokenStream stream_KW_ARCHIVE=new RewriteRuleTokenStream(adaptor,"token KW_ARCHIVE");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
         pushMsg("archive statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1253:5: ( KW_ARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1253:7: KW_ARCHIVE ( partitionSpec )*
            {
            KW_ARCHIVE297=(Token)match(input,KW_ARCHIVE,FOLLOW_KW_ARCHIVE_in_alterStatementSuffixArchive5555); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ARCHIVE.add(KW_ARCHIVE297);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1253:18: ( partitionSpec )*
            loop86:
            do {
                int alt86=2;
                switch ( input.LA(1) ) {
                case KW_PARTITION:
                    {
                    alt86=1;
                    }
                    break;

                }

                switch (alt86) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1253:19: partitionSpec
            	    {
            	    pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixArchive5558);
            	    partitionSpec298=partitionSpec();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec298.getTree());

            	    }
            	    break;

            	default :
            	    break loop86;
                }
            } while (true);


            // AST REWRITE
            // elements: partitionSpec
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1254:5: -> ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1254:8: ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_ARCHIVE, "TOK_ALTERTABLE_ARCHIVE")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1254:33: ( partitionSpec )*
                while ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixArchive"


    public static class alterStatementSuffixUnArchive_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixUnArchive"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1257:1: alterStatementSuffixUnArchive : KW_UNARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* ) ;
    public final HiveParser.alterStatementSuffixUnArchive_return alterStatementSuffixUnArchive() throws RecognitionException {
        HiveParser.alterStatementSuffixUnArchive_return retval = new HiveParser.alterStatementSuffixUnArchive_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_UNARCHIVE299=null;
        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec300 =null;


        ASTNode KW_UNARCHIVE299_tree=null;
        RewriteRuleTokenStream stream_KW_UNARCHIVE=new RewriteRuleTokenStream(adaptor,"token KW_UNARCHIVE");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
         pushMsg("unarchive statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1260:5: ( KW_UNARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1260:7: KW_UNARCHIVE ( partitionSpec )*
            {
            KW_UNARCHIVE299=(Token)match(input,KW_UNARCHIVE,FOLLOW_KW_UNARCHIVE_in_alterStatementSuffixUnArchive5602); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_UNARCHIVE.add(KW_UNARCHIVE299);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1260:20: ( partitionSpec )*
            loop87:
            do {
                int alt87=2;
                switch ( input.LA(1) ) {
                case KW_PARTITION:
                    {
                    alt87=1;
                    }
                    break;

                }

                switch (alt87) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1260:21: partitionSpec
            	    {
            	    pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixUnArchive5605);
            	    partitionSpec300=partitionSpec();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec300.getTree());

            	    }
            	    break;

            	default :
            	    break loop87;
                }
            } while (true);


            // AST REWRITE
            // elements: partitionSpec
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1261:5: -> ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1261:8: ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_UNARCHIVE, "TOK_ALTERTABLE_UNARCHIVE")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1261:35: ( partitionSpec )*
                while ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixUnArchive"


    public static class partitionLocation_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "partitionLocation"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1264:1: partitionLocation : KW_LOCATION locn= StringLiteral -> ^( TOK_PARTITIONLOCATION $locn) ;
    public final HiveParser.partitionLocation_return partitionLocation() throws RecognitionException {
        HiveParser.partitionLocation_return retval = new HiveParser.partitionLocation_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token locn=null;
        Token KW_LOCATION301=null;

        ASTNode locn_tree=null;
        ASTNode KW_LOCATION301_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");

         pushMsg("partition location", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1267:5: ( KW_LOCATION locn= StringLiteral -> ^( TOK_PARTITIONLOCATION $locn) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1268:7: KW_LOCATION locn= StringLiteral
            {
            KW_LOCATION301=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_partitionLocation5655); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION301);


            locn=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_partitionLocation5659); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(locn);


            // AST REWRITE
            // elements: locn
            // token labels: locn
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_locn=new RewriteRuleTokenStream(adaptor,"token locn",locn);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1268:38: -> ^( TOK_PARTITIONLOCATION $locn)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1268:41: ^( TOK_PARTITIONLOCATION $locn)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_PARTITIONLOCATION, "TOK_PARTITIONLOCATION")
                , root_1);

                adaptor.addChild(root_1, stream_locn.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "partitionLocation"


    public static class alterStatementSuffixDropPartitions_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixDropPartitions"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1271:1: alterStatementSuffixDropPartitions[boolean table] : KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( KW_PURGE )? ( replicationClause )? -> { table }? ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) -> ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( replicationClause )? ) ;
    public final HiveParser.alterStatementSuffixDropPartitions_return alterStatementSuffixDropPartitions(boolean table) throws RecognitionException {
        HiveParser.alterStatementSuffixDropPartitions_return retval = new HiveParser.alterStatementSuffixDropPartitions_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_DROP302=null;
        Token COMMA305=null;
        Token KW_PURGE307=null;
        HiveParser.ifExists_return ifExists303 =null;

        HiveParser_IdentifiersParser.dropPartitionSpec_return dropPartitionSpec304 =null;

        HiveParser_IdentifiersParser.dropPartitionSpec_return dropPartitionSpec306 =null;

        HiveParser.replicationClause_return replicationClause308 =null;


        ASTNode KW_DROP302_tree=null;
        ASTNode COMMA305_tree=null;
        ASTNode KW_PURGE307_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_PURGE=new RewriteRuleTokenStream(adaptor,"token KW_PURGE");
        RewriteRuleSubtreeStream stream_dropPartitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule dropPartitionSpec");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
        RewriteRuleSubtreeStream stream_replicationClause=new RewriteRuleSubtreeStream(adaptor,"rule replicationClause");
         pushMsg("drop partition statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1274:5: ( KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( KW_PURGE )? ( replicationClause )? -> { table }? ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) -> ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( replicationClause )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1274:7: KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( KW_PURGE )? ( replicationClause )?
            {
            KW_DROP302=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_alterStatementSuffixDropPartitions5696); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP302);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1274:15: ( ifExists )?
            int alt88=2;
            switch ( input.LA(1) ) {
                case KW_IF:
                    {
                    alt88=1;
                    }
                    break;
            }

            switch (alt88) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1274:15: ifExists
                    {
                    pushFollow(FOLLOW_ifExists_in_alterStatementSuffixDropPartitions5698);
                    ifExists303=ifExists();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_ifExists.add(ifExists303.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions5701);
            dropPartitionSpec304=dropPartitionSpec();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_dropPartitionSpec.add(dropPartitionSpec304.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1274:43: ( COMMA dropPartitionSpec )*
            loop89:
            do {
                int alt89=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt89=1;
                    }
                    break;

                }

                switch (alt89) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1274:44: COMMA dropPartitionSpec
            	    {
            	    COMMA305=(Token)match(input,COMMA,FOLLOW_COMMA_in_alterStatementSuffixDropPartitions5704); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA305);


            	    pushFollow(FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions5706);
            	    dropPartitionSpec306=dropPartitionSpec();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_dropPartitionSpec.add(dropPartitionSpec306.getTree());

            	    }
            	    break;

            	default :
            	    break loop89;
                }
            } while (true);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1274:70: ( KW_PURGE )?
            int alt90=2;
            switch ( input.LA(1) ) {
                case KW_PURGE:
                    {
                    alt90=1;
                    }
                    break;
            }

            switch (alt90) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1274:70: KW_PURGE
                    {
                    KW_PURGE307=(Token)match(input,KW_PURGE,FOLLOW_KW_PURGE_in_alterStatementSuffixDropPartitions5710); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_PURGE.add(KW_PURGE307);


                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1274:80: ( replicationClause )?
            int alt91=2;
            switch ( input.LA(1) ) {
                case KW_FOR:
                    {
                    alt91=1;
                    }
                    break;
            }

            switch (alt91) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1274:80: replicationClause
                    {
                    pushFollow(FOLLOW_replicationClause_in_alterStatementSuffixDropPartitions5713);
                    replicationClause308=replicationClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_replicationClause.add(replicationClause308.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: ifExists, dropPartitionSpec, ifExists, dropPartitionSpec, replicationClause, KW_PURGE, replicationClause
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1275:5: -> { table }? ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
            if ( table ) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1275:19: ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_DROPPARTS, "TOK_ALTERTABLE_DROPPARTS")
                , root_1);

                if ( !(stream_dropPartitionSpec.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_dropPartitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_dropPartitionSpec.nextTree());

                }
                stream_dropPartitionSpec.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1275:65: ( ifExists )?
                if ( stream_ifExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifExists.nextTree());

                }
                stream_ifExists.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1275:75: ( KW_PURGE )?
                if ( stream_KW_PURGE.hasNext() ) {
                    adaptor.addChild(root_1, 
                    stream_KW_PURGE.nextNode()
                    );

                }
                stream_KW_PURGE.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1275:85: ( replicationClause )?
                if ( stream_replicationClause.hasNext() ) {
                    adaptor.addChild(root_1, stream_replicationClause.nextTree());

                }
                stream_replicationClause.reset();

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 1276:5: -> ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( replicationClause )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1276:19: ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( replicationClause )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERVIEW_DROPPARTS, "TOK_ALTERVIEW_DROPPARTS")
                , root_1);

                if ( !(stream_dropPartitionSpec.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_dropPartitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_dropPartitionSpec.nextTree());

                }
                stream_dropPartitionSpec.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1276:64: ( ifExists )?
                if ( stream_ifExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifExists.nextTree());

                }
                stream_ifExists.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1276:74: ( replicationClause )?
                if ( stream_replicationClause.hasNext() ) {
                    adaptor.addChild(root_1, stream_replicationClause.nextTree());

                }
                stream_replicationClause.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixDropPartitions"


    public static class alterStatementSuffixProperties_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixProperties"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1279:1: alterStatementSuffixProperties : ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? ) );
    public final HiveParser.alterStatementSuffixProperties_return alterStatementSuffixProperties() throws RecognitionException {
        HiveParser.alterStatementSuffixProperties_return retval = new HiveParser.alterStatementSuffixProperties_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_SET309=null;
        Token KW_TBLPROPERTIES310=null;
        Token KW_UNSET312=null;
        Token KW_TBLPROPERTIES313=null;
        HiveParser.tableProperties_return tableProperties311 =null;

        HiveParser.ifExists_return ifExists314 =null;

        HiveParser.tableProperties_return tableProperties315 =null;


        ASTNode KW_SET309_tree=null;
        ASTNode KW_TBLPROPERTIES310_tree=null;
        ASTNode KW_UNSET312_tree=null;
        ASTNode KW_TBLPROPERTIES313_tree=null;
        RewriteRuleTokenStream stream_KW_UNSET=new RewriteRuleTokenStream(adaptor,"token KW_UNSET");
        RewriteRuleTokenStream stream_KW_TBLPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_TBLPROPERTIES");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
         pushMsg("alter properties statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1282:5: ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? ) )
            int alt93=2;
            switch ( input.LA(1) ) {
            case KW_SET:
                {
                alt93=1;
                }
                break;
            case KW_UNSET:
                {
                alt93=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 93, 0, input);

                throw nvae;

            }

            switch (alt93) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1282:7: KW_SET KW_TBLPROPERTIES tableProperties
                    {
                    KW_SET309=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixProperties5795); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET309);


                    KW_TBLPROPERTIES310=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties5797); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES310);


                    pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixProperties5799);
                    tableProperties311=tableProperties();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties311.getTree());

                    // AST REWRITE
                    // elements: tableProperties
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1283:5: -> ^( TOK_ALTERTABLE_PROPERTIES tableProperties )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1283:8: ^( TOK_ALTERTABLE_PROPERTIES tableProperties )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERTABLE_PROPERTIES, "TOK_ALTERTABLE_PROPERTIES")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableProperties.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1284:7: KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties
                    {
                    KW_UNSET312=(Token)match(input,KW_UNSET,FOLLOW_KW_UNSET_in_alterStatementSuffixProperties5819); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_UNSET.add(KW_UNSET312);


                    KW_TBLPROPERTIES313=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties5821); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES313);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1284:33: ( ifExists )?
                    int alt92=2;
                    switch ( input.LA(1) ) {
                        case KW_IF:
                            {
                            alt92=1;
                            }
                            break;
                    }

                    switch (alt92) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1284:33: ifExists
                            {
                            pushFollow(FOLLOW_ifExists_in_alterStatementSuffixProperties5823);
                            ifExists314=ifExists();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_ifExists.add(ifExists314.getTree());

                            }
                            break;

                    }


                    pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixProperties5826);
                    tableProperties315=tableProperties();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties315.getTree());

                    // AST REWRITE
                    // elements: ifExists, tableProperties
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1285:5: -> ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1285:8: ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERTABLE_DROPPROPERTIES, "TOK_ALTERTABLE_DROPPROPERTIES")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableProperties.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1285:56: ( ifExists )?
                        if ( stream_ifExists.hasNext() ) {
                            adaptor.addChild(root_1, stream_ifExists.nextTree());

                        }
                        stream_ifExists.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixProperties"


    public static class alterViewSuffixProperties_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterViewSuffixProperties"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1288:1: alterViewSuffixProperties : ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERVIEW_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? ) );
    public final HiveParser.alterViewSuffixProperties_return alterViewSuffixProperties() throws RecognitionException {
        HiveParser.alterViewSuffixProperties_return retval = new HiveParser.alterViewSuffixProperties_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_SET316=null;
        Token KW_TBLPROPERTIES317=null;
        Token KW_UNSET319=null;
        Token KW_TBLPROPERTIES320=null;
        HiveParser.tableProperties_return tableProperties318 =null;

        HiveParser.ifExists_return ifExists321 =null;

        HiveParser.tableProperties_return tableProperties322 =null;


        ASTNode KW_SET316_tree=null;
        ASTNode KW_TBLPROPERTIES317_tree=null;
        ASTNode KW_UNSET319_tree=null;
        ASTNode KW_TBLPROPERTIES320_tree=null;
        RewriteRuleTokenStream stream_KW_UNSET=new RewriteRuleTokenStream(adaptor,"token KW_UNSET");
        RewriteRuleTokenStream stream_KW_TBLPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_TBLPROPERTIES");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
         pushMsg("alter view properties statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1291:5: ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERVIEW_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? ) )
            int alt95=2;
            switch ( input.LA(1) ) {
            case KW_SET:
                {
                alt95=1;
                }
                break;
            case KW_UNSET:
                {
                alt95=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 95, 0, input);

                throw nvae;

            }

            switch (alt95) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1291:7: KW_SET KW_TBLPROPERTIES tableProperties
                    {
                    KW_SET316=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterViewSuffixProperties5868); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET316);


                    KW_TBLPROPERTIES317=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties5870); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES317);


                    pushFollow(FOLLOW_tableProperties_in_alterViewSuffixProperties5872);
                    tableProperties318=tableProperties();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties318.getTree());

                    // AST REWRITE
                    // elements: tableProperties
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1292:5: -> ^( TOK_ALTERVIEW_PROPERTIES tableProperties )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1292:8: ^( TOK_ALTERVIEW_PROPERTIES tableProperties )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERVIEW_PROPERTIES, "TOK_ALTERVIEW_PROPERTIES")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableProperties.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1293:7: KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties
                    {
                    KW_UNSET319=(Token)match(input,KW_UNSET,FOLLOW_KW_UNSET_in_alterViewSuffixProperties5892); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_UNSET.add(KW_UNSET319);


                    KW_TBLPROPERTIES320=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties5894); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES320);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1293:33: ( ifExists )?
                    int alt94=2;
                    switch ( input.LA(1) ) {
                        case KW_IF:
                            {
                            alt94=1;
                            }
                            break;
                    }

                    switch (alt94) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1293:33: ifExists
                            {
                            pushFollow(FOLLOW_ifExists_in_alterViewSuffixProperties5896);
                            ifExists321=ifExists();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_ifExists.add(ifExists321.getTree());

                            }
                            break;

                    }


                    pushFollow(FOLLOW_tableProperties_in_alterViewSuffixProperties5899);
                    tableProperties322=tableProperties();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties322.getTree());

                    // AST REWRITE
                    // elements: tableProperties, ifExists
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1294:5: -> ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1294:8: ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERVIEW_DROPPROPERTIES, "TOK_ALTERVIEW_DROPPROPERTIES")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableProperties.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1294:55: ( ifExists )?
                        if ( stream_ifExists.hasNext() ) {
                            adaptor.addChild(root_1, stream_ifExists.nextTree());

                        }
                        stream_ifExists.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterViewSuffixProperties"


    public static class alterStatementSuffixSerdeProperties_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixSerdeProperties"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1297:1: alterStatementSuffixSerdeProperties : ( KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )? -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? ) | KW_SET KW_SERDEPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties ) );
    public final HiveParser.alterStatementSuffixSerdeProperties_return alterStatementSuffixSerdeProperties() throws RecognitionException {
        HiveParser.alterStatementSuffixSerdeProperties_return retval = new HiveParser.alterStatementSuffixSerdeProperties_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token serdeName=null;
        Token KW_SET323=null;
        Token KW_SERDE324=null;
        Token KW_WITH325=null;
        Token KW_SERDEPROPERTIES326=null;
        Token KW_SET328=null;
        Token KW_SERDEPROPERTIES329=null;
        HiveParser.tableProperties_return tableProperties327 =null;

        HiveParser.tableProperties_return tableProperties330 =null;


        ASTNode serdeName_tree=null;
        ASTNode KW_SET323_tree=null;
        ASTNode KW_SERDE324_tree=null;
        ASTNode KW_WITH325_tree=null;
        ASTNode KW_SERDEPROPERTIES326_tree=null;
        ASTNode KW_SET328_tree=null;
        ASTNode KW_SERDEPROPERTIES329_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleTokenStream stream_KW_SERDEPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_SERDEPROPERTIES");
        RewriteRuleTokenStream stream_KW_SERDE=new RewriteRuleTokenStream(adaptor,"token KW_SERDE");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
         pushMsg("alter serdes statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:5: ( KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )? -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? ) | KW_SET KW_SERDEPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties ) )
            int alt97=2;
            switch ( input.LA(1) ) {
            case KW_SET:
                {
                switch ( input.LA(2) ) {
                case KW_SERDE:
                    {
                    alt97=1;
                    }
                    break;
                case KW_SERDEPROPERTIES:
                    {
                    alt97=2;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 97, 1, input);

                    throw nvae;

                }

                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 97, 0, input);

                throw nvae;

            }

            switch (alt97) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:7: KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )?
                    {
                    KW_SET323=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties5941); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET323);


                    KW_SERDE324=(Token)match(input,KW_SERDE,FOLLOW_KW_SERDE_in_alterStatementSuffixSerdeProperties5943); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SERDE.add(KW_SERDE324);


                    serdeName=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixSerdeProperties5947); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(serdeName);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:47: ( KW_WITH KW_SERDEPROPERTIES tableProperties )?
                    int alt96=2;
                    switch ( input.LA(1) ) {
                        case KW_WITH:
                            {
                            alt96=1;
                            }
                            break;
                    }

                    switch (alt96) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:48: KW_WITH KW_SERDEPROPERTIES tableProperties
                            {
                            KW_WITH325=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_alterStatementSuffixSerdeProperties5950); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH325);


                            KW_SERDEPROPERTIES326=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties5952); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES326);


                            pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties5954);
                            tableProperties327=tableProperties();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties327.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: tableProperties, serdeName
                    // token labels: serdeName
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_serdeName=new RewriteRuleTokenStream(adaptor,"token serdeName",serdeName);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1301:5: -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1301:8: ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERTABLE_SERIALIZER, "TOK_ALTERTABLE_SERIALIZER")
                        , root_1);

                        adaptor.addChild(root_1, stream_serdeName.nextNode());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1301:47: ( tableProperties )?
                        if ( stream_tableProperties.hasNext() ) {
                            adaptor.addChild(root_1, stream_tableProperties.nextTree());

                        }
                        stream_tableProperties.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1302:7: KW_SET KW_SERDEPROPERTIES tableProperties
                    {
                    KW_SET328=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties5980); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET328);


                    KW_SERDEPROPERTIES329=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties5982); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES329);


                    pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties5984);
                    tableProperties330=tableProperties();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties330.getTree());

                    // AST REWRITE
                    // elements: tableProperties
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1303:5: -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1303:8: ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERTABLE_SERDEPROPERTIES, "TOK_ALTERTABLE_SERDEPROPERTIES")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableProperties.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixSerdeProperties"


    public static class tablePartitionPrefix_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tablePartitionPrefix"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1306:1: tablePartitionPrefix : tableName ( partitionSpec )? -> ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? ) ;
    public final HiveParser.tablePartitionPrefix_return tablePartitionPrefix() throws RecognitionException {
        HiveParser.tablePartitionPrefix_return retval = new HiveParser.tablePartitionPrefix_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser_FromClauseParser.tableName_return tableName331 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec332 =null;


        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
        pushMsg("table partition prefix", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1309:3: ( tableName ( partitionSpec )? -> ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1309:5: tableName ( partitionSpec )?
            {
            pushFollow(FOLLOW_tableName_in_tablePartitionPrefix6021);
            tableName331=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(tableName331.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1309:15: ( partitionSpec )?
            int alt98=2;
            switch ( input.LA(1) ) {
                case KW_PARTITION:
                    {
                    alt98=1;
                    }
                    break;
            }

            switch (alt98) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1309:15: partitionSpec
                    {
                    pushFollow(FOLLOW_partitionSpec_in_tablePartitionPrefix6023);
                    partitionSpec332=partitionSpec();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec332.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: tableName, partitionSpec
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1310:3: -> ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1310:5: ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABLE_PARTITION, "TOK_TABLE_PARTITION")
                , root_1);

                adaptor.addChild(root_1, stream_tableName.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1310:37: ( partitionSpec )?
                if ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tablePartitionPrefix"


    public static class alterStatementSuffixFileFormat_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixFileFormat"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1313:1: alterStatementSuffixFileFormat : KW_SET KW_FILEFORMAT fileFormat -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat ) ;
    public final HiveParser.alterStatementSuffixFileFormat_return alterStatementSuffixFileFormat() throws RecognitionException {
        HiveParser.alterStatementSuffixFileFormat_return retval = new HiveParser.alterStatementSuffixFileFormat_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_SET333=null;
        Token KW_FILEFORMAT334=null;
        HiveParser.fileFormat_return fileFormat335 =null;


        ASTNode KW_SET333_tree=null;
        ASTNode KW_FILEFORMAT334_tree=null;
        RewriteRuleTokenStream stream_KW_FILEFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_FILEFORMAT");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleSubtreeStream stream_fileFormat=new RewriteRuleSubtreeStream(adaptor,"rule fileFormat");
        pushMsg("alter fileformat statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:2: ( KW_SET KW_FILEFORMAT fileFormat -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:4: KW_SET KW_FILEFORMAT fileFormat
            {
            KW_SET333=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixFileFormat6058); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET333);


            KW_FILEFORMAT334=(Token)match(input,KW_FILEFORMAT,FOLLOW_KW_FILEFORMAT_in_alterStatementSuffixFileFormat6060); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FILEFORMAT.add(KW_FILEFORMAT334);


            pushFollow(FOLLOW_fileFormat_in_alterStatementSuffixFileFormat6062);
            fileFormat335=fileFormat();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_fileFormat.add(fileFormat335.getTree());

            // AST REWRITE
            // elements: fileFormat
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1317:2: -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1317:5: ^( TOK_ALTERTABLE_FILEFORMAT fileFormat )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_FILEFORMAT, "TOK_ALTERTABLE_FILEFORMAT")
                , root_1);

                adaptor.addChild(root_1, stream_fileFormat.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixFileFormat"


    public static class alterStatementSuffixClusterbySortby_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixClusterbySortby"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1320:1: alterStatementSuffixClusterbySortby : ( KW_NOT KW_CLUSTERED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED ) | KW_NOT KW_SORTED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED ) | tableBuckets -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets ) );
    public final HiveParser.alterStatementSuffixClusterbySortby_return alterStatementSuffixClusterbySortby() throws RecognitionException {
        HiveParser.alterStatementSuffixClusterbySortby_return retval = new HiveParser.alterStatementSuffixClusterbySortby_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_NOT336=null;
        Token KW_CLUSTERED337=null;
        Token KW_NOT338=null;
        Token KW_SORTED339=null;
        HiveParser.tableBuckets_return tableBuckets340 =null;


        ASTNode KW_NOT336_tree=null;
        ASTNode KW_CLUSTERED337_tree=null;
        ASTNode KW_NOT338_tree=null;
        ASTNode KW_SORTED339_tree=null;
        RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
        RewriteRuleTokenStream stream_KW_SORTED=new RewriteRuleTokenStream(adaptor,"token KW_SORTED");
        RewriteRuleTokenStream stream_KW_CLUSTERED=new RewriteRuleTokenStream(adaptor,"token KW_CLUSTERED");
        RewriteRuleSubtreeStream stream_tableBuckets=new RewriteRuleSubtreeStream(adaptor,"rule tableBuckets");
        pushMsg("alter partition cluster by sort by statement", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:3: ( KW_NOT KW_CLUSTERED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED ) | KW_NOT KW_SORTED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED ) | tableBuckets -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets ) )
            int alt99=3;
            switch ( input.LA(1) ) {
            case KW_NOT:
                {
                switch ( input.LA(2) ) {
                case KW_CLUSTERED:
                    {
                    alt99=1;
                    }
                    break;
                case KW_SORTED:
                    {
                    alt99=2;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 99, 1, input);

                    throw nvae;

                }

                }
                break;
            case KW_CLUSTERED:
                {
                alt99=3;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 99, 0, input);

                throw nvae;

            }

            switch (alt99) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:5: KW_NOT KW_CLUSTERED
                    {
                    KW_NOT336=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby6093); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT336);


                    KW_CLUSTERED337=(Token)match(input,KW_CLUSTERED,FOLLOW_KW_CLUSTERED_in_alterStatementSuffixClusterbySortby6095); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_CLUSTERED.add(KW_CLUSTERED337);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1323:25: -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:28: ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT")
                        , root_1);

                        adaptor.addChild(root_1, 
                        (ASTNode)adaptor.create(TOK_NOT_CLUSTERED, "TOK_NOT_CLUSTERED")
                        );

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1324:5: KW_NOT KW_SORTED
                    {
                    KW_NOT338=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby6109); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT338);


                    KW_SORTED339=(Token)match(input,KW_SORTED,FOLLOW_KW_SORTED_in_alterStatementSuffixClusterbySortby6111); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SORTED.add(KW_SORTED339);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1324:22: -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1324:25: ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT")
                        , root_1);

                        adaptor.addChild(root_1, 
                        (ASTNode)adaptor.create(TOK_NOT_SORTED, "TOK_NOT_SORTED")
                        );

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1325:5: tableBuckets
                    {
                    pushFollow(FOLLOW_tableBuckets_in_alterStatementSuffixClusterbySortby6125);
                    tableBuckets340=tableBuckets();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableBuckets.add(tableBuckets340.getTree());

                    // AST REWRITE
                    // elements: tableBuckets
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1325:18: -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1325:21: ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableBuckets.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixClusterbySortby"


    public static class alterTblPartitionStatementSuffixSkewedLocation_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterTblPartitionStatementSuffixSkewedLocation"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1328:1: alterTblPartitionStatementSuffixSkewedLocation : KW_SET KW_SKEWED KW_LOCATION skewedLocations -> ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations ) ;
    public final HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return alterTblPartitionStatementSuffixSkewedLocation() throws RecognitionException {
        HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return retval = new HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_SET341=null;
        Token KW_SKEWED342=null;
        Token KW_LOCATION343=null;
        HiveParser.skewedLocations_return skewedLocations344 =null;


        ASTNode KW_SET341_tree=null;
        ASTNode KW_SKEWED342_tree=null;
        ASTNode KW_LOCATION343_tree=null;
        RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");
        RewriteRuleTokenStream stream_KW_SKEWED=new RewriteRuleTokenStream(adaptor,"token KW_SKEWED");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleSubtreeStream stream_skewedLocations=new RewriteRuleSubtreeStream(adaptor,"rule skewedLocations");
        pushMsg("alter partition skewed location", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1331:3: ( KW_SET KW_SKEWED KW_LOCATION skewedLocations -> ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1331:5: KW_SET KW_SKEWED KW_LOCATION skewedLocations
            {
            KW_SET341=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterTblPartitionStatementSuffixSkewedLocation6156); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET341);


            KW_SKEWED342=(Token)match(input,KW_SKEWED,FOLLOW_KW_SKEWED_in_alterTblPartitionStatementSuffixSkewedLocation6158); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SKEWED.add(KW_SKEWED342);


            KW_LOCATION343=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_alterTblPartitionStatementSuffixSkewedLocation6160); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION343);


            pushFollow(FOLLOW_skewedLocations_in_alterTblPartitionStatementSuffixSkewedLocation6162);
            skewedLocations344=skewedLocations();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_skewedLocations.add(skewedLocations344.getTree());

            // AST REWRITE
            // elements: skewedLocations
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1332:3: -> ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:6: ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_SKEWED_LOCATION, "TOK_ALTERTABLE_SKEWED_LOCATION")
                , root_1);

                adaptor.addChild(root_1, stream_skewedLocations.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterTblPartitionStatementSuffixSkewedLocation"


    public static class skewedLocations_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedLocations"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1335:1: skewedLocations : LPAREN skewedLocationsList RPAREN -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList ) ;
    public final HiveParser.skewedLocations_return skewedLocations() throws RecognitionException {
        HiveParser.skewedLocations_return retval = new HiveParser.skewedLocations_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token LPAREN345=null;
        Token RPAREN347=null;
        HiveParser.skewedLocationsList_return skewedLocationsList346 =null;


        ASTNode LPAREN345_tree=null;
        ASTNode RPAREN347_tree=null;
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleSubtreeStream stream_skewedLocationsList=new RewriteRuleSubtreeStream(adaptor,"rule skewedLocationsList");
         pushMsg("skewed locations", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1338:5: ( LPAREN skewedLocationsList RPAREN -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1339:7: LPAREN skewedLocationsList RPAREN
            {
            LPAREN345=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_skewedLocations6205); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN345);


            pushFollow(FOLLOW_skewedLocationsList_in_skewedLocations6207);
            skewedLocationsList346=skewedLocationsList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_skewedLocationsList.add(skewedLocationsList346.getTree());

            RPAREN347=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_skewedLocations6209); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN347);


            // AST REWRITE
            // elements: skewedLocationsList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1339:41: -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1339:44: ^( TOK_SKEWED_LOCATIONS skewedLocationsList )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SKEWED_LOCATIONS, "TOK_SKEWED_LOCATIONS")
                , root_1);

                adaptor.addChild(root_1, stream_skewedLocationsList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedLocations"


    public static class skewedLocationsList_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedLocationsList"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:1: skewedLocationsList : skewedLocationMap ( COMMA skewedLocationMap )* -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ ) ;
    public final HiveParser.skewedLocationsList_return skewedLocationsList() throws RecognitionException {
        HiveParser.skewedLocationsList_return retval = new HiveParser.skewedLocationsList_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token COMMA349=null;
        HiveParser.skewedLocationMap_return skewedLocationMap348 =null;

        HiveParser.skewedLocationMap_return skewedLocationMap350 =null;


        ASTNode COMMA349_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_skewedLocationMap=new RewriteRuleSubtreeStream(adaptor,"rule skewedLocationMap");
         pushMsg("skewed locations list", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1345:5: ( skewedLocationMap ( COMMA skewedLocationMap )* -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1346:7: skewedLocationMap ( COMMA skewedLocationMap )*
            {
            pushFollow(FOLLOW_skewedLocationMap_in_skewedLocationsList6250);
            skewedLocationMap348=skewedLocationMap();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_skewedLocationMap.add(skewedLocationMap348.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1346:25: ( COMMA skewedLocationMap )*
            loop100:
            do {
                int alt100=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt100=1;
                    }
                    break;

                }

                switch (alt100) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1346:26: COMMA skewedLocationMap
            	    {
            	    COMMA349=(Token)match(input,COMMA,FOLLOW_COMMA_in_skewedLocationsList6253); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA349);


            	    pushFollow(FOLLOW_skewedLocationMap_in_skewedLocationsList6255);
            	    skewedLocationMap350=skewedLocationMap();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_skewedLocationMap.add(skewedLocationMap350.getTree());

            	    }
            	    break;

            	default :
            	    break loop100;
                }
            } while (true);


            // AST REWRITE
            // elements: skewedLocationMap
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1346:52: -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1346:55: ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SKEWED_LOCATION_LIST, "TOK_SKEWED_LOCATION_LIST")
                , root_1);

                if ( !(stream_skewedLocationMap.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_skewedLocationMap.hasNext() ) {
                    adaptor.addChild(root_1, stream_skewedLocationMap.nextTree());

                }
                stream_skewedLocationMap.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedLocationsList"


    public static class skewedLocationMap_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedLocationMap"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1349:1: skewedLocationMap : key= skewedValueLocationElement EQUAL value= StringLiteral -> ^( TOK_SKEWED_LOCATION_MAP $key $value) ;
    public final HiveParser.skewedLocationMap_return skewedLocationMap() throws RecognitionException {
        HiveParser.skewedLocationMap_return retval = new HiveParser.skewedLocationMap_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token value=null;
        Token EQUAL351=null;
        HiveParser.skewedValueLocationElement_return key =null;


        ASTNode value_tree=null;
        ASTNode EQUAL351_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_EQUAL=new RewriteRuleTokenStream(adaptor,"token EQUAL");
        RewriteRuleSubtreeStream stream_skewedValueLocationElement=new RewriteRuleSubtreeStream(adaptor,"rule skewedValueLocationElement");
         pushMsg("specifying skewed location map", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1352:5: (key= skewedValueLocationElement EQUAL value= StringLiteral -> ^( TOK_SKEWED_LOCATION_MAP $key $value) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:7: key= skewedValueLocationElement EQUAL value= StringLiteral
            {
            pushFollow(FOLLOW_skewedValueLocationElement_in_skewedLocationMap6301);
            key=skewedValueLocationElement();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_skewedValueLocationElement.add(key.getTree());

            EQUAL351=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_skewedLocationMap6303); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_EQUAL.add(EQUAL351);


            value=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_skewedLocationMap6307); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(value);


            // AST REWRITE
            // elements: key, value
            // token labels: value
            // rule labels: key, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_value=new RewriteRuleTokenStream(adaptor,"token value",value);
            RewriteRuleSubtreeStream stream_key=new RewriteRuleSubtreeStream(adaptor,"rule key",key!=null?key.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1353:64: -> ^( TOK_SKEWED_LOCATION_MAP $key $value)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:67: ^( TOK_SKEWED_LOCATION_MAP $key $value)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SKEWED_LOCATION_MAP, "TOK_SKEWED_LOCATION_MAP")
                , root_1);

                adaptor.addChild(root_1, stream_key.nextTree());

                adaptor.addChild(root_1, stream_value.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedLocationMap"


    public static class alterStatementSuffixLocation_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixLocation"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1356:1: alterStatementSuffixLocation : KW_SET KW_LOCATION newLoc= StringLiteral -> ^( TOK_ALTERTABLE_LOCATION $newLoc) ;
    public final HiveParser.alterStatementSuffixLocation_return alterStatementSuffixLocation() throws RecognitionException {
        HiveParser.alterStatementSuffixLocation_return retval = new HiveParser.alterStatementSuffixLocation_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token newLoc=null;
        Token KW_SET352=null;
        Token KW_LOCATION353=null;

        ASTNode newLoc_tree=null;
        ASTNode KW_SET352_tree=null;
        ASTNode KW_LOCATION353_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");

        pushMsg("alter location", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:3: ( KW_SET KW_LOCATION newLoc= StringLiteral -> ^( TOK_ALTERTABLE_LOCATION $newLoc) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:5: KW_SET KW_LOCATION newLoc= StringLiteral
            {
            KW_SET352=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixLocation6344); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET352);


            KW_LOCATION353=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_alterStatementSuffixLocation6346); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION353);


            newLoc=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixLocation6350); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(newLoc);


            // AST REWRITE
            // elements: newLoc
            // token labels: newLoc
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_newLoc=new RewriteRuleTokenStream(adaptor,"token newLoc",newLoc);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1360:3: -> ^( TOK_ALTERTABLE_LOCATION $newLoc)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:6: ^( TOK_ALTERTABLE_LOCATION $newLoc)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_LOCATION, "TOK_ALTERTABLE_LOCATION")
                , root_1);

                adaptor.addChild(root_1, stream_newLoc.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixLocation"


    public static class alterStatementSuffixSkewedby_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixSkewedby"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1364:1: alterStatementSuffixSkewedby : ( tableSkewed -> ^( TOK_ALTERTABLE_SKEWED tableSkewed ) | KW_NOT KW_SKEWED -> ^( TOK_ALTERTABLE_SKEWED ) | KW_NOT storedAsDirs -> ^( TOK_ALTERTABLE_SKEWED storedAsDirs ) );
    public final HiveParser.alterStatementSuffixSkewedby_return alterStatementSuffixSkewedby() throws RecognitionException {
        HiveParser.alterStatementSuffixSkewedby_return retval = new HiveParser.alterStatementSuffixSkewedby_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_NOT355=null;
        Token KW_SKEWED356=null;
        Token KW_NOT357=null;
        HiveParser.tableSkewed_return tableSkewed354 =null;

        HiveParser.storedAsDirs_return storedAsDirs358 =null;


        ASTNode KW_NOT355_tree=null;
        ASTNode KW_SKEWED356_tree=null;
        ASTNode KW_NOT357_tree=null;
        RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
        RewriteRuleTokenStream stream_KW_SKEWED=new RewriteRuleTokenStream(adaptor,"token KW_SKEWED");
        RewriteRuleSubtreeStream stream_tableSkewed=new RewriteRuleSubtreeStream(adaptor,"rule tableSkewed");
        RewriteRuleSubtreeStream stream_storedAsDirs=new RewriteRuleSubtreeStream(adaptor,"rule storedAsDirs");
        pushMsg("alter skewed by statement", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:2: ( tableSkewed -> ^( TOK_ALTERTABLE_SKEWED tableSkewed ) | KW_NOT KW_SKEWED -> ^( TOK_ALTERTABLE_SKEWED ) | KW_NOT storedAsDirs -> ^( TOK_ALTERTABLE_SKEWED storedAsDirs ) )
            int alt101=3;
            switch ( input.LA(1) ) {
            case KW_SKEWED:
                {
                alt101=1;
                }
                break;
            case KW_NOT:
                {
                switch ( input.LA(2) ) {
                case KW_SKEWED:
                    {
                    alt101=2;
                    }
                    break;
                case KW_STORED:
                    {
                    alt101=3;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 101, 2, input);

                    throw nvae;

                }

                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 101, 0, input);

                throw nvae;

            }

            switch (alt101) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:4: tableSkewed
                    {
                    pushFollow(FOLLOW_tableSkewed_in_alterStatementSuffixSkewedby6384);
                    tableSkewed354=tableSkewed();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableSkewed.add(tableSkewed354.getTree());

                    // AST REWRITE
                    // elements: tableSkewed
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1368:2: -> ^( TOK_ALTERTABLE_SKEWED tableSkewed )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:4: ^( TOK_ALTERTABLE_SKEWED tableSkewed )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableSkewed.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:3: KW_NOT KW_SKEWED
                    {
                    KW_NOT355=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby6399); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT355);


                    KW_SKEWED356=(Token)match(input,KW_SKEWED,FOLLOW_KW_SKEWED_in_alterStatementSuffixSkewedby6401); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SKEWED.add(KW_SKEWED356);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1371:2: -> ^( TOK_ALTERTABLE_SKEWED )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1371:4: ^( TOK_ALTERTABLE_SKEWED )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1373:3: KW_NOT storedAsDirs
                    {
                    KW_NOT357=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby6414); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT357);


                    pushFollow(FOLLOW_storedAsDirs_in_alterStatementSuffixSkewedby6416);
                    storedAsDirs358=storedAsDirs();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_storedAsDirs.add(storedAsDirs358.getTree());

                    // AST REWRITE
                    // elements: storedAsDirs
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1374:2: -> ^( TOK_ALTERTABLE_SKEWED storedAsDirs )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1374:4: ^( TOK_ALTERTABLE_SKEWED storedAsDirs )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED")
                        , root_1);

                        adaptor.addChild(root_1, stream_storedAsDirs.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixSkewedby"


    public static class alterStatementSuffixExchangePartition_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixExchangePartition"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1377:1: alterStatementSuffixExchangePartition : KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName -> ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename) ;
    public final HiveParser.alterStatementSuffixExchangePartition_return alterStatementSuffixExchangePartition() throws RecognitionException {
        HiveParser.alterStatementSuffixExchangePartition_return retval = new HiveParser.alterStatementSuffixExchangePartition_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_EXCHANGE359=null;
        Token KW_WITH361=null;
        Token KW_TABLE362=null;
        HiveParser_FromClauseParser.tableName_return exchangename =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec360 =null;


        ASTNode KW_EXCHANGE359_tree=null;
        ASTNode KW_WITH361_tree=null;
        ASTNode KW_TABLE362_tree=null;
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_KW_EXCHANGE=new RewriteRuleTokenStream(adaptor,"token KW_EXCHANGE");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
        pushMsg("alter exchange partition", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1380:5: ( KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName -> ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1380:7: KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName
            {
            KW_EXCHANGE359=(Token)match(input,KW_EXCHANGE,FOLLOW_KW_EXCHANGE_in_alterStatementSuffixExchangePartition6447); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_EXCHANGE.add(KW_EXCHANGE359);


            pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixExchangePartition6449);
            partitionSpec360=partitionSpec();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec360.getTree());

            KW_WITH361=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_alterStatementSuffixExchangePartition6451); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH361);


            KW_TABLE362=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_alterStatementSuffixExchangePartition6453); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE362);


            pushFollow(FOLLOW_tableName_in_alterStatementSuffixExchangePartition6457);
            exchangename=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(exchangename.getTree());

            // AST REWRITE
            // elements: exchangename, partitionSpec
            // token labels: 
            // rule labels: exchangename, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_exchangename=new RewriteRuleSubtreeStream(adaptor,"rule exchangename",exchangename!=null?exchangename.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1381:5: -> ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1381:8: ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_EXCHANGEPARTITION, "TOK_ALTERTABLE_EXCHANGEPARTITION")
                , root_1);

                adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                adaptor.addChild(root_1, stream_exchangename.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixExchangePartition"


    public static class alterStatementSuffixRenamePart_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixRenamePart"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1384:1: alterStatementSuffixRenamePart : KW_RENAME KW_TO partitionSpec -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec ) ;
    public final HiveParser.alterStatementSuffixRenamePart_return alterStatementSuffixRenamePart() throws RecognitionException {
        HiveParser.alterStatementSuffixRenamePart_return retval = new HiveParser.alterStatementSuffixRenamePart_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_RENAME363=null;
        Token KW_TO364=null;
        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec365 =null;


        ASTNode KW_RENAME363_tree=null;
        ASTNode KW_TO364_tree=null;
        RewriteRuleTokenStream stream_KW_RENAME=new RewriteRuleTokenStream(adaptor,"token KW_RENAME");
        RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
         pushMsg("alter table rename partition statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1387:5: ( KW_RENAME KW_TO partitionSpec -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1387:7: KW_RENAME KW_TO partitionSpec
            {
            KW_RENAME363=(Token)match(input,KW_RENAME,FOLLOW_KW_RENAME_in_alterStatementSuffixRenamePart6499); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_RENAME.add(KW_RENAME363);


            KW_TO364=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_alterStatementSuffixRenamePart6501); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO364);


            pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixRenamePart6503);
            partitionSpec365=partitionSpec();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec365.getTree());

            // AST REWRITE
            // elements: partitionSpec
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1388:5: -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1388:7: ^( TOK_ALTERTABLE_RENAMEPART partitionSpec )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_RENAMEPART, "TOK_ALTERTABLE_RENAMEPART")
                , root_1);

                adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixRenamePart"


    public static class alterStatementSuffixStatsPart_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixStatsPart"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1391:1: alterStatementSuffixStatsPart : KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) ;
    public final HiveParser.alterStatementSuffixStatsPart_return alterStatementSuffixStatsPart() throws RecognitionException {
        HiveParser.alterStatementSuffixStatsPart_return retval = new HiveParser.alterStatementSuffixStatsPart_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token comment=null;
        Token KW_UPDATE366=null;
        Token KW_STATISTICS367=null;
        Token KW_FOR368=null;
        Token KW_COLUMN369=null;
        Token KW_SET370=null;
        Token KW_COMMENT372=null;
        HiveParser_IdentifiersParser.identifier_return colName =null;

        HiveParser.tableProperties_return tableProperties371 =null;


        ASTNode comment_tree=null;
        ASTNode KW_UPDATE366_tree=null;
        ASTNode KW_STATISTICS367_tree=null;
        ASTNode KW_FOR368_tree=null;
        ASTNode KW_COLUMN369_tree=null;
        ASTNode KW_SET370_tree=null;
        ASTNode KW_COMMENT372_tree=null;
        RewriteRuleTokenStream stream_KW_STATISTICS=new RewriteRuleTokenStream(adaptor,"token KW_STATISTICS");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
        RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
        RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
        RewriteRuleTokenStream stream_KW_COLUMN=new RewriteRuleTokenStream(adaptor,"token KW_COLUMN");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
         pushMsg("alter table stats partition statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1394:5: ( KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1394:7: KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )?
            {
            KW_UPDATE366=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_alterStatementSuffixStatsPart6541); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE366);


            KW_STATISTICS367=(Token)match(input,KW_STATISTICS,FOLLOW_KW_STATISTICS_in_alterStatementSuffixStatsPart6543); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_STATISTICS.add(KW_STATISTICS367);


            KW_FOR368=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_alterStatementSuffixStatsPart6545); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR368);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1394:38: ( KW_COLUMN )?
            int alt102=2;
            switch ( input.LA(1) ) {
                case KW_COLUMN:
                    {
                    alt102=1;
                    }
                    break;
            }

            switch (alt102) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1394:38: KW_COLUMN
                    {
                    KW_COLUMN369=(Token)match(input,KW_COLUMN,FOLLOW_KW_COLUMN_in_alterStatementSuffixStatsPart6547); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_COLUMN.add(KW_COLUMN369);


                    }
                    break;

            }


            pushFollow(FOLLOW_identifier_in_alterStatementSuffixStatsPart6552);
            colName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());

            KW_SET370=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixStatsPart6554); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET370);


            pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixStatsPart6556);
            tableProperties371=tableProperties();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties371.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1394:91: ( KW_COMMENT comment= StringLiteral )?
            int alt103=2;
            switch ( input.LA(1) ) {
                case KW_COMMENT:
                    {
                    alt103=1;
                    }
                    break;
            }

            switch (alt103) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1394:92: KW_COMMENT comment= StringLiteral
                    {
                    KW_COMMENT372=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_alterStatementSuffixStatsPart6559); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT372);


                    comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixStatsPart6563); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(comment);


                    }
                    break;

            }


            // AST REWRITE
            // elements: tableProperties, colName, comment
            // token labels: comment
            // rule labels: colName, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
            RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1395:5: -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1395:7: ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_UPDATECOLSTATS, "TOK_ALTERTABLE_UPDATECOLSTATS")
                , root_1);

                adaptor.addChild(root_1, stream_colName.nextTree());

                adaptor.addChild(root_1, stream_tableProperties.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1395:65: ( $comment)?
                if ( stream_comment.hasNext() ) {
                    adaptor.addChild(root_1, stream_comment.nextNode());

                }
                stream_comment.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixStatsPart"


    public static class alterStatementSuffixMergeFiles_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixMergeFiles"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1398:1: alterStatementSuffixMergeFiles : KW_CONCATENATE -> ^( TOK_ALTERTABLE_MERGEFILES ) ;
    public final HiveParser.alterStatementSuffixMergeFiles_return alterStatementSuffixMergeFiles() throws RecognitionException {
        HiveParser.alterStatementSuffixMergeFiles_return retval = new HiveParser.alterStatementSuffixMergeFiles_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_CONCATENATE373=null;

        ASTNode KW_CONCATENATE373_tree=null;
        RewriteRuleTokenStream stream_KW_CONCATENATE=new RewriteRuleTokenStream(adaptor,"token KW_CONCATENATE");

         pushMsg("", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1401:5: ( KW_CONCATENATE -> ^( TOK_ALTERTABLE_MERGEFILES ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1401:7: KW_CONCATENATE
            {
            KW_CONCATENATE373=(Token)match(input,KW_CONCATENATE,FOLLOW_KW_CONCATENATE_in_alterStatementSuffixMergeFiles6610); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_CONCATENATE.add(KW_CONCATENATE373);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1402:5: -> ^( TOK_ALTERTABLE_MERGEFILES )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1402:8: ^( TOK_ALTERTABLE_MERGEFILES )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_MERGEFILES, "TOK_ALTERTABLE_MERGEFILES")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixMergeFiles"


    public static class alterStatementSuffixBucketNum_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixBucketNum"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1405:1: alterStatementSuffixBucketNum : KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $num) ;
    public final HiveParser.alterStatementSuffixBucketNum_return alterStatementSuffixBucketNum() throws RecognitionException {
        HiveParser.alterStatementSuffixBucketNum_return retval = new HiveParser.alterStatementSuffixBucketNum_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token num=null;
        Token KW_INTO374=null;
        Token KW_BUCKETS375=null;

        ASTNode num_tree=null;
        ASTNode KW_INTO374_tree=null;
        ASTNode KW_BUCKETS375_tree=null;
        RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
        RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
        RewriteRuleTokenStream stream_KW_BUCKETS=new RewriteRuleTokenStream(adaptor,"token KW_BUCKETS");

         pushMsg("", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1408:5: ( KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $num) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1408:7: KW_INTO num= Number KW_BUCKETS
            {
            KW_INTO374=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_alterStatementSuffixBucketNum6647); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO374);


            num=(Token)match(input,Number,FOLLOW_Number_in_alterStatementSuffixBucketNum6651); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_Number.add(num);


            KW_BUCKETS375=(Token)match(input,KW_BUCKETS,FOLLOW_KW_BUCKETS_in_alterStatementSuffixBucketNum6653); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_BUCKETS.add(KW_BUCKETS375);


            // AST REWRITE
            // elements: num
            // token labels: num
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1409:5: -> ^( TOK_ALTERTABLE_BUCKETS $num)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1409:8: ^( TOK_ALTERTABLE_BUCKETS $num)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_BUCKETS, "TOK_ALTERTABLE_BUCKETS")
                , root_1);

                adaptor.addChild(root_1, stream_num.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixBucketNum"


    public static class alterStatementSuffixCompact_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixCompact"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1412:1: alterStatementSuffixCompact : KW_COMPACT compactType= StringLiteral ( KW_WITH KW_OVERWRITE KW_TBLPROPERTIES tableProperties )? -> ^( TOK_ALTERTABLE_COMPACT $compactType ( tableProperties )? ) ;
    public final HiveParser.alterStatementSuffixCompact_return alterStatementSuffixCompact() throws RecognitionException {
        HiveParser.alterStatementSuffixCompact_return retval = new HiveParser.alterStatementSuffixCompact_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token compactType=null;
        Token KW_COMPACT376=null;
        Token KW_WITH377=null;
        Token KW_OVERWRITE378=null;
        Token KW_TBLPROPERTIES379=null;
        HiveParser.tableProperties_return tableProperties380 =null;


        ASTNode compactType_tree=null;
        ASTNode KW_COMPACT376_tree=null;
        ASTNode KW_WITH377_tree=null;
        ASTNode KW_OVERWRITE378_tree=null;
        ASTNode KW_TBLPROPERTIES379_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleTokenStream stream_KW_COMPACT=new RewriteRuleTokenStream(adaptor,"token KW_COMPACT");
        RewriteRuleTokenStream stream_KW_OVERWRITE=new RewriteRuleTokenStream(adaptor,"token KW_OVERWRITE");
        RewriteRuleTokenStream stream_KW_TBLPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_TBLPROPERTIES");
        RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
         msgs.push("compaction request"); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1415:5: ( KW_COMPACT compactType= StringLiteral ( KW_WITH KW_OVERWRITE KW_TBLPROPERTIES tableProperties )? -> ^( TOK_ALTERTABLE_COMPACT $compactType ( tableProperties )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1415:7: KW_COMPACT compactType= StringLiteral ( KW_WITH KW_OVERWRITE KW_TBLPROPERTIES tableProperties )?
            {
            KW_COMPACT376=(Token)match(input,KW_COMPACT,FOLLOW_KW_COMPACT_in_alterStatementSuffixCompact6693); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_COMPACT.add(KW_COMPACT376);


            compactType=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixCompact6697); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(compactType);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1415:44: ( KW_WITH KW_OVERWRITE KW_TBLPROPERTIES tableProperties )?
            int alt104=2;
            switch ( input.LA(1) ) {
                case KW_WITH:
                    {
                    alt104=1;
                    }
                    break;
            }

            switch (alt104) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1415:45: KW_WITH KW_OVERWRITE KW_TBLPROPERTIES tableProperties
                    {
                    KW_WITH377=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_alterStatementSuffixCompact6700); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH377);


                    KW_OVERWRITE378=(Token)match(input,KW_OVERWRITE,FOLLOW_KW_OVERWRITE_in_alterStatementSuffixCompact6702); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_OVERWRITE.add(KW_OVERWRITE378);


                    KW_TBLPROPERTIES379=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixCompact6704); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES379);


                    pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixCompact6706);
                    tableProperties380=tableProperties();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableProperties.add(tableProperties380.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: tableProperties, compactType
            // token labels: compactType
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_compactType=new RewriteRuleTokenStream(adaptor,"token compactType",compactType);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1416:5: -> ^( TOK_ALTERTABLE_COMPACT $compactType ( tableProperties )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1416:8: ^( TOK_ALTERTABLE_COMPACT $compactType ( tableProperties )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_COMPACT, "TOK_ALTERTABLE_COMPACT")
                , root_1);

                adaptor.addChild(root_1, stream_compactType.nextNode());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1416:46: ( tableProperties )?
                if ( stream_tableProperties.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableProperties.nextTree());

                }
                stream_tableProperties.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { msgs.pop(); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixCompact"


    public static class fileFormat_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "fileFormat"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1420:1: fileFormat : ( KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral KW_SERDE serdeCls= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? ) |genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) );
    public final HiveParser.fileFormat_return fileFormat() throws RecognitionException {
        HiveParser.fileFormat_return retval = new HiveParser.fileFormat_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token inFmt=null;
        Token outFmt=null;
        Token serdeCls=null;
        Token inDriver=null;
        Token outDriver=null;
        Token KW_INPUTFORMAT381=null;
        Token KW_OUTPUTFORMAT382=null;
        Token KW_SERDE383=null;
        Token KW_INPUTDRIVER384=null;
        Token KW_OUTPUTDRIVER385=null;
        HiveParser_IdentifiersParser.identifier_return genericSpec =null;


        ASTNode inFmt_tree=null;
        ASTNode outFmt_tree=null;
        ASTNode serdeCls_tree=null;
        ASTNode inDriver_tree=null;
        ASTNode outDriver_tree=null;
        ASTNode KW_INPUTFORMAT381_tree=null;
        ASTNode KW_OUTPUTFORMAT382_tree=null;
        ASTNode KW_SERDE383_tree=null;
        ASTNode KW_INPUTDRIVER384_tree=null;
        ASTNode KW_OUTPUTDRIVER385_tree=null;
        RewriteRuleTokenStream stream_KW_INPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_INPUTFORMAT");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_INPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_INPUTDRIVER");
        RewriteRuleTokenStream stream_KW_SERDE=new RewriteRuleTokenStream(adaptor,"token KW_SERDE");
        RewriteRuleTokenStream stream_KW_OUTPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTFORMAT");
        RewriteRuleTokenStream stream_KW_OUTPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTDRIVER");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         pushMsg("file format specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1423:5: ( KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral KW_SERDE serdeCls= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? ) |genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) )
            int alt106=2;
            switch ( input.LA(1) ) {
            case KW_INPUTFORMAT:
                {
                switch ( input.LA(2) ) {
                case StringLiteral:
                    {
                    alt106=1;
                    }
                    break;
                case EOF:
                    {
                    alt106=2;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 106, 1, input);

                    throw nvae;

                }

                }
                break;
            case Identifier:
            case KW_ABORT:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_AUTOCOMMIT:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CACHE:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONSTRAINT:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURRENT_DATE:
            case KW_CURRENT_TIMESTAMP:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DAY:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DOW:
            case KW_DROP:
            case KW_DUMP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FOREIGN:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOUR:
            case KW_IDXPROPERTIES:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ISOLATION:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEY:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LAST:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LEVEL:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATCHED:
            case KW_MATERIALIZED:
            case KW_MERGE:
            case KW_METADATA:
            case KW_MINUTE:
            case KW_MONTH:
            case KW_MSCK:
            case KW_NONE:
            case KW_NORELY:
            case KW_NOSCAN:
            case KW_NOVALIDATE:
            case KW_NULL:
            case KW_NULLS:
            case KW_OF:
            case KW_OFFSET:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRIMARY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PURGE:
            case KW_QUARTER:
            case KW_RANGE:
            case KW_READ:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REFERENCES:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RELY:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPL:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SECOND:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SNAPSHOT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STATUS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTION:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALIDATE:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_VIEWS:
            case KW_WEEK:
            case KW_WHILE:
            case KW_WITH:
            case KW_WORK:
            case KW_WRITE:
            case KW_YEAR:
            case KW_BATCH:
            case KW_DAYOFWEEK:
            case KW_HOLD_DDLTIME:
            case KW_IGNORE:
            case KW_NO_DROP:
            case KW_OFFLINE:
            case KW_PROTECTION:
            case KW_READONLY:
                {
                alt106=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 106, 0, input);

                throw nvae;

            }

            switch (alt106) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1423:7: KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral KW_SERDE serdeCls= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
                    {
                    KW_INPUTFORMAT381=(Token)match(input,KW_INPUTFORMAT,FOLLOW_KW_INPUTFORMAT_in_fileFormat6752); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_INPUTFORMAT.add(KW_INPUTFORMAT381);


                    inFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat6756); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(inFmt);


                    KW_OUTPUTFORMAT382=(Token)match(input,KW_OUTPUTFORMAT,FOLLOW_KW_OUTPUTFORMAT_in_fileFormat6758); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_OUTPUTFORMAT.add(KW_OUTPUTFORMAT382);


                    outFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat6762); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(outFmt);


                    KW_SERDE383=(Token)match(input,KW_SERDE,FOLLOW_KW_SERDE_in_fileFormat6764); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SERDE.add(KW_SERDE383);


                    serdeCls=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat6768); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(serdeCls);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1423:111: ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
                    int alt105=2;
                    switch ( input.LA(1) ) {
                        case KW_INPUTDRIVER:
                            {
                            alt105=1;
                            }
                            break;
                    }

                    switch (alt105) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1423:112: KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral
                            {
                            KW_INPUTDRIVER384=(Token)match(input,KW_INPUTDRIVER,FOLLOW_KW_INPUTDRIVER_in_fileFormat6771); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_INPUTDRIVER.add(KW_INPUTDRIVER384);


                            inDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat6775); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_StringLiteral.add(inDriver);


                            KW_OUTPUTDRIVER385=(Token)match(input,KW_OUTPUTDRIVER,FOLLOW_KW_OUTPUTDRIVER_in_fileFormat6777); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_OUTPUTDRIVER.add(KW_OUTPUTDRIVER385);


                            outDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat6781); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_StringLiteral.add(outDriver);


                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: inDriver, inFmt, serdeCls, outDriver, outFmt
                    // token labels: inFmt, inDriver, serdeCls, outDriver, outFmt
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_inFmt=new RewriteRuleTokenStream(adaptor,"token inFmt",inFmt);
                    RewriteRuleTokenStream stream_inDriver=new RewriteRuleTokenStream(adaptor,"token inDriver",inDriver);
                    RewriteRuleTokenStream stream_serdeCls=new RewriteRuleTokenStream(adaptor,"token serdeCls",serdeCls);
                    RewriteRuleTokenStream stream_outDriver=new RewriteRuleTokenStream(adaptor,"token outDriver",outDriver);
                    RewriteRuleTokenStream stream_outFmt=new RewriteRuleTokenStream(adaptor,"token outFmt",outFmt);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1424:7: -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1424:10: ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_TABLEFILEFORMAT, "TOK_TABLEFILEFORMAT")
                        , root_1);

                        adaptor.addChild(root_1, stream_inFmt.nextNode());

                        adaptor.addChild(root_1, stream_outFmt.nextNode());

                        adaptor.addChild(root_1, stream_serdeCls.nextNode());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1424:58: ( $inDriver)?
                        if ( stream_inDriver.hasNext() ) {
                            adaptor.addChild(root_1, stream_inDriver.nextNode());

                        }
                        stream_inDriver.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1424:69: ( $outDriver)?
                        if ( stream_outDriver.hasNext() ) {
                            adaptor.addChild(root_1, stream_outDriver.nextNode());

                        }
                        stream_outDriver.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1425:7: genericSpec= identifier
                    {
                    pushFollow(FOLLOW_identifier_in_fileFormat6822);
                    genericSpec=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_identifier.add(genericSpec.getTree());

                    // AST REWRITE
                    // elements: genericSpec
                    // token labels: 
                    // rule labels: genericSpec, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_genericSpec=new RewriteRuleSubtreeStream(adaptor,"rule genericSpec",genericSpec!=null?genericSpec.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1425:30: -> ^( TOK_FILEFORMAT_GENERIC $genericSpec)
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1425:33: ^( TOK_FILEFORMAT_GENERIC $genericSpec)
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_FILEFORMAT_GENERIC, "TOK_FILEFORMAT_GENERIC")
                        , root_1);

                        adaptor.addChild(root_1, stream_genericSpec.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "fileFormat"


    public static class tabTypeExpr_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tabTypeExpr"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1428:1: tabTypeExpr : identifier ( DOT ^ identifier )? ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )? ;
    public final HiveParser.tabTypeExpr_return tabTypeExpr() throws RecognitionException {
        HiveParser.tabTypeExpr_return retval = new HiveParser.tabTypeExpr_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token DOT387=null;
        Token DOT390=null;
        Token KW_ELEM_TYPE391=null;
        Token KW_KEY_TYPE392=null;
        Token KW_VALUE_TYPE393=null;
        HiveParser_IdentifiersParser.identifier_return identifier386 =null;

        HiveParser_IdentifiersParser.identifier_return identifier388 =null;

        HiveParser_IdentifiersParser.identifier_return identifier389 =null;

        HiveParser_IdentifiersParser.identifier_return identifier394 =null;


        ASTNode DOT387_tree=null;
        ASTNode DOT390_tree=null;
        ASTNode KW_ELEM_TYPE391_tree=null;
        ASTNode KW_KEY_TYPE392_tree=null;
        ASTNode KW_VALUE_TYPE393_tree=null;

         pushMsg("specifying table types", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:4: ( identifier ( DOT ^ identifier )? ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )? )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:6: identifier ( DOT ^ identifier )? ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )?
            {
            root_0 = (ASTNode)adaptor.nil();


            pushFollow(FOLLOW_identifier_in_tabTypeExpr6857);
            identifier386=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier386.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:17: ( DOT ^ identifier )?
            int alt107=2;
            switch ( input.LA(1) ) {
                case DOT:
                    {
                    alt107=1;
                    }
                    break;
            }

            switch (alt107) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:18: DOT ^ identifier
                    {
                    DOT387=(Token)match(input,DOT,FOLLOW_DOT_in_tabTypeExpr6860); if (state.failed) return retval;
                    if ( state.backtracking==0 ) {
                    DOT387_tree = 
                    (ASTNode)adaptor.create(DOT387)
                    ;
                    root_0 = (ASTNode)adaptor.becomeRoot(DOT387_tree, root_0);
                    }

                    pushFollow(FOLLOW_identifier_in_tabTypeExpr6863);
                    identifier388=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier388.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1432:4: ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )?
            int alt110=2;
            switch ( input.LA(1) ) {
                case Identifier:
                case KW_ABORT:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_AUTOCOMMIT:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CACHE:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONSTRAINT:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURRENT_DATE:
                case KW_CURRENT_TIMESTAMP:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DAY:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DOW:
                case KW_DROP:
                case KW_DUMP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FOREIGN:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOUR:
                case KW_IDXPROPERTIES:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ISOLATION:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEY:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LAST:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LEVEL:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATCHED:
                case KW_MATERIALIZED:
                case KW_MERGE:
                case KW_METADATA:
                case KW_MINUTE:
                case KW_MONTH:
                case KW_MSCK:
                case KW_NONE:
                case KW_NORELY:
                case KW_NOSCAN:
                case KW_NOVALIDATE:
                case KW_NULL:
                case KW_NULLS:
                case KW_OF:
                case KW_OFFSET:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRIMARY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PURGE:
                case KW_QUARTER:
                case KW_RANGE:
                case KW_READ:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REFERENCES:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RELY:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPL:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SECOND:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SNAPSHOT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STATUS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTION:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALIDATE:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_VIEWS:
                case KW_WEEK:
                case KW_WHILE:
                case KW_WITH:
                case KW_WORK:
                case KW_WRITE:
                case KW_YEAR:
                case KW_BATCH:
                case KW_DAYOFWEEK:
                case KW_HOLD_DDLTIME:
                case KW_IGNORE:
                case KW_NO_DROP:
                case KW_OFFLINE:
                case KW_PROTECTION:
                case KW_READONLY:
                    {
                    alt110=1;
                    }
                    break;
                case KW_PARTITION:
                    {
                    switch ( input.LA(2) ) {
                        case EOF:
                        case DOT:
                        case KW_EXTENDED:
                        case KW_PARTITION:
                            {
                            alt110=1;
                            }
                            break;
                    }

                    }
                    break;
            }

            switch (alt110) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1432:5: identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )*
                    {
                    pushFollow(FOLLOW_identifier_in_tabTypeExpr6871);
                    identifier389=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier389.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1432:16: ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )*
                    loop109:
                    do {
                        int alt109=2;
                        switch ( input.LA(1) ) {
                        case DOT:
                            {
                            alt109=1;
                            }
                            break;

                        }

                        switch (alt109) {
                    	case 1 :
                    	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1432:17: DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier )
                    	    {
                    	    DOT390=(Token)match(input,DOT,FOLLOW_DOT_in_tabTypeExpr6874); if (state.failed) return retval;
                    	    if ( state.backtracking==0 ) {
                    	    DOT390_tree = 
                    	    (ASTNode)adaptor.create(DOT390)
                    	    ;
                    	    root_0 = (ASTNode)adaptor.becomeRoot(DOT390_tree, root_0);
                    	    }

                    	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1433:4: ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier )
                    	    int alt108=4;
                    	    switch ( input.LA(1) ) {
                    	    case KW_ELEM_TYPE:
                    	        {
                    	        int LA108_1 = input.LA(2);

                    	        if ( (synpred4_HiveParser()) ) {
                    	            alt108=1;
                    	        }
                    	        else if ( (true) ) {
                    	            alt108=4;
                    	        }
                    	        else {
                    	            if (state.backtracking>0) {state.failed=true; return retval;}
                    	            NoViableAltException nvae =
                    	                new NoViableAltException("", 108, 1, input);

                    	            throw nvae;

                    	        }
                    	        }
                    	        break;
                    	    case KW_KEY_TYPE:
                    	        {
                    	        int LA108_2 = input.LA(2);

                    	        if ( (synpred5_HiveParser()) ) {
                    	            alt108=2;
                    	        }
                    	        else if ( (true) ) {
                    	            alt108=4;
                    	        }
                    	        else {
                    	            if (state.backtracking>0) {state.failed=true; return retval;}
                    	            NoViableAltException nvae =
                    	                new NoViableAltException("", 108, 2, input);

                    	            throw nvae;

                    	        }
                    	        }
                    	        break;
                    	    case KW_VALUE_TYPE:
                    	        {
                    	        int LA108_3 = input.LA(2);

                    	        if ( (synpred6_HiveParser()) ) {
                    	            alt108=3;
                    	        }
                    	        else if ( (true) ) {
                    	            alt108=4;
                    	        }
                    	        else {
                    	            if (state.backtracking>0) {state.failed=true; return retval;}
                    	            NoViableAltException nvae =
                    	                new NoViableAltException("", 108, 3, input);

                    	            throw nvae;

                    	        }
                    	        }
                    	        break;
                    	    case Identifier:
                    	    case KW_ABORT:
                    	    case KW_ADD:
                    	    case KW_ADMIN:
                    	    case KW_AFTER:
                    	    case KW_ALL:
                    	    case KW_ALTER:
                    	    case KW_ANALYZE:
                    	    case KW_ARCHIVE:
                    	    case KW_ARRAY:
                    	    case KW_AS:
                    	    case KW_ASC:
                    	    case KW_AUTHORIZATION:
                    	    case KW_AUTOCOMMIT:
                    	    case KW_BEFORE:
                    	    case KW_BETWEEN:
                    	    case KW_BIGINT:
                    	    case KW_BINARY:
                    	    case KW_BOOLEAN:
                    	    case KW_BOTH:
                    	    case KW_BUCKET:
                    	    case KW_BUCKETS:
                    	    case KW_BY:
                    	    case KW_CACHE:
                    	    case KW_CASCADE:
                    	    case KW_CHANGE:
                    	    case KW_CLUSTER:
                    	    case KW_CLUSTERED:
                    	    case KW_CLUSTERSTATUS:
                    	    case KW_COLLECTION:
                    	    case KW_COLUMNS:
                    	    case KW_COMMENT:
                    	    case KW_COMPACT:
                    	    case KW_COMPACTIONS:
                    	    case KW_COMPUTE:
                    	    case KW_CONCATENATE:
                    	    case KW_CONSTRAINT:
                    	    case KW_CONTINUE:
                    	    case KW_CREATE:
                    	    case KW_CUBE:
                    	    case KW_CURRENT_DATE:
                    	    case KW_CURRENT_TIMESTAMP:
                    	    case KW_CURSOR:
                    	    case KW_DATA:
                    	    case KW_DATABASES:
                    	    case KW_DATE:
                    	    case KW_DATETIME:
                    	    case KW_DAY:
                    	    case KW_DBPROPERTIES:
                    	    case KW_DECIMAL:
                    	    case KW_DEFERRED:
                    	    case KW_DEFINED:
                    	    case KW_DELETE:
                    	    case KW_DELIMITED:
                    	    case KW_DEPENDENCY:
                    	    case KW_DESC:
                    	    case KW_DESCRIBE:
                    	    case KW_DIRECTORIES:
                    	    case KW_DIRECTORY:
                    	    case KW_DISABLE:
                    	    case KW_DISTRIBUTE:
                    	    case KW_DOUBLE:
                    	    case KW_DOW:
                    	    case KW_DROP:
                    	    case KW_DUMP:
                    	    case KW_ENABLE:
                    	    case KW_ESCAPED:
                    	    case KW_EXCLUSIVE:
                    	    case KW_EXISTS:
                    	    case KW_EXPLAIN:
                    	    case KW_EXPORT:
                    	    case KW_EXTERNAL:
                    	    case KW_FALSE:
                    	    case KW_FETCH:
                    	    case KW_FIELDS:
                    	    case KW_FILE:
                    	    case KW_FILEFORMAT:
                    	    case KW_FIRST:
                    	    case KW_FLOAT:
                    	    case KW_FOR:
                    	    case KW_FOREIGN:
                    	    case KW_FORMAT:
                    	    case KW_FORMATTED:
                    	    case KW_FULL:
                    	    case KW_FUNCTIONS:
                    	    case KW_GRANT:
                    	    case KW_GROUP:
                    	    case KW_GROUPING:
                    	    case KW_HOUR:
                    	    case KW_IDXPROPERTIES:
                    	    case KW_IMPORT:
                    	    case KW_IN:
                    	    case KW_INDEX:
                    	    case KW_INDEXES:
                    	    case KW_INNER:
                    	    case KW_INPATH:
                    	    case KW_INPUTDRIVER:
                    	    case KW_INPUTFORMAT:
                    	    case KW_INSERT:
                    	    case KW_INT:
                    	    case KW_INTERSECT:
                    	    case KW_INTO:
                    	    case KW_IS:
                    	    case KW_ISOLATION:
                    	    case KW_ITEMS:
                    	    case KW_JAR:
                    	    case KW_KEY:
                    	    case KW_KEYS:
                    	    case KW_LAST:
                    	    case KW_LATERAL:
                    	    case KW_LEFT:
                    	    case KW_LEVEL:
                    	    case KW_LIKE:
                    	    case KW_LIMIT:
                    	    case KW_LINES:
                    	    case KW_LOAD:
                    	    case KW_LOCAL:
                    	    case KW_LOCATION:
                    	    case KW_LOCK:
                    	    case KW_LOCKS:
                    	    case KW_LOGICAL:
                    	    case KW_LONG:
                    	    case KW_MAPJOIN:
                    	    case KW_MATCHED:
                    	    case KW_MATERIALIZED:
                    	    case KW_MERGE:
                    	    case KW_METADATA:
                    	    case KW_MINUTE:
                    	    case KW_MONTH:
                    	    case KW_MSCK:
                    	    case KW_NONE:
                    	    case KW_NORELY:
                    	    case KW_NOSCAN:
                    	    case KW_NOVALIDATE:
                    	    case KW_NULL:
                    	    case KW_NULLS:
                    	    case KW_OF:
                    	    case KW_OFFSET:
                    	    case KW_OPTION:
                    	    case KW_ORDER:
                    	    case KW_OUT:
                    	    case KW_OUTER:
                    	    case KW_OUTPUTDRIVER:
                    	    case KW_OUTPUTFORMAT:
                    	    case KW_OVERWRITE:
                    	    case KW_OWNER:
                    	    case KW_PARTITION:
                    	    case KW_PARTITIONED:
                    	    case KW_PARTITIONS:
                    	    case KW_PERCENT:
                    	    case KW_PLUS:
                    	    case KW_PRETTY:
                    	    case KW_PRIMARY:
                    	    case KW_PRINCIPALS:
                    	    case KW_PROCEDURE:
                    	    case KW_PURGE:
                    	    case KW_QUARTER:
                    	    case KW_RANGE:
                    	    case KW_READ:
                    	    case KW_READS:
                    	    case KW_REBUILD:
                    	    case KW_RECORDREADER:
                    	    case KW_RECORDWRITER:
                    	    case KW_REFERENCES:
                    	    case KW_REGEXP:
                    	    case KW_RELOAD:
                    	    case KW_RELY:
                    	    case KW_RENAME:
                    	    case KW_REPAIR:
                    	    case KW_REPL:
                    	    case KW_REPLACE:
                    	    case KW_REPLICATION:
                    	    case KW_RESTRICT:
                    	    case KW_REVOKE:
                    	    case KW_REWRITE:
                    	    case KW_RIGHT:
                    	    case KW_RLIKE:
                    	    case KW_ROLE:
                    	    case KW_ROLES:
                    	    case KW_ROLLUP:
                    	    case KW_ROW:
                    	    case KW_ROWS:
                    	    case KW_SCHEMA:
                    	    case KW_SCHEMAS:
                    	    case KW_SECOND:
                    	    case KW_SEMI:
                    	    case KW_SERDE:
                    	    case KW_SERDEPROPERTIES:
                    	    case KW_SERVER:
                    	    case KW_SET:
                    	    case KW_SETS:
                    	    case KW_SHARED:
                    	    case KW_SHOW:
                    	    case KW_SHOW_DATABASE:
                    	    case KW_SKEWED:
                    	    case KW_SMALLINT:
                    	    case KW_SNAPSHOT:
                    	    case KW_SORT:
                    	    case KW_SORTED:
                    	    case KW_SSL:
                    	    case KW_STATISTICS:
                    	    case KW_STATUS:
                    	    case KW_STORED:
                    	    case KW_STREAMTABLE:
                    	    case KW_STRING:
                    	    case KW_STRUCT:
                    	    case KW_TABLE:
                    	    case KW_TABLES:
                    	    case KW_TBLPROPERTIES:
                    	    case KW_TEMPORARY:
                    	    case KW_TERMINATED:
                    	    case KW_TIMESTAMP:
                    	    case KW_TINYINT:
                    	    case KW_TO:
                    	    case KW_TOUCH:
                    	    case KW_TRANSACTION:
                    	    case KW_TRANSACTIONS:
                    	    case KW_TRIGGER:
                    	    case KW_TRUE:
                    	    case KW_TRUNCATE:
                    	    case KW_UNARCHIVE:
                    	    case KW_UNDO:
                    	    case KW_UNION:
                    	    case KW_UNIONTYPE:
                    	    case KW_UNLOCK:
                    	    case KW_UNSET:
                    	    case KW_UNSIGNED:
                    	    case KW_UPDATE:
                    	    case KW_URI:
                    	    case KW_USE:
                    	    case KW_USER:
                    	    case KW_USING:
                    	    case KW_UTC:
                    	    case KW_UTCTIMESTAMP:
                    	    case KW_VALIDATE:
                    	    case KW_VALUES:
                    	    case KW_VIEW:
                    	    case KW_VIEWS:
                    	    case KW_WEEK:
                    	    case KW_WHILE:
                    	    case KW_WITH:
                    	    case KW_WORK:
                    	    case KW_WRITE:
                    	    case KW_YEAR:
                    	    case KW_BATCH:
                    	    case KW_DAYOFWEEK:
                    	    case KW_HOLD_DDLTIME:
                    	    case KW_IGNORE:
                    	    case KW_NO_DROP:
                    	    case KW_OFFLINE:
                    	    case KW_PROTECTION:
                    	    case KW_READONLY:
                    	        {
                    	        alt108=4;
                    	        }
                    	        break;
                    	    default:
                    	        if (state.backtracking>0) {state.failed=true; return retval;}
                    	        NoViableAltException nvae =
                    	            new NoViableAltException("", 108, 0, input);

                    	        throw nvae;

                    	    }

                    	    switch (alt108) {
                    	        case 1 :
                    	            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:4: ( KW_ELEM_TYPE )=> KW_ELEM_TYPE
                    	            {
                    	            KW_ELEM_TYPE391=(Token)match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_tabTypeExpr6891); if (state.failed) return retval;
                    	            if ( state.backtracking==0 ) {
                    	            KW_ELEM_TYPE391_tree = 
                    	            (ASTNode)adaptor.create(KW_ELEM_TYPE391)
                    	            ;
                    	            adaptor.addChild(root_0, KW_ELEM_TYPE391_tree);
                    	            }

                    	            }
                    	            break;
                    	        case 2 :
                    	            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1436:4: ( KW_KEY_TYPE )=> KW_KEY_TYPE
                    	            {
                    	            KW_KEY_TYPE392=(Token)match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_tabTypeExpr6908); if (state.failed) return retval;
                    	            if ( state.backtracking==0 ) {
                    	            KW_KEY_TYPE392_tree = 
                    	            (ASTNode)adaptor.create(KW_KEY_TYPE392)
                    	            ;
                    	            adaptor.addChild(root_0, KW_KEY_TYPE392_tree);
                    	            }

                    	            }
                    	            break;
                    	        case 3 :
                    	            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:4: ( KW_VALUE_TYPE )=> KW_VALUE_TYPE
                    	            {
                    	            KW_VALUE_TYPE393=(Token)match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_tabTypeExpr6925); if (state.failed) return retval;
                    	            if ( state.backtracking==0 ) {
                    	            KW_VALUE_TYPE393_tree = 
                    	            (ASTNode)adaptor.create(KW_VALUE_TYPE393)
                    	            ;
                    	            adaptor.addChild(root_0, KW_VALUE_TYPE393_tree);
                    	            }

                    	            }
                    	            break;
                    	        case 4 :
                    	            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1439:6: identifier
                    	            {
                    	            pushFollow(FOLLOW_identifier_in_tabTypeExpr6933);
                    	            identifier394=identifier();

                    	            state._fsp--;
                    	            if (state.failed) return retval;
                    	            if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier394.getTree());

                    	            }
                    	            break;

                    	    }


                    	    }
                    	    break;

                    	default :
                    	    break loop109;
                        }
                    } while (true);


                    }
                    break;

            }


            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tabTypeExpr"


    public static class partTypeExpr_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "partTypeExpr"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1444:1: partTypeExpr : tabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? ) ;
    public final HiveParser.partTypeExpr_return partTypeExpr() throws RecognitionException {
        HiveParser.partTypeExpr_return retval = new HiveParser.partTypeExpr_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.tabTypeExpr_return tabTypeExpr395 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec396 =null;


        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_tabTypeExpr=new RewriteRuleSubtreeStream(adaptor,"rule tabTypeExpr");
         pushMsg("specifying table partitions", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1447:5: ( tabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1447:8: tabTypeExpr ( partitionSpec )?
            {
            pushFollow(FOLLOW_tabTypeExpr_in_partTypeExpr6973);
            tabTypeExpr395=tabTypeExpr();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tabTypeExpr.add(tabTypeExpr395.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1447:20: ( partitionSpec )?
            int alt111=2;
            switch ( input.LA(1) ) {
                case KW_PARTITION:
                    {
                    alt111=1;
                    }
                    break;
            }

            switch (alt111) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1447:20: partitionSpec
                    {
                    pushFollow(FOLLOW_partitionSpec_in_partTypeExpr6975);
                    partitionSpec396=partitionSpec();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec396.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: partitionSpec, tabTypeExpr
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1447:35: -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1447:38: ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABTYPE, "TOK_TABTYPE")
                , root_1);

                adaptor.addChild(root_1, stream_tabTypeExpr.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1447:64: ( partitionSpec )?
                if ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "partTypeExpr"


    public static class tabPartColTypeExpr_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tabPartColTypeExpr"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1450:1: tabPartColTypeExpr : tableName ( partitionSpec )? ( extColumnName )? -> ^( TOK_TABTYPE tableName ( partitionSpec )? ( extColumnName )? ) ;
    public final HiveParser.tabPartColTypeExpr_return tabPartColTypeExpr() throws RecognitionException {
        HiveParser.tabPartColTypeExpr_return retval = new HiveParser.tabPartColTypeExpr_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser_FromClauseParser.tableName_return tableName397 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec398 =null;

        HiveParser.extColumnName_return extColumnName399 =null;


        RewriteRuleSubtreeStream stream_extColumnName=new RewriteRuleSubtreeStream(adaptor,"rule extColumnName");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("specifying table partitions columnName", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1453:5: ( tableName ( partitionSpec )? ( extColumnName )? -> ^( TOK_TABTYPE tableName ( partitionSpec )? ( extColumnName )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1453:8: tableName ( partitionSpec )? ( extColumnName )?
            {
            pushFollow(FOLLOW_tableName_in_tabPartColTypeExpr7015);
            tableName397=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(tableName397.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1453:18: ( partitionSpec )?
            int alt112=2;
            switch ( input.LA(1) ) {
                case KW_PARTITION:
                    {
                    switch ( input.LA(2) ) {
                        case LPAREN:
                            {
                            alt112=1;
                            }
                            break;
                    }

                    }
                    break;
            }

            switch (alt112) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1453:18: partitionSpec
                    {
                    pushFollow(FOLLOW_partitionSpec_in_tabPartColTypeExpr7017);
                    partitionSpec398=partitionSpec();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec398.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1453:33: ( extColumnName )?
            int alt113=2;
            switch ( input.LA(1) ) {
                case Identifier:
                case KW_ABORT:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_AUTOCOMMIT:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CACHE:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONSTRAINT:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURRENT_DATE:
                case KW_CURRENT_TIMESTAMP:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DAY:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DOW:
                case KW_DROP:
                case KW_DUMP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FOREIGN:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOUR:
                case KW_IDXPROPERTIES:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ISOLATION:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEY:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LAST:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LEVEL:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATCHED:
                case KW_MATERIALIZED:
                case KW_MERGE:
                case KW_METADATA:
                case KW_MINUTE:
                case KW_MONTH:
                case KW_MSCK:
                case KW_NONE:
                case KW_NORELY:
                case KW_NOSCAN:
                case KW_NOVALIDATE:
                case KW_NULL:
                case KW_NULLS:
                case KW_OF:
                case KW_OFFSET:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRIMARY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PURGE:
                case KW_QUARTER:
                case KW_RANGE:
                case KW_READ:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REFERENCES:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RELY:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPL:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SECOND:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SNAPSHOT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STATUS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTION:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALIDATE:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_VIEWS:
                case KW_WEEK:
                case KW_WHILE:
                case KW_WITH:
                case KW_WORK:
                case KW_WRITE:
                case KW_YEAR:
                case KW_BATCH:
                case KW_DAYOFWEEK:
                case KW_HOLD_DDLTIME:
                case KW_IGNORE:
                case KW_NO_DROP:
                case KW_OFFLINE:
                case KW_PROTECTION:
                case KW_READONLY:
                    {
                    alt113=1;
                    }
                    break;
            }

            switch (alt113) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1453:33: extColumnName
                    {
                    pushFollow(FOLLOW_extColumnName_in_tabPartColTypeExpr7020);
                    extColumnName399=extColumnName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_extColumnName.add(extColumnName399.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: extColumnName, partitionSpec, tableName
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1453:48: -> ^( TOK_TABTYPE tableName ( partitionSpec )? ( extColumnName )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1453:51: ^( TOK_TABTYPE tableName ( partitionSpec )? ( extColumnName )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABTYPE, "TOK_TABTYPE")
                , root_1);

                adaptor.addChild(root_1, stream_tableName.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1453:75: ( partitionSpec )?
                if ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1453:90: ( extColumnName )?
                if ( stream_extColumnName.hasNext() ) {
                    adaptor.addChild(root_1, stream_extColumnName.nextTree());

                }
                stream_extColumnName.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tabPartColTypeExpr"


    public static class descStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "descStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1456:1: descStatement : ( KW_DESCRIBE | KW_DESC ) ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED | KW_PRETTY )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) ) ;
    public final HiveParser.descStatement_return descStatement() throws RecognitionException {
        HiveParser.descStatement_return retval = new HiveParser.descStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token descOptions=null;
        Token KW_DESCRIBE400=null;
        Token KW_DESC401=null;
        Token KW_DATABASE402=null;
        Token KW_SCHEMA403=null;
        Token KW_EXTENDED404=null;
        Token KW_FUNCTION405=null;
        Token KW_EXTENDED406=null;
        HiveParser_IdentifiersParser.identifier_return dbName =null;

        HiveParser_IdentifiersParser.descFuncNames_return name =null;

        HiveParser.tabPartColTypeExpr_return parttype =null;


        ASTNode descOptions_tree=null;
        ASTNode KW_DESCRIBE400_tree=null;
        ASTNode KW_DESC401_tree=null;
        ASTNode KW_DATABASE402_tree=null;
        ASTNode KW_SCHEMA403_tree=null;
        ASTNode KW_EXTENDED404_tree=null;
        ASTNode KW_FUNCTION405_tree=null;
        ASTNode KW_EXTENDED406_tree=null;
        RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
        RewriteRuleTokenStream stream_KW_PRETTY=new RewriteRuleTokenStream(adaptor,"token KW_PRETTY");
        RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
        RewriteRuleTokenStream stream_KW_EXTENDED=new RewriteRuleTokenStream(adaptor,"token KW_EXTENDED");
        RewriteRuleTokenStream stream_KW_DESC=new RewriteRuleTokenStream(adaptor,"token KW_DESC");
        RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
        RewriteRuleTokenStream stream_KW_FORMATTED=new RewriteRuleTokenStream(adaptor,"token KW_FORMATTED");
        RewriteRuleTokenStream stream_KW_DESCRIBE=new RewriteRuleTokenStream(adaptor,"token KW_DESCRIBE");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_tabPartColTypeExpr=new RewriteRuleSubtreeStream(adaptor,"rule tabPartColTypeExpr");
        RewriteRuleSubtreeStream stream_descFuncNames=new RewriteRuleSubtreeStream(adaptor,"rule descFuncNames");
         pushMsg("describe statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1459:5: ( ( KW_DESCRIBE | KW_DESC ) ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED | KW_PRETTY )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1460:5: ( KW_DESCRIBE | KW_DESC ) ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED | KW_PRETTY )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) )
            {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1460:5: ( KW_DESCRIBE | KW_DESC )
            int alt114=2;
            switch ( input.LA(1) ) {
            case KW_DESCRIBE:
                {
                alt114=1;
                }
                break;
            case KW_DESC:
                {
                alt114=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 114, 0, input);

                throw nvae;

            }

            switch (alt114) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1460:6: KW_DESCRIBE
                    {
                    KW_DESCRIBE400=(Token)match(input,KW_DESCRIBE,FOLLOW_KW_DESCRIBE_in_descStatement7067); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_DESCRIBE.add(KW_DESCRIBE400);


                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1460:18: KW_DESC
                    {
                    KW_DESC401=(Token)match(input,KW_DESC,FOLLOW_KW_DESC_in_descStatement7069); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_DESC.add(KW_DESC401);


                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1461:5: ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED | KW_PRETTY )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) )
            int alt119=4;
            alt119 = dfa119.predict(input);
            switch (alt119) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1462:5: ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier )
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1462:32: ( KW_DATABASE | KW_SCHEMA )
                    int alt115=2;
                    switch ( input.LA(1) ) {
                    case KW_DATABASE:
                        {
                        alt115=1;
                        }
                        break;
                    case KW_SCHEMA:
                        {
                        alt115=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 115, 0, input);

                        throw nvae;

                    }

                    switch (alt115) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1462:33: KW_DATABASE
                            {
                            KW_DATABASE402=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_descStatement7091); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE402);


                            }
                            break;
                        case 2 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1462:45: KW_SCHEMA
                            {
                            KW_SCHEMA403=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_descStatement7093); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA403);


                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1462:56: ( KW_EXTENDED )?
                    int alt116=2;
                    switch ( input.LA(1) ) {
                        case KW_EXTENDED:
                            {
                            alt116=1;
                            }
                            break;
                    }

                    switch (alt116) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1462:56: KW_EXTENDED
                            {
                            KW_EXTENDED404=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_descStatement7096); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_EXTENDED.add(KW_EXTENDED404);


                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1462:69: (dbName= identifier )
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1462:70: dbName= identifier
                    {
                    pushFollow(FOLLOW_identifier_in_descStatement7102);
                    dbName=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());

                    }


                    // AST REWRITE
                    // elements: KW_EXTENDED, dbName
                    // token labels: 
                    // rule labels: dbName, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1462:89: -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1462:92: ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_DESCDATABASE, "TOK_DESCDATABASE")
                        , root_1);

                        adaptor.addChild(root_1, stream_dbName.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1462:119: ( KW_EXTENDED )?
                        if ( stream_KW_EXTENDED.hasNext() ) {
                            adaptor.addChild(root_1, 
                            stream_KW_EXTENDED.nextNode()
                            );

                        }
                        stream_KW_EXTENDED.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1464:5: ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames )
                    {
                    KW_FUNCTION405=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_descStatement7133); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_FUNCTION.add(KW_FUNCTION405);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1464:34: ( KW_EXTENDED )?
                    int alt117=2;
                    switch ( input.LA(1) ) {
                        case KW_EXTENDED:
                            {
                            alt117=1;
                            }
                            break;
                    }

                    switch (alt117) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1464:34: KW_EXTENDED
                            {
                            KW_EXTENDED406=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_descStatement7135); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_EXTENDED.add(KW_EXTENDED406);


                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1464:47: (name= descFuncNames )
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1464:48: name= descFuncNames
                    {
                    pushFollow(FOLLOW_descFuncNames_in_descStatement7141);
                    name=descFuncNames();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_descFuncNames.add(name.getTree());

                    }


                    // AST REWRITE
                    // elements: KW_EXTENDED, name
                    // token labels: 
                    // rule labels: name, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1464:68: -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1464:71: ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_DESCFUNCTION, "TOK_DESCFUNCTION")
                        , root_1);

                        adaptor.addChild(root_1, stream_name.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1464:96: ( KW_EXTENDED )?
                        if ( stream_KW_EXTENDED.hasNext() ) {
                            adaptor.addChild(root_1, 
                            stream_KW_EXTENDED.nextNode()
                            );

                        }
                        stream_KW_EXTENDED.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1466:5: ( KW_FORMATTED | KW_EXTENDED | KW_PRETTY )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY ) parttype= tabPartColTypeExpr )
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1466:45: ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY ) parttype= tabPartColTypeExpr )
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1466:46: (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY ) parttype= tabPartColTypeExpr
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1466:46: (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY )
                    int alt118=3;
                    switch ( input.LA(1) ) {
                    case KW_FORMATTED:
                        {
                        alt118=1;
                        }
                        break;
                    case KW_EXTENDED:
                        {
                        alt118=2;
                        }
                        break;
                    case KW_PRETTY:
                        {
                        alt118=3;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 118, 0, input);

                        throw nvae;

                    }

                    switch (alt118) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1466:47: descOptions= KW_FORMATTED
                            {
                            descOptions=(Token)match(input,KW_FORMATTED,FOLLOW_KW_FORMATTED_in_descStatement7180); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_FORMATTED.add(descOptions);


                            }
                            break;
                        case 2 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1466:72: descOptions= KW_EXTENDED
                            {
                            descOptions=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_descStatement7184); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_EXTENDED.add(descOptions);


                            }
                            break;
                        case 3 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1466:96: descOptions= KW_PRETTY
                            {
                            descOptions=(Token)match(input,KW_PRETTY,FOLLOW_KW_PRETTY_in_descStatement7188); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_PRETTY.add(descOptions);


                            }
                            break;

                    }


                    pushFollow(FOLLOW_tabPartColTypeExpr_in_descStatement7193);
                    parttype=tabPartColTypeExpr();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tabPartColTypeExpr.add(parttype.getTree());

                    }


                    // AST REWRITE
                    // elements: parttype, descOptions
                    // token labels: descOptions
                    // rule labels: parttype, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_descOptions=new RewriteRuleTokenStream(adaptor,"token descOptions",descOptions);
                    RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1466:148: -> ^( TOK_DESCTABLE $parttype $descOptions)
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1466:151: ^( TOK_DESCTABLE $parttype $descOptions)
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_DESCTABLE, "TOK_DESCTABLE")
                        , root_1);

                        adaptor.addChild(root_1, stream_parttype.nextTree());

                        adaptor.addChild(root_1, stream_descOptions.nextNode());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 4 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1468:5: parttype= tabPartColTypeExpr
                    {
                    pushFollow(FOLLOW_tabPartColTypeExpr_in_descStatement7220);
                    parttype=tabPartColTypeExpr();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tabPartColTypeExpr.add(parttype.getTree());

                    // AST REWRITE
                    // elements: parttype
                    // token labels: 
                    // rule labels: parttype, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1468:33: -> ^( TOK_DESCTABLE $parttype)
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1468:36: ^( TOK_DESCTABLE $parttype)
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_DESCTABLE, "TOK_DESCTABLE")
                        , root_1);

                        adaptor.addChild(root_1, stream_parttype.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }


            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "descStatement"


    public static class analyzeStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "analyzeStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1472:1: analyzeStatement : KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) ( ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) | ( KW_CACHE )=> KW_CACHE KW_METADATA -> ^( TOK_CACHE_METADATA $parttype) ) ;
    public final HiveParser.analyzeStatement_return analyzeStatement() throws RecognitionException {
        HiveParser.analyzeStatement_return retval = new HiveParser.analyzeStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token noscan=null;
        Token partialscan=null;
        Token KW_ANALYZE407=null;
        Token KW_TABLE408=null;
        Token KW_COMPUTE409=null;
        Token KW_STATISTICS410=null;
        Token KW_FOR411=null;
        Token KW_COLUMNS412=null;
        Token KW_CACHE413=null;
        Token KW_METADATA414=null;
        HiveParser_IdentifiersParser.tableOrPartition_return parttype =null;

        HiveParser.columnNameList_return statsColumnName =null;


        ASTNode noscan_tree=null;
        ASTNode partialscan_tree=null;
        ASTNode KW_ANALYZE407_tree=null;
        ASTNode KW_TABLE408_tree=null;
        ASTNode KW_COMPUTE409_tree=null;
        ASTNode KW_STATISTICS410_tree=null;
        ASTNode KW_FOR411_tree=null;
        ASTNode KW_COLUMNS412_tree=null;
        ASTNode KW_CACHE413_tree=null;
        ASTNode KW_METADATA414_tree=null;
        RewriteRuleTokenStream stream_KW_STATISTICS=new RewriteRuleTokenStream(adaptor,"token KW_STATISTICS");
        RewriteRuleTokenStream stream_KW_ANALYZE=new RewriteRuleTokenStream(adaptor,"token KW_ANALYZE");
        RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
        RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
        RewriteRuleTokenStream stream_KW_PARTIALSCAN=new RewriteRuleTokenStream(adaptor,"token KW_PARTIALSCAN");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_KW_COMPUTE=new RewriteRuleTokenStream(adaptor,"token KW_COMPUTE");
        RewriteRuleTokenStream stream_KW_METADATA=new RewriteRuleTokenStream(adaptor,"token KW_METADATA");
        RewriteRuleTokenStream stream_KW_NOSCAN=new RewriteRuleTokenStream(adaptor,"token KW_NOSCAN");
        RewriteRuleTokenStream stream_KW_CACHE=new RewriteRuleTokenStream(adaptor,"token KW_CACHE");
        RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
         pushMsg("analyze statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1475:5: ( KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) ( ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) | ( KW_CACHE )=> KW_CACHE KW_METADATA -> ^( TOK_CACHE_METADATA $parttype) ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1475:7: KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) ( ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) | ( KW_CACHE )=> KW_CACHE KW_METADATA -> ^( TOK_CACHE_METADATA $parttype) )
            {
            KW_ANALYZE407=(Token)match(input,KW_ANALYZE,FOLLOW_KW_ANALYZE_in_analyzeStatement7262); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ANALYZE.add(KW_ANALYZE407);


            KW_TABLE408=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_analyzeStatement7264); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE408);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1475:27: (parttype= tableOrPartition )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1475:28: parttype= tableOrPartition
            {
            pushFollow(FOLLOW_tableOrPartition_in_analyzeStatement7269);
            parttype=tableOrPartition();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableOrPartition.add(parttype.getTree());

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1476:7: ( ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) | ( KW_CACHE )=> KW_CACHE KW_METADATA -> ^( TOK_CACHE_METADATA $parttype) )
            int alt122=2;
            int LA122_0 = input.LA(1);

            if ( (LA122_0==KW_COMPUTE) && (synpred10_HiveParser())) {
                alt122=1;
            }
            else if ( (LA122_0==KW_CACHE) && (synpred11_HiveParser())) {
                alt122=2;
            }
            else {
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 122, 0, input);

                throw nvae;

            }
            switch (alt122) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:7: ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )?
                    {
                    KW_COMPUTE409=(Token)match(input,KW_COMPUTE,FOLLOW_KW_COMPUTE_in_analyzeStatement7292); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_COMPUTE.add(KW_COMPUTE409);


                    KW_STATISTICS410=(Token)match(input,KW_STATISTICS,FOLLOW_KW_STATISTICS_in_analyzeStatement7294); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_STATISTICS.add(KW_STATISTICS410);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:48: ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )?
                    int alt121=4;
                    switch ( input.LA(1) ) {
                        case KW_NOSCAN:
                            {
                            alt121=1;
                            }
                            break;
                        case KW_PARTIALSCAN:
                            {
                            alt121=2;
                            }
                            break;
                        case KW_FOR:
                            {
                            alt121=3;
                            }
                            break;
                    }

                    switch (alt121) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:49: (noscan= KW_NOSCAN )
                            {
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:49: (noscan= KW_NOSCAN )
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:50: noscan= KW_NOSCAN
                            {
                            noscan=(Token)match(input,KW_NOSCAN,FOLLOW_KW_NOSCAN_in_analyzeStatement7300); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_NOSCAN.add(noscan);


                            }


                            }
                            break;
                        case 2 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:70: (partialscan= KW_PARTIALSCAN )
                            {
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:70: (partialscan= KW_PARTIALSCAN )
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:71: partialscan= KW_PARTIALSCAN
                            {
                            partialscan=(Token)match(input,KW_PARTIALSCAN,FOLLOW_KW_PARTIALSCAN_in_analyzeStatement7308); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_PARTIALSCAN.add(partialscan);


                            }


                            }
                            break;
                        case 3 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1478:57: ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? )
                            {
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1478:57: ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? )
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1478:58: KW_FOR KW_COLUMNS (statsColumnName= columnNameList )?
                            {
                            KW_FOR411=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_analyzeStatement7368); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR411);


                            KW_COLUMNS412=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_analyzeStatement7370); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS412);


                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1478:76: (statsColumnName= columnNameList )?
                            int alt120=2;
                            switch ( input.LA(1) ) {
                                case Identifier:
                                case KW_ABORT:
                                case KW_ADD:
                                case KW_ADMIN:
                                case KW_AFTER:
                                case KW_ALL:
                                case KW_ALTER:
                                case KW_ANALYZE:
                                case KW_ARCHIVE:
                                case KW_ARRAY:
                                case KW_AS:
                                case KW_ASC:
                                case KW_AUTHORIZATION:
                                case KW_AUTOCOMMIT:
                                case KW_BEFORE:
                                case KW_BETWEEN:
                                case KW_BIGINT:
                                case KW_BINARY:
                                case KW_BOOLEAN:
                                case KW_BOTH:
                                case KW_BUCKET:
                                case KW_BUCKETS:
                                case KW_BY:
                                case KW_CACHE:
                                case KW_CASCADE:
                                case KW_CHANGE:
                                case KW_CLUSTER:
                                case KW_CLUSTERED:
                                case KW_CLUSTERSTATUS:
                                case KW_COLLECTION:
                                case KW_COLUMNS:
                                case KW_COMMENT:
                                case KW_COMPACT:
                                case KW_COMPACTIONS:
                                case KW_COMPUTE:
                                case KW_CONCATENATE:
                                case KW_CONSTRAINT:
                                case KW_CONTINUE:
                                case KW_CREATE:
                                case KW_CUBE:
                                case KW_CURRENT_DATE:
                                case KW_CURRENT_TIMESTAMP:
                                case KW_CURSOR:
                                case KW_DATA:
                                case KW_DATABASES:
                                case KW_DATE:
                                case KW_DATETIME:
                                case KW_DAY:
                                case KW_DBPROPERTIES:
                                case KW_DECIMAL:
                                case KW_DEFERRED:
                                case KW_DEFINED:
                                case KW_DELETE:
                                case KW_DELIMITED:
                                case KW_DEPENDENCY:
                                case KW_DESC:
                                case KW_DESCRIBE:
                                case KW_DIRECTORIES:
                                case KW_DIRECTORY:
                                case KW_DISABLE:
                                case KW_DISTRIBUTE:
                                case KW_DOUBLE:
                                case KW_DOW:
                                case KW_DROP:
                                case KW_DUMP:
                                case KW_ELEM_TYPE:
                                case KW_ENABLE:
                                case KW_ESCAPED:
                                case KW_EXCLUSIVE:
                                case KW_EXISTS:
                                case KW_EXPLAIN:
                                case KW_EXPORT:
                                case KW_EXTERNAL:
                                case KW_FALSE:
                                case KW_FETCH:
                                case KW_FIELDS:
                                case KW_FILE:
                                case KW_FILEFORMAT:
                                case KW_FIRST:
                                case KW_FLOAT:
                                case KW_FOR:
                                case KW_FOREIGN:
                                case KW_FORMAT:
                                case KW_FORMATTED:
                                case KW_FULL:
                                case KW_FUNCTIONS:
                                case KW_GRANT:
                                case KW_GROUP:
                                case KW_GROUPING:
                                case KW_HOUR:
                                case KW_IDXPROPERTIES:
                                case KW_IMPORT:
                                case KW_IN:
                                case KW_INDEX:
                                case KW_INDEXES:
                                case KW_INNER:
                                case KW_INPATH:
                                case KW_INPUTDRIVER:
                                case KW_INPUTFORMAT:
                                case KW_INSERT:
                                case KW_INT:
                                case KW_INTERSECT:
                                case KW_INTO:
                                case KW_IS:
                                case KW_ISOLATION:
                                case KW_ITEMS:
                                case KW_JAR:
                                case KW_KEY:
                                case KW_KEYS:
                                case KW_KEY_TYPE:
                                case KW_LAST:
                                case KW_LATERAL:
                                case KW_LEFT:
                                case KW_LEVEL:
                                case KW_LIKE:
                                case KW_LIMIT:
                                case KW_LINES:
                                case KW_LOAD:
                                case KW_LOCAL:
                                case KW_LOCATION:
                                case KW_LOCK:
                                case KW_LOCKS:
                                case KW_LOGICAL:
                                case KW_LONG:
                                case KW_MAPJOIN:
                                case KW_MATCHED:
                                case KW_MATERIALIZED:
                                case KW_MERGE:
                                case KW_METADATA:
                                case KW_MINUTE:
                                case KW_MONTH:
                                case KW_MSCK:
                                case KW_NONE:
                                case KW_NORELY:
                                case KW_NOSCAN:
                                case KW_NOVALIDATE:
                                case KW_NULL:
                                case KW_NULLS:
                                case KW_OF:
                                case KW_OFFSET:
                                case KW_OPTION:
                                case KW_ORDER:
                                case KW_OUT:
                                case KW_OUTER:
                                case KW_OUTPUTDRIVER:
                                case KW_OUTPUTFORMAT:
                                case KW_OVERWRITE:
                                case KW_OWNER:
                                case KW_PARTITION:
                                case KW_PARTITIONED:
                                case KW_PARTITIONS:
                                case KW_PERCENT:
                                case KW_PLUS:
                                case KW_PRETTY:
                                case KW_PRIMARY:
                                case KW_PRINCIPALS:
                                case KW_PROCEDURE:
                                case KW_PURGE:
                                case KW_QUARTER:
                                case KW_RANGE:
                                case KW_READ:
                                case KW_READS:
                                case KW_REBUILD:
                                case KW_RECORDREADER:
                                case KW_RECORDWRITER:
                                case KW_REFERENCES:
                                case KW_REGEXP:
                                case KW_RELOAD:
                                case KW_RELY:
                                case KW_RENAME:
                                case KW_REPAIR:
                                case KW_REPL:
                                case KW_REPLACE:
                                case KW_REPLICATION:
                                case KW_RESTRICT:
                                case KW_REVOKE:
                                case KW_REWRITE:
                                case KW_RIGHT:
                                case KW_RLIKE:
                                case KW_ROLE:
                                case KW_ROLES:
                                case KW_ROLLUP:
                                case KW_ROW:
                                case KW_ROWS:
                                case KW_SCHEMA:
                                case KW_SCHEMAS:
                                case KW_SECOND:
                                case KW_SEMI:
                                case KW_SERDE:
                                case KW_SERDEPROPERTIES:
                                case KW_SERVER:
                                case KW_SET:
                                case KW_SETS:
                                case KW_SHARED:
                                case KW_SHOW:
                                case KW_SHOW_DATABASE:
                                case KW_SKEWED:
                                case KW_SMALLINT:
                                case KW_SNAPSHOT:
                                case KW_SORT:
                                case KW_SORTED:
                                case KW_SSL:
                                case KW_STATISTICS:
                                case KW_STATUS:
                                case KW_STORED:
                                case KW_STREAMTABLE:
                                case KW_STRING:
                                case KW_STRUCT:
                                case KW_TABLE:
                                case KW_TABLES:
                                case KW_TBLPROPERTIES:
                                case KW_TEMPORARY:
                                case KW_TERMINATED:
                                case KW_TIMESTAMP:
                                case KW_TINYINT:
                                case KW_TO:
                                case KW_TOUCH:
                                case KW_TRANSACTION:
                                case KW_TRANSACTIONS:
                                case KW_TRIGGER:
                                case KW_TRUE:
                                case KW_TRUNCATE:
                                case KW_UNARCHIVE:
                                case KW_UNDO:
                                case KW_UNION:
                                case KW_UNIONTYPE:
                                case KW_UNLOCK:
                                case KW_UNSET:
                                case KW_UNSIGNED:
                                case KW_UPDATE:
                                case KW_URI:
                                case KW_USE:
                                case KW_USER:
                                case KW_USING:
                                case KW_UTC:
                                case KW_UTCTIMESTAMP:
                                case KW_VALIDATE:
                                case KW_VALUES:
                                case KW_VALUE_TYPE:
                                case KW_VIEW:
                                case KW_VIEWS:
                                case KW_WEEK:
                                case KW_WHILE:
                                case KW_WITH:
                                case KW_WORK:
                                case KW_WRITE:
                                case KW_YEAR:
                                case KW_BATCH:
                                case KW_DAYOFWEEK:
                                case KW_HOLD_DDLTIME:
                                case KW_IGNORE:
                                case KW_NO_DROP:
                                case KW_OFFLINE:
                                case KW_PROTECTION:
                                case KW_READONLY:
                                    {
                                    alt120=1;
                                    }
                                    break;
                            }

                            switch (alt120) {
                                case 1 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1478:77: statsColumnName= columnNameList
                                    {
                                    pushFollow(FOLLOW_columnNameList_in_analyzeStatement7375);
                                    statsColumnName=columnNameList();

                                    state._fsp--;
                                    if (state.failed) return retval;
                                    if ( state.backtracking==0 ) stream_columnNameList.add(statsColumnName.getTree());

                                    }
                                    break;

                            }


                            }


                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: partialscan, KW_COLUMNS, noscan, statsColumnName, parttype
                    // token labels: partialscan, noscan
                    // rule labels: statsColumnName, parttype, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_partialscan=new RewriteRuleTokenStream(adaptor,"token partialscan",partialscan);
                    RewriteRuleTokenStream stream_noscan=new RewriteRuleTokenStream(adaptor,"token noscan",noscan);
                    RewriteRuleSubtreeStream stream_statsColumnName=new RewriteRuleSubtreeStream(adaptor,"rule statsColumnName",statsColumnName!=null?statsColumnName.tree:null);
                    RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1479:7: -> ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( KW_COLUMNS )? ( $statsColumnName)? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1479:10: ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( KW_COLUMNS )? ( $statsColumnName)? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ANALYZE, "TOK_ANALYZE")
                        , root_1);

                        adaptor.addChild(root_1, stream_parttype.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1479:35: ( $noscan)?
                        if ( stream_noscan.hasNext() ) {
                            adaptor.addChild(root_1, stream_noscan.nextNode());

                        }
                        stream_noscan.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1479:44: ( $partialscan)?
                        if ( stream_partialscan.hasNext() ) {
                            adaptor.addChild(root_1, stream_partialscan.nextNode());

                        }
                        stream_partialscan.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1479:57: ( KW_COLUMNS )?
                        if ( stream_KW_COLUMNS.hasNext() ) {
                            adaptor.addChild(root_1, 
                            stream_KW_COLUMNS.nextNode()
                            );

                        }
                        stream_KW_COLUMNS.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1479:70: ( $statsColumnName)?
                        if ( stream_statsColumnName.hasNext() ) {
                            adaptor.addChild(root_1, stream_statsColumnName.nextTree());

                        }
                        stream_statsColumnName.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1481:7: ( KW_CACHE )=> KW_CACHE KW_METADATA
                    {
                    KW_CACHE413=(Token)match(input,KW_CACHE,FOLLOW_KW_CACHE_in_analyzeStatement7432); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_CACHE.add(KW_CACHE413);


                    KW_METADATA414=(Token)match(input,KW_METADATA,FOLLOW_KW_METADATA_in_analyzeStatement7434); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_METADATA.add(KW_METADATA414);


                    // AST REWRITE
                    // elements: parttype
                    // token labels: 
                    // rule labels: parttype, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1481:42: -> ^( TOK_CACHE_METADATA $parttype)
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1481:45: ^( TOK_CACHE_METADATA $parttype)
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_CACHE_METADATA, "TOK_CACHE_METADATA")
                        , root_1);

                        adaptor.addChild(root_1, stream_parttype.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }


            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "analyzeStatement"


    public static class showStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "showStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1485:1: showStatement : ( KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )? -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? ) | KW_SHOW KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? -> ^( TOK_SHOWCOLUMNS tableName ( $db_name)? ) | KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier | showFunctionIdentifier )? -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? ) | KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )? -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? ) | KW_SHOW KW_CREATE ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier -> ^( TOK_SHOW_CREATEDATABASE $db_name) | KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) ) | KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )? -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? ) | KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )? -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? ) | KW_SHOW KW_LOCKS ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) ) | KW_SHOW (showOptions= KW_FORMATTED )? ( KW_INDEX | KW_INDEXES ) KW_ON showStmtIdentifier ( ( KW_FROM | KW_IN ) db_name= identifier )? -> ^( TOK_SHOWINDEXES showStmtIdentifier ( $showOptions)? ( $db_name)? ) | KW_SHOW KW_COMPACTIONS -> ^( TOK_SHOW_COMPACTIONS ) | KW_SHOW KW_TRANSACTIONS -> ^( TOK_SHOW_TRANSACTIONS ) | KW_SHOW KW_CONF StringLiteral -> ^( TOK_SHOWCONF StringLiteral ) );
    public final HiveParser.showStatement_return showStatement() throws RecognitionException {
        HiveParser.showStatement_return retval = new HiveParser.showStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token prptyName=null;
        Token dbName=null;
        Token isExtended=null;
        Token showOptions=null;
        Token KW_SHOW415=null;
        Token KW_DATABASES416=null;
        Token KW_SCHEMAS417=null;
        Token KW_LIKE418=null;
        Token KW_SHOW420=null;
        Token KW_TABLES421=null;
        Token KW_FROM422=null;
        Token KW_IN423=null;
        Token KW_LIKE424=null;
        Token KW_SHOW427=null;
        Token KW_COLUMNS428=null;
        Token KW_FROM429=null;
        Token KW_IN430=null;
        Token KW_FROM432=null;
        Token KW_IN433=null;
        Token KW_SHOW434=null;
        Token KW_FUNCTIONS435=null;
        Token KW_LIKE436=null;
        Token KW_SHOW439=null;
        Token KW_PARTITIONS440=null;
        Token KW_SHOW442=null;
        Token KW_CREATE443=null;
        Token KW_DATABASE444=null;
        Token KW_SCHEMA445=null;
        Token KW_TABLE446=null;
        Token KW_SHOW447=null;
        Token KW_TABLE448=null;
        Token KW_EXTENDED449=null;
        Token KW_FROM450=null;
        Token KW_IN451=null;
        Token KW_LIKE452=null;
        Token KW_SHOW455=null;
        Token KW_TBLPROPERTIES456=null;
        Token LPAREN458=null;
        Token RPAREN459=null;
        Token KW_SHOW460=null;
        Token KW_LOCKS461=null;
        Token KW_DATABASE462=null;
        Token KW_SCHEMA463=null;
        Token KW_SHOW464=null;
        Token KW_INDEX465=null;
        Token KW_INDEXES466=null;
        Token KW_ON467=null;
        Token KW_FROM469=null;
        Token KW_IN470=null;
        Token KW_SHOW471=null;
        Token KW_COMPACTIONS472=null;
        Token KW_SHOW473=null;
        Token KW_TRANSACTIONS474=null;
        Token KW_SHOW475=null;
        Token KW_CONF476=null;
        Token StringLiteral477=null;
        HiveParser_IdentifiersParser.identifier_return db_name =null;

        HiveParser_FromClauseParser.tableName_return tabName =null;

        HiveParser.partTypeExpr_return parttype =null;

        HiveParser.showStmtIdentifier_return showStmtIdentifier419 =null;

        HiveParser.showStmtIdentifier_return showStmtIdentifier425 =null;

        HiveParser.showStmtIdentifier_return showStmtIdentifier426 =null;

        HiveParser_FromClauseParser.tableName_return tableName431 =null;

        HiveParser.showFunctionIdentifier_return showFunctionIdentifier437 =null;

        HiveParser.showFunctionIdentifier_return showFunctionIdentifier438 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec441 =null;

        HiveParser.showStmtIdentifier_return showStmtIdentifier453 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec454 =null;

        HiveParser_FromClauseParser.tableName_return tableName457 =null;

        HiveParser.showStmtIdentifier_return showStmtIdentifier468 =null;


        ASTNode prptyName_tree=null;
        ASTNode dbName_tree=null;
        ASTNode isExtended_tree=null;
        ASTNode showOptions_tree=null;
        ASTNode KW_SHOW415_tree=null;
        ASTNode KW_DATABASES416_tree=null;
        ASTNode KW_SCHEMAS417_tree=null;
        ASTNode KW_LIKE418_tree=null;
        ASTNode KW_SHOW420_tree=null;
        ASTNode KW_TABLES421_tree=null;
        ASTNode KW_FROM422_tree=null;
        ASTNode KW_IN423_tree=null;
        ASTNode KW_LIKE424_tree=null;
        ASTNode KW_SHOW427_tree=null;
        ASTNode KW_COLUMNS428_tree=null;
        ASTNode KW_FROM429_tree=null;
        ASTNode KW_IN430_tree=null;
        ASTNode KW_FROM432_tree=null;
        ASTNode KW_IN433_tree=null;
        ASTNode KW_SHOW434_tree=null;
        ASTNode KW_FUNCTIONS435_tree=null;
        ASTNode KW_LIKE436_tree=null;
        ASTNode KW_SHOW439_tree=null;
        ASTNode KW_PARTITIONS440_tree=null;
        ASTNode KW_SHOW442_tree=null;
        ASTNode KW_CREATE443_tree=null;
        ASTNode KW_DATABASE444_tree=null;
        ASTNode KW_SCHEMA445_tree=null;
        ASTNode KW_TABLE446_tree=null;
        ASTNode KW_SHOW447_tree=null;
        ASTNode KW_TABLE448_tree=null;
        ASTNode KW_EXTENDED449_tree=null;
        ASTNode KW_FROM450_tree=null;
        ASTNode KW_IN451_tree=null;
        ASTNode KW_LIKE452_tree=null;
        ASTNode KW_SHOW455_tree=null;
        ASTNode KW_TBLPROPERTIES456_tree=null;
        ASTNode LPAREN458_tree=null;
        ASTNode RPAREN459_tree=null;
        ASTNode KW_SHOW460_tree=null;
        ASTNode KW_LOCKS461_tree=null;
        ASTNode KW_DATABASE462_tree=null;
        ASTNode KW_SCHEMA463_tree=null;
        ASTNode KW_SHOW464_tree=null;
        ASTNode KW_INDEX465_tree=null;
        ASTNode KW_INDEXES466_tree=null;
        ASTNode KW_ON467_tree=null;
        ASTNode KW_FROM469_tree=null;
        ASTNode KW_IN470_tree=null;
        ASTNode KW_SHOW471_tree=null;
        ASTNode KW_COMPACTIONS472_tree=null;
        ASTNode KW_SHOW473_tree=null;
        ASTNode KW_TRANSACTIONS474_tree=null;
        ASTNode KW_SHOW475_tree=null;
        ASTNode KW_CONF476_tree=null;
        ASTNode StringLiteral477_tree=null;
        RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_KW_LIKE=new RewriteRuleTokenStream(adaptor,"token KW_LIKE");
        RewriteRuleTokenStream stream_KW_PARTITIONS=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONS");
        RewriteRuleTokenStream stream_KW_IN=new RewriteRuleTokenStream(adaptor,"token KW_IN");
        RewriteRuleTokenStream stream_KW_LOCKS=new RewriteRuleTokenStream(adaptor,"token KW_LOCKS");
        RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
        RewriteRuleTokenStream stream_KW_TABLES=new RewriteRuleTokenStream(adaptor,"token KW_TABLES");
        RewriteRuleTokenStream stream_KW_FUNCTIONS=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTIONS");
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_KW_EXTENDED=new RewriteRuleTokenStream(adaptor,"token KW_EXTENDED");
        RewriteRuleTokenStream stream_KW_CONF=new RewriteRuleTokenStream(adaptor,"token KW_CONF");
        RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
        RewriteRuleTokenStream stream_KW_TRANSACTIONS=new RewriteRuleTokenStream(adaptor,"token KW_TRANSACTIONS");
        RewriteRuleTokenStream stream_KW_SCHEMAS=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMAS");
        RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleTokenStream stream_KW_FORMATTED=new RewriteRuleTokenStream(adaptor,"token KW_FORMATTED");
        RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
        RewriteRuleTokenStream stream_KW_INDEX=new RewriteRuleTokenStream(adaptor,"token KW_INDEX");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_KW_COMPACTIONS=new RewriteRuleTokenStream(adaptor,"token KW_COMPACTIONS");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_DATABASES=new RewriteRuleTokenStream(adaptor,"token KW_DATABASES");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_INDEXES=new RewriteRuleTokenStream(adaptor,"token KW_INDEXES");
        RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
        RewriteRuleTokenStream stream_KW_TBLPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_TBLPROPERTIES");
        RewriteRuleSubtreeStream stream_showStmtIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule showStmtIdentifier");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_showFunctionIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule showFunctionIdentifier");
        RewriteRuleSubtreeStream stream_partTypeExpr=new RewriteRuleSubtreeStream(adaptor,"rule partTypeExpr");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("show statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:5: ( KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )? -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? ) | KW_SHOW KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? -> ^( TOK_SHOWCOLUMNS tableName ( $db_name)? ) | KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier | showFunctionIdentifier )? -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? ) | KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )? -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? ) | KW_SHOW KW_CREATE ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier -> ^( TOK_SHOW_CREATEDATABASE $db_name) | KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) ) | KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )? -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? ) | KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )? -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? ) | KW_SHOW KW_LOCKS ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) ) | KW_SHOW (showOptions= KW_FORMATTED )? ( KW_INDEX | KW_INDEXES ) KW_ON showStmtIdentifier ( ( KW_FROM | KW_IN ) db_name= identifier )? -> ^( TOK_SHOWINDEXES showStmtIdentifier ( $showOptions)? ( $db_name)? ) | KW_SHOW KW_COMPACTIONS -> ^( TOK_SHOW_COMPACTIONS ) | KW_SHOW KW_TRANSACTIONS -> ^( TOK_SHOW_TRANSACTIONS ) | KW_SHOW KW_CONF StringLiteral -> ^( TOK_SHOWCONF StringLiteral ) )
            int alt148=13;
            switch ( input.LA(1) ) {
            case KW_SHOW:
                {
                switch ( input.LA(2) ) {
                case KW_TABLES:
                    {
                    alt148=2;
                    }
                    break;
                case KW_COLUMNS:
                    {
                    alt148=3;
                    }
                    break;
                case KW_FUNCTIONS:
                    {
                    alt148=4;
                    }
                    break;
                case KW_PARTITIONS:
                    {
                    alt148=5;
                    }
                    break;
                case KW_CREATE:
                    {
                    alt148=6;
                    }
                    break;
                case KW_TABLE:
                    {
                    alt148=7;
                    }
                    break;
                case KW_TBLPROPERTIES:
                    {
                    alt148=8;
                    }
                    break;
                case KW_LOCKS:
                    {
                    alt148=9;
                    }
                    break;
                case KW_COMPACTIONS:
                    {
                    alt148=11;
                    }
                    break;
                case KW_TRANSACTIONS:
                    {
                    alt148=12;
                    }
                    break;
                case KW_CONF:
                    {
                    alt148=13;
                    }
                    break;
                case KW_DATABASES:
                case KW_SCHEMAS:
                    {
                    alt148=1;
                    }
                    break;
                case KW_FORMATTED:
                case KW_INDEX:
                case KW_INDEXES:
                    {
                    alt148=10;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 148, 1, input);

                    throw nvae;

                }

                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 148, 0, input);

                throw nvae;

            }

            switch (alt148) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:7: KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )?
                    {
                    KW_SHOW415=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement7478); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW415);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:15: ( KW_DATABASES | KW_SCHEMAS )
                    int alt123=2;
                    switch ( input.LA(1) ) {
                    case KW_DATABASES:
                        {
                        alt123=1;
                        }
                        break;
                    case KW_SCHEMAS:
                        {
                        alt123=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 123, 0, input);

                        throw nvae;

                    }

                    switch (alt123) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:16: KW_DATABASES
                            {
                            KW_DATABASES416=(Token)match(input,KW_DATABASES,FOLLOW_KW_DATABASES_in_showStatement7481); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_DATABASES.add(KW_DATABASES416);


                            }
                            break;
                        case 2 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:29: KW_SCHEMAS
                            {
                            KW_SCHEMAS417=(Token)match(input,KW_SCHEMAS,FOLLOW_KW_SCHEMAS_in_showStatement7483); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_SCHEMAS.add(KW_SCHEMAS417);


                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:41: ( KW_LIKE showStmtIdentifier )?
                    int alt124=2;
                    switch ( input.LA(1) ) {
                        case KW_LIKE:
                            {
                            alt124=1;
                            }
                            break;
                    }

                    switch (alt124) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:42: KW_LIKE showStmtIdentifier
                            {
                            KW_LIKE418=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement7487); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE418);


                            pushFollow(FOLLOW_showStmtIdentifier_in_showStatement7489);
                            showStmtIdentifier419=showStmtIdentifier();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier419.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: showStmtIdentifier
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1488:71: -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:74: ^( TOK_SHOWDATABASES ( showStmtIdentifier )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SHOWDATABASES, "TOK_SHOWDATABASES")
                        , root_1);

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:94: ( showStmtIdentifier )?
                        if ( stream_showStmtIdentifier.hasNext() ) {
                            adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());

                        }
                        stream_showStmtIdentifier.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1489:7: KW_SHOW KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
                    {
                    KW_SHOW420=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement7508); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW420);


                    KW_TABLES421=(Token)match(input,KW_TABLES,FOLLOW_KW_TABLES_in_showStatement7510); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TABLES.add(KW_TABLES421);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1489:25: ( ( KW_FROM | KW_IN ) db_name= identifier )?
                    int alt126=2;
                    switch ( input.LA(1) ) {
                        case KW_FROM:
                            {
                            alt126=1;
                            }
                            break;
                        case KW_IN:
                            {
                            switch ( input.LA(2) ) {
                                case Identifier:
                                case KW_ABORT:
                                case KW_ADD:
                                case KW_ADMIN:
                                case KW_AFTER:
                                case KW_ALL:
                                case KW_ALTER:
                                case KW_ANALYZE:
                                case KW_ARCHIVE:
                                case KW_ARRAY:
                                case KW_AS:
                                case KW_ASC:
                                case KW_AUTHORIZATION:
                                case KW_AUTOCOMMIT:
                                case KW_BEFORE:
                                case KW_BETWEEN:
                                case KW_BIGINT:
                                case KW_BINARY:
                                case KW_BOOLEAN:
                                case KW_BOTH:
                                case KW_BUCKET:
                                case KW_BUCKETS:
                                case KW_BY:
                                case KW_CACHE:
                                case KW_CASCADE:
                                case KW_CHANGE:
                                case KW_CLUSTER:
                                case KW_CLUSTERED:
                                case KW_CLUSTERSTATUS:
                                case KW_COLLECTION:
                                case KW_COLUMNS:
                                case KW_COMMENT:
                                case KW_COMPACT:
                                case KW_COMPACTIONS:
                                case KW_COMPUTE:
                                case KW_CONCATENATE:
                                case KW_CONSTRAINT:
                                case KW_CONTINUE:
                                case KW_CREATE:
                                case KW_CUBE:
                                case KW_CURRENT_DATE:
                                case KW_CURRENT_TIMESTAMP:
                                case KW_CURSOR:
                                case KW_DATA:
                                case KW_DATABASES:
                                case KW_DATE:
                                case KW_DATETIME:
                                case KW_DAY:
                                case KW_DBPROPERTIES:
                                case KW_DECIMAL:
                                case KW_DEFERRED:
                                case KW_DEFINED:
                                case KW_DELETE:
                                case KW_DELIMITED:
                                case KW_DEPENDENCY:
                                case KW_DESC:
                                case KW_DESCRIBE:
                                case KW_DIRECTORIES:
                                case KW_DIRECTORY:
                                case KW_DISABLE:
                                case KW_DISTRIBUTE:
                                case KW_DOUBLE:
                                case KW_DOW:
                                case KW_DROP:
                                case KW_DUMP:
                                case KW_ELEM_TYPE:
                                case KW_ENABLE:
                                case KW_ESCAPED:
                                case KW_EXCLUSIVE:
                                case KW_EXISTS:
                                case KW_EXPLAIN:
                                case KW_EXPORT:
                                case KW_EXTERNAL:
                                case KW_FALSE:
                                case KW_FETCH:
                                case KW_FIELDS:
                                case KW_FILE:
                                case KW_FILEFORMAT:
                                case KW_FIRST:
                                case KW_FLOAT:
                                case KW_FOR:
                                case KW_FOREIGN:
                                case KW_FORMAT:
                                case KW_FORMATTED:
                                case KW_FULL:
                                case KW_FUNCTIONS:
                                case KW_GRANT:
                                case KW_GROUP:
                                case KW_GROUPING:
                                case KW_HOUR:
                                case KW_IDXPROPERTIES:
                                case KW_IMPORT:
                                case KW_IN:
                                case KW_INDEX:
                                case KW_INDEXES:
                                case KW_INNER:
                                case KW_INPATH:
                                case KW_INPUTDRIVER:
                                case KW_INPUTFORMAT:
                                case KW_INSERT:
                                case KW_INT:
                                case KW_INTERSECT:
                                case KW_INTO:
                                case KW_IS:
                                case KW_ISOLATION:
                                case KW_ITEMS:
                                case KW_JAR:
                                case KW_KEY:
                                case KW_KEYS:
                                case KW_KEY_TYPE:
                                case KW_LAST:
                                case KW_LATERAL:
                                case KW_LEFT:
                                case KW_LEVEL:
                                case KW_LIKE:
                                case KW_LIMIT:
                                case KW_LINES:
                                case KW_LOAD:
                                case KW_LOCAL:
                                case KW_LOCATION:
                                case KW_LOCK:
                                case KW_LOCKS:
                                case KW_LOGICAL:
                                case KW_LONG:
                                case KW_MAPJOIN:
                                case KW_MATCHED:
                                case KW_MATERIALIZED:
                                case KW_MERGE:
                                case KW_METADATA:
                                case KW_MINUTE:
                                case KW_MONTH:
                                case KW_MSCK:
                                case KW_NONE:
                                case KW_NORELY:
                                case KW_NOSCAN:
                                case KW_NOVALIDATE:
                                case KW_NULL:
                                case KW_NULLS:
                                case KW_OF:
                                case KW_OFFSET:
                                case KW_OPTION:
                                case KW_ORDER:
                                case KW_OUT:
                                case KW_OUTER:
                                case KW_OUTPUTDRIVER:
                                case KW_OUTPUTFORMAT:
                                case KW_OVERWRITE:
                                case KW_OWNER:
                                case KW_PARTITION:
                                case KW_PARTITIONED:
                                case KW_PARTITIONS:
                                case KW_PERCENT:
                                case KW_PLUS:
                                case KW_PRETTY:
                                case KW_PRIMARY:
                                case KW_PRINCIPALS:
                                case KW_PROCEDURE:
                                case KW_PURGE:
                                case KW_QUARTER:
                                case KW_RANGE:
                                case KW_READ:
                                case KW_READS:
                                case KW_REBUILD:
                                case KW_RECORDREADER:
                                case KW_RECORDWRITER:
                                case KW_REFERENCES:
                                case KW_REGEXP:
                                case KW_RELOAD:
                                case KW_RELY:
                                case KW_RENAME:
                                case KW_REPAIR:
                                case KW_REPL:
                                case KW_REPLACE:
                                case KW_REPLICATION:
                                case KW_RESTRICT:
                                case KW_REVOKE:
                                case KW_REWRITE:
                                case KW_RIGHT:
                                case KW_RLIKE:
                                case KW_ROLE:
                                case KW_ROLES:
                                case KW_ROLLUP:
                                case KW_ROW:
                                case KW_ROWS:
                                case KW_SCHEMA:
                                case KW_SCHEMAS:
                                case KW_SECOND:
                                case KW_SEMI:
                                case KW_SERDE:
                                case KW_SERDEPROPERTIES:
                                case KW_SERVER:
                                case KW_SET:
                                case KW_SETS:
                                case KW_SHARED:
                                case KW_SHOW:
                                case KW_SHOW_DATABASE:
                                case KW_SKEWED:
                                case KW_SMALLINT:
                                case KW_SNAPSHOT:
                                case KW_SORT:
                                case KW_SORTED:
                                case KW_SSL:
                                case KW_STATISTICS:
                                case KW_STATUS:
                                case KW_STORED:
                                case KW_STREAMTABLE:
                                case KW_STRING:
                                case KW_STRUCT:
                                case KW_TABLE:
                                case KW_TABLES:
                                case KW_TBLPROPERTIES:
                                case KW_TEMPORARY:
                                case KW_TERMINATED:
                                case KW_TIMESTAMP:
                                case KW_TINYINT:
                                case KW_TO:
                                case KW_TOUCH:
                                case KW_TRANSACTION:
                                case KW_TRANSACTIONS:
                                case KW_TRIGGER:
                                case KW_TRUE:
                                case KW_TRUNCATE:
                                case KW_UNARCHIVE:
                                case KW_UNDO:
                                case KW_UNION:
                                case KW_UNIONTYPE:
                                case KW_UNLOCK:
                                case KW_UNSET:
                                case KW_UNSIGNED:
                                case KW_UPDATE:
                                case KW_URI:
                                case KW_USE:
                                case KW_USER:
                                case KW_USING:
                                case KW_UTC:
                                case KW_UTCTIMESTAMP:
                                case KW_VALIDATE:
                                case KW_VALUES:
                                case KW_VALUE_TYPE:
                                case KW_VIEW:
                                case KW_VIEWS:
                                case KW_WEEK:
                                case KW_WHILE:
                                case KW_WITH:
                                case KW_WORK:
                                case KW_WRITE:
                                case KW_YEAR:
                                case KW_BATCH:
                                case KW_DAYOFWEEK:
                                case KW_HOLD_DDLTIME:
                                case KW_IGNORE:
                                case KW_NO_DROP:
                                case KW_OFFLINE:
                                case KW_PROTECTION:
                                case KW_READONLY:
                                    {
                                    alt126=1;
                                    }
                                    break;
                            }

                            }
                            break;
                    }

                    switch (alt126) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1489:26: ( KW_FROM | KW_IN ) db_name= identifier
                            {
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1489:26: ( KW_FROM | KW_IN )
                            int alt125=2;
                            switch ( input.LA(1) ) {
                            case KW_FROM:
                                {
                                alt125=1;
                                }
                                break;
                            case KW_IN:
                                {
                                alt125=2;
                                }
                                break;
                            default:
                                if (state.backtracking>0) {state.failed=true; return retval;}
                                NoViableAltException nvae =
                                    new NoViableAltException("", 125, 0, input);

                                throw nvae;

                            }

                            switch (alt125) {
                                case 1 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1489:27: KW_FROM
                                    {
                                    KW_FROM422=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement7514); if (state.failed) return retval; 
                                    if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM422);


                                    }
                                    break;
                                case 2 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1489:35: KW_IN
                                    {
                                    KW_IN423=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement7516); if (state.failed) return retval; 
                                    if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN423);


                                    }
                                    break;

                            }


                            pushFollow(FOLLOW_identifier_in_showStatement7521);
                            db_name=identifier();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1489:63: ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
                    int alt127=3;
                    switch ( input.LA(1) ) {
                        case KW_LIKE:
                            {
                            switch ( input.LA(2) ) {
                                case Identifier:
                                case KW_ABORT:
                                case KW_ADD:
                                case KW_ADMIN:
                                case KW_AFTER:
                                case KW_ALL:
                                case KW_ALTER:
                                case KW_ANALYZE:
                                case KW_ARCHIVE:
                                case KW_ARRAY:
                                case KW_AS:
                                case KW_ASC:
                                case KW_AUTHORIZATION:
                                case KW_AUTOCOMMIT:
                                case KW_BEFORE:
                                case KW_BETWEEN:
                                case KW_BIGINT:
                                case KW_BINARY:
                                case KW_BOOLEAN:
                                case KW_BOTH:
                                case KW_BUCKET:
                                case KW_BUCKETS:
                                case KW_BY:
                                case KW_CACHE:
                                case KW_CASCADE:
                                case KW_CHANGE:
                                case KW_CLUSTER:
                                case KW_CLUSTERED:
                                case KW_CLUSTERSTATUS:
                                case KW_COLLECTION:
                                case KW_COLUMNS:
                                case KW_COMMENT:
                                case KW_COMPACT:
                                case KW_COMPACTIONS:
                                case KW_COMPUTE:
                                case KW_CONCATENATE:
                                case KW_CONSTRAINT:
                                case KW_CONTINUE:
                                case KW_CREATE:
                                case KW_CUBE:
                                case KW_CURRENT_DATE:
                                case KW_CURRENT_TIMESTAMP:
                                case KW_CURSOR:
                                case KW_DATA:
                                case KW_DATABASES:
                                case KW_DATE:
                                case KW_DATETIME:
                                case KW_DAY:
                                case KW_DBPROPERTIES:
                                case KW_DECIMAL:
                                case KW_DEFERRED:
                                case KW_DEFINED:
                                case KW_DELETE:
                                case KW_DELIMITED:
                                case KW_DEPENDENCY:
                                case KW_DESC:
                                case KW_DESCRIBE:
                                case KW_DIRECTORIES:
                                case KW_DIRECTORY:
                                case KW_DISABLE:
                                case KW_DISTRIBUTE:
                                case KW_DOUBLE:
                                case KW_DOW:
                                case KW_DROP:
                                case KW_DUMP:
                                case KW_ELEM_TYPE:
                                case KW_ENABLE:
                                case KW_ESCAPED:
                                case KW_EXCLUSIVE:
                                case KW_EXISTS:
                                case KW_EXPLAIN:
                                case KW_EXPORT:
                                case KW_EXTERNAL:
                                case KW_FALSE:
                                case KW_FETCH:
                                case KW_FIELDS:
                                case KW_FILE:
                                case KW_FILEFORMAT:
                                case KW_FIRST:
                                case KW_FLOAT:
                                case KW_FOR:
                                case KW_FOREIGN:
                                case KW_FORMAT:
                                case KW_FORMATTED:
                                case KW_FULL:
                                case KW_FUNCTIONS:
                                case KW_GRANT:
                                case KW_GROUP:
                                case KW_GROUPING:
                                case KW_HOUR:
                                case KW_IDXPROPERTIES:
                                case KW_IMPORT:
                                case KW_IN:
                                case KW_INDEX:
                                case KW_INDEXES:
                                case KW_INNER:
                                case KW_INPATH:
                                case KW_INPUTDRIVER:
                                case KW_INPUTFORMAT:
                                case KW_INSERT:
                                case KW_INT:
                                case KW_INTERSECT:
                                case KW_INTO:
                                case KW_IS:
                                case KW_ISOLATION:
                                case KW_ITEMS:
                                case KW_JAR:
                                case KW_KEY:
                                case KW_KEYS:
                                case KW_KEY_TYPE:
                                case KW_LAST:
                                case KW_LATERAL:
                                case KW_LEFT:
                                case KW_LEVEL:
                                case KW_LIKE:
                                case KW_LIMIT:
                                case KW_LINES:
                                case KW_LOAD:
                                case KW_LOCAL:
                                case KW_LOCATION:
                                case KW_LOCK:
                                case KW_LOCKS:
                                case KW_LOGICAL:
                                case KW_LONG:
                                case KW_MAPJOIN:
                                case KW_MATCHED:
                                case KW_MATERIALIZED:
                                case KW_MERGE:
                                case KW_METADATA:
                                case KW_MINUTE:
                                case KW_MONTH:
                                case KW_MSCK:
                                case KW_NONE:
                                case KW_NORELY:
                                case KW_NOSCAN:
                                case KW_NOVALIDATE:
                                case KW_NULL:
                                case KW_NULLS:
                                case KW_OF:
                                case KW_OFFSET:
                                case KW_OPTION:
                                case KW_ORDER:
                                case KW_OUT:
                                case KW_OUTER:
                                case KW_OUTPUTDRIVER:
                                case KW_OUTPUTFORMAT:
                                case KW_OVERWRITE:
                                case KW_OWNER:
                                case KW_PARTITION:
                                case KW_PARTITIONED:
                                case KW_PARTITIONS:
                                case KW_PERCENT:
                                case KW_PLUS:
                                case KW_PRETTY:
                                case KW_PRIMARY:
                                case KW_PRINCIPALS:
                                case KW_PROCEDURE:
                                case KW_PURGE:
                                case KW_QUARTER:
                                case KW_RANGE:
                                case KW_READ:
                                case KW_READS:
                                case KW_REBUILD:
                                case KW_RECORDREADER:
                                case KW_RECORDWRITER:
                                case KW_REFERENCES:
                                case KW_REGEXP:
                                case KW_RELOAD:
                                case KW_RELY:
                                case KW_RENAME:
                                case KW_REPAIR:
                                case KW_REPL:
                                case KW_REPLACE:
                                case KW_REPLICATION:
                                case KW_RESTRICT:
                                case KW_REVOKE:
                                case KW_REWRITE:
                                case KW_RIGHT:
                                case KW_RLIKE:
                                case KW_ROLE:
                                case KW_ROLES:
                                case KW_ROLLUP:
                                case KW_ROW:
                                case KW_ROWS:
                                case KW_SCHEMA:
                                case KW_SCHEMAS:
                                case KW_SECOND:
                                case KW_SEMI:
                                case KW_SERDE:
                                case KW_SERDEPROPERTIES:
                                case KW_SERVER:
                                case KW_SET:
                                case KW_SETS:
                                case KW_SHARED:
                                case KW_SHOW:
                                case KW_SHOW_DATABASE:
                                case KW_SKEWED:
                                case KW_SMALLINT:
                                case KW_SNAPSHOT:
                                case KW_SORT:
                                case KW_SORTED:
                                case KW_SSL:
                                case KW_STATISTICS:
                                case KW_STATUS:
                                case KW_STORED:
                                case KW_STREAMTABLE:
                                case KW_STRING:
                                case KW_STRUCT:
                                case KW_TABLE:
                                case KW_TABLES:
                                case KW_TBLPROPERTIES:
                                case KW_TEMPORARY:
                                case KW_TERMINATED:
                                case KW_TIMESTAMP:
                                case KW_TINYINT:
                                case KW_TO:
                                case KW_TOUCH:
                                case KW_TRANSACTION:
                                case KW_TRANSACTIONS:
                                case KW_TRIGGER:
                                case KW_TRUE:
                                case KW_TRUNCATE:
                                case KW_UNARCHIVE:
                                case KW_UNDO:
                                case KW_UNION:
                                case KW_UNIONTYPE:
                                case KW_UNLOCK:
                                case KW_UNSET:
                                case KW_UNSIGNED:
                                case KW_UPDATE:
                                case KW_URI:
                                case KW_USE:
                                case KW_USER:
                                case KW_USING:
                                case KW_UTC:
                                case KW_UTCTIMESTAMP:
                                case KW_VALIDATE:
                                case KW_VALUES:
                                case KW_VALUE_TYPE:
                                case KW_VIEW:
                                case KW_VIEWS:
                                case KW_WEEK:
                                case KW_WHILE:
                                case KW_WITH:
                                case KW_WORK:
                                case KW_WRITE:
                                case KW_YEAR:
                                case StringLiteral:
                                case KW_BATCH:
                                case KW_DAYOFWEEK:
                                case KW_HOLD_DDLTIME:
                                case KW_IGNORE:
                                case KW_NO_DROP:
                                case KW_OFFLINE:
                                case KW_PROTECTION:
                                case KW_READONLY:
                                    {
                                    alt127=1;
                                    }
                                    break;
                                case EOF:
                                    {
                                    alt127=2;
                                    }
                                    break;
                            }

                            }
                            break;
                        case Identifier:
                        case KW_ABORT:
                        case KW_ADD:
                        case KW_ADMIN:
                        case KW_AFTER:
                        case KW_ALL:
                        case KW_ALTER:
                        case KW_ANALYZE:
                        case KW_ARCHIVE:
                        case KW_ARRAY:
                        case KW_AS:
                        case KW_ASC:
                        case KW_AUTHORIZATION:
                        case KW_AUTOCOMMIT:
                        case KW_BEFORE:
                        case KW_BETWEEN:
                        case KW_BIGINT:
                        case KW_BINARY:
                        case KW_BOOLEAN:
                        case KW_BOTH:
                        case KW_BUCKET:
                        case KW_BUCKETS:
                        case KW_BY:
                        case KW_CACHE:
                        case KW_CASCADE:
                        case KW_CHANGE:
                        case KW_CLUSTER:
                        case KW_CLUSTERED:
                        case KW_CLUSTERSTATUS:
                        case KW_COLLECTION:
                        case KW_COLUMNS:
                        case KW_COMMENT:
                        case KW_COMPACT:
                        case KW_COMPACTIONS:
                        case KW_COMPUTE:
                        case KW_CONCATENATE:
                        case KW_CONSTRAINT:
                        case KW_CONTINUE:
                        case KW_CREATE:
                        case KW_CUBE:
                        case KW_CURRENT_DATE:
                        case KW_CURRENT_TIMESTAMP:
                        case KW_CURSOR:
                        case KW_DATA:
                        case KW_DATABASES:
                        case KW_DATE:
                        case KW_DATETIME:
                        case KW_DAY:
                        case KW_DBPROPERTIES:
                        case KW_DECIMAL:
                        case KW_DEFERRED:
                        case KW_DEFINED:
                        case KW_DELETE:
                        case KW_DELIMITED:
                        case KW_DEPENDENCY:
                        case KW_DESC:
                        case KW_DESCRIBE:
                        case KW_DIRECTORIES:
                        case KW_DIRECTORY:
                        case KW_DISABLE:
                        case KW_DISTRIBUTE:
                        case KW_DOUBLE:
                        case KW_DOW:
                        case KW_DROP:
                        case KW_DUMP:
                        case KW_ELEM_TYPE:
                        case KW_ENABLE:
                        case KW_ESCAPED:
                        case KW_EXCLUSIVE:
                        case KW_EXISTS:
                        case KW_EXPLAIN:
                        case KW_EXPORT:
                        case KW_EXTERNAL:
                        case KW_FALSE:
                        case KW_FETCH:
                        case KW_FIELDS:
                        case KW_FILE:
                        case KW_FILEFORMAT:
                        case KW_FIRST:
                        case KW_FLOAT:
                        case KW_FOR:
                        case KW_FOREIGN:
                        case KW_FORMAT:
                        case KW_FORMATTED:
                        case KW_FULL:
                        case KW_FUNCTIONS:
                        case KW_GRANT:
                        case KW_GROUP:
                        case KW_GROUPING:
                        case KW_HOUR:
                        case KW_IDXPROPERTIES:
                        case KW_IMPORT:
                        case KW_IN:
                        case KW_INDEX:
                        case KW_INDEXES:
                        case KW_INNER:
                        case KW_INPATH:
                        case KW_INPUTDRIVER:
                        case KW_INPUTFORMAT:
                        case KW_INSERT:
                        case KW_INT:
                        case KW_INTERSECT:
                        case KW_INTO:
                        case KW_IS:
                        case KW_ISOLATION:
                        case KW_ITEMS:
                        case KW_JAR:
                        case KW_KEY:
                        case KW_KEYS:
                        case KW_KEY_TYPE:
                        case KW_LAST:
                        case KW_LATERAL:
                        case KW_LEFT:
                        case KW_LEVEL:
                        case KW_LIMIT:
                        case KW_LINES:
                        case KW_LOAD:
                        case KW_LOCAL:
                        case KW_LOCATION:
                        case KW_LOCK:
                        case KW_LOCKS:
                        case KW_LOGICAL:
                        case KW_LONG:
                        case KW_MAPJOIN:
                        case KW_MATCHED:
                        case KW_MATERIALIZED:
                        case KW_MERGE:
                        case KW_METADATA:
                        case KW_MINUTE:
                        case KW_MONTH:
                        case KW_MSCK:
                        case KW_NONE:
                        case KW_NORELY:
                        case KW_NOSCAN:
                        case KW_NOVALIDATE:
                        case KW_NULL:
                        case KW_NULLS:
                        case KW_OF:
                        case KW_OFFSET:
                        case KW_OPTION:
                        case KW_ORDER:
                        case KW_OUT:
                        case KW_OUTER:
                        case KW_OUTPUTDRIVER:
                        case KW_OUTPUTFORMAT:
                        case KW_OVERWRITE:
                        case KW_OWNER:
                        case KW_PARTITION:
                        case KW_PARTITIONED:
                        case KW_PARTITIONS:
                        case KW_PERCENT:
                        case KW_PLUS:
                        case KW_PRETTY:
                        case KW_PRIMARY:
                        case KW_PRINCIPALS:
                        case KW_PROCEDURE:
                        case KW_PURGE:
                        case KW_QUARTER:
                        case KW_RANGE:
                        case KW_READ:
                        case KW_READS:
                        case KW_REBUILD:
                        case KW_RECORDREADER:
                        case KW_RECORDWRITER:
                        case KW_REFERENCES:
                        case KW_REGEXP:
                        case KW_RELOAD:
                        case KW_RELY:
                        case KW_RENAME:
                        case KW_REPAIR:
                        case KW_REPL:
                        case KW_REPLACE:
                        case KW_REPLICATION:
                        case KW_RESTRICT:
                        case KW_REVOKE:
                        case KW_REWRITE:
                        case KW_RIGHT:
                        case KW_RLIKE:
                        case KW_ROLE:
                        case KW_ROLES:
                        case KW_ROLLUP:
                        case KW_ROW:
                        case KW_ROWS:
                        case KW_SCHEMA:
                        case KW_SCHEMAS:
                        case KW_SECOND:
                        case KW_SEMI:
                        case KW_SERDE:
                        case KW_SERDEPROPERTIES:
                        case KW_SERVER:
                        case KW_SET:
                        case KW_SETS:
                        case KW_SHARED:
                        case KW_SHOW:
                        case KW_SHOW_DATABASE:
                        case KW_SKEWED:
                        case KW_SMALLINT:
                        case KW_SNAPSHOT:
                        case KW_SORT:
                        case KW_SORTED:
                        case KW_SSL:
                        case KW_STATISTICS:
                        case KW_STATUS:
                        case KW_STORED:
                        case KW_STREAMTABLE:
                        case KW_STRING:
                        case KW_STRUCT:
                        case KW_TABLE:
                        case KW_TABLES:
                        case KW_TBLPROPERTIES:
                        case KW_TEMPORARY:
                        case KW_TERMINATED:
                        case KW_TIMESTAMP:
                        case KW_TINYINT:
                        case KW_TO:
                        case KW_TOUCH:
                        case KW_TRANSACTION:
                        case KW_TRANSACTIONS:
                        case KW_TRIGGER:
                        case KW_TRUE:
                        case KW_TRUNCATE:
                        case KW_UNARCHIVE:
                        case KW_UNDO:
                        case KW_UNION:
                        case KW_UNIONTYPE:
                        case KW_UNLOCK:
                        case KW_UNSET:
                        case KW_UNSIGNED:
                        case KW_UPDATE:
                        case KW_URI:
                        case KW_USE:
                        case KW_USER:
                        case KW_USING:
                        case KW_UTC:
                        case KW_UTCTIMESTAMP:
                        case KW_VALIDATE:
                        case KW_VALUES:
                        case KW_VALUE_TYPE:
                        case KW_VIEW:
                        case KW_VIEWS:
                        case KW_WEEK:
                        case KW_WHILE:
                        case KW_WITH:
                        case KW_WORK:
                        case KW_WRITE:
                        case KW_YEAR:
                        case StringLiteral:
                        case KW_BATCH:
                        case KW_DAYOFWEEK:
                        case KW_HOLD_DDLTIME:
                        case KW_IGNORE:
                        case KW_NO_DROP:
                        case KW_OFFLINE:
                        case KW_PROTECTION:
                        case KW_READONLY:
                            {
                            alt127=2;
                            }
                            break;
                    }

                    switch (alt127) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1489:64: KW_LIKE showStmtIdentifier
                            {
                            KW_LIKE424=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement7526); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE424);


                            pushFollow(FOLLOW_showStmtIdentifier_in_showStatement7528);
                            showStmtIdentifier425=showStmtIdentifier();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier425.getTree());

                            }
                            break;
                        case 2 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1489:91: showStmtIdentifier
                            {
                            pushFollow(FOLLOW_showStmtIdentifier_in_showStatement7530);
                            showStmtIdentifier426=showStmtIdentifier();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier426.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: showStmtIdentifier, db_name
                    // token labels: 
                    // rule labels: db_name, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1489:113: -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1489:116: ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SHOWTABLES, "TOK_SHOWTABLES")
                        , root_1);

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1489:133: ( TOK_FROM $db_name)?
                        if ( stream_db_name.hasNext() ) {
                            adaptor.addChild(root_1, 
                            (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM")
                            );

                            adaptor.addChild(root_1, stream_db_name.nextTree());

                        }
                        stream_db_name.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1489:154: ( showStmtIdentifier )?
                        if ( stream_showStmtIdentifier.hasNext() ) {
                            adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());

                        }
                        stream_showStmtIdentifier.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1490:7: KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )?
                    {
                    KW_SHOW427=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement7558); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW427);


                    KW_COLUMNS428=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_showStatement7560); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS428);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1490:26: ( KW_FROM | KW_IN )
                    int alt128=2;
                    switch ( input.LA(1) ) {
                    case KW_FROM:
                        {
                        alt128=1;
                        }
                        break;
                    case KW_IN:
                        {
                        alt128=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 128, 0, input);

                        throw nvae;

                    }

                    switch (alt128) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1490:27: KW_FROM
                            {
                            KW_FROM429=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement7563); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM429);


                            }
                            break;
                        case 2 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1490:35: KW_IN
                            {
                            KW_IN430=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement7565); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN430);


                            }
                            break;

                    }


                    pushFollow(FOLLOW_tableName_in_showStatement7568);
                    tableName431=tableName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableName.add(tableName431.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1490:52: ( ( KW_FROM | KW_IN ) db_name= identifier )?
                    int alt130=2;
                    switch ( input.LA(1) ) {
                        case KW_FROM:
                        case KW_IN:
                            {
                            alt130=1;
                            }
                            break;
                    }

                    switch (alt130) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1490:53: ( KW_FROM | KW_IN ) db_name= identifier
                            {
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1490:53: ( KW_FROM | KW_IN )
                            int alt129=2;
                            switch ( input.LA(1) ) {
                            case KW_FROM:
                                {
                                alt129=1;
                                }
                                break;
                            case KW_IN:
                                {
                                alt129=2;
                                }
                                break;
                            default:
                                if (state.backtracking>0) {state.failed=true; return retval;}
                                NoViableAltException nvae =
                                    new NoViableAltException("", 129, 0, input);

                                throw nvae;

                            }

                            switch (alt129) {
                                case 1 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1490:54: KW_FROM
                                    {
                                    KW_FROM432=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement7572); if (state.failed) return retval; 
                                    if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM432);


                                    }
                                    break;
                                case 2 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1490:62: KW_IN
                                    {
                                    KW_IN433=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement7574); if (state.failed) return retval; 
                                    if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN433);


                                    }
                                    break;

                            }


                            pushFollow(FOLLOW_identifier_in_showStatement7579);
                            db_name=identifier();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: tableName, db_name
                    // token labels: 
                    // rule labels: db_name, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1491:5: -> ^( TOK_SHOWCOLUMNS tableName ( $db_name)? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1491:8: ^( TOK_SHOWCOLUMNS tableName ( $db_name)? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SHOWCOLUMNS, "TOK_SHOWCOLUMNS")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableName.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1491:37: ( $db_name)?
                        if ( stream_db_name.hasNext() ) {
                            adaptor.addChild(root_1, stream_db_name.nextTree());

                        }
                        stream_db_name.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 4 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1492:7: KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier | showFunctionIdentifier )?
                    {
                    KW_SHOW434=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement7605); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW434);


                    KW_FUNCTIONS435=(Token)match(input,KW_FUNCTIONS,FOLLOW_KW_FUNCTIONS_in_showStatement7607); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_FUNCTIONS.add(KW_FUNCTIONS435);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1492:28: ( KW_LIKE showFunctionIdentifier | showFunctionIdentifier )?
                    int alt131=3;
                    switch ( input.LA(1) ) {
                        case KW_LIKE:
                            {
                            switch ( input.LA(2) ) {
                                case Identifier:
                                case KW_ABORT:
                                case KW_ADD:
                                case KW_ADMIN:
                                case KW_AFTER:
                                case KW_ALL:
                                case KW_ALTER:
                                case KW_ANALYZE:
                                case KW_ARCHIVE:
                                case KW_ARRAY:
                                case KW_AS:
                                case KW_ASC:
                                case KW_AUTHORIZATION:
                                case KW_AUTOCOMMIT:
                                case KW_BEFORE:
                                case KW_BETWEEN:
                                case KW_BIGINT:
                                case KW_BINARY:
                                case KW_BOOLEAN:
                                case KW_BOTH:
                                case KW_BUCKET:
                                case KW_BUCKETS:
                                case KW_BY:
                                case KW_CACHE:
                                case KW_CASCADE:
                                case KW_CHANGE:
                                case KW_CLUSTER:
                                case KW_CLUSTERED:
                                case KW_CLUSTERSTATUS:
                                case KW_COLLECTION:
                                case KW_COLUMNS:
                                case KW_COMMENT:
                                case KW_COMPACT:
                                case KW_COMPACTIONS:
                                case KW_COMPUTE:
                                case KW_CONCATENATE:
                                case KW_CONSTRAINT:
                                case KW_CONTINUE:
                                case KW_CREATE:
                                case KW_CUBE:
                                case KW_CURRENT_DATE:
                                case KW_CURRENT_TIMESTAMP:
                                case KW_CURSOR:
                                case KW_DATA:
                                case KW_DATABASES:
                                case KW_DATE:
                                case KW_DATETIME:
                                case KW_DAY:
                                case KW_DBPROPERTIES:
                                case KW_DECIMAL:
                                case KW_DEFERRED:
                                case KW_DEFINED:
                                case KW_DELETE:
                                case KW_DELIMITED:
                                case KW_DEPENDENCY:
                                case KW_DESC:
                                case KW_DESCRIBE:
                                case KW_DIRECTORIES:
                                case KW_DIRECTORY:
                                case KW_DISABLE:
                                case KW_DISTRIBUTE:
                                case KW_DOUBLE:
                                case KW_DOW:
                                case KW_DROP:
                                case KW_DUMP:
                                case KW_ELEM_TYPE:
                                case KW_ENABLE:
                                case KW_ESCAPED:
                                case KW_EXCLUSIVE:
                                case KW_EXISTS:
                                case KW_EXPLAIN:
                                case KW_EXPORT:
                                case KW_EXTERNAL:
                                case KW_FALSE:
                                case KW_FETCH:
                                case KW_FIELDS:
                                case KW_FILE:
                                case KW_FILEFORMAT:
                                case KW_FIRST:
                                case KW_FLOAT:
                                case KW_FOR:
                                case KW_FOREIGN:
                                case KW_FORMAT:
                                case KW_FORMATTED:
                                case KW_FULL:
                                case KW_FUNCTIONS:
                                case KW_GRANT:
                                case KW_GROUP:
                                case KW_GROUPING:
                                case KW_HOUR:
                                case KW_IDXPROPERTIES:
                                case KW_IMPORT:
                                case KW_IN:
                                case KW_INDEX:
                                case KW_INDEXES:
                                case KW_INNER:
                                case KW_INPATH:
                                case KW_INPUTDRIVER:
                                case KW_INPUTFORMAT:
                                case KW_INSERT:
                                case KW_INT:
                                case KW_INTERSECT:
                                case KW_INTO:
                                case KW_IS:
                                case KW_ISOLATION:
                                case KW_ITEMS:
                                case KW_JAR:
                                case KW_KEY:
                                case KW_KEYS:
                                case KW_KEY_TYPE:
                                case KW_LAST:
                                case KW_LATERAL:
                                case KW_LEFT:
                                case KW_LEVEL:
                                case KW_LIKE:
                                case KW_LIMIT:
                                case KW_LINES:
                                case KW_LOAD:
                                case KW_LOCAL:
                                case KW_LOCATION:
                                case KW_LOCK:
                                case KW_LOCKS:
                                case KW_LOGICAL:
                                case KW_LONG:
                                case KW_MAPJOIN:
                                case KW_MATCHED:
                                case KW_MATERIALIZED:
                                case KW_MERGE:
                                case KW_METADATA:
                                case KW_MINUTE:
                                case KW_MONTH:
                                case KW_MSCK:
                                case KW_NONE:
                                case KW_NORELY:
                                case KW_NOSCAN:
                                case KW_NOVALIDATE:
                                case KW_NULL:
                                case KW_NULLS:
                                case KW_OF:
                                case KW_OFFSET:
                                case KW_OPTION:
                                case KW_ORDER:
                                case KW_OUT:
                                case KW_OUTER:
                                case KW_OUTPUTDRIVER:
                                case KW_OUTPUTFORMAT:
                                case KW_OVERWRITE:
                                case KW_OWNER:
                                case KW_PARTITION:
                                case KW_PARTITIONED:
                                case KW_PARTITIONS:
                                case KW_PERCENT:
                                case KW_PLUS:
                                case KW_PRETTY:
                                case KW_PRIMARY:
                                case KW_PRINCIPALS:
                                case KW_PROCEDURE:
                                case KW_PURGE:
                                case KW_QUARTER:
                                case KW_RANGE:
                                case KW_READ:
                                case KW_READS:
                                case KW_REBUILD:
                                case KW_RECORDREADER:
                                case KW_RECORDWRITER:
                                case KW_REFERENCES:
                                case KW_REGEXP:
                                case KW_RELOAD:
                                case KW_RELY:
                                case KW_RENAME:
                                case KW_REPAIR:
                                case KW_REPL:
                                case KW_REPLACE:
                                case KW_REPLICATION:
                                case KW_RESTRICT:
                                case KW_REVOKE:
                                case KW_REWRITE:
                                case KW_RIGHT:
                                case KW_RLIKE:
                                case KW_ROLE:
                                case KW_ROLES:
                                case KW_ROLLUP:
                                case KW_ROW:
                                case KW_ROWS:
                                case KW_SCHEMA:
                                case KW_SCHEMAS:
                                case KW_SECOND:
                                case KW_SEMI:
                                case KW_SERDE:
                                case KW_SERDEPROPERTIES:
                                case KW_SERVER:
                                case KW_SET:
                                case KW_SETS:
                                case KW_SHARED:
                                case KW_SHOW:
                                case KW_SHOW_DATABASE:
                                case KW_SKEWED:
                                case KW_SMALLINT:
                                case KW_SNAPSHOT:
                                case KW_SORT:
                                case KW_SORTED:
                                case KW_SSL:
                                case KW_STATISTICS:
                                case KW_STATUS:
                                case KW_STORED:
                                case KW_STREAMTABLE:
                                case KW_STRING:
                                case KW_STRUCT:
                                case KW_TABLE:
                                case KW_TABLES:
                                case KW_TBLPROPERTIES:
                                case KW_TEMPORARY:
                                case KW_TERMINATED:
                                case KW_TIMESTAMP:
                                case KW_TINYINT:
                                case KW_TO:
                                case KW_TOUCH:
                                case KW_TRANSACTION:
                                case KW_TRANSACTIONS:
                                case KW_TRIGGER:
                                case KW_TRUE:
                                case KW_TRUNCATE:
                                case KW_UNARCHIVE:
                                case KW_UNDO:
                                case KW_UNION:
                                case KW_UNIONTYPE:
                                case KW_UNLOCK:
                                case KW_UNSET:
                                case KW_UNSIGNED:
                                case KW_UPDATE:
                                case KW_URI:
                                case KW_USE:
                                case KW_USER:
                                case KW_USING:
                                case KW_UTC:
                                case KW_UTCTIMESTAMP:
                                case KW_VALIDATE:
                                case KW_VALUES:
                                case KW_VALUE_TYPE:
                                case KW_VIEW:
                                case KW_VIEWS:
                                case KW_WEEK:
                                case KW_WHILE:
                                case KW_WITH:
                                case KW_WORK:
                                case KW_WRITE:
                                case KW_YEAR:
                                case StringLiteral:
                                case KW_BATCH:
                                case KW_DAYOFWEEK:
                                case KW_HOLD_DDLTIME:
                                case KW_IGNORE:
                                case KW_NO_DROP:
                                case KW_OFFLINE:
                                case KW_PROTECTION:
                                case KW_READONLY:
                                    {
                                    alt131=1;
                                    }
                                    break;
                                case EOF:
                                case DOT:
                                    {
                                    alt131=2;
                                    }
                                    break;
                            }

                            }
                            break;
                        case Identifier:
                        case KW_ABORT:
                        case KW_ADD:
                        case KW_ADMIN:
                        case KW_AFTER:
                        case KW_ALL:
                        case KW_ALTER:
                        case KW_ANALYZE:
                        case KW_ARCHIVE:
                        case KW_ARRAY:
                        case KW_AS:
                        case KW_ASC:
                        case KW_AUTHORIZATION:
                        case KW_AUTOCOMMIT:
                        case KW_BEFORE:
                        case KW_BETWEEN:
                        case KW_BIGINT:
                        case KW_BINARY:
                        case KW_BOOLEAN:
                        case KW_BOTH:
                        case KW_BUCKET:
                        case KW_BUCKETS:
                        case KW_BY:
                        case KW_CACHE:
                        case KW_CASCADE:
                        case KW_CHANGE:
                        case KW_CLUSTER:
                        case KW_CLUSTERED:
                        case KW_CLUSTERSTATUS:
                        case KW_COLLECTION:
                        case KW_COLUMNS:
                        case KW_COMMENT:
                        case KW_COMPACT:
                        case KW_COMPACTIONS:
                        case KW_COMPUTE:
                        case KW_CONCATENATE:
                        case KW_CONSTRAINT:
                        case KW_CONTINUE:
                        case KW_CREATE:
                        case KW_CUBE:
                        case KW_CURRENT_DATE:
                        case KW_CURRENT_TIMESTAMP:
                        case KW_CURSOR:
                        case KW_DATA:
                        case KW_DATABASES:
                        case KW_DATE:
                        case KW_DATETIME:
                        case KW_DAY:
                        case KW_DBPROPERTIES:
                        case KW_DECIMAL:
                        case KW_DEFERRED:
                        case KW_DEFINED:
                        case KW_DELETE:
                        case KW_DELIMITED:
                        case KW_DEPENDENCY:
                        case KW_DESC:
                        case KW_DESCRIBE:
                        case KW_DIRECTORIES:
                        case KW_DIRECTORY:
                        case KW_DISABLE:
                        case KW_DISTRIBUTE:
                        case KW_DOUBLE:
                        case KW_DOW:
                        case KW_DROP:
                        case KW_DUMP:
                        case KW_ELEM_TYPE:
                        case KW_ENABLE:
                        case KW_ESCAPED:
                        case KW_EXCLUSIVE:
                        case KW_EXISTS:
                        case KW_EXPLAIN:
                        case KW_EXPORT:
                        case KW_EXTERNAL:
                        case KW_FALSE:
                        case KW_FETCH:
                        case KW_FIELDS:
                        case KW_FILE:
                        case KW_FILEFORMAT:
                        case KW_FIRST:
                        case KW_FLOAT:
                        case KW_FOR:
                        case KW_FOREIGN:
                        case KW_FORMAT:
                        case KW_FORMATTED:
                        case KW_FULL:
                        case KW_FUNCTIONS:
                        case KW_GRANT:
                        case KW_GROUP:
                        case KW_GROUPING:
                        case KW_HOUR:
                        case KW_IDXPROPERTIES:
                        case KW_IMPORT:
                        case KW_IN:
                        case KW_INDEX:
                        case KW_INDEXES:
                        case KW_INNER:
                        case KW_INPATH:
                        case KW_INPUTDRIVER:
                        case KW_INPUTFORMAT:
                        case KW_INSERT:
                        case KW_INT:
                        case KW_INTERSECT:
                        case KW_INTO:
                        case KW_IS:
                        case KW_ISOLATION:
                        case KW_ITEMS:
                        case KW_JAR:
                        case KW_KEY:
                        case KW_KEYS:
                        case KW_KEY_TYPE:
                        case KW_LAST:
                        case KW_LATERAL:
                        case KW_LEFT:
                        case KW_LEVEL:
                        case KW_LIMIT:
                        case KW_LINES:
                        case KW_LOAD:
                        case KW_LOCAL:
                        case KW_LOCATION:
                        case KW_LOCK:
                        case KW_LOCKS:
                        case KW_LOGICAL:
                        case KW_LONG:
                        case KW_MAPJOIN:
                        case KW_MATCHED:
                        case KW_MATERIALIZED:
                        case KW_MERGE:
                        case KW_METADATA:
                        case KW_MINUTE:
                        case KW_MONTH:
                        case KW_MSCK:
                        case KW_NONE:
                        case KW_NORELY:
                        case KW_NOSCAN:
                        case KW_NOVALIDATE:
                        case KW_NULL:
                        case KW_NULLS:
                        case KW_OF:
                        case KW_OFFSET:
                        case KW_OPTION:
                        case KW_ORDER:
                        case KW_OUT:
                        case KW_OUTER:
                        case KW_OUTPUTDRIVER:
                        case KW_OUTPUTFORMAT:
                        case KW_OVERWRITE:
                        case KW_OWNER:
                        case KW_PARTITION:
                        case KW_PARTITIONED:
                        case KW_PARTITIONS:
                        case KW_PERCENT:
                        case KW_PLUS:
                        case KW_PRETTY:
                        case KW_PRIMARY:
                        case KW_PRINCIPALS:
                        case KW_PROCEDURE:
                        case KW_PURGE:
                        case KW_QUARTER:
                        case KW_RANGE:
                        case KW_READ:
                        case KW_READS:
                        case KW_REBUILD:
                        case KW_RECORDREADER:
                        case KW_RECORDWRITER:
                        case KW_REFERENCES:
                        case KW_REGEXP:
                        case KW_RELOAD:
                        case KW_RELY:
                        case KW_RENAME:
                        case KW_REPAIR:
                        case KW_REPL:
                        case KW_REPLACE:
                        case KW_REPLICATION:
                        case KW_RESTRICT:
                        case KW_REVOKE:
                        case KW_REWRITE:
                        case KW_RIGHT:
                        case KW_RLIKE:
                        case KW_ROLE:
                        case KW_ROLES:
                        case KW_ROLLUP:
                        case KW_ROW:
                        case KW_ROWS:
                        case KW_SCHEMA:
                        case KW_SCHEMAS:
                        case KW_SECOND:
                        case KW_SEMI:
                        case KW_SERDE:
                        case KW_SERDEPROPERTIES:
                        case KW_SERVER:
                        case KW_SET:
                        case KW_SETS:
                        case KW_SHARED:
                        case KW_SHOW:
                        case KW_SHOW_DATABASE:
                        case KW_SKEWED:
                        case KW_SMALLINT:
                        case KW_SNAPSHOT:
                        case KW_SORT:
                        case KW_SORTED:
                        case KW_SSL:
                        case KW_STATISTICS:
                        case KW_STATUS:
                        case KW_STORED:
                        case KW_STREAMTABLE:
                        case KW_STRING:
                        case KW_STRUCT:
                        case KW_TABLE:
                        case KW_TABLES:
                        case KW_TBLPROPERTIES:
                        case KW_TEMPORARY:
                        case KW_TERMINATED:
                        case KW_TIMESTAMP:
                        case KW_TINYINT:
                        case KW_TO:
                        case KW_TOUCH:
                        case KW_TRANSACTION:
                        case KW_TRANSACTIONS:
                        case KW_TRIGGER:
                        case KW_TRUE:
                        case KW_TRUNCATE:
                        case KW_UNARCHIVE:
                        case KW_UNDO:
                        case KW_UNION:
                        case KW_UNIONTYPE:
                        case KW_UNLOCK:
                        case KW_UNSET:
                        case KW_UNSIGNED:
                        case KW_UPDATE:
                        case KW_URI:
                        case KW_USE:
                        case KW_USER:
                        case KW_USING:
                        case KW_UTC:
                        case KW_UTCTIMESTAMP:
                        case KW_VALIDATE:
                        case KW_VALUES:
                        case KW_VALUE_TYPE:
                        case KW_VIEW:
                        case KW_VIEWS:
                        case KW_WEEK:
                        case KW_WHILE:
                        case KW_WITH:
                        case KW_WORK:
                        case KW_WRITE:
                        case KW_YEAR:
                        case StringLiteral:
                        case KW_BATCH:
                        case KW_DAYOFWEEK:
                        case KW_HOLD_DDLTIME:
                        case KW_IGNORE:
                        case KW_NO_DROP:
                        case KW_OFFLINE:
                        case KW_PROTECTION:
                        case KW_READONLY:
                            {
                            alt131=2;
                            }
                            break;
                    }

                    switch (alt131) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1492:29: KW_LIKE showFunctionIdentifier
                            {
                            KW_LIKE436=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement7610); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE436);


                            pushFollow(FOLLOW_showFunctionIdentifier_in_showStatement7612);
                            showFunctionIdentifier437=showFunctionIdentifier();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_showFunctionIdentifier.add(showFunctionIdentifier437.getTree());

                            }
                            break;
                        case 2 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1492:60: showFunctionIdentifier
                            {
                            pushFollow(FOLLOW_showFunctionIdentifier_in_showStatement7614);
                            showFunctionIdentifier438=showFunctionIdentifier();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_showFunctionIdentifier.add(showFunctionIdentifier438.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: showFunctionIdentifier, KW_LIKE
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1492:86: -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1492:89: ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SHOWFUNCTIONS, "TOK_SHOWFUNCTIONS")
                        , root_1);

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1492:109: ( KW_LIKE )?
                        if ( stream_KW_LIKE.hasNext() ) {
                            adaptor.addChild(root_1, 
                            stream_KW_LIKE.nextNode()
                            );

                        }
                        stream_KW_LIKE.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1492:118: ( showFunctionIdentifier )?
                        if ( stream_showFunctionIdentifier.hasNext() ) {
                            adaptor.addChild(root_1, stream_showFunctionIdentifier.nextTree());

                        }
                        stream_showFunctionIdentifier.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 5 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1493:7: KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )?
                    {
                    KW_SHOW439=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement7637); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW439);


                    KW_PARTITIONS440=(Token)match(input,KW_PARTITIONS,FOLLOW_KW_PARTITIONS_in_showStatement7639); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_PARTITIONS.add(KW_PARTITIONS440);


                    pushFollow(FOLLOW_tableName_in_showStatement7643);
                    tabName=tableName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1493:47: ( partitionSpec )?
                    int alt132=2;
                    switch ( input.LA(1) ) {
                        case KW_PARTITION:
                            {
                            alt132=1;
                            }
                            break;
                    }

                    switch (alt132) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1493:47: partitionSpec
                            {
                            pushFollow(FOLLOW_partitionSpec_in_showStatement7645);
                            partitionSpec441=partitionSpec();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec441.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: tabName, partitionSpec
                    // token labels: 
                    // rule labels: tabName, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1493:62: -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1493:65: ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SHOWPARTITIONS, "TOK_SHOWPARTITIONS")
                        , root_1);

                        adaptor.addChild(root_1, stream_tabName.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1493:95: ( partitionSpec )?
                        if ( stream_partitionSpec.hasNext() ) {
                            adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                        }
                        stream_partitionSpec.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 6 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1494:7: KW_SHOW KW_CREATE ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier -> ^( TOK_SHOW_CREATEDATABASE $db_name) | KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) )
                    {
                    KW_SHOW442=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement7667); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW442);


                    KW_CREATE443=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_showStatement7669); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE443);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1494:25: ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier -> ^( TOK_SHOW_CREATEDATABASE $db_name) | KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) )
                    int alt134=2;
                    int LA134_0 = input.LA(1);

                    if ( (LA134_0==KW_DATABASE) && (synpred12_HiveParser())) {
                        alt134=1;
                    }
                    else if ( (LA134_0==KW_SCHEMA) && (synpred12_HiveParser())) {
                        alt134=1;
                    }
                    else if ( (LA134_0==KW_TABLE) ) {
                        alt134=2;
                    }
                    else {
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 134, 0, input);

                        throw nvae;

                    }
                    switch (alt134) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1495:9: ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier
                            {
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1495:36: ( KW_DATABASE | KW_SCHEMA )
                            int alt133=2;
                            switch ( input.LA(1) ) {
                            case KW_DATABASE:
                                {
                                alt133=1;
                                }
                                break;
                            case KW_SCHEMA:
                                {
                                alt133=2;
                                }
                                break;
                            default:
                                if (state.backtracking>0) {state.failed=true; return retval;}
                                NoViableAltException nvae =
                                    new NoViableAltException("", 133, 0, input);

                                throw nvae;

                            }

                            switch (alt133) {
                                case 1 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1495:37: KW_DATABASE
                                    {
                                    KW_DATABASE444=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_showStatement7690); if (state.failed) return retval; 
                                    if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE444);


                                    }
                                    break;
                                case 2 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1495:49: KW_SCHEMA
                                    {
                                    KW_SCHEMA445=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_showStatement7692); if (state.failed) return retval; 
                                    if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA445);


                                    }
                                    break;

                            }


                            pushFollow(FOLLOW_identifier_in_showStatement7697);
                            db_name=identifier();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());

                            // AST REWRITE
                            // elements: db_name
                            // token labels: 
                            // rule labels: db_name, retval
                            // token list labels: 
                            // rule list labels: 
                            // wildcard labels: 
                            if ( state.backtracking==0 ) {

                            retval.tree = root_0;
                            RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.tree:null);
                            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                            root_0 = (ASTNode)adaptor.nil();
                            // 1495:79: -> ^( TOK_SHOW_CREATEDATABASE $db_name)
                            {
                                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1495:82: ^( TOK_SHOW_CREATEDATABASE $db_name)
                                {
                                ASTNode root_1 = (ASTNode)adaptor.nil();
                                root_1 = (ASTNode)adaptor.becomeRoot(
                                (ASTNode)adaptor.create(TOK_SHOW_CREATEDATABASE, "TOK_SHOW_CREATEDATABASE")
                                , root_1);

                                adaptor.addChild(root_1, stream_db_name.nextTree());

                                adaptor.addChild(root_0, root_1);
                                }

                            }


                            retval.tree = root_0;
                            }

                            }
                            break;
                        case 2 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1497:9: KW_TABLE tabName= tableName
                            {
                            KW_TABLE446=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_showStatement7726); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE446);


                            pushFollow(FOLLOW_tableName_in_showStatement7730);
                            tabName=tableName();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());

                            // AST REWRITE
                            // elements: tabName
                            // token labels: 
                            // rule labels: tabName, retval
                            // token list labels: 
                            // rule list labels: 
                            // wildcard labels: 
                            if ( state.backtracking==0 ) {

                            retval.tree = root_0;
                            RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.tree:null);
                            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                            root_0 = (ASTNode)adaptor.nil();
                            // 1497:36: -> ^( TOK_SHOW_CREATETABLE $tabName)
                            {
                                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1497:39: ^( TOK_SHOW_CREATETABLE $tabName)
                                {
                                ASTNode root_1 = (ASTNode)adaptor.nil();
                                root_1 = (ASTNode)adaptor.becomeRoot(
                                (ASTNode)adaptor.create(TOK_SHOW_CREATETABLE, "TOK_SHOW_CREATETABLE")
                                , root_1);

                                adaptor.addChild(root_1, stream_tabName.nextTree());

                                adaptor.addChild(root_0, root_1);
                                }

                            }


                            retval.tree = root_0;
                            }

                            }
                            break;

                    }


                    }
                    break;
                case 7 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1499:7: KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )?
                    {
                    KW_SHOW447=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement7755); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW447);


                    KW_TABLE448=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_showStatement7757); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE448);


                    KW_EXTENDED449=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement7759); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_EXTENDED.add(KW_EXTENDED449);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1499:36: ( ( KW_FROM | KW_IN ) db_name= identifier )?
                    int alt136=2;
                    switch ( input.LA(1) ) {
                        case KW_FROM:
                        case KW_IN:
                            {
                            alt136=1;
                            }
                            break;
                    }

                    switch (alt136) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1499:37: ( KW_FROM | KW_IN ) db_name= identifier
                            {
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1499:37: ( KW_FROM | KW_IN )
                            int alt135=2;
                            switch ( input.LA(1) ) {
                            case KW_FROM:
                                {
                                alt135=1;
                                }
                                break;
                            case KW_IN:
                                {
                                alt135=2;
                                }
                                break;
                            default:
                                if (state.backtracking>0) {state.failed=true; return retval;}
                                NoViableAltException nvae =
                                    new NoViableAltException("", 135, 0, input);

                                throw nvae;

                            }

                            switch (alt135) {
                                case 1 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1499:38: KW_FROM
                                    {
                                    KW_FROM450=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement7763); if (state.failed) return retval; 
                                    if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM450);


                                    }
                                    break;
                                case 2 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1499:46: KW_IN
                                    {
                                    KW_IN451=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement7765); if (state.failed) return retval; 
                                    if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN451);


                                    }
                                    break;

                            }


                            pushFollow(FOLLOW_identifier_in_showStatement7770);
                            db_name=identifier();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());

                            }
                            break;

                    }


                    KW_LIKE452=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement7774); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE452);


                    pushFollow(FOLLOW_showStmtIdentifier_in_showStatement7776);
                    showStmtIdentifier453=showStmtIdentifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier453.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1499:101: ( partitionSpec )?
                    int alt137=2;
                    switch ( input.LA(1) ) {
                        case KW_PARTITION:
                            {
                            alt137=1;
                            }
                            break;
                    }

                    switch (alt137) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1499:101: partitionSpec
                            {
                            pushFollow(FOLLOW_partitionSpec_in_showStatement7778);
                            partitionSpec454=partitionSpec();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec454.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: showStmtIdentifier, partitionSpec, db_name
                    // token labels: 
                    // rule labels: db_name, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1500:5: -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1500:8: ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SHOW_TABLESTATUS, "TOK_SHOW_TABLESTATUS")
                        , root_1);

                        adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1500:51: ( $db_name)?
                        if ( stream_db_name.hasNext() ) {
                            adaptor.addChild(root_1, stream_db_name.nextTree());

                        }
                        stream_db_name.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1500:60: ( partitionSpec )?
                        if ( stream_partitionSpec.hasNext() ) {
                            adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                        }
                        stream_partitionSpec.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 8 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1501:7: KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )?
                    {
                    KW_SHOW455=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement7806); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW455);


                    KW_TBLPROPERTIES456=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_showStatement7808); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES456);


                    pushFollow(FOLLOW_tableName_in_showStatement7810);
                    tableName457=tableName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableName.add(tableName457.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1501:42: ( LPAREN prptyName= StringLiteral RPAREN )?
                    int alt138=2;
                    switch ( input.LA(1) ) {
                        case LPAREN:
                            {
                            alt138=1;
                            }
                            break;
                    }

                    switch (alt138) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1501:43: LPAREN prptyName= StringLiteral RPAREN
                            {
                            LPAREN458=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_showStatement7813); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN458);


                            prptyName=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showStatement7817); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_StringLiteral.add(prptyName);


                            RPAREN459=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_showStatement7819); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN459);


                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: prptyName, tableName
                    // token labels: prptyName
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_prptyName=new RewriteRuleTokenStream(adaptor,"token prptyName",prptyName);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1501:83: -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1501:86: ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SHOW_TBLPROPERTIES, "TOK_SHOW_TBLPROPERTIES")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableName.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1501:122: ( $prptyName)?
                        if ( stream_prptyName.hasNext() ) {
                            adaptor.addChild(root_1, stream_prptyName.nextNode());

                        }
                        stream_prptyName.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 9 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1502:7: KW_SHOW KW_LOCKS ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) )
                    {
                    KW_SHOW460=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement7841); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW460);


                    KW_LOCKS461=(Token)match(input,KW_LOCKS,FOLLOW_KW_LOCKS_in_showStatement7843); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_LOCKS.add(KW_LOCKS461);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1503:7: ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) )
                    int alt143=2;
                    int LA143_0 = input.LA(1);

                    if ( (LA143_0==KW_DATABASE) && (synpred13_HiveParser())) {
                        alt143=1;
                    }
                    else if ( (LA143_0==KW_SCHEMA) ) {
                        switch ( input.LA(2) ) {
                        case Identifier:
                            {
                            int LA143_8 = input.LA(3);

                            if ( (synpred13_HiveParser()) ) {
                                alt143=1;
                            }
                            else if ( (true) ) {
                                alt143=2;
                            }
                            else {
                                if (state.backtracking>0) {state.failed=true; return retval;}
                                NoViableAltException nvae =
                                    new NoViableAltException("", 143, 8, input);

                                throw nvae;

                            }
                            }
                            break;
                        case EOF:
                        case DOT:
                        case KW_ABORT:
                        case KW_ADD:
                        case KW_ADMIN:
                        case KW_AFTER:
                        case KW_ALL:
                        case KW_ALTER:
                        case KW_ANALYZE:
                        case KW_ARCHIVE:
                        case KW_ARRAY:
                        case KW_AS:
                        case KW_ASC:
                        case KW_AUTHORIZATION:
                        case KW_AUTOCOMMIT:
                        case KW_BEFORE:
                        case KW_BETWEEN:
                        case KW_BIGINT:
                        case KW_BINARY:
                        case KW_BOOLEAN:
                        case KW_BOTH:
                        case KW_BUCKET:
                        case KW_BUCKETS:
                        case KW_BY:
                        case KW_CACHE:
                        case KW_CASCADE:
                        case KW_CHANGE:
                        case KW_CLUSTER:
                        case KW_CLUSTERED:
                        case KW_CLUSTERSTATUS:
                        case KW_COLLECTION:
                        case KW_COLUMNS:
                        case KW_COMMENT:
                        case KW_COMPACT:
                        case KW_COMPACTIONS:
                        case KW_COMPUTE:
                        case KW_CONCATENATE:
                        case KW_CONSTRAINT:
                        case KW_CONTINUE:
                        case KW_CREATE:
                        case KW_CUBE:
                        case KW_CURRENT_DATE:
                        case KW_CURRENT_TIMESTAMP:
                        case KW_CURSOR:
                        case KW_DATA:
                        case KW_DATABASES:
                        case KW_DATE:
                        case KW_DATETIME:
                        case KW_DAY:
                        case KW_DBPROPERTIES:
                        case KW_DECIMAL:
                        case KW_DEFERRED:
                        case KW_DEFINED:
                        case KW_DELETE:
                        case KW_DELIMITED:
                        case KW_DEPENDENCY:
                        case KW_DESC:
                        case KW_DESCRIBE:
                        case KW_DIRECTORIES:
                        case KW_DIRECTORY:
                        case KW_DISABLE:
                        case KW_DISTRIBUTE:
                        case KW_DOUBLE:
                        case KW_DOW:
                        case KW_DROP:
                        case KW_DUMP:
                        case KW_ELEM_TYPE:
                        case KW_ENABLE:
                        case KW_ESCAPED:
                        case KW_EXCLUSIVE:
                        case KW_EXISTS:
                        case KW_EXPLAIN:
                        case KW_EXPORT:
                        case KW_EXTENDED:
                        case KW_EXTERNAL:
                        case KW_FALSE:
                        case KW_FETCH:
                        case KW_FIELDS:
                        case KW_FILE:
                        case KW_FILEFORMAT:
                        case KW_FIRST:
                        case KW_FLOAT:
                        case KW_FOR:
                        case KW_FOREIGN:
                        case KW_FORMAT:
                        case KW_FORMATTED:
                        case KW_FULL:
                        case KW_FUNCTIONS:
                        case KW_GRANT:
                        case KW_GROUP:
                        case KW_GROUPING:
                        case KW_HOUR:
                        case KW_IDXPROPERTIES:
                        case KW_IMPORT:
                        case KW_IN:
                        case KW_INDEX:
                        case KW_INDEXES:
                        case KW_INNER:
                        case KW_INPATH:
                        case KW_INPUTDRIVER:
                        case KW_INPUTFORMAT:
                        case KW_INSERT:
                        case KW_INT:
                        case KW_INTERSECT:
                        case KW_INTO:
                        case KW_IS:
                        case KW_ISOLATION:
                        case KW_ITEMS:
                        case KW_JAR:
                        case KW_KEY:
                        case KW_KEYS:
                        case KW_KEY_TYPE:
                        case KW_LAST:
                        case KW_LATERAL:
                        case KW_LEFT:
                        case KW_LEVEL:
                        case KW_LIKE:
                        case KW_LIMIT:
                        case KW_LINES:
                        case KW_LOAD:
                        case KW_LOCAL:
                        case KW_LOCATION:
                        case KW_LOCK:
                        case KW_LOCKS:
                        case KW_LOGICAL:
                        case KW_LONG:
                        case KW_MAPJOIN:
                        case KW_MATCHED:
                        case KW_MATERIALIZED:
                        case KW_MERGE:
                        case KW_METADATA:
                        case KW_MINUTE:
                        case KW_MONTH:
                        case KW_MSCK:
                        case KW_NONE:
                        case KW_NORELY:
                        case KW_NOSCAN:
                        case KW_NOVALIDATE:
                        case KW_NULL:
                        case KW_NULLS:
                        case KW_OF:
                        case KW_OFFSET:
                        case KW_OPTION:
                        case KW_ORDER:
                        case KW_OUT:
                        case KW_OUTER:
                        case KW_OUTPUTDRIVER:
                        case KW_OUTPUTFORMAT:
                        case KW_OVERWRITE:
                        case KW_OWNER:
                        case KW_PARTITION:
                        case KW_PARTITIONED:
                        case KW_PARTITIONS:
                        case KW_PERCENT:
                        case KW_PLUS:
                        case KW_PRETTY:
                        case KW_PRIMARY:
                        case KW_PRINCIPALS:
                        case KW_PROCEDURE:
                        case KW_PURGE:
                        case KW_QUARTER:
                        case KW_RANGE:
                        case KW_READ:
                        case KW_READS:
                        case KW_REBUILD:
                        case KW_RECORDREADER:
                        case KW_RECORDWRITER:
                        case KW_REFERENCES:
                        case KW_REGEXP:
                        case KW_RELOAD:
                        case KW_RELY:
                        case KW_RENAME:
                        case KW_REPAIR:
                        case KW_REPL:
                        case KW_REPLACE:
                        case KW_REPLICATION:
                        case KW_RESTRICT:
                        case KW_REVOKE:
                        case KW_REWRITE:
                        case KW_RIGHT:
                        case KW_RLIKE:
                        case KW_ROLE:
                        case KW_ROLES:
                        case KW_ROLLUP:
                        case KW_ROW:
                        case KW_ROWS:
                        case KW_SCHEMA:
                        case KW_SCHEMAS:
                        case KW_SECOND:
                        case KW_SEMI:
                        case KW_SERDE:
                        case KW_SERDEPROPERTIES:
                        case KW_SERVER:
                        case KW_SET:
                        case KW_SETS:
                        case KW_SHARED:
                        case KW_SHOW:
                        case KW_SHOW_DATABASE:
                        case KW_SKEWED:
                        case KW_SMALLINT:
                        case KW_SNAPSHOT:
                        case KW_SORT:
                        case KW_SORTED:
                        case KW_SSL:
                        case KW_STATISTICS:
                        case KW_STATUS:
                        case KW_STORED:
                        case KW_STREAMTABLE:
                        case KW_STRING:
                        case KW_STRUCT:
                        case KW_TABLE:
                        case KW_TABLES:
                        case KW_TBLPROPERTIES:
                        case KW_TEMPORARY:
                        case KW_TERMINATED:
                        case KW_TIMESTAMP:
                        case KW_TINYINT:
                        case KW_TO:
                        case KW_TOUCH:
                        case KW_TRANSACTION:
                        case KW_TRANSACTIONS:
                        case KW_TRIGGER:
                        case KW_TRUE:
                        case KW_TRUNCATE:
                        case KW_UNARCHIVE:
                        case KW_UNDO:
                        case KW_UNION:
                        case KW_UNIONTYPE:
                        case KW_UNLOCK:
                        case KW_UNSET:
                        case KW_UNSIGNED:
                        case KW_UPDATE:
                        case KW_URI:
                        case KW_USE:
                        case KW_USER:
                        case KW_USING:
                        case KW_UTC:
                        case KW_UTCTIMESTAMP:
                        case KW_VALIDATE:
                        case KW_VALUES:
                        case KW_VALUE_TYPE:
                        case KW_VIEW:
                        case KW_VIEWS:
                        case KW_WEEK:
                        case KW_WHILE:
                        case KW_WITH:
                        case KW_WORK:
                        case KW_WRITE:
                        case KW_YEAR:
                        case KW_BATCH:
                        case KW_DAYOFWEEK:
                        case KW_HOLD_DDLTIME:
                        case KW_IGNORE:
                        case KW_NO_DROP:
                        case KW_OFFLINE:
                        case KW_PROTECTION:
                        case KW_READONLY:
                            {
                            alt143=2;
                            }
                            break;
                        default:
                            if (state.backtracking>0) {state.failed=true; return retval;}
                            NoViableAltException nvae =
                                new NoViableAltException("", 143, 2, input);

                            throw nvae;

                        }

                    }
                    else if ( (LA143_0==EOF||(LA143_0 >= Identifier && LA143_0 <= KW_ANALYZE)||(LA143_0 >= KW_ARCHIVE && LA143_0 <= KW_CASCADE)||LA143_0==KW_CHANGE||(LA143_0 >= KW_CLUSTER && LA143_0 <= KW_COLLECTION)||(LA143_0 >= KW_COLUMNS && LA143_0 <= KW_COMMENT)||(LA143_0 >= KW_COMPACT && LA143_0 <= KW_CONCATENATE)||(LA143_0 >= KW_CONSTRAINT && LA143_0 <= KW_CREATE)||LA143_0==KW_CUBE||(LA143_0 >= KW_CURRENT_DATE && LA143_0 <= KW_DATA)||(LA143_0 >= KW_DATABASES && LA143_0 <= KW_DISABLE)||(LA143_0 >= KW_DISTRIBUTE && LA143_0 <= KW_ELEM_TYPE)||LA143_0==KW_ENABLE||LA143_0==KW_ESCAPED||(LA143_0 >= KW_EXCLUSIVE && LA143_0 <= KW_EXTERNAL)||(LA143_0 >= KW_FALSE && LA143_0 <= KW_FLOAT)||(LA143_0 >= KW_FOR && LA143_0 <= KW_FORMATTED)||LA143_0==KW_FULL||(LA143_0 >= KW_FUNCTIONS && LA143_0 <= KW_GROUPING)||(LA143_0 >= KW_HOUR && LA143_0 <= KW_IDXPROPERTIES)||(LA143_0 >= KW_IMPORT && LA143_0 <= KW_INTERSECT)||(LA143_0 >= KW_INTO && LA143_0 <= KW_JAR)||(LA143_0 >= KW_KEY && LA143_0 <= KW_LEFT)||(LA143_0 >= KW_LEVEL && LA143_0 <= KW_LONG)||(LA143_0 >= KW_MAPJOIN && LA143_0 <= KW_METADATA)||(LA143_0 >= KW_MINUTE && LA143_0 <= KW_MONTH)||(LA143_0 >= KW_MSCK && LA143_0 <= KW_NOSCAN)||(LA143_0 >= KW_NOVALIDATE && LA143_0 <= KW_OFFSET)||LA143_0==KW_OPTION||(LA143_0 >= KW_ORDER && LA143_0 <= KW_OUTPUTFORMAT)||(LA143_0 >= KW_OVERWRITE && LA143_0 <= KW_OWNER)||(LA143_0 >= KW_PARTITION && LA143_0 <= KW_PLUS)||(LA143_0 >= KW_PRETTY && LA143_0 <= KW_RECORDWRITER)||(LA143_0 >= KW_REFERENCES && LA143_0 <= KW_ROLES)||(LA143_0 >= KW_ROLLUP && LA143_0 <= KW_ROWS)||(LA143_0 >= KW_SCHEMAS && LA143_0 <= KW_SECOND)||(LA143_0 >= KW_SEMI && LA143_0 <= KW_SSL)||(LA143_0 >= KW_STATISTICS && LA143_0 <= KW_TABLES)||(LA143_0 >= KW_TBLPROPERTIES && LA143_0 <= KW_TERMINATED)||(LA143_0 >= KW_TIMESTAMP && LA143_0 <= KW_TRANSACTIONS)||(LA143_0 >= KW_TRIGGER && LA143_0 <= KW_UNARCHIVE)||(LA143_0 >= KW_UNDO && LA143_0 <= KW_UNIONTYPE)||(LA143_0 >= KW_UNLOCK && LA143_0 <= KW_VALUE_TYPE)||(LA143_0 >= KW_VIEW && LA143_0 <= KW_WEEK)||LA143_0==KW_WHILE||(LA143_0 >= KW_WITH && LA143_0 <= KW_YEAR)||LA143_0==KW_BATCH||LA143_0==KW_DAYOFWEEK||LA143_0==KW_HOLD_DDLTIME||LA143_0==KW_IGNORE||LA143_0==KW_NO_DROP||LA143_0==KW_OFFLINE||LA143_0==KW_PROTECTION||LA143_0==KW_READONLY) ) {
                        alt143=2;
                    }
                    else {
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 143, 0, input);

                        throw nvae;

                    }
                    switch (alt143) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:7: ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) (isExtended= KW_EXTENDED )?
                            {
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:34: ( KW_DATABASE | KW_SCHEMA )
                            int alt139=2;
                            switch ( input.LA(1) ) {
                            case KW_DATABASE:
                                {
                                alt139=1;
                                }
                                break;
                            case KW_SCHEMA:
                                {
                                alt139=2;
                                }
                                break;
                            default:
                                if (state.backtracking>0) {state.failed=true; return retval;}
                                NoViableAltException nvae =
                                    new NoViableAltException("", 139, 0, input);

                                throw nvae;

                            }

                            switch (alt139) {
                                case 1 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:35: KW_DATABASE
                                    {
                                    KW_DATABASE462=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_showStatement7869); if (state.failed) return retval; 
                                    if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE462);


                                    }
                                    break;
                                case 2 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:47: KW_SCHEMA
                                    {
                                    KW_SCHEMA463=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_showStatement7871); if (state.failed) return retval; 
                                    if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA463);


                                    }
                                    break;

                            }


                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:58: (dbName= Identifier )
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:59: dbName= Identifier
                            {
                            dbName=(Token)match(input,Identifier,FOLLOW_Identifier_in_showStatement7877); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_Identifier.add(dbName);


                            }


                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:78: (isExtended= KW_EXTENDED )?
                            int alt140=2;
                            switch ( input.LA(1) ) {
                                case KW_EXTENDED:
                                    {
                                    alt140=1;
                                    }
                                    break;
                            }

                            switch (alt140) {
                                case 1 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:79: isExtended= KW_EXTENDED
                                    {
                                    isExtended=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement7883); if (state.failed) return retval; 
                                    if ( state.backtracking==0 ) stream_KW_EXTENDED.add(isExtended);


                                    }
                                    break;

                            }


                            // AST REWRITE
                            // elements: dbName, isExtended
                            // token labels: dbName, isExtended
                            // rule labels: retval
                            // token list labels: 
                            // rule list labels: 
                            // wildcard labels: 
                            if ( state.backtracking==0 ) {

                            retval.tree = root_0;
                            RewriteRuleTokenStream stream_dbName=new RewriteRuleTokenStream(adaptor,"token dbName",dbName);
                            RewriteRuleTokenStream stream_isExtended=new RewriteRuleTokenStream(adaptor,"token isExtended",isExtended);
                            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                            root_0 = (ASTNode)adaptor.nil();
                            // 1504:104: -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? )
                            {
                                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:107: ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? )
                                {
                                ASTNode root_1 = (ASTNode)adaptor.nil();
                                root_1 = (ASTNode)adaptor.becomeRoot(
                                (ASTNode)adaptor.create(TOK_SHOWDBLOCKS, "TOK_SHOWDBLOCKS")
                                , root_1);

                                adaptor.addChild(root_1, stream_dbName.nextNode());

                                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:134: ( $isExtended)?
                                if ( stream_isExtended.hasNext() ) {
                                    adaptor.addChild(root_1, stream_isExtended.nextNode());

                                }
                                stream_isExtended.reset();

                                adaptor.addChild(root_0, root_1);
                                }

                            }


                            retval.tree = root_0;
                            }

                            }
                            break;
                        case 2 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1506:7: (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )?
                            {
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1506:7: (parttype= partTypeExpr )?
                            int alt141=2;
                            switch ( input.LA(1) ) {
                                case Identifier:
                                case KW_ABORT:
                                case KW_ADD:
                                case KW_ADMIN:
                                case KW_AFTER:
                                case KW_ALL:
                                case KW_ALTER:
                                case KW_ANALYZE:
                                case KW_ARCHIVE:
                                case KW_ARRAY:
                                case KW_AS:
                                case KW_ASC:
                                case KW_AUTHORIZATION:
                                case KW_AUTOCOMMIT:
                                case KW_BEFORE:
                                case KW_BETWEEN:
                                case KW_BIGINT:
                                case KW_BINARY:
                                case KW_BOOLEAN:
                                case KW_BOTH:
                                case KW_BUCKET:
                                case KW_BUCKETS:
                                case KW_BY:
                                case KW_CACHE:
                                case KW_CASCADE:
                                case KW_CHANGE:
                                case KW_CLUSTER:
                                case KW_CLUSTERED:
                                case KW_CLUSTERSTATUS:
                                case KW_COLLECTION:
                                case KW_COLUMNS:
                                case KW_COMMENT:
                                case KW_COMPACT:
                                case KW_COMPACTIONS:
                                case KW_COMPUTE:
                                case KW_CONCATENATE:
                                case KW_CONSTRAINT:
                                case KW_CONTINUE:
                                case KW_CREATE:
                                case KW_CUBE:
                                case KW_CURRENT_DATE:
                                case KW_CURRENT_TIMESTAMP:
                                case KW_CURSOR:
                                case KW_DATA:
                                case KW_DATABASES:
                                case KW_DATE:
                                case KW_DATETIME:
                                case KW_DAY:
                                case KW_DBPROPERTIES:
                                case KW_DECIMAL:
                                case KW_DEFERRED:
                                case KW_DEFINED:
                                case KW_DELETE:
                                case KW_DELIMITED:
                                case KW_DEPENDENCY:
                                case KW_DESC:
                                case KW_DESCRIBE:
                                case KW_DIRECTORIES:
                                case KW_DIRECTORY:
                                case KW_DISABLE:
                                case KW_DISTRIBUTE:
                                case KW_DOUBLE:
                                case KW_DOW:
                                case KW_DROP:
                                case KW_DUMP:
                                case KW_ELEM_TYPE:
                                case KW_ENABLE:
                                case KW_ESCAPED:
                                case KW_EXCLUSIVE:
                                case KW_EXISTS:
                                case KW_EXPLAIN:
                                case KW_EXPORT:
                                case KW_EXTERNAL:
                                case KW_FALSE:
                                case KW_FETCH:
                                case KW_FIELDS:
                                case KW_FILE:
                                case KW_FILEFORMAT:
                                case KW_FIRST:
                                case KW_FLOAT:
                                case KW_FOR:
                                case KW_FOREIGN:
                                case KW_FORMAT:
                                case KW_FORMATTED:
                                case KW_FULL:
                                case KW_FUNCTIONS:
                                case KW_GRANT:
                                case KW_GROUP:
                                case KW_GROUPING:
                                case KW_HOUR:
                                case KW_IDXPROPERTIES:
                                case KW_IMPORT:
                                case KW_IN:
                                case KW_INDEX:
                                case KW_INDEXES:
                                case KW_INNER:
                                case KW_INPATH:
                                case KW_INPUTDRIVER:
                                case KW_INPUTFORMAT:
                                case KW_INSERT:
                                case KW_INT:
                                case KW_INTERSECT:
                                case KW_INTO:
                                case KW_IS:
                                case KW_ISOLATION:
                                case KW_ITEMS:
                                case KW_JAR:
                                case KW_KEY:
                                case KW_KEYS:
                                case KW_KEY_TYPE:
                                case KW_LAST:
                                case KW_LATERAL:
                                case KW_LEFT:
                                case KW_LEVEL:
                                case KW_LIKE:
                                case KW_LIMIT:
                                case KW_LINES:
                                case KW_LOAD:
                                case KW_LOCAL:
                                case KW_LOCATION:
                                case KW_LOCK:
                                case KW_LOCKS:
                                case KW_LOGICAL:
                                case KW_LONG:
                                case KW_MAPJOIN:
                                case KW_MATCHED:
                                case KW_MATERIALIZED:
                                case KW_MERGE:
                                case KW_METADATA:
                                case KW_MINUTE:
                                case KW_MONTH:
                                case KW_MSCK:
                                case KW_NONE:
                                case KW_NORELY:
                                case KW_NOSCAN:
                                case KW_NOVALIDATE:
                                case KW_NULL:
                                case KW_NULLS:
                                case KW_OF:
                                case KW_OFFSET:
                                case KW_OPTION:
                                case KW_ORDER:
                                case KW_OUT:
                                case KW_OUTER:
                                case KW_OUTPUTDRIVER:
                                case KW_OUTPUTFORMAT:
                                case KW_OVERWRITE:
                                case KW_OWNER:
                                case KW_PARTITION:
                                case KW_PARTITIONED:
                                case KW_PARTITIONS:
                                case KW_PERCENT:
                                case KW_PLUS:
                                case KW_PRETTY:
                                case KW_PRIMARY:
                                case KW_PRINCIPALS:
                                case KW_PROCEDURE:
                                case KW_PURGE:
                                case KW_QUARTER:
                                case KW_RANGE:
                                case KW_READ:
                                case KW_READS:
                                case KW_REBUILD:
                                case KW_RECORDREADER:
                                case KW_RECORDWRITER:
                                case KW_REFERENCES:
                                case KW_REGEXP:
                                case KW_RELOAD:
                                case KW_RELY:
                                case KW_RENAME:
                                case KW_REPAIR:
                                case KW_REPL:
                                case KW_REPLACE:
                                case KW_REPLICATION:
                                case KW_RESTRICT:
                                case KW_REVOKE:
                                case KW_REWRITE:
                                case KW_RIGHT:
                                case KW_RLIKE:
                                case KW_ROLE:
                                case KW_ROLES:
                                case KW_ROLLUP:
                                case KW_ROW:
                                case KW_ROWS:
                                case KW_SCHEMA:
                                case KW_SCHEMAS:
                                case KW_SECOND:
                                case KW_SEMI:
                                case KW_SERDE:
                                case KW_SERDEPROPERTIES:
                                case KW_SERVER:
                                case KW_SET:
                                case KW_SETS:
                                case KW_SHARED:
                                case KW_SHOW:
                                case KW_SHOW_DATABASE:
                                case KW_SKEWED:
                                case KW_SMALLINT:
                                case KW_SNAPSHOT:
                                case KW_SORT:
                                case KW_SORTED:
                                case KW_SSL:
                                case KW_STATISTICS:
                                case KW_STATUS:
                                case KW_STORED:
                                case KW_STREAMTABLE:
                                case KW_STRING:
                                case KW_STRUCT:
                                case KW_TABLE:
                                case KW_TABLES:
                                case KW_TBLPROPERTIES:
                                case KW_TEMPORARY:
                                case KW_TERMINATED:
                                case KW_TIMESTAMP:
                                case KW_TINYINT:
                                case KW_TO:
                                case KW_TOUCH:
                                case KW_TRANSACTION:
                                case KW_TRANSACTIONS:
                                case KW_TRIGGER:
                                case KW_TRUE:
                                case KW_TRUNCATE:
                                case KW_UNARCHIVE:
                                case KW_UNDO:
                                case KW_UNION:
                                case KW_UNIONTYPE:
                                case KW_UNLOCK:
                                case KW_UNSET:
                                case KW_UNSIGNED:
                                case KW_UPDATE:
                                case KW_URI:
                                case KW_USE:
                                case KW_USER:
                                case KW_USING:
                                case KW_UTC:
                                case KW_UTCTIMESTAMP:
                                case KW_VALIDATE:
                                case KW_VALUES:
                                case KW_VALUE_TYPE:
                                case KW_VIEW:
                                case KW_VIEWS:
                                case KW_WEEK:
                                case KW_WHILE:
                                case KW_WITH:
                                case KW_WORK:
                                case KW_WRITE:
                                case KW_YEAR:
                                case KW_BATCH:
                                case KW_DAYOFWEEK:
                                case KW_HOLD_DDLTIME:
                                case KW_IGNORE:
                                case KW_NO_DROP:
                                case KW_OFFLINE:
                                case KW_PROTECTION:
                                case KW_READONLY:
                                    {
                                    alt141=1;
                                    }
                                    break;
                            }

                            switch (alt141) {
                                case 1 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1506:8: parttype= partTypeExpr
                                    {
                                    pushFollow(FOLLOW_partTypeExpr_in_showStatement7917);
                                    parttype=partTypeExpr();

                                    state._fsp--;
                                    if (state.failed) return retval;
                                    if ( state.backtracking==0 ) stream_partTypeExpr.add(parttype.getTree());

                                    }
                                    break;

                            }


                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1506:32: (isExtended= KW_EXTENDED )?
                            int alt142=2;
                            switch ( input.LA(1) ) {
                                case KW_EXTENDED:
                                    {
                                    alt142=1;
                                    }
                                    break;
                            }

                            switch (alt142) {
                                case 1 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1506:33: isExtended= KW_EXTENDED
                                    {
                                    isExtended=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement7924); if (state.failed) return retval; 
                                    if ( state.backtracking==0 ) stream_KW_EXTENDED.add(isExtended);


                                    }
                                    break;

                            }


                            // AST REWRITE
                            // elements: parttype, isExtended
                            // token labels: isExtended
                            // rule labels: parttype, retval
                            // token list labels: 
                            // rule list labels: 
                            // wildcard labels: 
                            if ( state.backtracking==0 ) {

                            retval.tree = root_0;
                            RewriteRuleTokenStream stream_isExtended=new RewriteRuleTokenStream(adaptor,"token isExtended",isExtended);
                            RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.tree:null);
                            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                            root_0 = (ASTNode)adaptor.nil();
                            // 1506:58: -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? )
                            {
                                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1506:61: ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? )
                                {
                                ASTNode root_1 = (ASTNode)adaptor.nil();
                                root_1 = (ASTNode)adaptor.becomeRoot(
                                (ASTNode)adaptor.create(TOK_SHOWLOCKS, "TOK_SHOWLOCKS")
                                , root_1);

                                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1506:78: ( $parttype)?
                                if ( stream_parttype.hasNext() ) {
                                    adaptor.addChild(root_1, stream_parttype.nextTree());

                                }
                                stream_parttype.reset();

                                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1506:89: ( $isExtended)?
                                if ( stream_isExtended.hasNext() ) {
                                    adaptor.addChild(root_1, stream_isExtended.nextNode());

                                }
                                stream_isExtended.reset();

                                adaptor.addChild(root_0, root_1);
                                }

                            }


                            retval.tree = root_0;
                            }

                            }
                            break;

                    }


                    }
                    break;
                case 10 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1508:7: KW_SHOW (showOptions= KW_FORMATTED )? ( KW_INDEX | KW_INDEXES ) KW_ON showStmtIdentifier ( ( KW_FROM | KW_IN ) db_name= identifier )?
                    {
                    KW_SHOW464=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement7956); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW464);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1508:15: (showOptions= KW_FORMATTED )?
                    int alt144=2;
                    switch ( input.LA(1) ) {
                        case KW_FORMATTED:
                            {
                            alt144=1;
                            }
                            break;
                    }

                    switch (alt144) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1508:16: showOptions= KW_FORMATTED
                            {
                            showOptions=(Token)match(input,KW_FORMATTED,FOLLOW_KW_FORMATTED_in_showStatement7961); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_FORMATTED.add(showOptions);


                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1508:43: ( KW_INDEX | KW_INDEXES )
                    int alt145=2;
                    switch ( input.LA(1) ) {
                    case KW_INDEX:
                        {
                        alt145=1;
                        }
                        break;
                    case KW_INDEXES:
                        {
                        alt145=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 145, 0, input);

                        throw nvae;

                    }

                    switch (alt145) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1508:44: KW_INDEX
                            {
                            KW_INDEX465=(Token)match(input,KW_INDEX,FOLLOW_KW_INDEX_in_showStatement7966); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_INDEX.add(KW_INDEX465);


                            }
                            break;
                        case 2 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1508:53: KW_INDEXES
                            {
                            KW_INDEXES466=(Token)match(input,KW_INDEXES,FOLLOW_KW_INDEXES_in_showStatement7968); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_INDEXES.add(KW_INDEXES466);


                            }
                            break;

                    }


                    KW_ON467=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_showStatement7971); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON467);


                    pushFollow(FOLLOW_showStmtIdentifier_in_showStatement7973);
                    showStmtIdentifier468=showStmtIdentifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier468.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1508:90: ( ( KW_FROM | KW_IN ) db_name= identifier )?
                    int alt147=2;
                    switch ( input.LA(1) ) {
                        case KW_FROM:
                        case KW_IN:
                            {
                            alt147=1;
                            }
                            break;
                    }

                    switch (alt147) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1508:91: ( KW_FROM | KW_IN ) db_name= identifier
                            {
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1508:91: ( KW_FROM | KW_IN )
                            int alt146=2;
                            switch ( input.LA(1) ) {
                            case KW_FROM:
                                {
                                alt146=1;
                                }
                                break;
                            case KW_IN:
                                {
                                alt146=2;
                                }
                                break;
                            default:
                                if (state.backtracking>0) {state.failed=true; return retval;}
                                NoViableAltException nvae =
                                    new NoViableAltException("", 146, 0, input);

                                throw nvae;

                            }

                            switch (alt146) {
                                case 1 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1508:92: KW_FROM
                                    {
                                    KW_FROM469=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement7977); if (state.failed) return retval; 
                                    if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM469);


                                    }
                                    break;
                                case 2 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1508:100: KW_IN
                                    {
                                    KW_IN470=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement7979); if (state.failed) return retval; 
                                    if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN470);


                                    }
                                    break;

                            }


                            pushFollow(FOLLOW_identifier_in_showStatement7984);
                            db_name=identifier();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: showOptions, db_name, showStmtIdentifier
                    // token labels: showOptions
                    // rule labels: db_name, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_showOptions=new RewriteRuleTokenStream(adaptor,"token showOptions",showOptions);
                    RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1509:5: -> ^( TOK_SHOWINDEXES showStmtIdentifier ( $showOptions)? ( $db_name)? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1509:8: ^( TOK_SHOWINDEXES showStmtIdentifier ( $showOptions)? ( $db_name)? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SHOWINDEXES, "TOK_SHOWINDEXES")
                        , root_1);

                        adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1509:46: ( $showOptions)?
                        if ( stream_showOptions.hasNext() ) {
                            adaptor.addChild(root_1, stream_showOptions.nextNode());

                        }
                        stream_showOptions.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1509:60: ( $db_name)?
                        if ( stream_db_name.hasNext() ) {
                            adaptor.addChild(root_1, stream_db_name.nextTree());

                        }
                        stream_db_name.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 11 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1510:7: KW_SHOW KW_COMPACTIONS
                    {
                    KW_SHOW471=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8014); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW471);


                    KW_COMPACTIONS472=(Token)match(input,KW_COMPACTIONS,FOLLOW_KW_COMPACTIONS_in_showStatement8016); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_COMPACTIONS.add(KW_COMPACTIONS472);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1510:30: -> ^( TOK_SHOW_COMPACTIONS )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1510:33: ^( TOK_SHOW_COMPACTIONS )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SHOW_COMPACTIONS, "TOK_SHOW_COMPACTIONS")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 12 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:7: KW_SHOW KW_TRANSACTIONS
                    {
                    KW_SHOW473=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8030); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW473);


                    KW_TRANSACTIONS474=(Token)match(input,KW_TRANSACTIONS,FOLLOW_KW_TRANSACTIONS_in_showStatement8032); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TRANSACTIONS.add(KW_TRANSACTIONS474);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1511:31: -> ^( TOK_SHOW_TRANSACTIONS )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:34: ^( TOK_SHOW_TRANSACTIONS )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SHOW_TRANSACTIONS, "TOK_SHOW_TRANSACTIONS")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 13 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1512:7: KW_SHOW KW_CONF StringLiteral
                    {
                    KW_SHOW475=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement8046); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW475);


                    KW_CONF476=(Token)match(input,KW_CONF,FOLLOW_KW_CONF_in_showStatement8048); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_CONF.add(KW_CONF476);


                    StringLiteral477=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showStatement8050); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral477);


                    // AST REWRITE
                    // elements: StringLiteral
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1512:37: -> ^( TOK_SHOWCONF StringLiteral )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1512:40: ^( TOK_SHOWCONF StringLiteral )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SHOWCONF, "TOK_SHOWCONF")
                        , root_1);

                        adaptor.addChild(root_1, 
                        stream_StringLiteral.nextNode()
                        );

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "showStatement"


    public static class lockStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "lockStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1515:1: lockStatement : KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? ) ;
    public final HiveParser.lockStatement_return lockStatement() throws RecognitionException {
        HiveParser.lockStatement_return retval = new HiveParser.lockStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_LOCK478=null;
        Token KW_TABLE479=null;
        HiveParser_FromClauseParser.tableName_return tableName480 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec481 =null;

        HiveParser.lockMode_return lockMode482 =null;


        ASTNode KW_LOCK478_tree=null;
        ASTNode KW_TABLE479_tree=null;
        RewriteRuleTokenStream stream_KW_LOCK=new RewriteRuleTokenStream(adaptor,"token KW_LOCK");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleSubtreeStream stream_lockMode=new RewriteRuleSubtreeStream(adaptor,"rule lockMode");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("lock statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:5: ( KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:7: KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode
            {
            KW_LOCK478=(Token)match(input,KW_LOCK,FOLLOW_KW_LOCK_in_lockStatement8085); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_LOCK.add(KW_LOCK478);


            KW_TABLE479=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_lockStatement8087); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE479);


            pushFollow(FOLLOW_tableName_in_lockStatement8089);
            tableName480=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(tableName480.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:34: ( partitionSpec )?
            int alt149=2;
            switch ( input.LA(1) ) {
                case KW_PARTITION:
                    {
                    alt149=1;
                    }
                    break;
            }

            switch (alt149) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:34: partitionSpec
                    {
                    pushFollow(FOLLOW_partitionSpec_in_lockStatement8091);
                    partitionSpec481=partitionSpec();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec481.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_lockMode_in_lockStatement8094);
            lockMode482=lockMode();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_lockMode.add(lockMode482.getTree());

            // AST REWRITE
            // elements: lockMode, partitionSpec, tableName
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1518:58: -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:61: ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_LOCKTABLE, "TOK_LOCKTABLE")
                , root_1);

                adaptor.addChild(root_1, stream_tableName.nextTree());

                adaptor.addChild(root_1, stream_lockMode.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:96: ( partitionSpec )?
                if ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "lockStatement"


    public static class lockDatabase_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "lockDatabase"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1521:1: lockDatabase : KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) lockMode -> ^( TOK_LOCKDB $dbName lockMode ) ;
    public final HiveParser.lockDatabase_return lockDatabase() throws RecognitionException {
        HiveParser.lockDatabase_return retval = new HiveParser.lockDatabase_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token dbName=null;
        Token KW_LOCK483=null;
        Token KW_DATABASE484=null;
        Token KW_SCHEMA485=null;
        HiveParser.lockMode_return lockMode486 =null;


        ASTNode dbName_tree=null;
        ASTNode KW_LOCK483_tree=null;
        ASTNode KW_DATABASE484_tree=null;
        ASTNode KW_SCHEMA485_tree=null;
        RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
        RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
        RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
        RewriteRuleTokenStream stream_KW_LOCK=new RewriteRuleTokenStream(adaptor,"token KW_LOCK");
        RewriteRuleSubtreeStream stream_lockMode=new RewriteRuleSubtreeStream(adaptor,"rule lockMode");
         pushMsg("lock database statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1524:5: ( KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) lockMode -> ^( TOK_LOCKDB $dbName lockMode ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1524:7: KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) lockMode
            {
            KW_LOCK483=(Token)match(input,KW_LOCK,FOLLOW_KW_LOCK_in_lockDatabase8134); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_LOCK.add(KW_LOCK483);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1524:15: ( KW_DATABASE | KW_SCHEMA )
            int alt150=2;
            switch ( input.LA(1) ) {
            case KW_DATABASE:
                {
                alt150=1;
                }
                break;
            case KW_SCHEMA:
                {
                alt150=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 150, 0, input);

                throw nvae;

            }

            switch (alt150) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1524:16: KW_DATABASE
                    {
                    KW_DATABASE484=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_lockDatabase8137); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE484);


                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1524:28: KW_SCHEMA
                    {
                    KW_SCHEMA485=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_lockDatabase8139); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA485);


                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1524:39: (dbName= Identifier )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1524:40: dbName= Identifier
            {
            dbName=(Token)match(input,Identifier,FOLLOW_Identifier_in_lockDatabase8145); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_Identifier.add(dbName);


            }


            pushFollow(FOLLOW_lockMode_in_lockDatabase8148);
            lockMode486=lockMode();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_lockMode.add(lockMode486.getTree());

            // AST REWRITE
            // elements: dbName, lockMode
            // token labels: dbName
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_dbName=new RewriteRuleTokenStream(adaptor,"token dbName",dbName);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1524:68: -> ^( TOK_LOCKDB $dbName lockMode )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1524:71: ^( TOK_LOCKDB $dbName lockMode )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_LOCKDB, "TOK_LOCKDB")
                , root_1);

                adaptor.addChild(root_1, stream_dbName.nextNode());

                adaptor.addChild(root_1, stream_lockMode.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "lockDatabase"


    public static class lockMode_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "lockMode"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1527:1: lockMode : ( KW_SHARED | KW_EXCLUSIVE );
    public final HiveParser.lockMode_return lockMode() throws RecognitionException {
        HiveParser.lockMode_return retval = new HiveParser.lockMode_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token set487=null;

        ASTNode set487_tree=null;

         pushMsg("lock mode", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1530:5: ( KW_SHARED | KW_EXCLUSIVE )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:
            {
            root_0 = (ASTNode)adaptor.nil();


            set487=(Token)input.LT(1);

            if ( input.LA(1)==KW_EXCLUSIVE||input.LA(1)==KW_SHARED ) {
                input.consume();
                if ( state.backtracking==0 ) adaptor.addChild(root_0, 
                (ASTNode)adaptor.create(set487)
                );
                state.errorRecovery=false;
                state.failed=false;
            }
            else {
                if (state.backtracking>0) {state.failed=true; return retval;}
                MismatchedSetException mse = new MismatchedSetException(null,input);
                throw mse;
            }


            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "lockMode"


    public static class unlockStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "unlockStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1533:1: unlockStatement : KW_UNLOCK KW_TABLE tableName ( partitionSpec )? -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? ) ;
    public final HiveParser.unlockStatement_return unlockStatement() throws RecognitionException {
        HiveParser.unlockStatement_return retval = new HiveParser.unlockStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_UNLOCK488=null;
        Token KW_TABLE489=null;
        HiveParser_FromClauseParser.tableName_return tableName490 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec491 =null;


        ASTNode KW_UNLOCK488_tree=null;
        ASTNode KW_TABLE489_tree=null;
        RewriteRuleTokenStream stream_KW_UNLOCK=new RewriteRuleTokenStream(adaptor,"token KW_UNLOCK");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("unlock statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1536:5: ( KW_UNLOCK KW_TABLE tableName ( partitionSpec )? -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1536:7: KW_UNLOCK KW_TABLE tableName ( partitionSpec )?
            {
            KW_UNLOCK488=(Token)match(input,KW_UNLOCK,FOLLOW_KW_UNLOCK_in_unlockStatement8217); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_UNLOCK.add(KW_UNLOCK488);


            KW_TABLE489=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_unlockStatement8219); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE489);


            pushFollow(FOLLOW_tableName_in_unlockStatement8221);
            tableName490=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(tableName490.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1536:36: ( partitionSpec )?
            int alt151=2;
            switch ( input.LA(1) ) {
                case KW_PARTITION:
                    {
                    alt151=1;
                    }
                    break;
            }

            switch (alt151) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1536:36: partitionSpec
                    {
                    pushFollow(FOLLOW_partitionSpec_in_unlockStatement8223);
                    partitionSpec491=partitionSpec();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec491.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: partitionSpec, tableName
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1536:52: -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1536:55: ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_UNLOCKTABLE, "TOK_UNLOCKTABLE")
                , root_1);

                adaptor.addChild(root_1, stream_tableName.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1536:83: ( partitionSpec )?
                if ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "unlockStatement"


    public static class unlockDatabase_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "unlockDatabase"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1539:1: unlockDatabase : KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) -> ^( TOK_UNLOCKDB $dbName) ;
    public final HiveParser.unlockDatabase_return unlockDatabase() throws RecognitionException {
        HiveParser.unlockDatabase_return retval = new HiveParser.unlockDatabase_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token dbName=null;
        Token KW_UNLOCK492=null;
        Token KW_DATABASE493=null;
        Token KW_SCHEMA494=null;

        ASTNode dbName_tree=null;
        ASTNode KW_UNLOCK492_tree=null;
        ASTNode KW_DATABASE493_tree=null;
        ASTNode KW_SCHEMA494_tree=null;
        RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
        RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
        RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
        RewriteRuleTokenStream stream_KW_UNLOCK=new RewriteRuleTokenStream(adaptor,"token KW_UNLOCK");

         pushMsg("unlock database statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1542:5: ( KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) -> ^( TOK_UNLOCKDB $dbName) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1542:7: KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier )
            {
            KW_UNLOCK492=(Token)match(input,KW_UNLOCK,FOLLOW_KW_UNLOCK_in_unlockDatabase8263); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_UNLOCK.add(KW_UNLOCK492);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1542:17: ( KW_DATABASE | KW_SCHEMA )
            int alt152=2;
            switch ( input.LA(1) ) {
            case KW_DATABASE:
                {
                alt152=1;
                }
                break;
            case KW_SCHEMA:
                {
                alt152=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 152, 0, input);

                throw nvae;

            }

            switch (alt152) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1542:18: KW_DATABASE
                    {
                    KW_DATABASE493=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_unlockDatabase8266); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE493);


                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1542:30: KW_SCHEMA
                    {
                    KW_SCHEMA494=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_unlockDatabase8268); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA494);


                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1542:41: (dbName= Identifier )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1542:42: dbName= Identifier
            {
            dbName=(Token)match(input,Identifier,FOLLOW_Identifier_in_unlockDatabase8274); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_Identifier.add(dbName);


            }


            // AST REWRITE
            // elements: dbName
            // token labels: dbName
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_dbName=new RewriteRuleTokenStream(adaptor,"token dbName",dbName);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1542:61: -> ^( TOK_UNLOCKDB $dbName)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1542:64: ^( TOK_UNLOCKDB $dbName)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_UNLOCKDB, "TOK_UNLOCKDB")
                , root_1);

                adaptor.addChild(root_1, stream_dbName.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "unlockDatabase"


    public static class createRoleStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "createRoleStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1545:1: createRoleStatement : KW_CREATE KW_ROLE roleName= identifier -> ^( TOK_CREATEROLE $roleName) ;
    public final HiveParser.createRoleStatement_return createRoleStatement() throws RecognitionException {
        HiveParser.createRoleStatement_return retval = new HiveParser.createRoleStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_CREATE495=null;
        Token KW_ROLE496=null;
        HiveParser_IdentifiersParser.identifier_return roleName =null;


        ASTNode KW_CREATE495_tree=null;
        ASTNode KW_ROLE496_tree=null;
        RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         pushMsg("create role", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1548:5: ( KW_CREATE KW_ROLE roleName= identifier -> ^( TOK_CREATEROLE $roleName) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1548:7: KW_CREATE KW_ROLE roleName= identifier
            {
            KW_CREATE495=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createRoleStatement8311); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE495);


            KW_ROLE496=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_createRoleStatement8313); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE496);


            pushFollow(FOLLOW_identifier_in_createRoleStatement8317);
            roleName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(roleName.getTree());

            // AST REWRITE
            // elements: roleName
            // token labels: 
            // rule labels: roleName, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_roleName=new RewriteRuleSubtreeStream(adaptor,"rule roleName",roleName!=null?roleName.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1549:5: -> ^( TOK_CREATEROLE $roleName)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1549:8: ^( TOK_CREATEROLE $roleName)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_CREATEROLE, "TOK_CREATEROLE")
                , root_1);

                adaptor.addChild(root_1, stream_roleName.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "createRoleStatement"


    public static class dropRoleStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dropRoleStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1552:1: dropRoleStatement : KW_DROP KW_ROLE roleName= identifier -> ^( TOK_DROPROLE $roleName) ;
    public final HiveParser.dropRoleStatement_return dropRoleStatement() throws RecognitionException {
        HiveParser.dropRoleStatement_return retval = new HiveParser.dropRoleStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_DROP497=null;
        Token KW_ROLE498=null;
        HiveParser_IdentifiersParser.identifier_return roleName =null;


        ASTNode KW_DROP497_tree=null;
        ASTNode KW_ROLE498_tree=null;
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        pushMsg("drop role", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1555:5: ( KW_DROP KW_ROLE roleName= identifier -> ^( TOK_DROPROLE $roleName) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1555:7: KW_DROP KW_ROLE roleName= identifier
            {
            KW_DROP497=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropRoleStatement8357); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP497);


            KW_ROLE498=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_dropRoleStatement8359); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE498);


            pushFollow(FOLLOW_identifier_in_dropRoleStatement8363);
            roleName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(roleName.getTree());

            // AST REWRITE
            // elements: roleName
            // token labels: 
            // rule labels: roleName, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_roleName=new RewriteRuleSubtreeStream(adaptor,"rule roleName",roleName!=null?roleName.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1556:5: -> ^( TOK_DROPROLE $roleName)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1556:8: ^( TOK_DROPROLE $roleName)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DROPROLE, "TOK_DROPROLE")
                , root_1);

                adaptor.addChild(root_1, stream_roleName.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dropRoleStatement"


    public static class grantPrivileges_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "grantPrivileges"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1559:1: grantPrivileges : KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )? -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? ) ;
    public final HiveParser.grantPrivileges_return grantPrivileges() throws RecognitionException {
        HiveParser.grantPrivileges_return retval = new HiveParser.grantPrivileges_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_GRANT499=null;
        Token KW_TO501=null;
        HiveParser.privilegeList_return privList =null;

        HiveParser.privilegeObject_return privilegeObject500 =null;

        HiveParser.principalSpecification_return principalSpecification502 =null;

        HiveParser.withGrantOption_return withGrantOption503 =null;


        ASTNode KW_GRANT499_tree=null;
        ASTNode KW_TO501_tree=null;
        RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
        RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
        RewriteRuleSubtreeStream stream_withGrantOption=new RewriteRuleSubtreeStream(adaptor,"rule withGrantOption");
        RewriteRuleSubtreeStream stream_privilegeList=new RewriteRuleSubtreeStream(adaptor,"rule privilegeList");
        RewriteRuleSubtreeStream stream_privilegeObject=new RewriteRuleSubtreeStream(adaptor,"rule privilegeObject");
        RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");
        pushMsg("grant privileges", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1562:5: ( KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )? -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1562:7: KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )?
            {
            KW_GRANT499=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_grantPrivileges8403); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT499);


            pushFollow(FOLLOW_privilegeList_in_grantPrivileges8407);
            privList=privilegeList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_privilegeList.add(privList.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1563:7: ( privilegeObject )?
            int alt153=2;
            switch ( input.LA(1) ) {
                case KW_ON:
                    {
                    alt153=1;
                    }
                    break;
            }

            switch (alt153) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1563:7: privilegeObject
                    {
                    pushFollow(FOLLOW_privilegeObject_in_grantPrivileges8415);
                    privilegeObject500=privilegeObject();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_privilegeObject.add(privilegeObject500.getTree());

                    }
                    break;

            }


            KW_TO501=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_grantPrivileges8424); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO501);


            pushFollow(FOLLOW_principalSpecification_in_grantPrivileges8426);
            principalSpecification502=principalSpecification();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_principalSpecification.add(principalSpecification502.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1565:7: ( withGrantOption )?
            int alt154=2;
            switch ( input.LA(1) ) {
                case KW_WITH:
                    {
                    alt154=1;
                    }
                    break;
            }

            switch (alt154) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1565:7: withGrantOption
                    {
                    pushFollow(FOLLOW_withGrantOption_in_grantPrivileges8434);
                    withGrantOption503=withGrantOption();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_withGrantOption.add(withGrantOption503.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: principalSpecification, privList, privilegeObject, withGrantOption
            // token labels: 
            // rule labels: privList, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_privList=new RewriteRuleSubtreeStream(adaptor,"rule privList",privList!=null?privList.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1566:5: -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1566:8: ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_GRANT, "TOK_GRANT")
                , root_1);

                adaptor.addChild(root_1, stream_privList.nextTree());

                adaptor.addChild(root_1, stream_principalSpecification.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1566:53: ( privilegeObject )?
                if ( stream_privilegeObject.hasNext() ) {
                    adaptor.addChild(root_1, stream_privilegeObject.nextTree());

                }
                stream_privilegeObject.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1566:70: ( withGrantOption )?
                if ( stream_withGrantOption.hasNext() ) {
                    adaptor.addChild(root_1, stream_withGrantOption.nextTree());

                }
                stream_withGrantOption.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "grantPrivileges"


    public static class revokePrivileges_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "revokePrivileges"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1569:1: revokePrivileges : KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? ) ;
    public final HiveParser.revokePrivileges_return revokePrivileges() throws RecognitionException {
        HiveParser.revokePrivileges_return retval = new HiveParser.revokePrivileges_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_REVOKE504=null;
        Token KW_FROM508=null;
        HiveParser.grantOptionFor_return grantOptionFor505 =null;

        HiveParser.privilegeList_return privilegeList506 =null;

        HiveParser.privilegeObject_return privilegeObject507 =null;

        HiveParser.principalSpecification_return principalSpecification509 =null;


        ASTNode KW_REVOKE504_tree=null;
        ASTNode KW_FROM508_tree=null;
        RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
        RewriteRuleTokenStream stream_KW_REVOKE=new RewriteRuleTokenStream(adaptor,"token KW_REVOKE");
        RewriteRuleSubtreeStream stream_grantOptionFor=new RewriteRuleSubtreeStream(adaptor,"rule grantOptionFor");
        RewriteRuleSubtreeStream stream_privilegeList=new RewriteRuleSubtreeStream(adaptor,"rule privilegeList");
        RewriteRuleSubtreeStream stream_privilegeObject=new RewriteRuleSubtreeStream(adaptor,"rule privilegeObject");
        RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");
        pushMsg("revoke privileges", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1572:5: ( KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1572:7: KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification
            {
            KW_REVOKE504=(Token)match(input,KW_REVOKE,FOLLOW_KW_REVOKE_in_revokePrivileges8483); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_REVOKE.add(KW_REVOKE504);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1572:17: ( grantOptionFor )?
            int alt155=2;
            switch ( input.LA(1) ) {
                case KW_GRANT:
                    {
                    alt155=1;
                    }
                    break;
            }

            switch (alt155) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1572:17: grantOptionFor
                    {
                    pushFollow(FOLLOW_grantOptionFor_in_revokePrivileges8485);
                    grantOptionFor505=grantOptionFor();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_grantOptionFor.add(grantOptionFor505.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_privilegeList_in_revokePrivileges8488);
            privilegeList506=privilegeList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_privilegeList.add(privilegeList506.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1572:47: ( privilegeObject )?
            int alt156=2;
            switch ( input.LA(1) ) {
                case KW_ON:
                    {
                    alt156=1;
                    }
                    break;
            }

            switch (alt156) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1572:47: privilegeObject
                    {
                    pushFollow(FOLLOW_privilegeObject_in_revokePrivileges8490);
                    privilegeObject507=privilegeObject();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_privilegeObject.add(privilegeObject507.getTree());

                    }
                    break;

            }


            KW_FROM508=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_revokePrivileges8493); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM508);


            pushFollow(FOLLOW_principalSpecification_in_revokePrivileges8495);
            principalSpecification509=principalSpecification();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_principalSpecification.add(principalSpecification509.getTree());

            // AST REWRITE
            // elements: privilegeObject, grantOptionFor, privilegeList, principalSpecification
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1573:5: -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1573:8: ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_REVOKE, "TOK_REVOKE")
                , root_1);

                adaptor.addChild(root_1, stream_privilegeList.nextTree());

                adaptor.addChild(root_1, stream_principalSpecification.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1573:58: ( privilegeObject )?
                if ( stream_privilegeObject.hasNext() ) {
                    adaptor.addChild(root_1, stream_privilegeObject.nextTree());

                }
                stream_privilegeObject.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1573:75: ( grantOptionFor )?
                if ( stream_grantOptionFor.hasNext() ) {
                    adaptor.addChild(root_1, stream_grantOptionFor.nextTree());

                }
                stream_grantOptionFor.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "revokePrivileges"


    public static class grantRole_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "grantRole"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1576:1: grantRole : KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )? -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ ) ;
    public final HiveParser.grantRole_return grantRole() throws RecognitionException {
        HiveParser.grantRole_return retval = new HiveParser.grantRole_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_GRANT510=null;
        Token KW_ROLE511=null;
        Token COMMA513=null;
        Token KW_TO515=null;
        HiveParser_IdentifiersParser.identifier_return identifier512 =null;

        HiveParser_IdentifiersParser.identifier_return identifier514 =null;

        HiveParser.principalSpecification_return principalSpecification516 =null;

        HiveParser.withAdminOption_return withAdminOption517 =null;


        ASTNode KW_GRANT510_tree=null;
        ASTNode KW_ROLE511_tree=null;
        ASTNode COMMA513_tree=null;
        ASTNode KW_TO515_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
        RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
        RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_withAdminOption=new RewriteRuleSubtreeStream(adaptor,"rule withAdminOption");
        RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");
        pushMsg("grant role", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1579:5: ( KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )? -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1579:7: KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )?
            {
            KW_GRANT510=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_grantRole8542); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT510);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1579:16: ( KW_ROLE )?
            int alt157=2;
            switch ( input.LA(1) ) {
                case KW_ROLE:
                    {
                    switch ( input.LA(2) ) {
                        case Identifier:
                        case KW_ABORT:
                        case KW_ADD:
                        case KW_ADMIN:
                        case KW_AFTER:
                        case KW_ALL:
                        case KW_ALTER:
                        case KW_ANALYZE:
                        case KW_ARCHIVE:
                        case KW_ARRAY:
                        case KW_AS:
                        case KW_ASC:
                        case KW_AUTHORIZATION:
                        case KW_AUTOCOMMIT:
                        case KW_BEFORE:
                        case KW_BETWEEN:
                        case KW_BIGINT:
                        case KW_BINARY:
                        case KW_BOOLEAN:
                        case KW_BOTH:
                        case KW_BUCKET:
                        case KW_BUCKETS:
                        case KW_BY:
                        case KW_CACHE:
                        case KW_CASCADE:
                        case KW_CHANGE:
                        case KW_CLUSTER:
                        case KW_CLUSTERED:
                        case KW_CLUSTERSTATUS:
                        case KW_COLLECTION:
                        case KW_COLUMNS:
                        case KW_COMMENT:
                        case KW_COMPACT:
                        case KW_COMPACTIONS:
                        case KW_COMPUTE:
                        case KW_CONCATENATE:
                        case KW_CONSTRAINT:
                        case KW_CONTINUE:
                        case KW_CREATE:
                        case KW_CUBE:
                        case KW_CURRENT_DATE:
                        case KW_CURRENT_TIMESTAMP:
                        case KW_CURSOR:
                        case KW_DATA:
                        case KW_DATABASES:
                        case KW_DATE:
                        case KW_DATETIME:
                        case KW_DAY:
                        case KW_DBPROPERTIES:
                        case KW_DECIMAL:
                        case KW_DEFERRED:
                        case KW_DEFINED:
                        case KW_DELETE:
                        case KW_DELIMITED:
                        case KW_DEPENDENCY:
                        case KW_DESC:
                        case KW_DESCRIBE:
                        case KW_DIRECTORIES:
                        case KW_DIRECTORY:
                        case KW_DISABLE:
                        case KW_DISTRIBUTE:
                        case KW_DOUBLE:
                        case KW_DOW:
                        case KW_DROP:
                        case KW_DUMP:
                        case KW_ELEM_TYPE:
                        case KW_ENABLE:
                        case KW_ESCAPED:
                        case KW_EXCLUSIVE:
                        case KW_EXISTS:
                        case KW_EXPLAIN:
                        case KW_EXPORT:
                        case KW_EXTERNAL:
                        case KW_FALSE:
                        case KW_FETCH:
                        case KW_FIELDS:
                        case KW_FILE:
                        case KW_FILEFORMAT:
                        case KW_FIRST:
                        case KW_FLOAT:
                        case KW_FOR:
                        case KW_FOREIGN:
                        case KW_FORMAT:
                        case KW_FORMATTED:
                        case KW_FULL:
                        case KW_FUNCTIONS:
                        case KW_GRANT:
                        case KW_GROUP:
                        case KW_GROUPING:
                        case KW_HOUR:
                        case KW_IDXPROPERTIES:
                        case KW_IMPORT:
                        case KW_IN:
                        case KW_INDEX:
                        case KW_INDEXES:
                        case KW_INNER:
                        case KW_INPATH:
                        case KW_INPUTDRIVER:
                        case KW_INPUTFORMAT:
                        case KW_INSERT:
                        case KW_INT:
                        case KW_INTERSECT:
                        case KW_INTO:
                        case KW_IS:
                        case KW_ISOLATION:
                        case KW_ITEMS:
                        case KW_JAR:
                        case KW_KEY:
                        case KW_KEYS:
                        case KW_KEY_TYPE:
                        case KW_LAST:
                        case KW_LATERAL:
                        case KW_LEFT:
                        case KW_LEVEL:
                        case KW_LIKE:
                        case KW_LIMIT:
                        case KW_LINES:
                        case KW_LOAD:
                        case KW_LOCAL:
                        case KW_LOCATION:
                        case KW_LOCK:
                        case KW_LOCKS:
                        case KW_LOGICAL:
                        case KW_LONG:
                        case KW_MAPJOIN:
                        case KW_MATCHED:
                        case KW_MATERIALIZED:
                        case KW_MERGE:
                        case KW_METADATA:
                        case KW_MINUTE:
                        case KW_MONTH:
                        case KW_MSCK:
                        case KW_NONE:
                        case KW_NORELY:
                        case KW_NOSCAN:
                        case KW_NOVALIDATE:
                        case KW_NULL:
                        case KW_NULLS:
                        case KW_OF:
                        case KW_OFFSET:
                        case KW_OPTION:
                        case KW_ORDER:
                        case KW_OUT:
                        case KW_OUTER:
                        case KW_OUTPUTDRIVER:
                        case KW_OUTPUTFORMAT:
                        case KW_OVERWRITE:
                        case KW_OWNER:
                        case KW_PARTITION:
                        case KW_PARTITIONED:
                        case KW_PARTITIONS:
                        case KW_PERCENT:
                        case KW_PLUS:
                        case KW_PRETTY:
                        case KW_PRIMARY:
                        case KW_PRINCIPALS:
                        case KW_PROCEDURE:
                        case KW_PURGE:
                        case KW_QUARTER:
                        case KW_RANGE:
                        case KW_READ:
                        case KW_READS:
                        case KW_REBUILD:
                        case KW_RECORDREADER:
                        case KW_RECORDWRITER:
                        case KW_REFERENCES:
                        case KW_REGEXP:
                        case KW_RELOAD:
                        case KW_RELY:
                        case KW_RENAME:
                        case KW_REPAIR:
                        case KW_REPL:
                        case KW_REPLACE:
                        case KW_REPLICATION:
                        case KW_RESTRICT:
                        case KW_REVOKE:
                        case KW_REWRITE:
                        case KW_RIGHT:
                        case KW_RLIKE:
                        case KW_ROLE:
                        case KW_ROLES:
                        case KW_ROLLUP:
                        case KW_ROW:
                        case KW_ROWS:
                        case KW_SCHEMA:
                        case KW_SCHEMAS:
                        case KW_SECOND:
                        case KW_SEMI:
                        case KW_SERDE:
                        case KW_SERDEPROPERTIES:
                        case KW_SERVER:
                        case KW_SET:
                        case KW_SETS:
                        case KW_SHARED:
                        case KW_SHOW:
                        case KW_SHOW_DATABASE:
                        case KW_SKEWED:
                        case KW_SMALLINT:
                        case KW_SNAPSHOT:
                        case KW_SORT:
                        case KW_SORTED:
                        case KW_SSL:
                        case KW_STATISTICS:
                        case KW_STATUS:
                        case KW_STORED:
                        case KW_STREAMTABLE:
                        case KW_STRING:
                        case KW_STRUCT:
                        case KW_TABLE:
                        case KW_TABLES:
                        case KW_TBLPROPERTIES:
                        case KW_TEMPORARY:
                        case KW_TERMINATED:
                        case KW_TIMESTAMP:
                        case KW_TINYINT:
                        case KW_TOUCH:
                        case KW_TRANSACTION:
                        case KW_TRANSACTIONS:
                        case KW_TRIGGER:
                        case KW_TRUE:
                        case KW_TRUNCATE:
                        case KW_UNARCHIVE:
                        case KW_UNDO:
                        case KW_UNION:
                        case KW_UNIONTYPE:
                        case KW_UNLOCK:
                        case KW_UNSET:
                        case KW_UNSIGNED:
                        case KW_UPDATE:
                        case KW_URI:
                        case KW_USE:
                        case KW_USER:
                        case KW_USING:
                        case KW_UTC:
                        case KW_UTCTIMESTAMP:
                        case KW_VALIDATE:
                        case KW_VALUES:
                        case KW_VALUE_TYPE:
                        case KW_VIEW:
                        case KW_VIEWS:
                        case KW_WEEK:
                        case KW_WHILE:
                        case KW_WITH:
                        case KW_WORK:
                        case KW_WRITE:
                        case KW_YEAR:
                        case KW_BATCH:
                        case KW_DAYOFWEEK:
                        case KW_HOLD_DDLTIME:
                        case KW_IGNORE:
                        case KW_NO_DROP:
                        case KW_OFFLINE:
                        case KW_PROTECTION:
                        case KW_READONLY:
                            {
                            alt157=1;
                            }
                            break;
                        case KW_TO:
                            {
                            switch ( input.LA(3) ) {
                                case COMMA:
                                case KW_TO:
                                    {
                                    alt157=1;
                                    }
                                    break;
                            }

                            }
                            break;
                    }

                    }
                    break;
            }

            switch (alt157) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1579:16: KW_ROLE
                    {
                    KW_ROLE511=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_grantRole8544); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE511);


                    }
                    break;

            }


            pushFollow(FOLLOW_identifier_in_grantRole8547);
            identifier512=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(identifier512.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1579:36: ( COMMA identifier )*
            loop158:
            do {
                int alt158=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt158=1;
                    }
                    break;

                }

                switch (alt158) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1579:37: COMMA identifier
            	    {
            	    COMMA513=(Token)match(input,COMMA,FOLLOW_COMMA_in_grantRole8550); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA513);


            	    pushFollow(FOLLOW_identifier_in_grantRole8552);
            	    identifier514=identifier();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_identifier.add(identifier514.getTree());

            	    }
            	    break;

            	default :
            	    break loop158;
                }
            } while (true);


            KW_TO515=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_grantRole8556); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO515);


            pushFollow(FOLLOW_principalSpecification_in_grantRole8558);
            principalSpecification516=principalSpecification();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_principalSpecification.add(principalSpecification516.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1579:85: ( withAdminOption )?
            int alt159=2;
            switch ( input.LA(1) ) {
                case KW_WITH:
                    {
                    alt159=1;
                    }
                    break;
            }

            switch (alt159) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1579:85: withAdminOption
                    {
                    pushFollow(FOLLOW_withAdminOption_in_grantRole8560);
                    withAdminOption517=withAdminOption();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_withAdminOption.add(withAdminOption517.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: identifier, principalSpecification, withAdminOption
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1580:5: -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1580:8: ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_GRANT_ROLE, "TOK_GRANT_ROLE")
                , root_1);

                adaptor.addChild(root_1, stream_principalSpecification.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1580:48: ( withAdminOption )?
                if ( stream_withAdminOption.hasNext() ) {
                    adaptor.addChild(root_1, stream_withAdminOption.nextTree());

                }
                stream_withAdminOption.reset();

                if ( !(stream_identifier.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_identifier.hasNext() ) {
                    adaptor.addChild(root_1, stream_identifier.nextTree());

                }
                stream_identifier.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "grantRole"


    public static class revokeRole_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "revokeRole"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1583:1: revokeRole : KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ ) ;
    public final HiveParser.revokeRole_return revokeRole() throws RecognitionException {
        HiveParser.revokeRole_return retval = new HiveParser.revokeRole_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_REVOKE518=null;
        Token KW_ROLE520=null;
        Token COMMA522=null;
        Token KW_FROM524=null;
        HiveParser.adminOptionFor_return adminOptionFor519 =null;

        HiveParser_IdentifiersParser.identifier_return identifier521 =null;

        HiveParser_IdentifiersParser.identifier_return identifier523 =null;

        HiveParser.principalSpecification_return principalSpecification525 =null;


        ASTNode KW_REVOKE518_tree=null;
        ASTNode KW_ROLE520_tree=null;
        ASTNode COMMA522_tree=null;
        ASTNode KW_FROM524_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
        RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
        RewriteRuleTokenStream stream_KW_REVOKE=new RewriteRuleTokenStream(adaptor,"token KW_REVOKE");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_adminOptionFor=new RewriteRuleSubtreeStream(adaptor,"rule adminOptionFor");
        RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");
        pushMsg("revoke role", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:5: ( KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:7: KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification
            {
            KW_REVOKE518=(Token)match(input,KW_REVOKE,FOLLOW_KW_REVOKE_in_revokeRole8606); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_REVOKE.add(KW_REVOKE518);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:17: ( adminOptionFor )?
            int alt160=2;
            switch ( input.LA(1) ) {
                case KW_ADMIN:
                    {
                    switch ( input.LA(2) ) {
                        case KW_OPTION:
                            {
                            alt160=1;
                            }
                            break;
                    }

                    }
                    break;
            }

            switch (alt160) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:17: adminOptionFor
                    {
                    pushFollow(FOLLOW_adminOptionFor_in_revokeRole8608);
                    adminOptionFor519=adminOptionFor();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_adminOptionFor.add(adminOptionFor519.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:33: ( KW_ROLE )?
            int alt161=2;
            switch ( input.LA(1) ) {
                case KW_ROLE:
                    {
                    switch ( input.LA(2) ) {
                        case Identifier:
                        case KW_ABORT:
                        case KW_ADD:
                        case KW_ADMIN:
                        case KW_AFTER:
                        case KW_ALL:
                        case KW_ALTER:
                        case KW_ANALYZE:
                        case KW_ARCHIVE:
                        case KW_ARRAY:
                        case KW_AS:
                        case KW_ASC:
                        case KW_AUTHORIZATION:
                        case KW_AUTOCOMMIT:
                        case KW_BEFORE:
                        case KW_BETWEEN:
                        case KW_BIGINT:
                        case KW_BINARY:
                        case KW_BOOLEAN:
                        case KW_BOTH:
                        case KW_BUCKET:
                        case KW_BUCKETS:
                        case KW_BY:
                        case KW_CACHE:
                        case KW_CASCADE:
                        case KW_CHANGE:
                        case KW_CLUSTER:
                        case KW_CLUSTERED:
                        case KW_CLUSTERSTATUS:
                        case KW_COLLECTION:
                        case KW_COLUMNS:
                        case KW_COMMENT:
                        case KW_COMPACT:
                        case KW_COMPACTIONS:
                        case KW_COMPUTE:
                        case KW_CONCATENATE:
                        case KW_CONSTRAINT:
                        case KW_CONTINUE:
                        case KW_CREATE:
                        case KW_CUBE:
                        case KW_CURRENT_DATE:
                        case KW_CURRENT_TIMESTAMP:
                        case KW_CURSOR:
                        case KW_DATA:
                        case KW_DATABASES:
                        case KW_DATE:
                        case KW_DATETIME:
                        case KW_DAY:
                        case KW_DBPROPERTIES:
                        case KW_DECIMAL:
                        case KW_DEFERRED:
                        case KW_DEFINED:
                        case KW_DELETE:
                        case KW_DELIMITED:
                        case KW_DEPENDENCY:
                        case KW_DESC:
                        case KW_DESCRIBE:
                        case KW_DIRECTORIES:
                        case KW_DIRECTORY:
                        case KW_DISABLE:
                        case KW_DISTRIBUTE:
                        case KW_DOUBLE:
                        case KW_DOW:
                        case KW_DROP:
                        case KW_DUMP:
                        case KW_ELEM_TYPE:
                        case KW_ENABLE:
                        case KW_ESCAPED:
                        case KW_EXCLUSIVE:
                        case KW_EXISTS:
                        case KW_EXPLAIN:
                        case KW_EXPORT:
                        case KW_EXTERNAL:
                        case KW_FALSE:
                        case KW_FETCH:
                        case KW_FIELDS:
                        case KW_FILE:
                        case KW_FILEFORMAT:
                        case KW_FIRST:
                        case KW_FLOAT:
                        case KW_FOR:
                        case KW_FOREIGN:
                        case KW_FORMAT:
                        case KW_FORMATTED:
                        case KW_FULL:
                        case KW_FUNCTIONS:
                        case KW_GRANT:
                        case KW_GROUP:
                        case KW_GROUPING:
                        case KW_HOUR:
                        case KW_IDXPROPERTIES:
                        case KW_IMPORT:
                        case KW_IN:
                        case KW_INDEX:
                        case KW_INDEXES:
                        case KW_INNER:
                        case KW_INPATH:
                        case KW_INPUTDRIVER:
                        case KW_INPUTFORMAT:
                        case KW_INSERT:
                        case KW_INT:
                        case KW_INTERSECT:
                        case KW_INTO:
                        case KW_IS:
                        case KW_ISOLATION:
                        case KW_ITEMS:
                        case KW_JAR:
                        case KW_KEY:
                        case KW_KEYS:
                        case KW_KEY_TYPE:
                        case KW_LAST:
                        case KW_LATERAL:
                        case KW_LEFT:
                        case KW_LEVEL:
                        case KW_LIKE:
                        case KW_LIMIT:
                        case KW_LINES:
                        case KW_LOAD:
                        case KW_LOCAL:
                        case KW_LOCATION:
                        case KW_LOCK:
                        case KW_LOCKS:
                        case KW_LOGICAL:
                        case KW_LONG:
                        case KW_MAPJOIN:
                        case KW_MATCHED:
                        case KW_MATERIALIZED:
                        case KW_MERGE:
                        case KW_METADATA:
                        case KW_MINUTE:
                        case KW_MONTH:
                        case KW_MSCK:
                        case KW_NONE:
                        case KW_NORELY:
                        case KW_NOSCAN:
                        case KW_NOVALIDATE:
                        case KW_NULL:
                        case KW_NULLS:
                        case KW_OF:
                        case KW_OFFSET:
                        case KW_OPTION:
                        case KW_ORDER:
                        case KW_OUT:
                        case KW_OUTER:
                        case KW_OUTPUTDRIVER:
                        case KW_OUTPUTFORMAT:
                        case KW_OVERWRITE:
                        case KW_OWNER:
                        case KW_PARTITION:
                        case KW_PARTITIONED:
                        case KW_PARTITIONS:
                        case KW_PERCENT:
                        case KW_PLUS:
                        case KW_PRETTY:
                        case KW_PRIMARY:
                        case KW_PRINCIPALS:
                        case KW_PROCEDURE:
                        case KW_PURGE:
                        case KW_QUARTER:
                        case KW_RANGE:
                        case KW_READ:
                        case KW_READS:
                        case KW_REBUILD:
                        case KW_RECORDREADER:
                        case KW_RECORDWRITER:
                        case KW_REFERENCES:
                        case KW_REGEXP:
                        case KW_RELOAD:
                        case KW_RELY:
                        case KW_RENAME:
                        case KW_REPAIR:
                        case KW_REPL:
                        case KW_REPLACE:
                        case KW_REPLICATION:
                        case KW_RESTRICT:
                        case KW_REVOKE:
                        case KW_REWRITE:
                        case KW_RIGHT:
                        case KW_RLIKE:
                        case KW_ROLE:
                        case KW_ROLES:
                        case KW_ROLLUP:
                        case KW_ROW:
                        case KW_ROWS:
                        case KW_SCHEMA:
                        case KW_SCHEMAS:
                        case KW_SECOND:
                        case KW_SEMI:
                        case KW_SERDE:
                        case KW_SERDEPROPERTIES:
                        case KW_SERVER:
                        case KW_SET:
                        case KW_SETS:
                        case KW_SHARED:
                        case KW_SHOW:
                        case KW_SHOW_DATABASE:
                        case KW_SKEWED:
                        case KW_SMALLINT:
                        case KW_SNAPSHOT:
                        case KW_SORT:
                        case KW_SORTED:
                        case KW_SSL:
                        case KW_STATISTICS:
                        case KW_STATUS:
                        case KW_STORED:
                        case KW_STREAMTABLE:
                        case KW_STRING:
                        case KW_STRUCT:
                        case KW_TABLE:
                        case KW_TABLES:
                        case KW_TBLPROPERTIES:
                        case KW_TEMPORARY:
                        case KW_TERMINATED:
                        case KW_TIMESTAMP:
                        case KW_TINYINT:
                        case KW_TO:
                        case KW_TOUCH:
                        case KW_TRANSACTION:
                        case KW_TRANSACTIONS:
                        case KW_TRIGGER:
                        case KW_TRUE:
                        case KW_TRUNCATE:
                        case KW_UNARCHIVE:
                        case KW_UNDO:
                        case KW_UNION:
                        case KW_UNIONTYPE:
                        case KW_UNLOCK:
                        case KW_UNSET:
                        case KW_UNSIGNED:
                        case KW_UPDATE:
                        case KW_URI:
                        case KW_USE:
                        case KW_USER:
                        case KW_USING:
                        case KW_UTC:
                        case KW_UTCTIMESTAMP:
                        case KW_VALIDATE:
                        case KW_VALUES:
                        case KW_VALUE_TYPE:
                        case KW_VIEW:
                        case KW_VIEWS:
                        case KW_WEEK:
                        case KW_WHILE:
                        case KW_WITH:
                        case KW_WORK:
                        case KW_WRITE:
                        case KW_YEAR:
                        case KW_BATCH:
                        case KW_DAYOFWEEK:
                        case KW_HOLD_DDLTIME:
                        case KW_IGNORE:
                        case KW_NO_DROP:
                        case KW_OFFLINE:
                        case KW_PROTECTION:
                        case KW_READONLY:
                            {
                            alt161=1;
                            }
                            break;
                    }

                    }
                    break;
            }

            switch (alt161) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:33: KW_ROLE
                    {
                    KW_ROLE520=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_revokeRole8611); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE520);


                    }
                    break;

            }


            pushFollow(FOLLOW_identifier_in_revokeRole8614);
            identifier521=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(identifier521.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:53: ( COMMA identifier )*
            loop162:
            do {
                int alt162=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt162=1;
                    }
                    break;

                }

                switch (alt162) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:54: COMMA identifier
            	    {
            	    COMMA522=(Token)match(input,COMMA,FOLLOW_COMMA_in_revokeRole8617); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA522);


            	    pushFollow(FOLLOW_identifier_in_revokeRole8619);
            	    identifier523=identifier();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_identifier.add(identifier523.getTree());

            	    }
            	    break;

            	default :
            	    break loop162;
                }
            } while (true);


            KW_FROM524=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_revokeRole8623); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM524);


            pushFollow(FOLLOW_principalSpecification_in_revokeRole8625);
            principalSpecification525=principalSpecification();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_principalSpecification.add(principalSpecification525.getTree());

            // AST REWRITE
            // elements: adminOptionFor, identifier, principalSpecification
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1587:5: -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1587:8: ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_REVOKE_ROLE, "TOK_REVOKE_ROLE")
                , root_1);

                adaptor.addChild(root_1, stream_principalSpecification.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1587:49: ( adminOptionFor )?
                if ( stream_adminOptionFor.hasNext() ) {
                    adaptor.addChild(root_1, stream_adminOptionFor.nextTree());

                }
                stream_adminOptionFor.reset();

                if ( !(stream_identifier.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_identifier.hasNext() ) {
                    adaptor.addChild(root_1, stream_identifier.nextTree());

                }
                stream_identifier.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "revokeRole"


    public static class showRoleGrants_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "showRoleGrants"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1590:1: showRoleGrants : KW_SHOW KW_ROLE KW_GRANT principalName -> ^( TOK_SHOW_ROLE_GRANT principalName ) ;
    public final HiveParser.showRoleGrants_return showRoleGrants() throws RecognitionException {
        HiveParser.showRoleGrants_return retval = new HiveParser.showRoleGrants_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_SHOW526=null;
        Token KW_ROLE527=null;
        Token KW_GRANT528=null;
        HiveParser.principalName_return principalName529 =null;


        ASTNode KW_SHOW526_tree=null;
        ASTNode KW_ROLE527_tree=null;
        ASTNode KW_GRANT528_tree=null;
        RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
        RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
        RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
        RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");
        pushMsg("show role grants", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1593:5: ( KW_SHOW KW_ROLE KW_GRANT principalName -> ^( TOK_SHOW_ROLE_GRANT principalName ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1593:7: KW_SHOW KW_ROLE KW_GRANT principalName
            {
            KW_SHOW526=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showRoleGrants8670); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW526);


            KW_ROLE527=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_showRoleGrants8672); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE527);


            KW_GRANT528=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_showRoleGrants8674); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT528);


            pushFollow(FOLLOW_principalName_in_showRoleGrants8676);
            principalName529=principalName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_principalName.add(principalName529.getTree());

            // AST REWRITE
            // elements: principalName
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1594:5: -> ^( TOK_SHOW_ROLE_GRANT principalName )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1594:8: ^( TOK_SHOW_ROLE_GRANT principalName )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SHOW_ROLE_GRANT, "TOK_SHOW_ROLE_GRANT")
                , root_1);

                adaptor.addChild(root_1, stream_principalName.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "showRoleGrants"


    public static class showRoles_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "showRoles"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1598:1: showRoles : KW_SHOW KW_ROLES -> ^( TOK_SHOW_ROLES ) ;
    public final HiveParser.showRoles_return showRoles() throws RecognitionException {
        HiveParser.showRoles_return retval = new HiveParser.showRoles_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_SHOW530=null;
        Token KW_ROLES531=null;

        ASTNode KW_SHOW530_tree=null;
        ASTNode KW_ROLES531_tree=null;
        RewriteRuleTokenStream stream_KW_ROLES=new RewriteRuleTokenStream(adaptor,"token KW_ROLES");
        RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");

        pushMsg("show roles", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1601:5: ( KW_SHOW KW_ROLES -> ^( TOK_SHOW_ROLES ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1601:7: KW_SHOW KW_ROLES
            {
            KW_SHOW530=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showRoles8716); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW530);


            KW_ROLES531=(Token)match(input,KW_ROLES,FOLLOW_KW_ROLES_in_showRoles8718); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ROLES.add(KW_ROLES531);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1602:5: -> ^( TOK_SHOW_ROLES )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1602:8: ^( TOK_SHOW_ROLES )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SHOW_ROLES, "TOK_SHOW_ROLES")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "showRoles"


    public static class showCurrentRole_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "showCurrentRole"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1605:1: showCurrentRole : KW_SHOW KW_CURRENT KW_ROLES -> ^( TOK_SHOW_SET_ROLE ) ;
    public final HiveParser.showCurrentRole_return showCurrentRole() throws RecognitionException {
        HiveParser.showCurrentRole_return retval = new HiveParser.showCurrentRole_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_SHOW532=null;
        Token KW_CURRENT533=null;
        Token KW_ROLES534=null;

        ASTNode KW_SHOW532_tree=null;
        ASTNode KW_CURRENT533_tree=null;
        ASTNode KW_ROLES534_tree=null;
        RewriteRuleTokenStream stream_KW_ROLES=new RewriteRuleTokenStream(adaptor,"token KW_ROLES");
        RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
        RewriteRuleTokenStream stream_KW_CURRENT=new RewriteRuleTokenStream(adaptor,"token KW_CURRENT");

        pushMsg("show current role", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1608:5: ( KW_SHOW KW_CURRENT KW_ROLES -> ^( TOK_SHOW_SET_ROLE ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1608:7: KW_SHOW KW_CURRENT KW_ROLES
            {
            KW_SHOW532=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showCurrentRole8755); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW532);


            KW_CURRENT533=(Token)match(input,KW_CURRENT,FOLLOW_KW_CURRENT_in_showCurrentRole8757); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_CURRENT.add(KW_CURRENT533);


            KW_ROLES534=(Token)match(input,KW_ROLES,FOLLOW_KW_ROLES_in_showCurrentRole8759); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ROLES.add(KW_ROLES534);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1609:5: -> ^( TOK_SHOW_SET_ROLE )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:8: ^( TOK_SHOW_SET_ROLE )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SHOW_SET_ROLE, "TOK_SHOW_SET_ROLE")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "showCurrentRole"


    public static class setRole_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "setRole"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1612:1: setRole : KW_SET KW_ROLE ( ( KW_ALL )=> (all= KW_ALL ) -> ^( TOK_SHOW_SET_ROLE Identifier[$all.text] ) | ( KW_NONE )=> (none= KW_NONE ) -> ^( TOK_SHOW_SET_ROLE Identifier[$none.text] ) | identifier -> ^( TOK_SHOW_SET_ROLE identifier ) ) ;
    public final HiveParser.setRole_return setRole() throws RecognitionException {
        HiveParser.setRole_return retval = new HiveParser.setRole_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token all=null;
        Token none=null;
        Token KW_SET535=null;
        Token KW_ROLE536=null;
        HiveParser_IdentifiersParser.identifier_return identifier537 =null;


        ASTNode all_tree=null;
        ASTNode none_tree=null;
        ASTNode KW_SET535_tree=null;
        ASTNode KW_ROLE536_tree=null;
        RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
        RewriteRuleTokenStream stream_KW_NONE=new RewriteRuleTokenStream(adaptor,"token KW_NONE");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        pushMsg("set role", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:5: ( KW_SET KW_ROLE ( ( KW_ALL )=> (all= KW_ALL ) -> ^( TOK_SHOW_SET_ROLE Identifier[$all.text] ) | ( KW_NONE )=> (none= KW_NONE ) -> ^( TOK_SHOW_SET_ROLE Identifier[$none.text] ) | identifier -> ^( TOK_SHOW_SET_ROLE identifier ) ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:7: KW_SET KW_ROLE ( ( KW_ALL )=> (all= KW_ALL ) -> ^( TOK_SHOW_SET_ROLE Identifier[$all.text] ) | ( KW_NONE )=> (none= KW_NONE ) -> ^( TOK_SHOW_SET_ROLE Identifier[$none.text] ) | identifier -> ^( TOK_SHOW_SET_ROLE identifier ) )
            {
            KW_SET535=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_setRole8796); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET535);


            KW_ROLE536=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_setRole8798); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE536);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1616:5: ( ( KW_ALL )=> (all= KW_ALL ) -> ^( TOK_SHOW_SET_ROLE Identifier[$all.text] ) | ( KW_NONE )=> (none= KW_NONE ) -> ^( TOK_SHOW_SET_ROLE Identifier[$none.text] ) | identifier -> ^( TOK_SHOW_SET_ROLE identifier ) )
            int alt163=3;
            switch ( input.LA(1) ) {
            case KW_ALL:
                {
                int LA163_1 = input.LA(2);

                if ( (synpred14_HiveParser()) ) {
                    alt163=1;
                }
                else if ( ((useSQL11ReservedKeywordsForIdentifier())) ) {
                    alt163=3;
                }
                else {
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 163, 1, input);

                    throw nvae;

                }
                }
                break;
            case KW_NONE:
                {
                int LA163_2 = input.LA(2);

                if ( (synpred15_HiveParser()) ) {
                    alt163=2;
                }
                else if ( ((useSQL11ReservedKeywordsForIdentifier())) ) {
                    alt163=3;
                }
                else {
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 163, 2, input);

                    throw nvae;

                }
                }
                break;
            case Identifier:
            case KW_ABORT:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_AUTOCOMMIT:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CACHE:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONSTRAINT:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURRENT_DATE:
            case KW_CURRENT_TIMESTAMP:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DAY:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DOW:
            case KW_DROP:
            case KW_DUMP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FOREIGN:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOUR:
            case KW_IDXPROPERTIES:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ISOLATION:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEY:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LAST:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LEVEL:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATCHED:
            case KW_MATERIALIZED:
            case KW_MERGE:
            case KW_METADATA:
            case KW_MINUTE:
            case KW_MONTH:
            case KW_MSCK:
            case KW_NORELY:
            case KW_NOSCAN:
            case KW_NOVALIDATE:
            case KW_NULL:
            case KW_NULLS:
            case KW_OF:
            case KW_OFFSET:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRIMARY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PURGE:
            case KW_QUARTER:
            case KW_RANGE:
            case KW_READ:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REFERENCES:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RELY:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPL:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SECOND:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SNAPSHOT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STATUS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTION:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALIDATE:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_VIEWS:
            case KW_WEEK:
            case KW_WHILE:
            case KW_WITH:
            case KW_WORK:
            case KW_WRITE:
            case KW_YEAR:
            case KW_BATCH:
            case KW_DAYOFWEEK:
            case KW_HOLD_DDLTIME:
            case KW_IGNORE:
            case KW_NO_DROP:
            case KW_OFFLINE:
            case KW_PROTECTION:
            case KW_READONLY:
                {
                alt163=3;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 163, 0, input);

                throw nvae;

            }

            switch (alt163) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:5: ( KW_ALL )=> (all= KW_ALL )
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:17: (all= KW_ALL )
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:18: all= KW_ALL
                    {
                    all=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setRole8820); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ALL.add(all);


                    }


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1617:30: -> ^( TOK_SHOW_SET_ROLE Identifier[$all.text] )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:33: ^( TOK_SHOW_SET_ROLE Identifier[$all.text] )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SHOW_SET_ROLE, "TOK_SHOW_SET_ROLE")
                        , root_1);

                        adaptor.addChild(root_1, 
                        (ASTNode)adaptor.create(Identifier, (all!=null?all.getText():null))
                        );

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1619:5: ( KW_NONE )=> (none= KW_NONE )
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1619:18: (none= KW_NONE )
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1619:19: none= KW_NONE
                    {
                    none=(Token)match(input,KW_NONE,FOLLOW_KW_NONE_in_setRole8851); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_NONE.add(none);


                    }


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1619:33: -> ^( TOK_SHOW_SET_ROLE Identifier[$none.text] )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1619:36: ^( TOK_SHOW_SET_ROLE Identifier[$none.text] )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SHOW_SET_ROLE, "TOK_SHOW_SET_ROLE")
                        , root_1);

                        adaptor.addChild(root_1, 
                        (ASTNode)adaptor.create(Identifier, (none!=null?none.getText():null))
                        );

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1621:5: identifier
                    {
                    pushFollow(FOLLOW_identifier_in_setRole8873);
                    identifier537=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_identifier.add(identifier537.getTree());

                    // AST REWRITE
                    // elements: identifier
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1621:16: -> ^( TOK_SHOW_SET_ROLE identifier )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1621:19: ^( TOK_SHOW_SET_ROLE identifier )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SHOW_SET_ROLE, "TOK_SHOW_SET_ROLE")
                        , root_1);

                        adaptor.addChild(root_1, stream_identifier.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }


            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "setRole"


    public static class showGrants_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "showGrants"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1625:1: showGrants : KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )? -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? ) ;
    public final HiveParser.showGrants_return showGrants() throws RecognitionException {
        HiveParser.showGrants_return retval = new HiveParser.showGrants_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_SHOW538=null;
        Token KW_GRANT539=null;
        Token KW_ON541=null;
        HiveParser.principalName_return principalName540 =null;

        HiveParser.privilegeIncludeColObject_return privilegeIncludeColObject542 =null;


        ASTNode KW_SHOW538_tree=null;
        ASTNode KW_GRANT539_tree=null;
        ASTNode KW_ON541_tree=null;
        RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
        RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleSubtreeStream stream_privilegeIncludeColObject=new RewriteRuleSubtreeStream(adaptor,"rule privilegeIncludeColObject");
        RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");
        pushMsg("show grants", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:5: ( KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )? -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:7: KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )?
            {
            KW_SHOW538=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showGrants8914); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW538);


            KW_GRANT539=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_showGrants8916); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT539);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:24: ( principalName )?
            int alt164=2;
            switch ( input.LA(1) ) {
                case KW_GROUP:
                case KW_ROLE:
                case KW_USER:
                    {
                    alt164=1;
                    }
                    break;
            }

            switch (alt164) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:24: principalName
                    {
                    pushFollow(FOLLOW_principalName_in_showGrants8918);
                    principalName540=principalName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_principalName.add(principalName540.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:39: ( KW_ON privilegeIncludeColObject )?
            int alt165=2;
            switch ( input.LA(1) ) {
                case KW_ON:
                    {
                    alt165=1;
                    }
                    break;
            }

            switch (alt165) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:40: KW_ON privilegeIncludeColObject
                    {
                    KW_ON541=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_showGrants8922); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON541);


                    pushFollow(FOLLOW_privilegeIncludeColObject_in_showGrants8924);
                    privilegeIncludeColObject542=privilegeIncludeColObject();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_privilegeIncludeColObject.add(privilegeIncludeColObject542.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: principalName, privilegeIncludeColObject
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1629:5: -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1629:8: ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SHOW_GRANT, "TOK_SHOW_GRANT")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1629:25: ( principalName )?
                if ( stream_principalName.hasNext() ) {
                    adaptor.addChild(root_1, stream_principalName.nextTree());

                }
                stream_principalName.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1629:40: ( privilegeIncludeColObject )?
                if ( stream_privilegeIncludeColObject.hasNext() ) {
                    adaptor.addChild(root_1, stream_privilegeIncludeColObject.nextTree());

                }
                stream_privilegeIncludeColObject.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "showGrants"


    public static class showRolePrincipals_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "showRolePrincipals"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1632:1: showRolePrincipals : KW_SHOW KW_PRINCIPALS roleName= identifier -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName) ;
    public final HiveParser.showRolePrincipals_return showRolePrincipals() throws RecognitionException {
        HiveParser.showRolePrincipals_return retval = new HiveParser.showRolePrincipals_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_SHOW543=null;
        Token KW_PRINCIPALS544=null;
        HiveParser_IdentifiersParser.identifier_return roleName =null;


        ASTNode KW_SHOW543_tree=null;
        ASTNode KW_PRINCIPALS544_tree=null;
        RewriteRuleTokenStream stream_KW_PRINCIPALS=new RewriteRuleTokenStream(adaptor,"token KW_PRINCIPALS");
        RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        pushMsg("show role principals", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1635:5: ( KW_SHOW KW_PRINCIPALS roleName= identifier -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1635:7: KW_SHOW KW_PRINCIPALS roleName= identifier
            {
            KW_SHOW543=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showRolePrincipals8969); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW543);


            KW_PRINCIPALS544=(Token)match(input,KW_PRINCIPALS,FOLLOW_KW_PRINCIPALS_in_showRolePrincipals8971); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_PRINCIPALS.add(KW_PRINCIPALS544);


            pushFollow(FOLLOW_identifier_in_showRolePrincipals8975);
            roleName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(roleName.getTree());

            // AST REWRITE
            // elements: roleName
            // token labels: 
            // rule labels: roleName, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_roleName=new RewriteRuleSubtreeStream(adaptor,"rule roleName",roleName!=null?roleName.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1636:5: -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1636:8: ^( TOK_SHOW_ROLE_PRINCIPALS $roleName)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SHOW_ROLE_PRINCIPALS, "TOK_SHOW_ROLE_PRINCIPALS")
                , root_1);

                adaptor.addChild(root_1, stream_roleName.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "showRolePrincipals"


    public static class privilegeIncludeColObject_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "privilegeIncludeColObject"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:1: privilegeIncludeColObject : ( ( KW_ALL )=> KW_ALL -> ^( TOK_RESOURCE_ALL ) | privObjectCols -> ^( TOK_PRIV_OBJECT_COL privObjectCols ) );
    public final HiveParser.privilegeIncludeColObject_return privilegeIncludeColObject() throws RecognitionException {
        HiveParser.privilegeIncludeColObject_return retval = new HiveParser.privilegeIncludeColObject_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_ALL545=null;
        HiveParser.privObjectCols_return privObjectCols546 =null;


        ASTNode KW_ALL545_tree=null;
        RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");
        RewriteRuleSubtreeStream stream_privObjectCols=new RewriteRuleSubtreeStream(adaptor,"rule privObjectCols");
        pushMsg("privilege object including columns", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1643:5: ( ( KW_ALL )=> KW_ALL -> ^( TOK_RESOURCE_ALL ) | privObjectCols -> ^( TOK_PRIV_OBJECT_COL privObjectCols ) )
            int alt166=2;
            switch ( input.LA(1) ) {
            case KW_ALL:
                {
                int LA166_1 = input.LA(2);

                if ( (synpred16_HiveParser()) ) {
                    alt166=1;
                }
                else if ( ((useSQL11ReservedKeywordsForIdentifier())) ) {
                    alt166=2;
                }
                else {
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 166, 1, input);

                    throw nvae;

                }
                }
                break;
            case Identifier:
            case KW_ABORT:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_AUTOCOMMIT:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CACHE:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONSTRAINT:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURRENT_DATE:
            case KW_CURRENT_TIMESTAMP:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASE:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DAY:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DOW:
            case KW_DROP:
            case KW_DUMP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FOREIGN:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOUR:
            case KW_IDXPROPERTIES:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ISOLATION:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEY:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LAST:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LEVEL:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATCHED:
            case KW_MATERIALIZED:
            case KW_MERGE:
            case KW_METADATA:
            case KW_MINUTE:
            case KW_MONTH:
            case KW_MSCK:
            case KW_NONE:
            case KW_NORELY:
            case KW_NOSCAN:
            case KW_NOVALIDATE:
            case KW_NULL:
            case KW_NULLS:
            case KW_OF:
            case KW_OFFSET:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRIMARY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PURGE:
            case KW_QUARTER:
            case KW_RANGE:
            case KW_READ:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REFERENCES:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RELY:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPL:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SECOND:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SNAPSHOT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STATUS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTION:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALIDATE:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_VIEWS:
            case KW_WEEK:
            case KW_WHILE:
            case KW_WITH:
            case KW_WORK:
            case KW_WRITE:
            case KW_YEAR:
            case KW_BATCH:
            case KW_DAYOFWEEK:
            case KW_HOLD_DDLTIME:
            case KW_IGNORE:
            case KW_NO_DROP:
            case KW_OFFLINE:
            case KW_PROTECTION:
            case KW_READONLY:
                {
                alt166=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 166, 0, input);

                throw nvae;

            }

            switch (alt166) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1643:7: ( KW_ALL )=> KW_ALL
                    {
                    KW_ALL545=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_privilegeIncludeColObject9022); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL545);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1643:26: -> ^( TOK_RESOURCE_ALL )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1643:29: ^( TOK_RESOURCE_ALL )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_RESOURCE_ALL, "TOK_RESOURCE_ALL")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1644:7: privObjectCols
                    {
                    pushFollow(FOLLOW_privObjectCols_in_privilegeIncludeColObject9036);
                    privObjectCols546=privObjectCols();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_privObjectCols.add(privObjectCols546.getTree());

                    // AST REWRITE
                    // elements: privObjectCols
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1644:22: -> ^( TOK_PRIV_OBJECT_COL privObjectCols )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1644:25: ^( TOK_PRIV_OBJECT_COL privObjectCols )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_PRIV_OBJECT_COL, "TOK_PRIV_OBJECT_COL")
                        , root_1);

                        adaptor.addChild(root_1, stream_privObjectCols.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "privilegeIncludeColObject"


    public static class privilegeObject_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "privilegeObject"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1647:1: privilegeObject : KW_ON privObject -> ^( TOK_PRIV_OBJECT privObject ) ;
    public final HiveParser.privilegeObject_return privilegeObject() throws RecognitionException {
        HiveParser.privilegeObject_return retval = new HiveParser.privilegeObject_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_ON547=null;
        HiveParser.privObject_return privObject548 =null;


        ASTNode KW_ON547_tree=null;
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleSubtreeStream stream_privObject=new RewriteRuleSubtreeStream(adaptor,"rule privObject");
        pushMsg("privilege object", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1650:5: ( KW_ON privObject -> ^( TOK_PRIV_OBJECT privObject ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1650:7: KW_ON privObject
            {
            KW_ON547=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_privilegeObject9071); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON547);


            pushFollow(FOLLOW_privObject_in_privilegeObject9073);
            privObject548=privObject();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_privObject.add(privObject548.getTree());

            // AST REWRITE
            // elements: privObject
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1650:24: -> ^( TOK_PRIV_OBJECT privObject )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1650:27: ^( TOK_PRIV_OBJECT privObject )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_PRIV_OBJECT, "TOK_PRIV_OBJECT")
                , root_1);

                adaptor.addChild(root_1, stream_privObject.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "privilegeObject"


    public static class privObject_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "privObject"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1654:1: privObject : ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) );
    public final HiveParser.privObject_return privObject() throws RecognitionException {
        HiveParser.privObject_return retval = new HiveParser.privObject_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token path=null;
        Token KW_DATABASE549=null;
        Token KW_SCHEMA550=null;
        Token KW_TABLE552=null;
        Token KW_URI555=null;
        Token KW_SERVER556=null;
        HiveParser_IdentifiersParser.identifier_return identifier551 =null;

        HiveParser_FromClauseParser.tableName_return tableName553 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec554 =null;

        HiveParser_IdentifiersParser.identifier_return identifier557 =null;


        ASTNode path_tree=null;
        ASTNode KW_DATABASE549_tree=null;
        ASTNode KW_SCHEMA550_tree=null;
        ASTNode KW_TABLE552_tree=null;
        ASTNode KW_URI555_tree=null;
        ASTNode KW_SERVER556_tree=null;
        RewriteRuleTokenStream stream_KW_SERVER=new RewriteRuleTokenStream(adaptor,"token KW_SERVER");
        RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
        RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_URI=new RewriteRuleTokenStream(adaptor,"token KW_URI");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1655:5: ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) )
            int alt170=4;
            switch ( input.LA(1) ) {
            case KW_DATABASE:
                {
                alt170=1;
                }
                break;
            case KW_SCHEMA:
                {
                switch ( input.LA(2) ) {
                case Identifier:
                case KW_ABORT:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_AUTOCOMMIT:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CACHE:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONSTRAINT:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURRENT_DATE:
                case KW_CURRENT_TIMESTAMP:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DAY:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DOW:
                case KW_DROP:
                case KW_DUMP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FOREIGN:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOUR:
                case KW_IDXPROPERTIES:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ISOLATION:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEY:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LAST:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LEVEL:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATCHED:
                case KW_MATERIALIZED:
                case KW_MERGE:
                case KW_METADATA:
                case KW_MINUTE:
                case KW_MONTH:
                case KW_MSCK:
                case KW_NONE:
                case KW_NORELY:
                case KW_NOSCAN:
                case KW_NOVALIDATE:
                case KW_NULL:
                case KW_NULLS:
                case KW_OF:
                case KW_OFFSET:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRIMARY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PURGE:
                case KW_QUARTER:
                case KW_RANGE:
                case KW_READ:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REFERENCES:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RELY:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPL:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SECOND:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SNAPSHOT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STATUS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TOUCH:
                case KW_TRANSACTION:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALIDATE:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_VIEWS:
                case KW_WEEK:
                case KW_WHILE:
                case KW_WITH:
                case KW_WORK:
                case KW_WRITE:
                case KW_YEAR:
                case KW_BATCH:
                case KW_DAYOFWEEK:
                case KW_HOLD_DDLTIME:
                case KW_IGNORE:
                case KW_NO_DROP:
                case KW_OFFLINE:
                case KW_PROTECTION:
                case KW_READONLY:
                    {
                    alt170=1;
                    }
                    break;
                case KW_PARTITION:
                    {
                    switch ( input.LA(3) ) {
                    case LPAREN:
                        {
                        alt170=2;
                        }
                        break;
                    case KW_FROM:
                    case KW_TO:
                        {
                        alt170=1;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 170, 11, input);

                        throw nvae;

                    }

                    }
                    break;
                case DOT:
                case KW_FROM:
                    {
                    alt170=2;
                    }
                    break;
                case KW_TO:
                    {
                    switch ( input.LA(3) ) {
                    case KW_FROM:
                    case KW_TO:
                        {
                        alt170=1;
                        }
                        break;
                    case KW_GROUP:
                    case KW_ROLE:
                    case KW_USER:
                        {
                        alt170=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 170, 13, input);

                        throw nvae;

                    }

                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 170, 2, input);

                    throw nvae;

                }

                }
                break;
            case Identifier:
            case KW_ABORT:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_AUTOCOMMIT:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CACHE:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONSTRAINT:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURRENT_DATE:
            case KW_CURRENT_TIMESTAMP:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DAY:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DOW:
            case KW_DROP:
            case KW_DUMP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FOREIGN:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOUR:
            case KW_IDXPROPERTIES:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ISOLATION:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEY:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LAST:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LEVEL:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATCHED:
            case KW_MATERIALIZED:
            case KW_MERGE:
            case KW_METADATA:
            case KW_MINUTE:
            case KW_MONTH:
            case KW_MSCK:
            case KW_NONE:
            case KW_NORELY:
            case KW_NOSCAN:
            case KW_NOVALIDATE:
            case KW_NULL:
            case KW_NULLS:
            case KW_OF:
            case KW_OFFSET:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRIMARY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PURGE:
            case KW_QUARTER:
            case KW_RANGE:
            case KW_READ:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REFERENCES:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RELY:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPL:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMAS:
            case KW_SECOND:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SNAPSHOT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STATUS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTION:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALIDATE:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_VIEWS:
            case KW_WEEK:
            case KW_WHILE:
            case KW_WITH:
            case KW_WORK:
            case KW_WRITE:
            case KW_YEAR:
            case KW_BATCH:
            case KW_DAYOFWEEK:
            case KW_HOLD_DDLTIME:
            case KW_IGNORE:
            case KW_NO_DROP:
            case KW_OFFLINE:
            case KW_PROTECTION:
            case KW_READONLY:
                {
                alt170=2;
                }
                break;
            case KW_URI:
                {
                switch ( input.LA(2) ) {
                case DOT:
                case KW_FROM:
                case KW_PARTITION:
                case KW_TO:
                    {
                    alt170=2;
                    }
                    break;
                case StringLiteral:
                    {
                    alt170=3;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 170, 5, input);

                    throw nvae;

                }

                }
                break;
            case KW_SERVER:
                {
                switch ( input.LA(2) ) {
                case DOT:
                case KW_FROM:
                    {
                    alt170=2;
                    }
                    break;
                case KW_PARTITION:
                    {
                    switch ( input.LA(3) ) {
                    case LPAREN:
                        {
                        alt170=2;
                        }
                        break;
                    case KW_FROM:
                    case KW_TO:
                        {
                        alt170=4;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 170, 22, input);

                        throw nvae;

                    }

                    }
                    break;
                case KW_TO:
                    {
                    switch ( input.LA(3) ) {
                    case KW_GROUP:
                    case KW_ROLE:
                    case KW_USER:
                        {
                        alt170=2;
                        }
                        break;
                    case KW_FROM:
                    case KW_TO:
                        {
                        alt170=4;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 170, 23, input);

                        throw nvae;

                    }

                    }
                    break;
                case Identifier:
                case KW_ABORT:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_AUTOCOMMIT:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CACHE:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONSTRAINT:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURRENT_DATE:
                case KW_CURRENT_TIMESTAMP:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DAY:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DOW:
                case KW_DROP:
                case KW_DUMP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FOREIGN:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOUR:
                case KW_IDXPROPERTIES:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ISOLATION:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEY:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LAST:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LEVEL:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATCHED:
                case KW_MATERIALIZED:
                case KW_MERGE:
                case KW_METADATA:
                case KW_MINUTE:
                case KW_MONTH:
                case KW_MSCK:
                case KW_NONE:
                case KW_NORELY:
                case KW_NOSCAN:
                case KW_NOVALIDATE:
                case KW_NULL:
                case KW_NULLS:
                case KW_OF:
                case KW_OFFSET:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRIMARY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PURGE:
                case KW_QUARTER:
                case KW_RANGE:
                case KW_READ:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REFERENCES:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RELY:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPL:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SECOND:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SNAPSHOT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STATUS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TOUCH:
                case KW_TRANSACTION:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALIDATE:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_VIEWS:
                case KW_WEEK:
                case KW_WHILE:
                case KW_WITH:
                case KW_WORK:
                case KW_WRITE:
                case KW_YEAR:
                case KW_BATCH:
                case KW_DAYOFWEEK:
                case KW_HOLD_DDLTIME:
                case KW_IGNORE:
                case KW_NO_DROP:
                case KW_OFFLINE:
                case KW_PROTECTION:
                case KW_READONLY:
                    {
                    alt170=4;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 170, 7, input);

                    throw nvae;

                }

                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 170, 0, input);

                throw nvae;

            }

            switch (alt170) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1655:7: ( KW_DATABASE | KW_SCHEMA ) identifier
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1655:7: ( KW_DATABASE | KW_SCHEMA )
                    int alt167=2;
                    switch ( input.LA(1) ) {
                    case KW_DATABASE:
                        {
                        alt167=1;
                        }
                        break;
                    case KW_SCHEMA:
                        {
                        alt167=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 167, 0, input);

                        throw nvae;

                    }

                    switch (alt167) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1655:8: KW_DATABASE
                            {
                            KW_DATABASE549=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_privObject9100); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE549);


                            }
                            break;
                        case 2 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1655:20: KW_SCHEMA
                            {
                            KW_SCHEMA550=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_privObject9102); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA550);


                            }
                            break;

                    }


                    pushFollow(FOLLOW_identifier_in_privObject9105);
                    identifier551=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_identifier.add(identifier551.getTree());

                    // AST REWRITE
                    // elements: identifier
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1655:42: -> ^( TOK_DB_TYPE identifier )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1655:45: ^( TOK_DB_TYPE identifier )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_DB_TYPE, "TOK_DB_TYPE")
                        , root_1);

                        adaptor.addChild(root_1, stream_identifier.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1656:7: ( KW_TABLE )? tableName ( partitionSpec )?
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1656:7: ( KW_TABLE )?
                    int alt168=2;
                    switch ( input.LA(1) ) {
                        case KW_TABLE:
                            {
                            switch ( input.LA(2) ) {
                                case Identifier:
                                case KW_ABORT:
                                case KW_ADD:
                                case KW_ADMIN:
                                case KW_AFTER:
                                case KW_ALL:
                                case KW_ALTER:
                                case KW_ANALYZE:
                                case KW_ARCHIVE:
                                case KW_ARRAY:
                                case KW_AS:
                                case KW_ASC:
                                case KW_AUTHORIZATION:
                                case KW_AUTOCOMMIT:
                                case KW_BEFORE:
                                case KW_BETWEEN:
                                case KW_BIGINT:
                                case KW_BINARY:
                                case KW_BOOLEAN:
                                case KW_BOTH:
                                case KW_BUCKET:
                                case KW_BUCKETS:
                                case KW_BY:
                                case KW_CACHE:
                                case KW_CASCADE:
                                case KW_CHANGE:
                                case KW_CLUSTER:
                                case KW_CLUSTERED:
                                case KW_CLUSTERSTATUS:
                                case KW_COLLECTION:
                                case KW_COLUMNS:
                                case KW_COMMENT:
                                case KW_COMPACT:
                                case KW_COMPACTIONS:
                                case KW_COMPUTE:
                                case KW_CONCATENATE:
                                case KW_CONSTRAINT:
                                case KW_CONTINUE:
                                case KW_CREATE:
                                case KW_CUBE:
                                case KW_CURRENT_DATE:
                                case KW_CURRENT_TIMESTAMP:
                                case KW_CURSOR:
                                case KW_DATA:
                                case KW_DATABASES:
                                case KW_DATE:
                                case KW_DATETIME:
                                case KW_DAY:
                                case KW_DBPROPERTIES:
                                case KW_DECIMAL:
                                case KW_DEFERRED:
                                case KW_DEFINED:
                                case KW_DELETE:
                                case KW_DELIMITED:
                                case KW_DEPENDENCY:
                                case KW_DESC:
                                case KW_DESCRIBE:
                                case KW_DIRECTORIES:
                                case KW_DIRECTORY:
                                case KW_DISABLE:
                                case KW_DISTRIBUTE:
                                case KW_DOUBLE:
                                case KW_DOW:
                                case KW_DROP:
                                case KW_DUMP:
                                case KW_ELEM_TYPE:
                                case KW_ENABLE:
                                case KW_ESCAPED:
                                case KW_EXCLUSIVE:
                                case KW_EXISTS:
                                case KW_EXPLAIN:
                                case KW_EXPORT:
                                case KW_EXTERNAL:
                                case KW_FALSE:
                                case KW_FETCH:
                                case KW_FIELDS:
                                case KW_FILE:
                                case KW_FILEFORMAT:
                                case KW_FIRST:
                                case KW_FLOAT:
                                case KW_FOR:
                                case KW_FOREIGN:
                                case KW_FORMAT:
                                case KW_FORMATTED:
                                case KW_FULL:
                                case KW_FUNCTIONS:
                                case KW_GRANT:
                                case KW_GROUP:
                                case KW_GROUPING:
                                case KW_HOUR:
                                case KW_IDXPROPERTIES:
                                case KW_IMPORT:
                                case KW_IN:
                                case KW_INDEX:
                                case KW_INDEXES:
                                case KW_INNER:
                                case KW_INPATH:
                                case KW_INPUTDRIVER:
                                case KW_INPUTFORMAT:
                                case KW_INSERT:
                                case KW_INT:
                                case KW_INTERSECT:
                                case KW_INTO:
                                case KW_IS:
                                case KW_ISOLATION:
                                case KW_ITEMS:
                                case KW_JAR:
                                case KW_KEY:
                                case KW_KEYS:
                                case KW_KEY_TYPE:
                                case KW_LAST:
                                case KW_LATERAL:
                                case KW_LEFT:
                                case KW_LEVEL:
                                case KW_LIKE:
                                case KW_LIMIT:
                                case KW_LINES:
                                case KW_LOAD:
                                case KW_LOCAL:
                                case KW_LOCATION:
                                case KW_LOCK:
                                case KW_LOCKS:
                                case KW_LOGICAL:
                                case KW_LONG:
                                case KW_MAPJOIN:
                                case KW_MATCHED:
                                case KW_MATERIALIZED:
                                case KW_MERGE:
                                case KW_METADATA:
                                case KW_MINUTE:
                                case KW_MONTH:
                                case KW_MSCK:
                                case KW_NONE:
                                case KW_NORELY:
                                case KW_NOSCAN:
                                case KW_NOVALIDATE:
                                case KW_NULL:
                                case KW_NULLS:
                                case KW_OF:
                                case KW_OFFSET:
                                case KW_OPTION:
                                case KW_ORDER:
                                case KW_OUT:
                                case KW_OUTER:
                                case KW_OUTPUTDRIVER:
                                case KW_OUTPUTFORMAT:
                                case KW_OVERWRITE:
                                case KW_OWNER:
                                case KW_PARTITIONED:
                                case KW_PARTITIONS:
                                case KW_PERCENT:
                                case KW_PLUS:
                                case KW_PRETTY:
                                case KW_PRIMARY:
                                case KW_PRINCIPALS:
                                case KW_PROCEDURE:
                                case KW_PURGE:
                                case KW_QUARTER:
                                case KW_RANGE:
                                case KW_READ:
                                case KW_READS:
                                case KW_REBUILD:
                                case KW_RECORDREADER:
                                case KW_RECORDWRITER:
                                case KW_REFERENCES:
                                case KW_REGEXP:
                                case KW_RELOAD:
                                case KW_RELY:
                                case KW_RENAME:
                                case KW_REPAIR:
                                case KW_REPL:
                                case KW_REPLACE:
                                case KW_REPLICATION:
                                case KW_RESTRICT:
                                case KW_REVOKE:
                                case KW_REWRITE:
                                case KW_RIGHT:
                                case KW_RLIKE:
                                case KW_ROLE:
                                case KW_ROLES:
                                case KW_ROLLUP:
                                case KW_ROW:
                                case KW_ROWS:
                                case KW_SCHEMA:
                                case KW_SCHEMAS:
                                case KW_SECOND:
                                case KW_SEMI:
                                case KW_SERDE:
                                case KW_SERDEPROPERTIES:
                                case KW_SERVER:
                                case KW_SET:
                                case KW_SETS:
                                case KW_SHARED:
                                case KW_SHOW:
                                case KW_SHOW_DATABASE:
                                case KW_SKEWED:
                                case KW_SMALLINT:
                                case KW_SNAPSHOT:
                                case KW_SORT:
                                case KW_SORTED:
                                case KW_SSL:
                                case KW_STATISTICS:
                                case KW_STATUS:
                                case KW_STORED:
                                case KW_STREAMTABLE:
                                case KW_STRING:
                                case KW_STRUCT:
                                case KW_TABLE:
                                case KW_TABLES:
                                case KW_TBLPROPERTIES:
                                case KW_TEMPORARY:
                                case KW_TERMINATED:
                                case KW_TIMESTAMP:
                                case KW_TINYINT:
                                case KW_TOUCH:
                                case KW_TRANSACTION:
                                case KW_TRANSACTIONS:
                                case KW_TRIGGER:
                                case KW_TRUE:
                                case KW_TRUNCATE:
                                case KW_UNARCHIVE:
                                case KW_UNDO:
                                case KW_UNION:
                                case KW_UNIONTYPE:
                                case KW_UNLOCK:
                                case KW_UNSET:
                                case KW_UNSIGNED:
                                case KW_UPDATE:
                                case KW_URI:
                                case KW_USE:
                                case KW_USER:
                                case KW_USING:
                                case KW_UTC:
                                case KW_UTCTIMESTAMP:
                                case KW_VALIDATE:
                                case KW_VALUES:
                                case KW_VALUE_TYPE:
                                case KW_VIEW:
                                case KW_VIEWS:
                                case KW_WEEK:
                                case KW_WHILE:
                                case KW_WITH:
                                case KW_WORK:
                                case KW_WRITE:
                                case KW_YEAR:
                                case KW_BATCH:
                                case KW_DAYOFWEEK:
                                case KW_HOLD_DDLTIME:
                                case KW_IGNORE:
                                case KW_NO_DROP:
                                case KW_OFFLINE:
                                case KW_PROTECTION:
                                case KW_READONLY:
                                    {
                                    alt168=1;
                                    }
                                    break;
                                case KW_PARTITION:
                                    {
                                    switch ( input.LA(3) ) {
                                        case DOT:
                                        case KW_FROM:
                                        case KW_PARTITION:
                                        case KW_TO:
                                            {
                                            alt168=1;
                                            }
                                            break;
                                    }

                                    }
                                    break;
                                case KW_TO:
                                    {
                                    switch ( input.LA(3) ) {
                                        case DOT:
                                        case KW_FROM:
                                        case KW_PARTITION:
                                        case KW_TO:
                                            {
                                            alt168=1;
                                            }
                                            break;
                                    }

                                    }
                                    break;
                            }

                            }
                            break;
                    }

                    switch (alt168) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1656:7: KW_TABLE
                            {
                            KW_TABLE552=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_privObject9121); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE552);


                            }
                            break;

                    }


                    pushFollow(FOLLOW_tableName_in_privObject9124);
                    tableName553=tableName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableName.add(tableName553.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1656:27: ( partitionSpec )?
                    int alt169=2;
                    switch ( input.LA(1) ) {
                        case KW_PARTITION:
                            {
                            alt169=1;
                            }
                            break;
                    }

                    switch (alt169) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1656:27: partitionSpec
                            {
                            pushFollow(FOLLOW_partitionSpec_in_privObject9126);
                            partitionSpec554=partitionSpec();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec554.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: tableName, partitionSpec
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1656:42: -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1656:45: ^( TOK_TABLE_TYPE tableName ( partitionSpec )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_TABLE_TYPE, "TOK_TABLE_TYPE")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableName.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1656:72: ( partitionSpec )?
                        if ( stream_partitionSpec.hasNext() ) {
                            adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                        }
                        stream_partitionSpec.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:7: KW_URI (path= StringLiteral )
                    {
                    KW_URI555=(Token)match(input,KW_URI,FOLLOW_KW_URI_in_privObject9146); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_URI.add(KW_URI555);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:14: (path= StringLiteral )
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:15: path= StringLiteral
                    {
                    path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_privObject9151); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(path);


                    }


                    // AST REWRITE
                    // elements: path
                    // token labels: path
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1657:35: -> ^( TOK_URI_TYPE $path)
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:39: ^( TOK_URI_TYPE $path)
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_URI_TYPE, "TOK_URI_TYPE")
                        , root_1);

                        adaptor.addChild(root_1, stream_path.nextNode());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 4 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1658:7: KW_SERVER identifier
                    {
                    KW_SERVER556=(Token)match(input,KW_SERVER,FOLLOW_KW_SERVER_in_privObject9170); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SERVER.add(KW_SERVER556);


                    pushFollow(FOLLOW_identifier_in_privObject9172);
                    identifier557=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_identifier.add(identifier557.getTree());

                    // AST REWRITE
                    // elements: identifier
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1658:28: -> ^( TOK_SERVER_TYPE identifier )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1658:31: ^( TOK_SERVER_TYPE identifier )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SERVER_TYPE, "TOK_SERVER_TYPE")
                        , root_1);

                        adaptor.addChild(root_1, stream_identifier.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "privObject"


    public static class privObjectCols_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "privObjectCols"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1661:1: privObjectCols : ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) );
    public final HiveParser.privObjectCols_return privObjectCols() throws RecognitionException {
        HiveParser.privObjectCols_return retval = new HiveParser.privObjectCols_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token path=null;
        Token KW_DATABASE558=null;
        Token KW_SCHEMA559=null;
        Token KW_TABLE561=null;
        Token LPAREN563=null;
        Token RPAREN564=null;
        Token KW_URI566=null;
        Token KW_SERVER567=null;
        HiveParser.columnNameList_return cols =null;

        HiveParser_IdentifiersParser.identifier_return identifier560 =null;

        HiveParser_FromClauseParser.tableName_return tableName562 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec565 =null;

        HiveParser_IdentifiersParser.identifier_return identifier568 =null;


        ASTNode path_tree=null;
        ASTNode KW_DATABASE558_tree=null;
        ASTNode KW_SCHEMA559_tree=null;
        ASTNode KW_TABLE561_tree=null;
        ASTNode LPAREN563_tree=null;
        ASTNode RPAREN564_tree=null;
        ASTNode KW_URI566_tree=null;
        ASTNode KW_SERVER567_tree=null;
        RewriteRuleTokenStream stream_KW_SERVER=new RewriteRuleTokenStream(adaptor,"token KW_SERVER");
        RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
        RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_KW_URI=new RewriteRuleTokenStream(adaptor,"token KW_URI");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1662:5: ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) )
            int alt175=4;
            switch ( input.LA(1) ) {
            case KW_DATABASE:
                {
                alt175=1;
                }
                break;
            case KW_SCHEMA:
                {
                switch ( input.LA(2) ) {
                case Identifier:
                case KW_ABORT:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_AUTOCOMMIT:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CACHE:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONSTRAINT:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURRENT_DATE:
                case KW_CURRENT_TIMESTAMP:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DAY:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DOW:
                case KW_DROP:
                case KW_DUMP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FOREIGN:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOUR:
                case KW_IDXPROPERTIES:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ISOLATION:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEY:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LAST:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LEVEL:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATCHED:
                case KW_MATERIALIZED:
                case KW_MERGE:
                case KW_METADATA:
                case KW_MINUTE:
                case KW_MONTH:
                case KW_MSCK:
                case KW_NONE:
                case KW_NORELY:
                case KW_NOSCAN:
                case KW_NOVALIDATE:
                case KW_NULL:
                case KW_NULLS:
                case KW_OF:
                case KW_OFFSET:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRIMARY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PURGE:
                case KW_QUARTER:
                case KW_RANGE:
                case KW_READ:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REFERENCES:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RELY:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPL:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SECOND:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SNAPSHOT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STATUS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTION:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALIDATE:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_VIEWS:
                case KW_WEEK:
                case KW_WHILE:
                case KW_WITH:
                case KW_WORK:
                case KW_WRITE:
                case KW_YEAR:
                case KW_BATCH:
                case KW_DAYOFWEEK:
                case KW_HOLD_DDLTIME:
                case KW_IGNORE:
                case KW_NO_DROP:
                case KW_OFFLINE:
                case KW_PROTECTION:
                case KW_READONLY:
                    {
                    alt175=1;
                    }
                    break;
                case KW_PARTITION:
                    {
                    switch ( input.LA(3) ) {
                    case LPAREN:
                        {
                        alt175=2;
                        }
                        break;
                    case EOF:
                        {
                        alt175=1;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 175, 11, input);

                        throw nvae;

                    }

                    }
                    break;
                case EOF:
                case DOT:
                case LPAREN:
                    {
                    alt175=2;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 175, 2, input);

                    throw nvae;

                }

                }
                break;
            case Identifier:
            case KW_ABORT:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_AUTOCOMMIT:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CACHE:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONSTRAINT:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURRENT_DATE:
            case KW_CURRENT_TIMESTAMP:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DAY:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DOW:
            case KW_DROP:
            case KW_DUMP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FOREIGN:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOUR:
            case KW_IDXPROPERTIES:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ISOLATION:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEY:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LAST:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LEVEL:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATCHED:
            case KW_MATERIALIZED:
            case KW_MERGE:
            case KW_METADATA:
            case KW_MINUTE:
            case KW_MONTH:
            case KW_MSCK:
            case KW_NONE:
            case KW_NORELY:
            case KW_NOSCAN:
            case KW_NOVALIDATE:
            case KW_NULL:
            case KW_NULLS:
            case KW_OF:
            case KW_OFFSET:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRIMARY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PURGE:
            case KW_QUARTER:
            case KW_RANGE:
            case KW_READ:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REFERENCES:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RELY:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPL:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMAS:
            case KW_SECOND:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SNAPSHOT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STATUS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTION:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALIDATE:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_VIEWS:
            case KW_WEEK:
            case KW_WHILE:
            case KW_WITH:
            case KW_WORK:
            case KW_WRITE:
            case KW_YEAR:
            case KW_BATCH:
            case KW_DAYOFWEEK:
            case KW_HOLD_DDLTIME:
            case KW_IGNORE:
            case KW_NO_DROP:
            case KW_OFFLINE:
            case KW_PROTECTION:
            case KW_READONLY:
                {
                alt175=2;
                }
                break;
            case KW_URI:
                {
                switch ( input.LA(2) ) {
                case EOF:
                case DOT:
                case KW_PARTITION:
                case LPAREN:
                    {
                    alt175=2;
                    }
                    break;
                case StringLiteral:
                    {
                    alt175=3;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 175, 5, input);

                    throw nvae;

                }

                }
                break;
            case KW_SERVER:
                {
                switch ( input.LA(2) ) {
                case EOF:
                case DOT:
                case LPAREN:
                    {
                    alt175=2;
                    }
                    break;
                case KW_PARTITION:
                    {
                    switch ( input.LA(3) ) {
                    case LPAREN:
                        {
                        alt175=2;
                        }
                        break;
                    case EOF:
                        {
                        alt175=4;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 175, 23, input);

                        throw nvae;

                    }

                    }
                    break;
                case Identifier:
                case KW_ABORT:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_AUTOCOMMIT:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CACHE:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONSTRAINT:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURRENT_DATE:
                case KW_CURRENT_TIMESTAMP:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DAY:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DOW:
                case KW_DROP:
                case KW_DUMP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FOREIGN:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOUR:
                case KW_IDXPROPERTIES:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ISOLATION:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEY:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LAST:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LEVEL:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATCHED:
                case KW_MATERIALIZED:
                case KW_MERGE:
                case KW_METADATA:
                case KW_MINUTE:
                case KW_MONTH:
                case KW_MSCK:
                case KW_NONE:
                case KW_NORELY:
                case KW_NOSCAN:
                case KW_NOVALIDATE:
                case KW_NULL:
                case KW_NULLS:
                case KW_OF:
                case KW_OFFSET:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRIMARY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PURGE:
                case KW_QUARTER:
                case KW_RANGE:
                case KW_READ:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REFERENCES:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RELY:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPL:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SECOND:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SNAPSHOT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STATUS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTION:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALIDATE:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_VIEWS:
                case KW_WEEK:
                case KW_WHILE:
                case KW_WITH:
                case KW_WORK:
                case KW_WRITE:
                case KW_YEAR:
                case KW_BATCH:
                case KW_DAYOFWEEK:
                case KW_HOLD_DDLTIME:
                case KW_IGNORE:
                case KW_NO_DROP:
                case KW_OFFLINE:
                case KW_PROTECTION:
                case KW_READONLY:
                    {
                    alt175=4;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 175, 7, input);

                    throw nvae;

                }

                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 175, 0, input);

                throw nvae;

            }

            switch (alt175) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1662:7: ( KW_DATABASE | KW_SCHEMA ) identifier
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1662:7: ( KW_DATABASE | KW_SCHEMA )
                    int alt171=2;
                    switch ( input.LA(1) ) {
                    case KW_DATABASE:
                        {
                        alt171=1;
                        }
                        break;
                    case KW_SCHEMA:
                        {
                        alt171=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 171, 0, input);

                        throw nvae;

                    }

                    switch (alt171) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1662:8: KW_DATABASE
                            {
                            KW_DATABASE558=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_privObjectCols9198); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE558);


                            }
                            break;
                        case 2 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1662:20: KW_SCHEMA
                            {
                            KW_SCHEMA559=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_privObjectCols9200); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA559);


                            }
                            break;

                    }


                    pushFollow(FOLLOW_identifier_in_privObjectCols9203);
                    identifier560=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_identifier.add(identifier560.getTree());

                    // AST REWRITE
                    // elements: identifier
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1662:42: -> ^( TOK_DB_TYPE identifier )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1662:45: ^( TOK_DB_TYPE identifier )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_DB_TYPE, "TOK_DB_TYPE")
                        , root_1);

                        adaptor.addChild(root_1, stream_identifier.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:7: ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )?
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:7: ( KW_TABLE )?
                    int alt172=2;
                    switch ( input.LA(1) ) {
                        case KW_TABLE:
                            {
                            switch ( input.LA(2) ) {
                                case Identifier:
                                case KW_ABORT:
                                case KW_ADD:
                                case KW_ADMIN:
                                case KW_AFTER:
                                case KW_ALL:
                                case KW_ALTER:
                                case KW_ANALYZE:
                                case KW_ARCHIVE:
                                case KW_ARRAY:
                                case KW_AS:
                                case KW_ASC:
                                case KW_AUTHORIZATION:
                                case KW_AUTOCOMMIT:
                                case KW_BEFORE:
                                case KW_BETWEEN:
                                case KW_BIGINT:
                                case KW_BINARY:
                                case KW_BOOLEAN:
                                case KW_BOTH:
                                case KW_BUCKET:
                                case KW_BUCKETS:
                                case KW_BY:
                                case KW_CACHE:
                                case KW_CASCADE:
                                case KW_CHANGE:
                                case KW_CLUSTER:
                                case KW_CLUSTERED:
                                case KW_CLUSTERSTATUS:
                                case KW_COLLECTION:
                                case KW_COLUMNS:
                                case KW_COMMENT:
                                case KW_COMPACT:
                                case KW_COMPACTIONS:
                                case KW_COMPUTE:
                                case KW_CONCATENATE:
                                case KW_CONSTRAINT:
                                case KW_CONTINUE:
                                case KW_CREATE:
                                case KW_CUBE:
                                case KW_CURRENT_DATE:
                                case KW_CURRENT_TIMESTAMP:
                                case KW_CURSOR:
                                case KW_DATA:
                                case KW_DATABASES:
                                case KW_DATE:
                                case KW_DATETIME:
                                case KW_DAY:
                                case KW_DBPROPERTIES:
                                case KW_DECIMAL:
                                case KW_DEFERRED:
                                case KW_DEFINED:
                                case KW_DELETE:
                                case KW_DELIMITED:
                                case KW_DEPENDENCY:
                                case KW_DESC:
                                case KW_DESCRIBE:
                                case KW_DIRECTORIES:
                                case KW_DIRECTORY:
                                case KW_DISABLE:
                                case KW_DISTRIBUTE:
                                case KW_DOUBLE:
                                case KW_DOW:
                                case KW_DROP:
                                case KW_DUMP:
                                case KW_ELEM_TYPE:
                                case KW_ENABLE:
                                case KW_ESCAPED:
                                case KW_EXCLUSIVE:
                                case KW_EXISTS:
                                case KW_EXPLAIN:
                                case KW_EXPORT:
                                case KW_EXTERNAL:
                                case KW_FALSE:
                                case KW_FETCH:
                                case KW_FIELDS:
                                case KW_FILE:
                                case KW_FILEFORMAT:
                                case KW_FIRST:
                                case KW_FLOAT:
                                case KW_FOR:
                                case KW_FOREIGN:
                                case KW_FORMAT:
                                case KW_FORMATTED:
                                case KW_FULL:
                                case KW_FUNCTIONS:
                                case KW_GRANT:
                                case KW_GROUP:
                                case KW_GROUPING:
                                case KW_HOUR:
                                case KW_IDXPROPERTIES:
                                case KW_IMPORT:
                                case KW_IN:
                                case KW_INDEX:
                                case KW_INDEXES:
                                case KW_INNER:
                                case KW_INPATH:
                                case KW_INPUTDRIVER:
                                case KW_INPUTFORMAT:
                                case KW_INSERT:
                                case KW_INT:
                                case KW_INTERSECT:
                                case KW_INTO:
                                case KW_IS:
                                case KW_ISOLATION:
                                case KW_ITEMS:
                                case KW_JAR:
                                case KW_KEY:
                                case KW_KEYS:
                                case KW_KEY_TYPE:
                                case KW_LAST:
                                case KW_LATERAL:
                                case KW_LEFT:
                                case KW_LEVEL:
                                case KW_LIKE:
                                case KW_LIMIT:
                                case KW_LINES:
                                case KW_LOAD:
                                case KW_LOCAL:
                                case KW_LOCATION:
                                case KW_LOCK:
                                case KW_LOCKS:
                                case KW_LOGICAL:
                                case KW_LONG:
                                case KW_MAPJOIN:
                                case KW_MATCHED:
                                case KW_MATERIALIZED:
                                case KW_MERGE:
                                case KW_METADATA:
                                case KW_MINUTE:
                                case KW_MONTH:
                                case KW_MSCK:
                                case KW_NONE:
                                case KW_NORELY:
                                case KW_NOSCAN:
                                case KW_NOVALIDATE:
                                case KW_NULL:
                                case KW_NULLS:
                                case KW_OF:
                                case KW_OFFSET:
                                case KW_OPTION:
                                case KW_ORDER:
                                case KW_OUT:
                                case KW_OUTER:
                                case KW_OUTPUTDRIVER:
                                case KW_OUTPUTFORMAT:
                                case KW_OVERWRITE:
                                case KW_OWNER:
                                case KW_PARTITIONED:
                                case KW_PARTITIONS:
                                case KW_PERCENT:
                                case KW_PLUS:
                                case KW_PRETTY:
                                case KW_PRIMARY:
                                case KW_PRINCIPALS:
                                case KW_PROCEDURE:
                                case KW_PURGE:
                                case KW_QUARTER:
                                case KW_RANGE:
                                case KW_READ:
                                case KW_READS:
                                case KW_REBUILD:
                                case KW_RECORDREADER:
                                case KW_RECORDWRITER:
                                case KW_REFERENCES:
                                case KW_REGEXP:
                                case KW_RELOAD:
                                case KW_RELY:
                                case KW_RENAME:
                                case KW_REPAIR:
                                case KW_REPL:
                                case KW_REPLACE:
                                case KW_REPLICATION:
                                case KW_RESTRICT:
                                case KW_REVOKE:
                                case KW_REWRITE:
                                case KW_RIGHT:
                                case KW_RLIKE:
                                case KW_ROLE:
                                case KW_ROLES:
                                case KW_ROLLUP:
                                case KW_ROW:
                                case KW_ROWS:
                                case KW_SCHEMA:
                                case KW_SCHEMAS:
                                case KW_SECOND:
                                case KW_SEMI:
                                case KW_SERDE:
                                case KW_SERDEPROPERTIES:
                                case KW_SERVER:
                                case KW_SET:
                                case KW_SETS:
                                case KW_SHARED:
                                case KW_SHOW:
                                case KW_SHOW_DATABASE:
                                case KW_SKEWED:
                                case KW_SMALLINT:
                                case KW_SNAPSHOT:
                                case KW_SORT:
                                case KW_SORTED:
                                case KW_SSL:
                                case KW_STATISTICS:
                                case KW_STATUS:
                                case KW_STORED:
                                case KW_STREAMTABLE:
                                case KW_STRING:
                                case KW_STRUCT:
                                case KW_TABLE:
                                case KW_TABLES:
                                case KW_TBLPROPERTIES:
                                case KW_TEMPORARY:
                                case KW_TERMINATED:
                                case KW_TIMESTAMP:
                                case KW_TINYINT:
                                case KW_TO:
                                case KW_TOUCH:
                                case KW_TRANSACTION:
                                case KW_TRANSACTIONS:
                                case KW_TRIGGER:
                                case KW_TRUE:
                                case KW_TRUNCATE:
                                case KW_UNARCHIVE:
                                case KW_UNDO:
                                case KW_UNION:
                                case KW_UNIONTYPE:
                                case KW_UNLOCK:
                                case KW_UNSET:
                                case KW_UNSIGNED:
                                case KW_UPDATE:
                                case KW_URI:
                                case KW_USE:
                                case KW_USER:
                                case KW_USING:
                                case KW_UTC:
                                case KW_UTCTIMESTAMP:
                                case KW_VALIDATE:
                                case KW_VALUES:
                                case KW_VALUE_TYPE:
                                case KW_VIEW:
                                case KW_VIEWS:
                                case KW_WEEK:
                                case KW_WHILE:
                                case KW_WITH:
                                case KW_WORK:
                                case KW_WRITE:
                                case KW_YEAR:
                                case KW_BATCH:
                                case KW_DAYOFWEEK:
                                case KW_HOLD_DDLTIME:
                                case KW_IGNORE:
                                case KW_NO_DROP:
                                case KW_OFFLINE:
                                case KW_PROTECTION:
                                case KW_READONLY:
                                    {
                                    alt172=1;
                                    }
                                    break;
                                case KW_PARTITION:
                                    {
                                    switch ( input.LA(3) ) {
                                        case LPAREN:
                                            {
                                            int LA172_12 = input.LA(4);

                                            if ( (!(((useSQL11ReservedKeywordsForIdentifier())))) ) {
                                                alt172=1;
                                            }
                                            }
                                            break;
                                        case EOF:
                                        case DOT:
                                        case KW_PARTITION:
                                            {
                                            alt172=1;
                                            }
                                            break;
                                    }

                                    }
                                    break;
                            }

                            }
                            break;
                    }

                    switch (alt172) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:7: KW_TABLE
                            {
                            KW_TABLE561=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_privObjectCols9219); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE561);


                            }
                            break;

                    }


                    pushFollow(FOLLOW_tableName_in_privObjectCols9222);
                    tableName562=tableName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableName.add(tableName562.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:27: ( LPAREN cols= columnNameList RPAREN )?
                    int alt173=2;
                    switch ( input.LA(1) ) {
                        case LPAREN:
                            {
                            alt173=1;
                            }
                            break;
                    }

                    switch (alt173) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:28: LPAREN cols= columnNameList RPAREN
                            {
                            LPAREN563=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_privObjectCols9225); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN563);


                            pushFollow(FOLLOW_columnNameList_in_privObjectCols9229);
                            cols=columnNameList();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_columnNameList.add(cols.getTree());

                            RPAREN564=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_privObjectCols9231); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN564);


                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:64: ( partitionSpec )?
                    int alt174=2;
                    switch ( input.LA(1) ) {
                        case KW_PARTITION:
                            {
                            alt174=1;
                            }
                            break;
                    }

                    switch (alt174) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:64: partitionSpec
                            {
                            pushFollow(FOLLOW_partitionSpec_in_privObjectCols9235);
                            partitionSpec565=partitionSpec();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec565.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: partitionSpec, cols, tableName
                    // token labels: 
                    // rule labels: cols, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_cols=new RewriteRuleSubtreeStream(adaptor,"rule cols",cols!=null?cols.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1663:79: -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:82: ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_TABLE_TYPE, "TOK_TABLE_TYPE")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableName.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:110: ( $cols)?
                        if ( stream_cols.hasNext() ) {
                            adaptor.addChild(root_1, stream_cols.nextTree());

                        }
                        stream_cols.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1663:116: ( partitionSpec )?
                        if ( stream_partitionSpec.hasNext() ) {
                            adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                        }
                        stream_partitionSpec.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1664:7: KW_URI (path= StringLiteral )
                    {
                    KW_URI566=(Token)match(input,KW_URI,FOLLOW_KW_URI_in_privObjectCols9259); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_URI.add(KW_URI566);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1664:14: (path= StringLiteral )
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1664:15: path= StringLiteral
                    {
                    path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_privObjectCols9264); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(path);


                    }


                    // AST REWRITE
                    // elements: path
                    // token labels: path
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1664:35: -> ^( TOK_URI_TYPE $path)
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1664:39: ^( TOK_URI_TYPE $path)
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_URI_TYPE, "TOK_URI_TYPE")
                        , root_1);

                        adaptor.addChild(root_1, stream_path.nextNode());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 4 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1665:7: KW_SERVER identifier
                    {
                    KW_SERVER567=(Token)match(input,KW_SERVER,FOLLOW_KW_SERVER_in_privObjectCols9283); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SERVER.add(KW_SERVER567);


                    pushFollow(FOLLOW_identifier_in_privObjectCols9285);
                    identifier568=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_identifier.add(identifier568.getTree());

                    // AST REWRITE
                    // elements: identifier
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1665:28: -> ^( TOK_SERVER_TYPE identifier )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1665:31: ^( TOK_SERVER_TYPE identifier )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SERVER_TYPE, "TOK_SERVER_TYPE")
                        , root_1);

                        adaptor.addChild(root_1, stream_identifier.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "privObjectCols"


    public static class privilegeList_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "privilegeList"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1668:1: privilegeList : privlegeDef ( COMMA privlegeDef )* -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ ) ;
    public final HiveParser.privilegeList_return privilegeList() throws RecognitionException {
        HiveParser.privilegeList_return retval = new HiveParser.privilegeList_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token COMMA570=null;
        HiveParser.privlegeDef_return privlegeDef569 =null;

        HiveParser.privlegeDef_return privlegeDef571 =null;


        ASTNode COMMA570_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_privlegeDef=new RewriteRuleSubtreeStream(adaptor,"rule privlegeDef");
        pushMsg("grant privilege list", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:5: ( privlegeDef ( COMMA privlegeDef )* -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:7: privlegeDef ( COMMA privlegeDef )*
            {
            pushFollow(FOLLOW_privlegeDef_in_privilegeList9320);
            privlegeDef569=privlegeDef();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_privlegeDef.add(privlegeDef569.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:19: ( COMMA privlegeDef )*
            loop176:
            do {
                int alt176=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt176=1;
                    }
                    break;

                }

                switch (alt176) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:20: COMMA privlegeDef
            	    {
            	    COMMA570=(Token)match(input,COMMA,FOLLOW_COMMA_in_privilegeList9323); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA570);


            	    pushFollow(FOLLOW_privlegeDef_in_privilegeList9325);
            	    privlegeDef571=privlegeDef();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_privlegeDef.add(privlegeDef571.getTree());

            	    }
            	    break;

            	default :
            	    break loop176;
                }
            } while (true);


            // AST REWRITE
            // elements: privlegeDef
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1672:5: -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:8: ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_PRIVILEGE_LIST, "TOK_PRIVILEGE_LIST")
                , root_1);

                if ( !(stream_privlegeDef.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_privlegeDef.hasNext() ) {
                    adaptor.addChild(root_1, stream_privlegeDef.nextTree());

                }
                stream_privlegeDef.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "privilegeList"


    public static class privlegeDef_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "privlegeDef"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:1: privlegeDef : privilegeType ( LPAREN cols= columnNameList RPAREN )? -> ^( TOK_PRIVILEGE privilegeType ( $cols)? ) ;
    public final HiveParser.privlegeDef_return privlegeDef() throws RecognitionException {
        HiveParser.privlegeDef_return retval = new HiveParser.privlegeDef_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token LPAREN573=null;
        Token RPAREN574=null;
        HiveParser.columnNameList_return cols =null;

        HiveParser.privilegeType_return privilegeType572 =null;


        ASTNode LPAREN573_tree=null;
        ASTNode RPAREN574_tree=null;
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
        RewriteRuleSubtreeStream stream_privilegeType=new RewriteRuleSubtreeStream(adaptor,"rule privilegeType");
        pushMsg("grant privilege", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1678:5: ( privilegeType ( LPAREN cols= columnNameList RPAREN )? -> ^( TOK_PRIVILEGE privilegeType ( $cols)? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1678:7: privilegeType ( LPAREN cols= columnNameList RPAREN )?
            {
            pushFollow(FOLLOW_privilegeType_in_privlegeDef9367);
            privilegeType572=privilegeType();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_privilegeType.add(privilegeType572.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1678:21: ( LPAREN cols= columnNameList RPAREN )?
            int alt177=2;
            switch ( input.LA(1) ) {
                case LPAREN:
                    {
                    alt177=1;
                    }
                    break;
            }

            switch (alt177) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1678:22: LPAREN cols= columnNameList RPAREN
                    {
                    LPAREN573=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_privlegeDef9370); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN573);


                    pushFollow(FOLLOW_columnNameList_in_privlegeDef9374);
                    cols=columnNameList();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_columnNameList.add(cols.getTree());

                    RPAREN574=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_privlegeDef9376); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN574);


                    }
                    break;

            }


            // AST REWRITE
            // elements: privilegeType, cols
            // token labels: 
            // rule labels: cols, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_cols=new RewriteRuleSubtreeStream(adaptor,"rule cols",cols!=null?cols.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1679:5: -> ^( TOK_PRIVILEGE privilegeType ( $cols)? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1679:8: ^( TOK_PRIVILEGE privilegeType ( $cols)? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_PRIVILEGE, "TOK_PRIVILEGE")
                , root_1);

                adaptor.addChild(root_1, stream_privilegeType.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1679:39: ( $cols)?
                if ( stream_cols.hasNext() ) {
                    adaptor.addChild(root_1, stream_cols.nextTree());

                }
                stream_cols.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "privlegeDef"


    public static class privilegeType_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "privilegeType"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1682:1: privilegeType : ( KW_ALL -> ^( TOK_PRIV_ALL ) | KW_ALTER -> ^( TOK_PRIV_ALTER_METADATA ) | KW_UPDATE -> ^( TOK_PRIV_ALTER_DATA ) | KW_CREATE -> ^( TOK_PRIV_CREATE ) | KW_DROP -> ^( TOK_PRIV_DROP ) | KW_INDEX -> ^( TOK_PRIV_INDEX ) | KW_LOCK -> ^( TOK_PRIV_LOCK ) | KW_SELECT -> ^( TOK_PRIV_SELECT ) | KW_SHOW_DATABASE -> ^( TOK_PRIV_SHOW_DATABASE ) | KW_INSERT -> ^( TOK_PRIV_INSERT ) | KW_DELETE -> ^( TOK_PRIV_DELETE ) );
    public final HiveParser.privilegeType_return privilegeType() throws RecognitionException {
        HiveParser.privilegeType_return retval = new HiveParser.privilegeType_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_ALL575=null;
        Token KW_ALTER576=null;
        Token KW_UPDATE577=null;
        Token KW_CREATE578=null;
        Token KW_DROP579=null;
        Token KW_INDEX580=null;
        Token KW_LOCK581=null;
        Token KW_SELECT582=null;
        Token KW_SHOW_DATABASE583=null;
        Token KW_INSERT584=null;
        Token KW_DELETE585=null;

        ASTNode KW_ALL575_tree=null;
        ASTNode KW_ALTER576_tree=null;
        ASTNode KW_UPDATE577_tree=null;
        ASTNode KW_CREATE578_tree=null;
        ASTNode KW_DROP579_tree=null;
        ASTNode KW_INDEX580_tree=null;
        ASTNode KW_LOCK581_tree=null;
        ASTNode KW_SELECT582_tree=null;
        ASTNode KW_SHOW_DATABASE583_tree=null;
        ASTNode KW_INSERT584_tree=null;
        ASTNode KW_DELETE585_tree=null;
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_DELETE=new RewriteRuleTokenStream(adaptor,"token KW_DELETE");
        RewriteRuleTokenStream stream_KW_SHOW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_SHOW_DATABASE");
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_KW_INDEX=new RewriteRuleTokenStream(adaptor,"token KW_INDEX");
        RewriteRuleTokenStream stream_KW_ALTER=new RewriteRuleTokenStream(adaptor,"token KW_ALTER");
        RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
        RewriteRuleTokenStream stream_KW_LOCK=new RewriteRuleTokenStream(adaptor,"token KW_LOCK");
        RewriteRuleTokenStream stream_KW_INSERT=new RewriteRuleTokenStream(adaptor,"token KW_INSERT");
        RewriteRuleTokenStream stream_KW_SELECT=new RewriteRuleTokenStream(adaptor,"token KW_SELECT");
        RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");

        pushMsg("privilege type", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1685:5: ( KW_ALL -> ^( TOK_PRIV_ALL ) | KW_ALTER -> ^( TOK_PRIV_ALTER_METADATA ) | KW_UPDATE -> ^( TOK_PRIV_ALTER_DATA ) | KW_CREATE -> ^( TOK_PRIV_CREATE ) | KW_DROP -> ^( TOK_PRIV_DROP ) | KW_INDEX -> ^( TOK_PRIV_INDEX ) | KW_LOCK -> ^( TOK_PRIV_LOCK ) | KW_SELECT -> ^( TOK_PRIV_SELECT ) | KW_SHOW_DATABASE -> ^( TOK_PRIV_SHOW_DATABASE ) | KW_INSERT -> ^( TOK_PRIV_INSERT ) | KW_DELETE -> ^( TOK_PRIV_DELETE ) )
            int alt178=11;
            switch ( input.LA(1) ) {
            case KW_ALL:
                {
                alt178=1;
                }
                break;
            case KW_ALTER:
                {
                alt178=2;
                }
                break;
            case KW_UPDATE:
                {
                alt178=3;
                }
                break;
            case KW_CREATE:
                {
                alt178=4;
                }
                break;
            case KW_DROP:
                {
                alt178=5;
                }
                break;
            case KW_INDEX:
                {
                alt178=6;
                }
                break;
            case KW_LOCK:
                {
                alt178=7;
                }
                break;
            case KW_SELECT:
                {
                alt178=8;
                }
                break;
            case KW_SHOW_DATABASE:
                {
                alt178=9;
                }
                break;
            case KW_INSERT:
                {
                alt178=10;
                }
                break;
            case KW_DELETE:
                {
                alt178=11;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 178, 0, input);

                throw nvae;

            }

            switch (alt178) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1685:7: KW_ALL
                    {
                    KW_ALL575=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_privilegeType9421); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL575);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1685:14: -> ^( TOK_PRIV_ALL )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1685:17: ^( TOK_PRIV_ALL )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_PRIV_ALL, "TOK_PRIV_ALL")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1686:7: KW_ALTER
                    {
                    KW_ALTER576=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_privilegeType9435); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER576);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1686:16: -> ^( TOK_PRIV_ALTER_METADATA )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1686:19: ^( TOK_PRIV_ALTER_METADATA )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_PRIV_ALTER_METADATA, "TOK_PRIV_ALTER_METADATA")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1687:7: KW_UPDATE
                    {
                    KW_UPDATE577=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_privilegeType9449); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE577);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1687:17: -> ^( TOK_PRIV_ALTER_DATA )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1687:20: ^( TOK_PRIV_ALTER_DATA )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_PRIV_ALTER_DATA, "TOK_PRIV_ALTER_DATA")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 4 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1688:7: KW_CREATE
                    {
                    KW_CREATE578=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_privilegeType9463); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE578);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1688:17: -> ^( TOK_PRIV_CREATE )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1688:20: ^( TOK_PRIV_CREATE )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_PRIV_CREATE, "TOK_PRIV_CREATE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 5 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1689:7: KW_DROP
                    {
                    KW_DROP579=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_privilegeType9477); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP579);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1689:15: -> ^( TOK_PRIV_DROP )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1689:18: ^( TOK_PRIV_DROP )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_PRIV_DROP, "TOK_PRIV_DROP")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 6 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1690:7: KW_INDEX
                    {
                    KW_INDEX580=(Token)match(input,KW_INDEX,FOLLOW_KW_INDEX_in_privilegeType9491); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_INDEX.add(KW_INDEX580);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1690:16: -> ^( TOK_PRIV_INDEX )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1690:19: ^( TOK_PRIV_INDEX )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_PRIV_INDEX, "TOK_PRIV_INDEX")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 7 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1691:7: KW_LOCK
                    {
                    KW_LOCK581=(Token)match(input,KW_LOCK,FOLLOW_KW_LOCK_in_privilegeType9505); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_LOCK.add(KW_LOCK581);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1691:15: -> ^( TOK_PRIV_LOCK )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1691:18: ^( TOK_PRIV_LOCK )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_PRIV_LOCK, "TOK_PRIV_LOCK")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 8 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1692:7: KW_SELECT
                    {
                    KW_SELECT582=(Token)match(input,KW_SELECT,FOLLOW_KW_SELECT_in_privilegeType9519); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SELECT.add(KW_SELECT582);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1692:17: -> ^( TOK_PRIV_SELECT )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1692:20: ^( TOK_PRIV_SELECT )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_PRIV_SELECT, "TOK_PRIV_SELECT")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 9 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1693:7: KW_SHOW_DATABASE
                    {
                    KW_SHOW_DATABASE583=(Token)match(input,KW_SHOW_DATABASE,FOLLOW_KW_SHOW_DATABASE_in_privilegeType9533); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SHOW_DATABASE.add(KW_SHOW_DATABASE583);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1693:24: -> ^( TOK_PRIV_SHOW_DATABASE )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1693:27: ^( TOK_PRIV_SHOW_DATABASE )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_PRIV_SHOW_DATABASE, "TOK_PRIV_SHOW_DATABASE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 10 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1694:7: KW_INSERT
                    {
                    KW_INSERT584=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_privilegeType9547); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_INSERT.add(KW_INSERT584);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1694:17: -> ^( TOK_PRIV_INSERT )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1694:20: ^( TOK_PRIV_INSERT )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_PRIV_INSERT, "TOK_PRIV_INSERT")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 11 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:7: KW_DELETE
                    {
                    KW_DELETE585=(Token)match(input,KW_DELETE,FOLLOW_KW_DELETE_in_privilegeType9561); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_DELETE.add(KW_DELETE585);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1695:17: -> ^( TOK_PRIV_DELETE )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:20: ^( TOK_PRIV_DELETE )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_PRIV_DELETE, "TOK_PRIV_DELETE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "privilegeType"


    public static class principalSpecification_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "principalSpecification"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1698:1: principalSpecification : principalName ( COMMA principalName )* -> ^( TOK_PRINCIPAL_NAME ( principalName )+ ) ;
    public final HiveParser.principalSpecification_return principalSpecification() throws RecognitionException {
        HiveParser.principalSpecification_return retval = new HiveParser.principalSpecification_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token COMMA587=null;
        HiveParser.principalName_return principalName586 =null;

        HiveParser.principalName_return principalName588 =null;


        ASTNode COMMA587_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");
         pushMsg("user/group/role name list", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1701:5: ( principalName ( COMMA principalName )* -> ^( TOK_PRINCIPAL_NAME ( principalName )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1701:7: principalName ( COMMA principalName )*
            {
            pushFollow(FOLLOW_principalName_in_principalSpecification9594);
            principalName586=principalName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_principalName.add(principalName586.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1701:21: ( COMMA principalName )*
            loop179:
            do {
                int alt179=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt179=1;
                    }
                    break;

                }

                switch (alt179) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1701:22: COMMA principalName
            	    {
            	    COMMA587=(Token)match(input,COMMA,FOLLOW_COMMA_in_principalSpecification9597); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA587);


            	    pushFollow(FOLLOW_principalName_in_principalSpecification9599);
            	    principalName588=principalName();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_principalName.add(principalName588.getTree());

            	    }
            	    break;

            	default :
            	    break loop179;
                }
            } while (true);


            // AST REWRITE
            // elements: principalName
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1701:44: -> ^( TOK_PRINCIPAL_NAME ( principalName )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1701:47: ^( TOK_PRINCIPAL_NAME ( principalName )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_PRINCIPAL_NAME, "TOK_PRINCIPAL_NAME")
                , root_1);

                if ( !(stream_principalName.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_principalName.hasNext() ) {
                    adaptor.addChild(root_1, stream_principalName.nextTree());

                }
                stream_principalName.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "principalSpecification"


    public static class principalName_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "principalName"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1704:1: principalName : ( KW_USER principalIdentifier -> ^( TOK_USER principalIdentifier ) | KW_GROUP principalIdentifier -> ^( TOK_GROUP principalIdentifier ) | KW_ROLE identifier -> ^( TOK_ROLE identifier ) );
    public final HiveParser.principalName_return principalName() throws RecognitionException {
        HiveParser.principalName_return retval = new HiveParser.principalName_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_USER589=null;
        Token KW_GROUP591=null;
        Token KW_ROLE593=null;
        HiveParser_IdentifiersParser.principalIdentifier_return principalIdentifier590 =null;

        HiveParser_IdentifiersParser.principalIdentifier_return principalIdentifier592 =null;

        HiveParser_IdentifiersParser.identifier_return identifier594 =null;


        ASTNode KW_USER589_tree=null;
        ASTNode KW_GROUP591_tree=null;
        ASTNode KW_ROLE593_tree=null;
        RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
        RewriteRuleTokenStream stream_KW_USER=new RewriteRuleTokenStream(adaptor,"token KW_USER");
        RewriteRuleTokenStream stream_KW_GROUP=new RewriteRuleTokenStream(adaptor,"token KW_GROUP");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_principalIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule principalIdentifier");
        pushMsg("user|group|role name", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1707:5: ( KW_USER principalIdentifier -> ^( TOK_USER principalIdentifier ) | KW_GROUP principalIdentifier -> ^( TOK_GROUP principalIdentifier ) | KW_ROLE identifier -> ^( TOK_ROLE identifier ) )
            int alt180=3;
            switch ( input.LA(1) ) {
            case KW_USER:
                {
                alt180=1;
                }
                break;
            case KW_GROUP:
                {
                alt180=2;
                }
                break;
            case KW_ROLE:
                {
                alt180=3;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 180, 0, input);

                throw nvae;

            }

            switch (alt180) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1707:7: KW_USER principalIdentifier
                    {
                    KW_USER589=(Token)match(input,KW_USER,FOLLOW_KW_USER_in_principalName9637); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_USER.add(KW_USER589);


                    pushFollow(FOLLOW_principalIdentifier_in_principalName9639);
                    principalIdentifier590=principalIdentifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_principalIdentifier.add(principalIdentifier590.getTree());

                    // AST REWRITE
                    // elements: principalIdentifier
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1707:35: -> ^( TOK_USER principalIdentifier )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1707:38: ^( TOK_USER principalIdentifier )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_USER, "TOK_USER")
                        , root_1);

                        adaptor.addChild(root_1, stream_principalIdentifier.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1708:7: KW_GROUP principalIdentifier
                    {
                    KW_GROUP591=(Token)match(input,KW_GROUP,FOLLOW_KW_GROUP_in_principalName9655); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_GROUP.add(KW_GROUP591);


                    pushFollow(FOLLOW_principalIdentifier_in_principalName9657);
                    principalIdentifier592=principalIdentifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_principalIdentifier.add(principalIdentifier592.getTree());

                    // AST REWRITE
                    // elements: principalIdentifier
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1708:36: -> ^( TOK_GROUP principalIdentifier )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1708:39: ^( TOK_GROUP principalIdentifier )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_GROUP, "TOK_GROUP")
                        , root_1);

                        adaptor.addChild(root_1, stream_principalIdentifier.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1709:7: KW_ROLE identifier
                    {
                    KW_ROLE593=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_principalName9673); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE593);


                    pushFollow(FOLLOW_identifier_in_principalName9675);
                    identifier594=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_identifier.add(identifier594.getTree());

                    // AST REWRITE
                    // elements: identifier
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1709:26: -> ^( TOK_ROLE identifier )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1709:29: ^( TOK_ROLE identifier )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ROLE, "TOK_ROLE")
                        , root_1);

                        adaptor.addChild(root_1, stream_identifier.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "principalName"


    public static class withGrantOption_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "withGrantOption"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1712:1: withGrantOption : KW_WITH KW_GRANT KW_OPTION -> ^( TOK_GRANT_WITH_OPTION ) ;
    public final HiveParser.withGrantOption_return withGrantOption() throws RecognitionException {
        HiveParser.withGrantOption_return retval = new HiveParser.withGrantOption_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_WITH595=null;
        Token KW_GRANT596=null;
        Token KW_OPTION597=null;

        ASTNode KW_WITH595_tree=null;
        ASTNode KW_GRANT596_tree=null;
        ASTNode KW_OPTION597_tree=null;
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
        RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");

        pushMsg("with grant option", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1715:5: ( KW_WITH KW_GRANT KW_OPTION -> ^( TOK_GRANT_WITH_OPTION ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1715:7: KW_WITH KW_GRANT KW_OPTION
            {
            KW_WITH595=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_withGrantOption9710); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH595);


            KW_GRANT596=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_withGrantOption9712); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT596);


            KW_OPTION597=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_withGrantOption9714); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_OPTION.add(KW_OPTION597);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1716:5: -> ^( TOK_GRANT_WITH_OPTION )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1716:8: ^( TOK_GRANT_WITH_OPTION )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_GRANT_WITH_OPTION, "TOK_GRANT_WITH_OPTION")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "withGrantOption"


    public static class grantOptionFor_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "grantOptionFor"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1719:1: grantOptionFor : KW_GRANT KW_OPTION KW_FOR -> ^( TOK_GRANT_OPTION_FOR ) ;
    public final HiveParser.grantOptionFor_return grantOptionFor() throws RecognitionException {
        HiveParser.grantOptionFor_return retval = new HiveParser.grantOptionFor_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_GRANT598=null;
        Token KW_OPTION599=null;
        Token KW_FOR600=null;

        ASTNode KW_GRANT598_tree=null;
        ASTNode KW_OPTION599_tree=null;
        ASTNode KW_FOR600_tree=null;
        RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
        RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
        RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");

        pushMsg("grant option for", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1722:5: ( KW_GRANT KW_OPTION KW_FOR -> ^( TOK_GRANT_OPTION_FOR ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1722:7: KW_GRANT KW_OPTION KW_FOR
            {
            KW_GRANT598=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_grantOptionFor9751); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT598);


            KW_OPTION599=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_grantOptionFor9753); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_OPTION.add(KW_OPTION599);


            KW_FOR600=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_grantOptionFor9755); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR600);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1723:5: -> ^( TOK_GRANT_OPTION_FOR )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1723:8: ^( TOK_GRANT_OPTION_FOR )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_GRANT_OPTION_FOR, "TOK_GRANT_OPTION_FOR")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "grantOptionFor"


    public static class adminOptionFor_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "adminOptionFor"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1726:1: adminOptionFor : KW_ADMIN KW_OPTION KW_FOR -> ^( TOK_ADMIN_OPTION_FOR ) ;
    public final HiveParser.adminOptionFor_return adminOptionFor() throws RecognitionException {
        HiveParser.adminOptionFor_return retval = new HiveParser.adminOptionFor_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_ADMIN601=null;
        Token KW_OPTION602=null;
        Token KW_FOR603=null;

        ASTNode KW_ADMIN601_tree=null;
        ASTNode KW_OPTION602_tree=null;
        ASTNode KW_FOR603_tree=null;
        RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
        RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");
        RewriteRuleTokenStream stream_KW_ADMIN=new RewriteRuleTokenStream(adaptor,"token KW_ADMIN");

        pushMsg("admin option for", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1729:5: ( KW_ADMIN KW_OPTION KW_FOR -> ^( TOK_ADMIN_OPTION_FOR ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1729:7: KW_ADMIN KW_OPTION KW_FOR
            {
            KW_ADMIN601=(Token)match(input,KW_ADMIN,FOLLOW_KW_ADMIN_in_adminOptionFor9788); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ADMIN.add(KW_ADMIN601);


            KW_OPTION602=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_adminOptionFor9790); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_OPTION.add(KW_OPTION602);


            KW_FOR603=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_adminOptionFor9792); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR603);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1730:5: -> ^( TOK_ADMIN_OPTION_FOR )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1730:8: ^( TOK_ADMIN_OPTION_FOR )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ADMIN_OPTION_FOR, "TOK_ADMIN_OPTION_FOR")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "adminOptionFor"


    public static class withAdminOption_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "withAdminOption"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1733:1: withAdminOption : KW_WITH KW_ADMIN KW_OPTION -> ^( TOK_GRANT_WITH_ADMIN_OPTION ) ;
    public final HiveParser.withAdminOption_return withAdminOption() throws RecognitionException {
        HiveParser.withAdminOption_return retval = new HiveParser.withAdminOption_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_WITH604=null;
        Token KW_ADMIN605=null;
        Token KW_OPTION606=null;

        ASTNode KW_WITH604_tree=null;
        ASTNode KW_ADMIN605_tree=null;
        ASTNode KW_OPTION606_tree=null;
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");
        RewriteRuleTokenStream stream_KW_ADMIN=new RewriteRuleTokenStream(adaptor,"token KW_ADMIN");

        pushMsg("with admin option", state);
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1736:5: ( KW_WITH KW_ADMIN KW_OPTION -> ^( TOK_GRANT_WITH_ADMIN_OPTION ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1736:7: KW_WITH KW_ADMIN KW_OPTION
            {
            KW_WITH604=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_withAdminOption9825); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH604);


            KW_ADMIN605=(Token)match(input,KW_ADMIN,FOLLOW_KW_ADMIN_in_withAdminOption9827); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ADMIN.add(KW_ADMIN605);


            KW_OPTION606=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_withAdminOption9829); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_OPTION.add(KW_OPTION606);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1737:5: -> ^( TOK_GRANT_WITH_ADMIN_OPTION )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1737:8: ^( TOK_GRANT_WITH_ADMIN_OPTION )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_GRANT_WITH_ADMIN_OPTION, "TOK_GRANT_WITH_ADMIN_OPTION")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) {popMsg(state);}
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "withAdminOption"


    public static class metastoreCheck_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "metastoreCheck"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1740:1: metastoreCheck : KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName ( partitionSpec )? ( COMMA partitionSpec )* )? -> ^( TOK_MSCK ( $repair)? ( tableName ( partitionSpec )* )? ) ;
    public final HiveParser.metastoreCheck_return metastoreCheck() throws RecognitionException {
        HiveParser.metastoreCheck_return retval = new HiveParser.metastoreCheck_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token repair=null;
        Token KW_MSCK607=null;
        Token KW_TABLE608=null;
        Token COMMA611=null;
        HiveParser_FromClauseParser.tableName_return tableName609 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec610 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec612 =null;


        ASTNode repair_tree=null;
        ASTNode KW_MSCK607_tree=null;
        ASTNode KW_TABLE608_tree=null;
        ASTNode COMMA611_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleTokenStream stream_KW_REPAIR=new RewriteRuleTokenStream(adaptor,"token KW_REPAIR");
        RewriteRuleTokenStream stream_KW_MSCK=new RewriteRuleTokenStream(adaptor,"token KW_MSCK");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("metastore check statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:5: ( KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName ( partitionSpec )? ( COMMA partitionSpec )* )? -> ^( TOK_MSCK ( $repair)? ( tableName ( partitionSpec )* )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:7: KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName ( partitionSpec )? ( COMMA partitionSpec )* )?
            {
            KW_MSCK607=(Token)match(input,KW_MSCK,FOLLOW_KW_MSCK_in_metastoreCheck9866); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_MSCK.add(KW_MSCK607);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:15: (repair= KW_REPAIR )?
            int alt181=2;
            switch ( input.LA(1) ) {
                case KW_REPAIR:
                    {
                    alt181=1;
                    }
                    break;
            }

            switch (alt181) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:16: repair= KW_REPAIR
                    {
                    repair=(Token)match(input,KW_REPAIR,FOLLOW_KW_REPAIR_in_metastoreCheck9871); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_REPAIR.add(repair);


                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:35: ( KW_TABLE tableName ( partitionSpec )? ( COMMA partitionSpec )* )?
            int alt184=2;
            switch ( input.LA(1) ) {
                case KW_TABLE:
                    {
                    alt184=1;
                    }
                    break;
            }

            switch (alt184) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:36: KW_TABLE tableName ( partitionSpec )? ( COMMA partitionSpec )*
                    {
                    KW_TABLE608=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_metastoreCheck9876); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE608);


                    pushFollow(FOLLOW_tableName_in_metastoreCheck9878);
                    tableName609=tableName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableName.add(tableName609.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:55: ( partitionSpec )?
                    int alt182=2;
                    switch ( input.LA(1) ) {
                        case KW_PARTITION:
                            {
                            alt182=1;
                            }
                            break;
                    }

                    switch (alt182) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:55: partitionSpec
                            {
                            pushFollow(FOLLOW_partitionSpec_in_metastoreCheck9880);
                            partitionSpec610=partitionSpec();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec610.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:70: ( COMMA partitionSpec )*
                    loop183:
                    do {
                        int alt183=2;
                        switch ( input.LA(1) ) {
                        case COMMA:
                            {
                            alt183=1;
                            }
                            break;

                        }

                        switch (alt183) {
                    	case 1 :
                    	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:71: COMMA partitionSpec
                    	    {
                    	    COMMA611=(Token)match(input,COMMA,FOLLOW_COMMA_in_metastoreCheck9884); if (state.failed) return retval; 
                    	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA611);


                    	    pushFollow(FOLLOW_partitionSpec_in_metastoreCheck9886);
                    	    partitionSpec612=partitionSpec();

                    	    state._fsp--;
                    	    if (state.failed) return retval;
                    	    if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec612.getTree());

                    	    }
                    	    break;

                    	default :
                    	    break loop183;
                        }
                    } while (true);


                    }
                    break;

            }


            // AST REWRITE
            // elements: tableName, repair, partitionSpec
            // token labels: repair
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_repair=new RewriteRuleTokenStream(adaptor,"token repair",repair);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1744:5: -> ^( TOK_MSCK ( $repair)? ( tableName ( partitionSpec )* )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1744:8: ^( TOK_MSCK ( $repair)? ( tableName ( partitionSpec )* )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_MSCK, "TOK_MSCK")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1744:20: ( $repair)?
                if ( stream_repair.hasNext() ) {
                    adaptor.addChild(root_1, stream_repair.nextNode());

                }
                stream_repair.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1744:28: ( tableName ( partitionSpec )* )?
                if ( stream_tableName.hasNext()||stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableName.nextTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1744:39: ( partitionSpec )*
                    while ( stream_partitionSpec.hasNext() ) {
                        adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                    }
                    stream_partitionSpec.reset();

                }
                stream_tableName.reset();
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "metastoreCheck"


    public static class resourceList_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "resourceList"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1747:1: resourceList : resource ( COMMA resource )* -> ^( TOK_RESOURCE_LIST ( resource )+ ) ;
    public final HiveParser.resourceList_return resourceList() throws RecognitionException {
        HiveParser.resourceList_return retval = new HiveParser.resourceList_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token COMMA614=null;
        HiveParser.resource_return resource613 =null;

        HiveParser.resource_return resource615 =null;


        ASTNode COMMA614_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_resource=new RewriteRuleSubtreeStream(adaptor,"rule resource");
         pushMsg("resource list", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1750:3: ( resource ( COMMA resource )* -> ^( TOK_RESOURCE_LIST ( resource )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1751:3: resource ( COMMA resource )*
            {
            pushFollow(FOLLOW_resource_in_resourceList9939);
            resource613=resource();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_resource.add(resource613.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1751:12: ( COMMA resource )*
            loop185:
            do {
                int alt185=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt185=1;
                    }
                    break;

                }

                switch (alt185) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1751:13: COMMA resource
            	    {
            	    COMMA614=(Token)match(input,COMMA,FOLLOW_COMMA_in_resourceList9942); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA614);


            	    pushFollow(FOLLOW_resource_in_resourceList9944);
            	    resource615=resource();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_resource.add(resource615.getTree());

            	    }
            	    break;

            	default :
            	    break loop185;
                }
            } while (true);


            // AST REWRITE
            // elements: resource
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1751:30: -> ^( TOK_RESOURCE_LIST ( resource )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1751:33: ^( TOK_RESOURCE_LIST ( resource )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_RESOURCE_LIST, "TOK_RESOURCE_LIST")
                , root_1);

                if ( !(stream_resource.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_resource.hasNext() ) {
                    adaptor.addChild(root_1, stream_resource.nextTree());

                }
                stream_resource.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "resourceList"


    public static class resource_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "resource"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1754:1: resource : resType= resourceType resPath= StringLiteral -> ^( TOK_RESOURCE_URI $resType $resPath) ;
    public final HiveParser.resource_return resource() throws RecognitionException {
        HiveParser.resource_return retval = new HiveParser.resource_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token resPath=null;
        HiveParser.resourceType_return resType =null;


        ASTNode resPath_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleSubtreeStream stream_resourceType=new RewriteRuleSubtreeStream(adaptor,"rule resourceType");
         pushMsg("resource", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1757:3: (resType= resourceType resPath= StringLiteral -> ^( TOK_RESOURCE_URI $resType $resPath) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1758:3: resType= resourceType resPath= StringLiteral
            {
            pushFollow(FOLLOW_resourceType_in_resource9982);
            resType=resourceType();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_resourceType.add(resType.getTree());

            resPath=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_resource9986); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(resPath);


            // AST REWRITE
            // elements: resType, resPath
            // token labels: resPath
            // rule labels: resType, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_resPath=new RewriteRuleTokenStream(adaptor,"token resPath",resPath);
            RewriteRuleSubtreeStream stream_resType=new RewriteRuleSubtreeStream(adaptor,"rule resType",resType!=null?resType.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1758:46: -> ^( TOK_RESOURCE_URI $resType $resPath)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1758:49: ^( TOK_RESOURCE_URI $resType $resPath)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_RESOURCE_URI, "TOK_RESOURCE_URI")
                , root_1);

                adaptor.addChild(root_1, stream_resType.nextTree());

                adaptor.addChild(root_1, stream_resPath.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "resource"


    public static class resourceType_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "resourceType"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1761:1: resourceType : ( KW_JAR -> ^( TOK_JAR ) | KW_FILE -> ^( TOK_FILE ) | KW_ARCHIVE -> ^( TOK_ARCHIVE ) );
    public final HiveParser.resourceType_return resourceType() throws RecognitionException {
        HiveParser.resourceType_return retval = new HiveParser.resourceType_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_JAR616=null;
        Token KW_FILE617=null;
        Token KW_ARCHIVE618=null;

        ASTNode KW_JAR616_tree=null;
        ASTNode KW_FILE617_tree=null;
        ASTNode KW_ARCHIVE618_tree=null;
        RewriteRuleTokenStream stream_KW_ARCHIVE=new RewriteRuleTokenStream(adaptor,"token KW_ARCHIVE");
        RewriteRuleTokenStream stream_KW_JAR=new RewriteRuleTokenStream(adaptor,"token KW_JAR");
        RewriteRuleTokenStream stream_KW_FILE=new RewriteRuleTokenStream(adaptor,"token KW_FILE");

         pushMsg("resource type", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1764:3: ( KW_JAR -> ^( TOK_JAR ) | KW_FILE -> ^( TOK_FILE ) | KW_ARCHIVE -> ^( TOK_ARCHIVE ) )
            int alt186=3;
            switch ( input.LA(1) ) {
            case KW_JAR:
                {
                alt186=1;
                }
                break;
            case KW_FILE:
                {
                alt186=2;
                }
                break;
            case KW_ARCHIVE:
                {
                alt186=3;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 186, 0, input);

                throw nvae;

            }

            switch (alt186) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1765:3: KW_JAR
                    {
                    KW_JAR616=(Token)match(input,KW_JAR,FOLLOW_KW_JAR_in_resourceType10023); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_JAR.add(KW_JAR616);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1765:10: -> ^( TOK_JAR )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1765:13: ^( TOK_JAR )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_JAR, "TOK_JAR")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:3: KW_FILE
                    {
                    KW_FILE617=(Token)match(input,KW_FILE,FOLLOW_KW_FILE_in_resourceType10037); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_FILE.add(KW_FILE617);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1767:11: -> ^( TOK_FILE )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:14: ^( TOK_FILE )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_FILE, "TOK_FILE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1769:3: KW_ARCHIVE
                    {
                    KW_ARCHIVE618=(Token)match(input,KW_ARCHIVE,FOLLOW_KW_ARCHIVE_in_resourceType10051); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ARCHIVE.add(KW_ARCHIVE618);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1769:14: -> ^( TOK_ARCHIVE )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1769:17: ^( TOK_ARCHIVE )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ARCHIVE, "TOK_ARCHIVE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "resourceType"


    public static class createFunctionStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "createFunctionStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1772:1: createFunctionStatement : KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )? -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY ) -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? ) ;
    public final HiveParser.createFunctionStatement_return createFunctionStatement() throws RecognitionException {
        HiveParser.createFunctionStatement_return retval = new HiveParser.createFunctionStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token temp=null;
        Token KW_CREATE619=null;
        Token KW_FUNCTION620=null;
        Token KW_AS622=null;
        Token StringLiteral623=null;
        Token KW_USING624=null;
        HiveParser.resourceList_return rList =null;

        HiveParser_IdentifiersParser.functionIdentifier_return functionIdentifier621 =null;


        ASTNode temp_tree=null;
        ASTNode KW_CREATE619_tree=null;
        ASTNode KW_FUNCTION620_tree=null;
        ASTNode KW_AS622_tree=null;
        ASTNode StringLiteral623_tree=null;
        ASTNode KW_USING624_tree=null;
        RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_USING=new RewriteRuleTokenStream(adaptor,"token KW_USING");
        RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleSubtreeStream stream_functionIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule functionIdentifier");
        RewriteRuleSubtreeStream stream_resourceList=new RewriteRuleSubtreeStream(adaptor,"rule resourceList");
         pushMsg("create function statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:5: ( KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )? -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY ) -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:7: KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )?
            {
            KW_CREATE619=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createFunctionStatement10082); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE619);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:17: (temp= KW_TEMPORARY )?
            int alt187=2;
            switch ( input.LA(1) ) {
                case KW_TEMPORARY:
                    {
                    alt187=1;
                    }
                    break;
            }

            switch (alt187) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:18: temp= KW_TEMPORARY
                    {
                    temp=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_createFunctionStatement10087); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(temp);


                    }
                    break;

            }


            KW_FUNCTION620=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_createFunctionStatement10091); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FUNCTION.add(KW_FUNCTION620);


            pushFollow(FOLLOW_functionIdentifier_in_createFunctionStatement10093);
            functionIdentifier621=functionIdentifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_functionIdentifier.add(functionIdentifier621.getTree());

            KW_AS622=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createFunctionStatement10095); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS622);


            StringLiteral623=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_createFunctionStatement10097); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral623);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1776:7: ( KW_USING rList= resourceList )?
            int alt188=2;
            switch ( input.LA(1) ) {
                case KW_USING:
                    {
                    alt188=1;
                    }
                    break;
            }

            switch (alt188) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1776:8: KW_USING rList= resourceList
                    {
                    KW_USING624=(Token)match(input,KW_USING,FOLLOW_KW_USING_in_createFunctionStatement10106); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_USING.add(KW_USING624);


                    pushFollow(FOLLOW_resourceList_in_createFunctionStatement10110);
                    rList=resourceList();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_resourceList.add(rList.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: rList, functionIdentifier, rList, StringLiteral, StringLiteral, functionIdentifier
            // token labels: 
            // rule labels: rList, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_rList=new RewriteRuleSubtreeStream(adaptor,"rule rList",rList!=null?rList.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1777:5: -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY )
            if (temp != null) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1777:25: ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_CREATEFUNCTION, "TOK_CREATEFUNCTION")
                , root_1);

                adaptor.addChild(root_1, stream_functionIdentifier.nextTree());

                adaptor.addChild(root_1, 
                stream_StringLiteral.nextNode()
                );

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1777:80: ( $rList)?
                if ( stream_rList.hasNext() ) {
                    adaptor.addChild(root_1, stream_rList.nextTree());

                }
                stream_rList.reset();

                adaptor.addChild(root_1, 
                (ASTNode)adaptor.create(TOK_TEMPORARY, "TOK_TEMPORARY")
                );

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 1778:5: -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1778:25: ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_CREATEFUNCTION, "TOK_CREATEFUNCTION")
                , root_1);

                adaptor.addChild(root_1, stream_functionIdentifier.nextTree());

                adaptor.addChild(root_1, 
                stream_StringLiteral.nextNode()
                );

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1778:80: ( $rList)?
                if ( stream_rList.hasNext() ) {
                    adaptor.addChild(root_1, stream_rList.nextTree());

                }
                stream_rList.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "createFunctionStatement"


    public static class dropFunctionStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dropFunctionStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1781:1: dropFunctionStatement : KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY ) -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? ) ;
    public final HiveParser.dropFunctionStatement_return dropFunctionStatement() throws RecognitionException {
        HiveParser.dropFunctionStatement_return retval = new HiveParser.dropFunctionStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token temp=null;
        Token KW_DROP625=null;
        Token KW_FUNCTION626=null;
        HiveParser.ifExists_return ifExists627 =null;

        HiveParser_IdentifiersParser.functionIdentifier_return functionIdentifier628 =null;


        ASTNode temp_tree=null;
        ASTNode KW_DROP625_tree=null;
        ASTNode KW_FUNCTION626_tree=null;
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
        RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
        RewriteRuleSubtreeStream stream_functionIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule functionIdentifier");
         pushMsg("drop function statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1784:5: ( KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY ) -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1784:7: KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier
            {
            KW_DROP625=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropFunctionStatement10196); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP625);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1784:15: (temp= KW_TEMPORARY )?
            int alt189=2;
            switch ( input.LA(1) ) {
                case KW_TEMPORARY:
                    {
                    alt189=1;
                    }
                    break;
            }

            switch (alt189) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1784:16: temp= KW_TEMPORARY
                    {
                    temp=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_dropFunctionStatement10201); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(temp);


                    }
                    break;

            }


            KW_FUNCTION626=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_dropFunctionStatement10205); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FUNCTION.add(KW_FUNCTION626);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1784:48: ( ifExists )?
            int alt190=2;
            switch ( input.LA(1) ) {
                case KW_IF:
                    {
                    alt190=1;
                    }
                    break;
            }

            switch (alt190) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1784:48: ifExists
                    {
                    pushFollow(FOLLOW_ifExists_in_dropFunctionStatement10207);
                    ifExists627=ifExists();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_ifExists.add(ifExists627.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_functionIdentifier_in_dropFunctionStatement10210);
            functionIdentifier628=functionIdentifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_functionIdentifier.add(functionIdentifier628.getTree());

            // AST REWRITE
            // elements: functionIdentifier, ifExists, ifExists, functionIdentifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1785:5: -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY )
            if (temp != null) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1785:25: ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DROPFUNCTION, "TOK_DROPFUNCTION")
                , root_1);

                adaptor.addChild(root_1, stream_functionIdentifier.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1785:63: ( ifExists )?
                if ( stream_ifExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifExists.nextTree());

                }
                stream_ifExists.reset();

                adaptor.addChild(root_1, 
                (ASTNode)adaptor.create(TOK_TEMPORARY, "TOK_TEMPORARY")
                );

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 1786:5: -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1786:25: ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DROPFUNCTION, "TOK_DROPFUNCTION")
                , root_1);

                adaptor.addChild(root_1, stream_functionIdentifier.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1786:63: ( ifExists )?
                if ( stream_ifExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifExists.nextTree());

                }
                stream_ifExists.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dropFunctionStatement"


    public static class reloadFunctionStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "reloadFunctionStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1789:1: reloadFunctionStatement : KW_RELOAD KW_FUNCTION -> ^( TOK_RELOADFUNCTION ) ;
    public final HiveParser.reloadFunctionStatement_return reloadFunctionStatement() throws RecognitionException {
        HiveParser.reloadFunctionStatement_return retval = new HiveParser.reloadFunctionStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_RELOAD629=null;
        Token KW_FUNCTION630=null;

        ASTNode KW_RELOAD629_tree=null;
        ASTNode KW_FUNCTION630_tree=null;
        RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
        RewriteRuleTokenStream stream_KW_RELOAD=new RewriteRuleTokenStream(adaptor,"token KW_RELOAD");

         pushMsg("reload function statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1792:5: ( KW_RELOAD KW_FUNCTION -> ^( TOK_RELOADFUNCTION ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1792:7: KW_RELOAD KW_FUNCTION
            {
            KW_RELOAD629=(Token)match(input,KW_RELOAD,FOLLOW_KW_RELOAD_in_reloadFunctionStatement10288); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_RELOAD.add(KW_RELOAD629);


            KW_FUNCTION630=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_reloadFunctionStatement10290); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FUNCTION.add(KW_FUNCTION630);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1792:29: -> ^( TOK_RELOADFUNCTION )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1792:32: ^( TOK_RELOADFUNCTION )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_RELOADFUNCTION, "TOK_RELOADFUNCTION")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "reloadFunctionStatement"


    public static class createMacroStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "createMacroStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1794:1: createMacroStatement : KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression ) ;
    public final HiveParser.createMacroStatement_return createMacroStatement() throws RecognitionException {
        HiveParser.createMacroStatement_return retval = new HiveParser.createMacroStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_CREATE631=null;
        Token KW_TEMPORARY632=null;
        Token KW_MACRO633=null;
        Token Identifier634=null;
        Token LPAREN635=null;
        Token RPAREN637=null;
        HiveParser.columnNameTypeList_return columnNameTypeList636 =null;

        HiveParser_IdentifiersParser.expression_return expression638 =null;


        ASTNode KW_CREATE631_tree=null;
        ASTNode KW_TEMPORARY632_tree=null;
        ASTNode KW_MACRO633_tree=null;
        ASTNode Identifier634_tree=null;
        ASTNode LPAREN635_tree=null;
        ASTNode RPAREN637_tree=null;
        RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
        RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_KW_MACRO=new RewriteRuleTokenStream(adaptor,"token KW_MACRO");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
        RewriteRuleSubtreeStream stream_columnNameTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeList");
         pushMsg("create macro statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1797:5: ( KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1797:7: KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression
            {
            KW_CREATE631=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createMacroStatement10318); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE631);


            KW_TEMPORARY632=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_createMacroStatement10320); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(KW_TEMPORARY632);


            KW_MACRO633=(Token)match(input,KW_MACRO,FOLLOW_KW_MACRO_in_createMacroStatement10322); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_MACRO.add(KW_MACRO633);


            Identifier634=(Token)match(input,Identifier,FOLLOW_Identifier_in_createMacroStatement10324); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_Identifier.add(Identifier634);


            LPAREN635=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createMacroStatement10332); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN635);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1798:14: ( columnNameTypeList )?
            int alt191=2;
            switch ( input.LA(1) ) {
                case Identifier:
                case KW_ABORT:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_AUTOCOMMIT:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CACHE:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONSTRAINT:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURRENT_DATE:
                case KW_CURRENT_TIMESTAMP:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DAY:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DOW:
                case KW_DROP:
                case KW_DUMP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FOREIGN:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOUR:
                case KW_IDXPROPERTIES:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ISOLATION:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEY:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LAST:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LEVEL:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATCHED:
                case KW_MATERIALIZED:
                case KW_MERGE:
                case KW_METADATA:
                case KW_MINUTE:
                case KW_MONTH:
                case KW_MSCK:
                case KW_NONE:
                case KW_NORELY:
                case KW_NOSCAN:
                case KW_NOVALIDATE:
                case KW_NULL:
                case KW_NULLS:
                case KW_OF:
                case KW_OFFSET:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRIMARY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PURGE:
                case KW_QUARTER:
                case KW_RANGE:
                case KW_READ:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REFERENCES:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RELY:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPL:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SECOND:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SNAPSHOT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STATUS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTION:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALIDATE:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_VIEWS:
                case KW_WEEK:
                case KW_WHILE:
                case KW_WITH:
                case KW_WORK:
                case KW_WRITE:
                case KW_YEAR:
                case KW_BATCH:
                case KW_DAYOFWEEK:
                case KW_HOLD_DDLTIME:
                case KW_IGNORE:
                case KW_NO_DROP:
                case KW_OFFLINE:
                case KW_PROTECTION:
                case KW_READONLY:
                    {
                    alt191=1;
                    }
                    break;
            }

            switch (alt191) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1798:14: columnNameTypeList
                    {
                    pushFollow(FOLLOW_columnNameTypeList_in_createMacroStatement10334);
                    columnNameTypeList636=columnNameTypeList();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_columnNameTypeList.add(columnNameTypeList636.getTree());

                    }
                    break;

            }


            RPAREN637=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createMacroStatement10337); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN637);


            pushFollow(FOLLOW_expression_in_createMacroStatement10339);
            expression638=expression();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_expression.add(expression638.getTree());

            // AST REWRITE
            // elements: columnNameTypeList, expression, Identifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1799:5: -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1799:8: ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_CREATEMACRO, "TOK_CREATEMACRO")
                , root_1);

                adaptor.addChild(root_1, 
                stream_Identifier.nextNode()
                );

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1799:37: ( columnNameTypeList )?
                if ( stream_columnNameTypeList.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());

                }
                stream_columnNameTypeList.reset();

                adaptor.addChild(root_1, stream_expression.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "createMacroStatement"


    public static class dropMacroStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dropMacroStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1802:1: dropMacroStatement : KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier -> ^( TOK_DROPMACRO Identifier ( ifExists )? ) ;
    public final HiveParser.dropMacroStatement_return dropMacroStatement() throws RecognitionException {
        HiveParser.dropMacroStatement_return retval = new HiveParser.dropMacroStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_DROP639=null;
        Token KW_TEMPORARY640=null;
        Token KW_MACRO641=null;
        Token Identifier643=null;
        HiveParser.ifExists_return ifExists642 =null;


        ASTNode KW_DROP639_tree=null;
        ASTNode KW_TEMPORARY640_tree=null;
        ASTNode KW_MACRO641_tree=null;
        ASTNode Identifier643_tree=null;
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
        RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
        RewriteRuleTokenStream stream_KW_MACRO=new RewriteRuleTokenStream(adaptor,"token KW_MACRO");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
         pushMsg("drop macro statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1805:5: ( KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier -> ^( TOK_DROPMACRO Identifier ( ifExists )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1805:7: KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier
            {
            KW_DROP639=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropMacroStatement10383); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP639);


            KW_TEMPORARY640=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_dropMacroStatement10385); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(KW_TEMPORARY640);


            KW_MACRO641=(Token)match(input,KW_MACRO,FOLLOW_KW_MACRO_in_dropMacroStatement10387); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_MACRO.add(KW_MACRO641);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1805:37: ( ifExists )?
            int alt192=2;
            switch ( input.LA(1) ) {
                case KW_IF:
                    {
                    alt192=1;
                    }
                    break;
            }

            switch (alt192) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1805:37: ifExists
                    {
                    pushFollow(FOLLOW_ifExists_in_dropMacroStatement10389);
                    ifExists642=ifExists();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_ifExists.add(ifExists642.getTree());

                    }
                    break;

            }


            Identifier643=(Token)match(input,Identifier,FOLLOW_Identifier_in_dropMacroStatement10392); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_Identifier.add(Identifier643);


            // AST REWRITE
            // elements: Identifier, ifExists
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1806:5: -> ^( TOK_DROPMACRO Identifier ( ifExists )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1806:8: ^( TOK_DROPMACRO Identifier ( ifExists )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DROPMACRO, "TOK_DROPMACRO")
                , root_1);

                adaptor.addChild(root_1, 
                stream_Identifier.nextNode()
                );

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1806:35: ( ifExists )?
                if ( stream_ifExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifExists.nextTree());

                }
                stream_ifExists.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dropMacroStatement"


    public static class createViewStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "createViewStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1809:1: createViewStatement : KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) ;
    public final HiveParser.createViewStatement_return createViewStatement() throws RecognitionException {
        HiveParser.createViewStatement_return retval = new HiveParser.createViewStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_CREATE644=null;
        Token KW_VIEW646=null;
        Token LPAREN648=null;
        Token RPAREN650=null;
        Token KW_AS654=null;
        HiveParser_FromClauseParser.tableName_return name =null;

        HiveParser.orReplace_return orReplace645 =null;

        HiveParser.ifNotExists_return ifNotExists647 =null;

        HiveParser.columnNameCommentList_return columnNameCommentList649 =null;

        HiveParser.tableComment_return tableComment651 =null;

        HiveParser.viewPartition_return viewPartition652 =null;

        HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed653 =null;

        HiveParser.selectStatementWithCTE_return selectStatementWithCTE655 =null;


        ASTNode KW_CREATE644_tree=null;
        ASTNode KW_VIEW646_tree=null;
        ASTNode LPAREN648_tree=null;
        ASTNode RPAREN650_tree=null;
        ASTNode KW_AS654_tree=null;
        RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleSubtreeStream stream_columnNameCommentList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameCommentList");
        RewriteRuleSubtreeStream stream_selectStatementWithCTE=new RewriteRuleSubtreeStream(adaptor,"rule selectStatementWithCTE");
        RewriteRuleSubtreeStream stream_orReplace=new RewriteRuleSubtreeStream(adaptor,"rule orReplace");
        RewriteRuleSubtreeStream stream_tablePropertiesPrefixed=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesPrefixed");
        RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
        RewriteRuleSubtreeStream stream_tableComment=new RewriteRuleSubtreeStream(adaptor,"rule tableComment");
        RewriteRuleSubtreeStream stream_viewPartition=new RewriteRuleSubtreeStream(adaptor,"rule viewPartition");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

            pushMsg("create view statement", state);

        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1814:5: ( KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1814:7: KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE
            {
            KW_CREATE644=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createViewStatement10434); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE644);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1814:17: ( orReplace )?
            int alt193=2;
            switch ( input.LA(1) ) {
                case KW_OR:
                    {
                    alt193=1;
                    }
                    break;
            }

            switch (alt193) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1814:18: orReplace
                    {
                    pushFollow(FOLLOW_orReplace_in_createViewStatement10437);
                    orReplace645=orReplace();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_orReplace.add(orReplace645.getTree());

                    }
                    break;

            }


            KW_VIEW646=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_createViewStatement10441); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW646);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1814:38: ( ifNotExists )?
            int alt194=2;
            switch ( input.LA(1) ) {
                case KW_IF:
                    {
                    alt194=1;
                    }
                    break;
            }

            switch (alt194) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1814:39: ifNotExists
                    {
                    pushFollow(FOLLOW_ifNotExists_in_createViewStatement10444);
                    ifNotExists647=ifNotExists();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists647.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_tableName_in_createViewStatement10450);
            name=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(name.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1815:9: ( LPAREN columnNameCommentList RPAREN )?
            int alt195=2;
            switch ( input.LA(1) ) {
                case LPAREN:
                    {
                    alt195=1;
                    }
                    break;
            }

            switch (alt195) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1815:10: LPAREN columnNameCommentList RPAREN
                    {
                    LPAREN648=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createViewStatement10461); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN648);


                    pushFollow(FOLLOW_columnNameCommentList_in_createViewStatement10463);
                    columnNameCommentList649=columnNameCommentList();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_columnNameCommentList.add(columnNameCommentList649.getTree());

                    RPAREN650=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createViewStatement10465); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN650);


                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1815:48: ( tableComment )?
            int alt196=2;
            switch ( input.LA(1) ) {
                case KW_COMMENT:
                    {
                    alt196=1;
                    }
                    break;
            }

            switch (alt196) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1815:48: tableComment
                    {
                    pushFollow(FOLLOW_tableComment_in_createViewStatement10469);
                    tableComment651=tableComment();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableComment.add(tableComment651.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1815:62: ( viewPartition )?
            int alt197=2;
            switch ( input.LA(1) ) {
                case KW_PARTITIONED:
                    {
                    alt197=1;
                    }
                    break;
            }

            switch (alt197) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1815:62: viewPartition
                    {
                    pushFollow(FOLLOW_viewPartition_in_createViewStatement10472);
                    viewPartition652=viewPartition();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_viewPartition.add(viewPartition652.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1816:9: ( tablePropertiesPrefixed )?
            int alt198=2;
            switch ( input.LA(1) ) {
                case KW_TBLPROPERTIES:
                    {
                    alt198=1;
                    }
                    break;
            }

            switch (alt198) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1816:9: tablePropertiesPrefixed
                    {
                    pushFollow(FOLLOW_tablePropertiesPrefixed_in_createViewStatement10483);
                    tablePropertiesPrefixed653=tablePropertiesPrefixed();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed653.getTree());

                    }
                    break;

            }


            KW_AS654=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createViewStatement10494); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS654);


            pushFollow(FOLLOW_selectStatementWithCTE_in_createViewStatement10504);
            selectStatementWithCTE655=selectStatementWithCTE();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_selectStatementWithCTE.add(selectStatementWithCTE655.getTree());

            // AST REWRITE
            // elements: ifNotExists, orReplace, name, viewPartition, tableComment, selectStatementWithCTE, columnNameCommentList, tablePropertiesPrefixed
            // token labels: 
            // rule labels: name, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1819:5: -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1819:8: ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_CREATEVIEW, "TOK_CREATEVIEW")
                , root_1);

                adaptor.addChild(root_1, stream_name.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1819:31: ( orReplace )?
                if ( stream_orReplace.hasNext() ) {
                    adaptor.addChild(root_1, stream_orReplace.nextTree());

                }
                stream_orReplace.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1820:10: ( ifNotExists )?
                if ( stream_ifNotExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifNotExists.nextTree());

                }
                stream_ifNotExists.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1821:10: ( columnNameCommentList )?
                if ( stream_columnNameCommentList.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameCommentList.nextTree());

                }
                stream_columnNameCommentList.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1822:10: ( tableComment )?
                if ( stream_tableComment.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableComment.nextTree());

                }
                stream_tableComment.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1823:10: ( viewPartition )?
                if ( stream_viewPartition.hasNext() ) {
                    adaptor.addChild(root_1, stream_viewPartition.nextTree());

                }
                stream_viewPartition.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1824:10: ( tablePropertiesPrefixed )?
                if ( stream_tablePropertiesPrefixed.hasNext() ) {
                    adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());

                }
                stream_tablePropertiesPrefixed.reset();

                adaptor.addChild(root_1, stream_selectStatementWithCTE.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "createViewStatement"


    public static class viewPartition_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "viewPartition"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1829:1: viewPartition : KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWPARTCOLS columnNameList ) ;
    public final HiveParser.viewPartition_return viewPartition() throws RecognitionException {
        HiveParser.viewPartition_return retval = new HiveParser.viewPartition_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_PARTITIONED656=null;
        Token KW_ON657=null;
        Token LPAREN658=null;
        Token RPAREN660=null;
        HiveParser.columnNameList_return columnNameList659 =null;


        ASTNode KW_PARTITIONED656_tree=null;
        ASTNode KW_ON657_tree=null;
        ASTNode LPAREN658_tree=null;
        ASTNode RPAREN660_tree=null;
        RewriteRuleTokenStream stream_KW_PARTITIONED=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONED");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
         pushMsg("view partition specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1832:5: ( KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWPARTCOLS columnNameList ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1832:7: KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN
            {
            KW_PARTITIONED656=(Token)match(input,KW_PARTITIONED,FOLLOW_KW_PARTITIONED_in_viewPartition10627); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_PARTITIONED.add(KW_PARTITIONED656);


            KW_ON657=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_viewPartition10629); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON657);


            LPAREN658=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_viewPartition10631); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN658);


            pushFollow(FOLLOW_columnNameList_in_viewPartition10633);
            columnNameList659=columnNameList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnNameList.add(columnNameList659.getTree());

            RPAREN660=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_viewPartition10635); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN660);


            // AST REWRITE
            // elements: columnNameList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1833:5: -> ^( TOK_VIEWPARTCOLS columnNameList )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1833:8: ^( TOK_VIEWPARTCOLS columnNameList )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_VIEWPARTCOLS, "TOK_VIEWPARTCOLS")
                , root_1);

                adaptor.addChild(root_1, stream_columnNameList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "viewPartition"


    public static class dropViewStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dropViewStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1836:1: dropViewStatement : KW_DROP KW_VIEW ( ifExists )? viewName -> ^( TOK_DROPVIEW viewName ( ifExists )? ) ;
    public final HiveParser.dropViewStatement_return dropViewStatement() throws RecognitionException {
        HiveParser.dropViewStatement_return retval = new HiveParser.dropViewStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_DROP661=null;
        Token KW_VIEW662=null;
        HiveParser.ifExists_return ifExists663 =null;

        HiveParser_FromClauseParser.viewName_return viewName664 =null;


        ASTNode KW_DROP661_tree=null;
        ASTNode KW_VIEW662_tree=null;
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
        RewriteRuleSubtreeStream stream_viewName=new RewriteRuleSubtreeStream(adaptor,"rule viewName");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
         pushMsg("drop view statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:5: ( KW_DROP KW_VIEW ( ifExists )? viewName -> ^( TOK_DROPVIEW viewName ( ifExists )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:7: KW_DROP KW_VIEW ( ifExists )? viewName
            {
            KW_DROP661=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropViewStatement10674); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP661);


            KW_VIEW662=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_dropViewStatement10676); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW662);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:23: ( ifExists )?
            int alt199=2;
            switch ( input.LA(1) ) {
                case KW_IF:
                    {
                    alt199=1;
                    }
                    break;
            }

            switch (alt199) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:23: ifExists
                    {
                    pushFollow(FOLLOW_ifExists_in_dropViewStatement10678);
                    ifExists663=ifExists();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_ifExists.add(ifExists663.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_viewName_in_dropViewStatement10681);
            viewName664=viewName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_viewName.add(viewName664.getTree());

            // AST REWRITE
            // elements: ifExists, viewName
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1839:42: -> ^( TOK_DROPVIEW viewName ( ifExists )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:45: ^( TOK_DROPVIEW viewName ( ifExists )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DROPVIEW, "TOK_DROPVIEW")
                , root_1);

                adaptor.addChild(root_1, stream_viewName.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:69: ( ifExists )?
                if ( stream_ifExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifExists.nextTree());

                }
                stream_ifExists.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dropViewStatement"


    public static class showFunctionIdentifier_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "showFunctionIdentifier"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1842:1: showFunctionIdentifier : ( functionIdentifier | StringLiteral );
    public final HiveParser.showFunctionIdentifier_return showFunctionIdentifier() throws RecognitionException {
        HiveParser.showFunctionIdentifier_return retval = new HiveParser.showFunctionIdentifier_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token StringLiteral666=null;
        HiveParser_IdentifiersParser.functionIdentifier_return functionIdentifier665 =null;


        ASTNode StringLiteral666_tree=null;

         pushMsg("identifier for show function statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1845:5: ( functionIdentifier | StringLiteral )
            int alt200=2;
            switch ( input.LA(1) ) {
            case Identifier:
            case KW_ABORT:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_AUTOCOMMIT:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CACHE:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONSTRAINT:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURRENT_DATE:
            case KW_CURRENT_TIMESTAMP:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DAY:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DOW:
            case KW_DROP:
            case KW_DUMP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FOREIGN:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOUR:
            case KW_IDXPROPERTIES:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ISOLATION:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEY:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LAST:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LEVEL:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATCHED:
            case KW_MATERIALIZED:
            case KW_MERGE:
            case KW_METADATA:
            case KW_MINUTE:
            case KW_MONTH:
            case KW_MSCK:
            case KW_NONE:
            case KW_NORELY:
            case KW_NOSCAN:
            case KW_NOVALIDATE:
            case KW_NULL:
            case KW_NULLS:
            case KW_OF:
            case KW_OFFSET:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRIMARY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PURGE:
            case KW_QUARTER:
            case KW_RANGE:
            case KW_READ:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REFERENCES:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RELY:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPL:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SECOND:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SNAPSHOT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STATUS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTION:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALIDATE:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_VIEWS:
            case KW_WEEK:
            case KW_WHILE:
            case KW_WITH:
            case KW_WORK:
            case KW_WRITE:
            case KW_YEAR:
            case KW_BATCH:
            case KW_DAYOFWEEK:
            case KW_HOLD_DDLTIME:
            case KW_IGNORE:
            case KW_NO_DROP:
            case KW_OFFLINE:
            case KW_PROTECTION:
            case KW_READONLY:
                {
                alt200=1;
                }
                break;
            case StringLiteral:
                {
                alt200=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 200, 0, input);

                throw nvae;

            }

            switch (alt200) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1845:7: functionIdentifier
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_functionIdentifier_in_showFunctionIdentifier10719);
                    functionIdentifier665=functionIdentifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, functionIdentifier665.getTree());

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1846:7: StringLiteral
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    StringLiteral666=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showFunctionIdentifier10727); if (state.failed) return retval;
                    if ( state.backtracking==0 ) {
                    StringLiteral666_tree = 
                    (ASTNode)adaptor.create(StringLiteral666)
                    ;
                    adaptor.addChild(root_0, StringLiteral666_tree);
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "showFunctionIdentifier"


    public static class showStmtIdentifier_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "showStmtIdentifier"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1849:1: showStmtIdentifier : ( identifier | StringLiteral );
    public final HiveParser.showStmtIdentifier_return showStmtIdentifier() throws RecognitionException {
        HiveParser.showStmtIdentifier_return retval = new HiveParser.showStmtIdentifier_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token StringLiteral668=null;
        HiveParser_IdentifiersParser.identifier_return identifier667 =null;


        ASTNode StringLiteral668_tree=null;

         pushMsg("identifier for show statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1852:5: ( identifier | StringLiteral )
            int alt201=2;
            switch ( input.LA(1) ) {
            case Identifier:
            case KW_ABORT:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_AUTOCOMMIT:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CACHE:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONSTRAINT:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURRENT_DATE:
            case KW_CURRENT_TIMESTAMP:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DAY:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DOW:
            case KW_DROP:
            case KW_DUMP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FOREIGN:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOUR:
            case KW_IDXPROPERTIES:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ISOLATION:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEY:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LAST:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LEVEL:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATCHED:
            case KW_MATERIALIZED:
            case KW_MERGE:
            case KW_METADATA:
            case KW_MINUTE:
            case KW_MONTH:
            case KW_MSCK:
            case KW_NONE:
            case KW_NORELY:
            case KW_NOSCAN:
            case KW_NOVALIDATE:
            case KW_NULL:
            case KW_NULLS:
            case KW_OF:
            case KW_OFFSET:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRIMARY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PURGE:
            case KW_QUARTER:
            case KW_RANGE:
            case KW_READ:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REFERENCES:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RELY:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPL:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SECOND:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SNAPSHOT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STATUS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTION:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALIDATE:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_VIEWS:
            case KW_WEEK:
            case KW_WHILE:
            case KW_WITH:
            case KW_WORK:
            case KW_WRITE:
            case KW_YEAR:
            case KW_BATCH:
            case KW_DAYOFWEEK:
            case KW_HOLD_DDLTIME:
            case KW_IGNORE:
            case KW_NO_DROP:
            case KW_OFFLINE:
            case KW_PROTECTION:
            case KW_READONLY:
                {
                alt201=1;
                }
                break;
            case StringLiteral:
                {
                alt201=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 201, 0, input);

                throw nvae;

            }

            switch (alt201) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1852:7: identifier
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_identifier_in_showStmtIdentifier10754);
                    identifier667=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier667.getTree());

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1853:7: StringLiteral
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    StringLiteral668=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showStmtIdentifier10762); if (state.failed) return retval;
                    if ( state.backtracking==0 ) {
                    StringLiteral668_tree = 
                    (ASTNode)adaptor.create(StringLiteral668)
                    ;
                    adaptor.addChild(root_0, StringLiteral668_tree);
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "showStmtIdentifier"


    public static class tableComment_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableComment"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1856:1: tableComment : KW_COMMENT comment= StringLiteral -> ^( TOK_TABLECOMMENT $comment) ;
    public final HiveParser.tableComment_return tableComment() throws RecognitionException {
        HiveParser.tableComment_return retval = new HiveParser.tableComment_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token comment=null;
        Token KW_COMMENT669=null;

        ASTNode comment_tree=null;
        ASTNode KW_COMMENT669_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");

         pushMsg("table's comment", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1859:5: ( KW_COMMENT comment= StringLiteral -> ^( TOK_TABLECOMMENT $comment) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1860:7: KW_COMMENT comment= StringLiteral
            {
            KW_COMMENT669=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_tableComment10795); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT669);


            comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableComment10799); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(comment);


            // AST REWRITE
            // elements: comment
            // token labels: comment
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1860:41: -> ^( TOK_TABLECOMMENT $comment)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1860:44: ^( TOK_TABLECOMMENT $comment)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABLECOMMENT, "TOK_TABLECOMMENT")
                , root_1);

                adaptor.addChild(root_1, stream_comment.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableComment"


    public static class tablePartition_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tablePartition"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1863:1: tablePartition : KW_PARTITIONED KW_BY LPAREN columnNameTypeList RPAREN -> ^( TOK_TABLEPARTCOLS columnNameTypeList ) ;
    public final HiveParser.tablePartition_return tablePartition() throws RecognitionException {
        HiveParser.tablePartition_return retval = new HiveParser.tablePartition_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_PARTITIONED670=null;
        Token KW_BY671=null;
        Token LPAREN672=null;
        Token RPAREN674=null;
        HiveParser.columnNameTypeList_return columnNameTypeList673 =null;


        ASTNode KW_PARTITIONED670_tree=null;
        ASTNode KW_BY671_tree=null;
        ASTNode LPAREN672_tree=null;
        ASTNode RPAREN674_tree=null;
        RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
        RewriteRuleTokenStream stream_KW_PARTITIONED=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONED");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleSubtreeStream stream_columnNameTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeList");
         pushMsg("table partition specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1866:5: ( KW_PARTITIONED KW_BY LPAREN columnNameTypeList RPAREN -> ^( TOK_TABLEPARTCOLS columnNameTypeList ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1866:7: KW_PARTITIONED KW_BY LPAREN columnNameTypeList RPAREN
            {
            KW_PARTITIONED670=(Token)match(input,KW_PARTITIONED,FOLLOW_KW_PARTITIONED_in_tablePartition10836); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_PARTITIONED.add(KW_PARTITIONED670);


            KW_BY671=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tablePartition10838); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY671);


            LPAREN672=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tablePartition10840); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN672);


            pushFollow(FOLLOW_columnNameTypeList_in_tablePartition10842);
            columnNameTypeList673=columnNameTypeList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnNameTypeList.add(columnNameTypeList673.getTree());

            RPAREN674=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tablePartition10844); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN674);


            // AST REWRITE
            // elements: columnNameTypeList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1867:5: -> ^( TOK_TABLEPARTCOLS columnNameTypeList )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1867:8: ^( TOK_TABLEPARTCOLS columnNameTypeList )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABLEPARTCOLS, "TOK_TABLEPARTCOLS")
                , root_1);

                adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tablePartition"


    public static class tableBuckets_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableBuckets"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1870:1: tableBuckets : KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num) ;
    public final HiveParser.tableBuckets_return tableBuckets() throws RecognitionException {
        HiveParser.tableBuckets_return retval = new HiveParser.tableBuckets_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token num=null;
        Token KW_CLUSTERED675=null;
        Token KW_BY676=null;
        Token LPAREN677=null;
        Token RPAREN678=null;
        Token KW_SORTED679=null;
        Token KW_BY680=null;
        Token LPAREN681=null;
        Token RPAREN682=null;
        Token KW_INTO683=null;
        Token KW_BUCKETS684=null;
        HiveParser.columnNameList_return bucketCols =null;

        HiveParser.columnNameOrderList_return sortCols =null;


        ASTNode num_tree=null;
        ASTNode KW_CLUSTERED675_tree=null;
        ASTNode KW_BY676_tree=null;
        ASTNode LPAREN677_tree=null;
        ASTNode RPAREN678_tree=null;
        ASTNode KW_SORTED679_tree=null;
        ASTNode KW_BY680_tree=null;
        ASTNode LPAREN681_tree=null;
        ASTNode RPAREN682_tree=null;
        ASTNode KW_INTO683_tree=null;
        ASTNode KW_BUCKETS684_tree=null;
        RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
        RewriteRuleTokenStream stream_KW_SORTED=new RewriteRuleTokenStream(adaptor,"token KW_SORTED");
        RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
        RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
        RewriteRuleTokenStream stream_KW_BUCKETS=new RewriteRuleTokenStream(adaptor,"token KW_BUCKETS");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_CLUSTERED=new RewriteRuleTokenStream(adaptor,"token KW_CLUSTERED");
        RewriteRuleSubtreeStream stream_columnNameOrderList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameOrderList");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
         pushMsg("table buckets specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1873:5: ( KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1874:7: KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS
            {
            KW_CLUSTERED675=(Token)match(input,KW_CLUSTERED,FOLLOW_KW_CLUSTERED_in_tableBuckets10889); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_CLUSTERED.add(KW_CLUSTERED675);


            KW_BY676=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableBuckets10891); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY676);


            LPAREN677=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableBuckets10893); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN677);


            pushFollow(FOLLOW_columnNameList_in_tableBuckets10897);
            bucketCols=columnNameList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnNameList.add(bucketCols.getTree());

            RPAREN678=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableBuckets10899); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN678);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1874:66: ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )?
            int alt202=2;
            switch ( input.LA(1) ) {
                case KW_SORTED:
                    {
                    alt202=1;
                    }
                    break;
            }

            switch (alt202) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1874:67: KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN
                    {
                    KW_SORTED679=(Token)match(input,KW_SORTED,FOLLOW_KW_SORTED_in_tableBuckets10902); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SORTED.add(KW_SORTED679);


                    KW_BY680=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableBuckets10904); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY680);


                    LPAREN681=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableBuckets10906); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN681);


                    pushFollow(FOLLOW_columnNameOrderList_in_tableBuckets10910);
                    sortCols=columnNameOrderList();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_columnNameOrderList.add(sortCols.getTree());

                    RPAREN682=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableBuckets10912); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN682);


                    }
                    break;

            }


            KW_INTO683=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_tableBuckets10916); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO683);


            num=(Token)match(input,Number,FOLLOW_Number_in_tableBuckets10920); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_Number.add(num);


            KW_BUCKETS684=(Token)match(input,KW_BUCKETS,FOLLOW_KW_BUCKETS_in_tableBuckets10922); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_BUCKETS.add(KW_BUCKETS684);


            // AST REWRITE
            // elements: num, sortCols, bucketCols
            // token labels: num
            // rule labels: bucketCols, sortCols, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
            RewriteRuleSubtreeStream stream_bucketCols=new RewriteRuleSubtreeStream(adaptor,"rule bucketCols",bucketCols!=null?bucketCols.tree:null);
            RewriteRuleSubtreeStream stream_sortCols=new RewriteRuleSubtreeStream(adaptor,"rule sortCols",sortCols!=null?sortCols.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1875:5: -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1875:8: ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ALTERTABLE_BUCKETS, "TOK_ALTERTABLE_BUCKETS")
                , root_1);

                adaptor.addChild(root_1, stream_bucketCols.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1875:46: ( $sortCols)?
                if ( stream_sortCols.hasNext() ) {
                    adaptor.addChild(root_1, stream_sortCols.nextTree());

                }
                stream_sortCols.reset();

                adaptor.addChild(root_1, stream_num.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableBuckets"


    public static class tableSkewed_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableSkewed"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1878:1: tableSkewed : KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( ( storedAsDirs )=> storedAsDirs )? -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? ) ;
    public final HiveParser.tableSkewed_return tableSkewed() throws RecognitionException {
        HiveParser.tableSkewed_return retval = new HiveParser.tableSkewed_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_SKEWED685=null;
        Token KW_BY686=null;
        Token LPAREN687=null;
        Token RPAREN688=null;
        Token KW_ON689=null;
        Token LPAREN690=null;
        Token RPAREN691=null;
        HiveParser.columnNameList_return skewedCols =null;

        HiveParser.skewedValueElement_return skewedValues =null;

        HiveParser.storedAsDirs_return storedAsDirs692 =null;


        ASTNode KW_SKEWED685_tree=null;
        ASTNode KW_BY686_tree=null;
        ASTNode LPAREN687_tree=null;
        ASTNode RPAREN688_tree=null;
        ASTNode KW_ON689_tree=null;
        ASTNode LPAREN690_tree=null;
        ASTNode RPAREN691_tree=null;
        RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_KW_SKEWED=new RewriteRuleTokenStream(adaptor,"token KW_SKEWED");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleSubtreeStream stream_skewedValueElement=new RewriteRuleSubtreeStream(adaptor,"rule skewedValueElement");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
        RewriteRuleSubtreeStream stream_storedAsDirs=new RewriteRuleSubtreeStream(adaptor,"rule storedAsDirs");
         pushMsg("table skewed specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:5: ( KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( ( storedAsDirs )=> storedAsDirs )? -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1882:6: KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( ( storedAsDirs )=> storedAsDirs )?
            {
            KW_SKEWED685=(Token)match(input,KW_SKEWED,FOLLOW_KW_SKEWED_in_tableSkewed10974); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SKEWED.add(KW_SKEWED685);


            KW_BY686=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableSkewed10976); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY686);


            LPAREN687=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableSkewed10978); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN687);


            pushFollow(FOLLOW_columnNameList_in_tableSkewed10982);
            skewedCols=columnNameList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnNameList.add(skewedCols.getTree());

            RPAREN688=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableSkewed10984); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN688);


            KW_ON689=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_tableSkewed10986); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON689);


            LPAREN690=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableSkewed10988); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN690);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1882:75: (skewedValues= skewedValueElement )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1882:76: skewedValues= skewedValueElement
            {
            pushFollow(FOLLOW_skewedValueElement_in_tableSkewed10993);
            skewedValues=skewedValueElement();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_skewedValueElement.add(skewedValues.getTree());

            }


            RPAREN691=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableSkewed10996); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN691);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1882:116: ( ( storedAsDirs )=> storedAsDirs )?
            int alt203=2;
            switch ( input.LA(1) ) {
                case KW_STORED:
                    {
                    switch ( input.LA(2) ) {
                        case KW_AS:
                            {
                            switch ( input.LA(3) ) {
                                case KW_DIRECTORIES:
                                    {
                                    int LA203_9 = input.LA(4);

                                    if ( (synpred17_HiveParser()) ) {
                                        alt203=1;
                                    }
                                    }
                                    break;
                            }

                            }
                            break;
                    }

                    }
                    break;
            }

            switch (alt203) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1882:117: ( storedAsDirs )=> storedAsDirs
                    {
                    pushFollow(FOLLOW_storedAsDirs_in_tableSkewed11005);
                    storedAsDirs692=storedAsDirs();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_storedAsDirs.add(storedAsDirs692.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: skewedCols, storedAsDirs, skewedValues
            // token labels: 
            // rule labels: skewedCols, skewedValues, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_skewedCols=new RewriteRuleSubtreeStream(adaptor,"rule skewedCols",skewedCols!=null?skewedCols.tree:null);
            RewriteRuleSubtreeStream stream_skewedValues=new RewriteRuleSubtreeStream(adaptor,"rule skewedValues",skewedValues!=null?skewedValues.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1883:5: -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1883:8: ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABLESKEWED, "TOK_TABLESKEWED")
                , root_1);

                adaptor.addChild(root_1, stream_skewedCols.nextTree());

                adaptor.addChild(root_1, stream_skewedValues.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1883:52: ( storedAsDirs )?
                if ( stream_storedAsDirs.hasNext() ) {
                    adaptor.addChild(root_1, stream_storedAsDirs.nextTree());

                }
                stream_storedAsDirs.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableSkewed"


    public static class rowFormat_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "rowFormat"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1886:1: rowFormat : ( rowFormatSerde -> ^( TOK_SERDE rowFormatSerde ) | rowFormatDelimited -> ^( TOK_SERDE rowFormatDelimited ) | -> ^( TOK_SERDE ) );
    public final HiveParser.rowFormat_return rowFormat() throws RecognitionException {
        HiveParser.rowFormat_return retval = new HiveParser.rowFormat_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.rowFormatSerde_return rowFormatSerde693 =null;

        HiveParser.rowFormatDelimited_return rowFormatDelimited694 =null;


        RewriteRuleSubtreeStream stream_rowFormatSerde=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatSerde");
        RewriteRuleSubtreeStream stream_rowFormatDelimited=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatDelimited");
         pushMsg("serde specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1889:5: ( rowFormatSerde -> ^( TOK_SERDE rowFormatSerde ) | rowFormatDelimited -> ^( TOK_SERDE rowFormatDelimited ) | -> ^( TOK_SERDE ) )
            int alt204=3;
            switch ( input.LA(1) ) {
            case KW_ROW:
                {
                switch ( input.LA(2) ) {
                case KW_FORMAT:
                    {
                    switch ( input.LA(3) ) {
                    case KW_SERDE:
                        {
                        alt204=1;
                        }
                        break;
                    case KW_DELIMITED:
                        {
                        alt204=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 204, 26, input);

                        throw nvae;

                    }

                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 204, 1, input);

                    throw nvae;

                }

                }
                break;
            case EOF:
            case KW_CLUSTER:
            case KW_DISTRIBUTE:
            case KW_EXCEPT:
            case KW_FROM:
            case KW_GROUP:
            case KW_HAVING:
            case KW_INSERT:
            case KW_INTERSECT:
            case KW_LATERAL:
            case KW_LIMIT:
            case KW_MAP:
            case KW_MINUS:
            case KW_ORDER:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REDUCE:
            case KW_SELECT:
            case KW_SORT:
            case KW_UNION:
            case KW_USING:
            case KW_WHERE:
            case KW_WINDOW:
            case RPAREN:
                {
                alt204=3;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 204, 0, input);

                throw nvae;

            }

            switch (alt204) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1889:7: rowFormatSerde
                    {
                    pushFollow(FOLLOW_rowFormatSerde_in_rowFormat11053);
                    rowFormatSerde693=rowFormatSerde();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_rowFormatSerde.add(rowFormatSerde693.getTree());

                    // AST REWRITE
                    // elements: rowFormatSerde
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1889:22: -> ^( TOK_SERDE rowFormatSerde )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1889:25: ^( TOK_SERDE rowFormatSerde )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SERDE, "TOK_SERDE")
                        , root_1);

                        adaptor.addChild(root_1, stream_rowFormatSerde.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1890:7: rowFormatDelimited
                    {
                    pushFollow(FOLLOW_rowFormatDelimited_in_rowFormat11069);
                    rowFormatDelimited694=rowFormatDelimited();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_rowFormatDelimited.add(rowFormatDelimited694.getTree());

                    // AST REWRITE
                    // elements: rowFormatDelimited
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1890:26: -> ^( TOK_SERDE rowFormatDelimited )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1890:29: ^( TOK_SERDE rowFormatDelimited )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SERDE, "TOK_SERDE")
                        , root_1);

                        adaptor.addChild(root_1, stream_rowFormatDelimited.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1891:9: 
                    {
                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1891:9: -> ^( TOK_SERDE )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1891:12: ^( TOK_SERDE )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_SERDE, "TOK_SERDE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "rowFormat"


    public static class recordReader_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "recordReader"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1894:1: recordReader : ( KW_RECORDREADER StringLiteral -> ^( TOK_RECORDREADER StringLiteral ) | -> ^( TOK_RECORDREADER ) );
    public final HiveParser.recordReader_return recordReader() throws RecognitionException {
        HiveParser.recordReader_return retval = new HiveParser.recordReader_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_RECORDREADER695=null;
        Token StringLiteral696=null;

        ASTNode KW_RECORDREADER695_tree=null;
        ASTNode StringLiteral696_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_RECORDREADER=new RewriteRuleTokenStream(adaptor,"token KW_RECORDREADER");

         pushMsg("record reader specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1897:5: ( KW_RECORDREADER StringLiteral -> ^( TOK_RECORDREADER StringLiteral ) | -> ^( TOK_RECORDREADER ) )
            int alt205=2;
            switch ( input.LA(1) ) {
            case KW_RECORDREADER:
                {
                alt205=1;
                }
                break;
            case EOF:
            case KW_CLUSTER:
            case KW_DISTRIBUTE:
            case KW_EXCEPT:
            case KW_FROM:
            case KW_GROUP:
            case KW_HAVING:
            case KW_INSERT:
            case KW_INTERSECT:
            case KW_LATERAL:
            case KW_LIMIT:
            case KW_MAP:
            case KW_MINUS:
            case KW_ORDER:
            case KW_REDUCE:
            case KW_SELECT:
            case KW_SORT:
            case KW_UNION:
            case KW_WHERE:
            case KW_WINDOW:
            case RPAREN:
                {
                alt205=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 205, 0, input);

                throw nvae;

            }

            switch (alt205) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1897:7: KW_RECORDREADER StringLiteral
                    {
                    KW_RECORDREADER695=(Token)match(input,KW_RECORDREADER,FOLLOW_KW_RECORDREADER_in_recordReader11118); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_RECORDREADER.add(KW_RECORDREADER695);


                    StringLiteral696=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_recordReader11120); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral696);


                    // AST REWRITE
                    // elements: StringLiteral
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1897:37: -> ^( TOK_RECORDREADER StringLiteral )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1897:40: ^( TOK_RECORDREADER StringLiteral )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_RECORDREADER, "TOK_RECORDREADER")
                        , root_1);

                        adaptor.addChild(root_1, 
                        stream_StringLiteral.nextNode()
                        );

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1898:9: 
                    {
                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1898:9: -> ^( TOK_RECORDREADER )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1898:12: ^( TOK_RECORDREADER )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_RECORDREADER, "TOK_RECORDREADER")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "recordReader"


    public static class recordWriter_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "recordWriter"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1901:1: recordWriter : ( KW_RECORDWRITER StringLiteral -> ^( TOK_RECORDWRITER StringLiteral ) | -> ^( TOK_RECORDWRITER ) );
    public final HiveParser.recordWriter_return recordWriter() throws RecognitionException {
        HiveParser.recordWriter_return retval = new HiveParser.recordWriter_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_RECORDWRITER697=null;
        Token StringLiteral698=null;

        ASTNode KW_RECORDWRITER697_tree=null;
        ASTNode StringLiteral698_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_RECORDWRITER=new RewriteRuleTokenStream(adaptor,"token KW_RECORDWRITER");

         pushMsg("record writer specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1904:5: ( KW_RECORDWRITER StringLiteral -> ^( TOK_RECORDWRITER StringLiteral ) | -> ^( TOK_RECORDWRITER ) )
            int alt206=2;
            switch ( input.LA(1) ) {
            case KW_RECORDWRITER:
                {
                alt206=1;
                }
                break;
            case KW_USING:
                {
                alt206=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 206, 0, input);

                throw nvae;

            }

            switch (alt206) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1904:7: KW_RECORDWRITER StringLiteral
                    {
                    KW_RECORDWRITER697=(Token)match(input,KW_RECORDWRITER,FOLLOW_KW_RECORDWRITER_in_recordWriter11169); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_RECORDWRITER.add(KW_RECORDWRITER697);


                    StringLiteral698=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_recordWriter11171); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral698);


                    // AST REWRITE
                    // elements: StringLiteral
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1904:37: -> ^( TOK_RECORDWRITER StringLiteral )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1904:40: ^( TOK_RECORDWRITER StringLiteral )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_RECORDWRITER, "TOK_RECORDWRITER")
                        , root_1);

                        adaptor.addChild(root_1, 
                        stream_StringLiteral.nextNode()
                        );

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1905:9: 
                    {
                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1905:9: -> ^( TOK_RECORDWRITER )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1905:12: ^( TOK_RECORDWRITER )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_RECORDWRITER, "TOK_RECORDWRITER")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "recordWriter"


    public static class rowFormatSerde_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "rowFormatSerde"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1908:1: rowFormatSerde : KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_SERDENAME $name ( $serdeprops)? ) ;
    public final HiveParser.rowFormatSerde_return rowFormatSerde() throws RecognitionException {
        HiveParser.rowFormatSerde_return retval = new HiveParser.rowFormatSerde_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token name=null;
        Token KW_ROW699=null;
        Token KW_FORMAT700=null;
        Token KW_SERDE701=null;
        Token KW_WITH702=null;
        Token KW_SERDEPROPERTIES703=null;
        HiveParser.tableProperties_return serdeprops =null;


        ASTNode name_tree=null;
        ASTNode KW_ROW699_tree=null;
        ASTNode KW_FORMAT700_tree=null;
        ASTNode KW_SERDE701_tree=null;
        ASTNode KW_WITH702_tree=null;
        ASTNode KW_SERDEPROPERTIES703_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleTokenStream stream_KW_ROW=new RewriteRuleTokenStream(adaptor,"token KW_ROW");
        RewriteRuleTokenStream stream_KW_SERDEPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_SERDEPROPERTIES");
        RewriteRuleTokenStream stream_KW_SERDE=new RewriteRuleTokenStream(adaptor,"token KW_SERDE");
        RewriteRuleTokenStream stream_KW_FORMAT=new RewriteRuleTokenStream(adaptor,"token KW_FORMAT");
        RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
         pushMsg("serde format specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1911:5: ( KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_SERDENAME $name ( $serdeprops)? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1911:7: KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
            {
            KW_ROW699=(Token)match(input,KW_ROW,FOLLOW_KW_ROW_in_rowFormatSerde11220); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ROW.add(KW_ROW699);


            KW_FORMAT700=(Token)match(input,KW_FORMAT,FOLLOW_KW_FORMAT_in_rowFormatSerde11222); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FORMAT.add(KW_FORMAT700);


            KW_SERDE701=(Token)match(input,KW_SERDE,FOLLOW_KW_SERDE_in_rowFormatSerde11224); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SERDE.add(KW_SERDE701);


            name=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_rowFormatSerde11228); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(name);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1911:52: ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
            int alt207=2;
            switch ( input.LA(1) ) {
                case KW_WITH:
                    {
                    alt207=1;
                    }
                    break;
            }

            switch (alt207) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1911:53: KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties
                    {
                    KW_WITH702=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_rowFormatSerde11231); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH702);


                    KW_SERDEPROPERTIES703=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_rowFormatSerde11233); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES703);


                    pushFollow(FOLLOW_tableProperties_in_rowFormatSerde11237);
                    serdeprops=tableProperties();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableProperties.add(serdeprops.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: name, serdeprops
            // token labels: name
            // rule labels: serdeprops, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_name=new RewriteRuleTokenStream(adaptor,"token name",name);
            RewriteRuleSubtreeStream stream_serdeprops=new RewriteRuleSubtreeStream(adaptor,"rule serdeprops",serdeprops!=null?serdeprops.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1912:5: -> ^( TOK_SERDENAME $name ( $serdeprops)? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1912:8: ^( TOK_SERDENAME $name ( $serdeprops)? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SERDENAME, "TOK_SERDENAME")
                , root_1);

                adaptor.addChild(root_1, stream_name.nextNode());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1912:31: ( $serdeprops)?
                if ( stream_serdeprops.hasNext() ) {
                    adaptor.addChild(root_1, stream_serdeprops.nextTree());

                }
                stream_serdeprops.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "rowFormatSerde"


    public static class rowFormatDelimited_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "rowFormatDelimited"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1915:1: rowFormatDelimited : KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? ) ;
    public final HiveParser.rowFormatDelimited_return rowFormatDelimited() throws RecognitionException {
        HiveParser.rowFormatDelimited_return retval = new HiveParser.rowFormatDelimited_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_ROW704=null;
        Token KW_FORMAT705=null;
        Token KW_DELIMITED706=null;
        HiveParser.tableRowFormatFieldIdentifier_return tableRowFormatFieldIdentifier707 =null;

        HiveParser.tableRowFormatCollItemsIdentifier_return tableRowFormatCollItemsIdentifier708 =null;

        HiveParser.tableRowFormatMapKeysIdentifier_return tableRowFormatMapKeysIdentifier709 =null;

        HiveParser.tableRowFormatLinesIdentifier_return tableRowFormatLinesIdentifier710 =null;

        HiveParser.tableRowNullFormat_return tableRowNullFormat711 =null;


        ASTNode KW_ROW704_tree=null;
        ASTNode KW_FORMAT705_tree=null;
        ASTNode KW_DELIMITED706_tree=null;
        RewriteRuleTokenStream stream_KW_ROW=new RewriteRuleTokenStream(adaptor,"token KW_ROW");
        RewriteRuleTokenStream stream_KW_DELIMITED=new RewriteRuleTokenStream(adaptor,"token KW_DELIMITED");
        RewriteRuleTokenStream stream_KW_FORMAT=new RewriteRuleTokenStream(adaptor,"token KW_FORMAT");
        RewriteRuleSubtreeStream stream_tableRowNullFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowNullFormat");
        RewriteRuleSubtreeStream stream_tableRowFormatFieldIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatFieldIdentifier");
        RewriteRuleSubtreeStream stream_tableRowFormatCollItemsIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatCollItemsIdentifier");
        RewriteRuleSubtreeStream stream_tableRowFormatMapKeysIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatMapKeysIdentifier");
        RewriteRuleSubtreeStream stream_tableRowFormatLinesIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatLinesIdentifier");
         pushMsg("serde properties specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1918:5: ( KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1919:7: KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )?
            {
            KW_ROW704=(Token)match(input,KW_ROW,FOLLOW_KW_ROW_in_rowFormatDelimited11289); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ROW.add(KW_ROW704);


            KW_FORMAT705=(Token)match(input,KW_FORMAT,FOLLOW_KW_FORMAT_in_rowFormatDelimited11291); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FORMAT.add(KW_FORMAT705);


            KW_DELIMITED706=(Token)match(input,KW_DELIMITED,FOLLOW_KW_DELIMITED_in_rowFormatDelimited11293); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DELIMITED.add(KW_DELIMITED706);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1919:37: ( tableRowFormatFieldIdentifier )?
            int alt208=2;
            switch ( input.LA(1) ) {
                case KW_FIELDS:
                    {
                    alt208=1;
                    }
                    break;
            }

            switch (alt208) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1919:37: tableRowFormatFieldIdentifier
                    {
                    pushFollow(FOLLOW_tableRowFormatFieldIdentifier_in_rowFormatDelimited11295);
                    tableRowFormatFieldIdentifier707=tableRowFormatFieldIdentifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableRowFormatFieldIdentifier.add(tableRowFormatFieldIdentifier707.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1919:68: ( tableRowFormatCollItemsIdentifier )?
            int alt209=2;
            switch ( input.LA(1) ) {
                case KW_COLLECTION:
                    {
                    alt209=1;
                    }
                    break;
            }

            switch (alt209) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1919:68: tableRowFormatCollItemsIdentifier
                    {
                    pushFollow(FOLLOW_tableRowFormatCollItemsIdentifier_in_rowFormatDelimited11298);
                    tableRowFormatCollItemsIdentifier708=tableRowFormatCollItemsIdentifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableRowFormatCollItemsIdentifier.add(tableRowFormatCollItemsIdentifier708.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1919:103: ( tableRowFormatMapKeysIdentifier )?
            int alt210=2;
            alt210 = dfa210.predict(input);
            switch (alt210) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1919:103: tableRowFormatMapKeysIdentifier
                    {
                    pushFollow(FOLLOW_tableRowFormatMapKeysIdentifier_in_rowFormatDelimited11301);
                    tableRowFormatMapKeysIdentifier709=tableRowFormatMapKeysIdentifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableRowFormatMapKeysIdentifier.add(tableRowFormatMapKeysIdentifier709.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1919:136: ( tableRowFormatLinesIdentifier )?
            int alt211=2;
            switch ( input.LA(1) ) {
                case KW_LINES:
                    {
                    alt211=1;
                    }
                    break;
            }

            switch (alt211) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1919:136: tableRowFormatLinesIdentifier
                    {
                    pushFollow(FOLLOW_tableRowFormatLinesIdentifier_in_rowFormatDelimited11304);
                    tableRowFormatLinesIdentifier710=tableRowFormatLinesIdentifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableRowFormatLinesIdentifier.add(tableRowFormatLinesIdentifier710.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1919:167: ( tableRowNullFormat )?
            int alt212=2;
            switch ( input.LA(1) ) {
                case KW_NULL:
                    {
                    alt212=1;
                    }
                    break;
            }

            switch (alt212) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1919:167: tableRowNullFormat
                    {
                    pushFollow(FOLLOW_tableRowNullFormat_in_rowFormatDelimited11307);
                    tableRowNullFormat711=tableRowNullFormat();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableRowNullFormat.add(tableRowNullFormat711.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: tableRowFormatFieldIdentifier, tableRowNullFormat, tableRowFormatLinesIdentifier, tableRowFormatCollItemsIdentifier, tableRowFormatMapKeysIdentifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1920:5: -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1920:8: ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SERDEPROPS, "TOK_SERDEPROPS")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1920:25: ( tableRowFormatFieldIdentifier )?
                if ( stream_tableRowFormatFieldIdentifier.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableRowFormatFieldIdentifier.nextTree());

                }
                stream_tableRowFormatFieldIdentifier.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1920:56: ( tableRowFormatCollItemsIdentifier )?
                if ( stream_tableRowFormatCollItemsIdentifier.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableRowFormatCollItemsIdentifier.nextTree());

                }
                stream_tableRowFormatCollItemsIdentifier.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1920:91: ( tableRowFormatMapKeysIdentifier )?
                if ( stream_tableRowFormatMapKeysIdentifier.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableRowFormatMapKeysIdentifier.nextTree());

                }
                stream_tableRowFormatMapKeysIdentifier.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1920:124: ( tableRowFormatLinesIdentifier )?
                if ( stream_tableRowFormatLinesIdentifier.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableRowFormatLinesIdentifier.nextTree());

                }
                stream_tableRowFormatLinesIdentifier.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1920:155: ( tableRowNullFormat )?
                if ( stream_tableRowNullFormat.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableRowNullFormat.nextTree());

                }
                stream_tableRowNullFormat.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "rowFormatDelimited"


    public static class tableRowFormat_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableRowFormat"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1923:1: tableRowFormat : ( rowFormatDelimited -> ^( TOK_TABLEROWFORMAT rowFormatDelimited ) | rowFormatSerde -> ^( TOK_TABLESERIALIZER rowFormatSerde ) );
    public final HiveParser.tableRowFormat_return tableRowFormat() throws RecognitionException {
        HiveParser.tableRowFormat_return retval = new HiveParser.tableRowFormat_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.rowFormatDelimited_return rowFormatDelimited712 =null;

        HiveParser.rowFormatSerde_return rowFormatSerde713 =null;


        RewriteRuleSubtreeStream stream_rowFormatSerde=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatSerde");
        RewriteRuleSubtreeStream stream_rowFormatDelimited=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatDelimited");
         pushMsg("table row format specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1926:5: ( rowFormatDelimited -> ^( TOK_TABLEROWFORMAT rowFormatDelimited ) | rowFormatSerde -> ^( TOK_TABLESERIALIZER rowFormatSerde ) )
            int alt213=2;
            switch ( input.LA(1) ) {
            case KW_ROW:
                {
                switch ( input.LA(2) ) {
                case KW_FORMAT:
                    {
                    switch ( input.LA(3) ) {
                    case KW_DELIMITED:
                        {
                        alt213=1;
                        }
                        break;
                    case KW_SERDE:
                        {
                        alt213=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 213, 2, input);

                        throw nvae;

                    }

                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 213, 1, input);

                    throw nvae;

                }

                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 213, 0, input);

                throw nvae;

            }

            switch (alt213) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1927:7: rowFormatDelimited
                    {
                    pushFollow(FOLLOW_rowFormatDelimited_in_tableRowFormat11366);
                    rowFormatDelimited712=rowFormatDelimited();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_rowFormatDelimited.add(rowFormatDelimited712.getTree());

                    // AST REWRITE
                    // elements: rowFormatDelimited
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1928:5: -> ^( TOK_TABLEROWFORMAT rowFormatDelimited )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1928:8: ^( TOK_TABLEROWFORMAT rowFormatDelimited )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_TABLEROWFORMAT, "TOK_TABLEROWFORMAT")
                        , root_1);

                        adaptor.addChild(root_1, stream_rowFormatDelimited.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1929:7: rowFormatSerde
                    {
                    pushFollow(FOLLOW_rowFormatSerde_in_tableRowFormat11386);
                    rowFormatSerde713=rowFormatSerde();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_rowFormatSerde.add(rowFormatSerde713.getTree());

                    // AST REWRITE
                    // elements: rowFormatSerde
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1930:5: -> ^( TOK_TABLESERIALIZER rowFormatSerde )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1930:8: ^( TOK_TABLESERIALIZER rowFormatSerde )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_TABLESERIALIZER, "TOK_TABLESERIALIZER")
                        , root_1);

                        adaptor.addChild(root_1, stream_rowFormatSerde.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableRowFormat"


    public static class tablePropertiesPrefixed_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tablePropertiesPrefixed"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1933:1: tablePropertiesPrefixed : KW_TBLPROPERTIES ! tableProperties ;
    public final HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed() throws RecognitionException {
        HiveParser.tablePropertiesPrefixed_return retval = new HiveParser.tablePropertiesPrefixed_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_TBLPROPERTIES714=null;
        HiveParser.tableProperties_return tableProperties715 =null;


        ASTNode KW_TBLPROPERTIES714_tree=null;

         pushMsg("table properties with prefix", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1936:5: ( KW_TBLPROPERTIES ! tableProperties )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1937:9: KW_TBLPROPERTIES ! tableProperties
            {
            root_0 = (ASTNode)adaptor.nil();


            KW_TBLPROPERTIES714=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_tablePropertiesPrefixed11433); if (state.failed) return retval;

            pushFollow(FOLLOW_tableProperties_in_tablePropertiesPrefixed11436);
            tableProperties715=tableProperties();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) adaptor.addChild(root_0, tableProperties715.getTree());

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tablePropertiesPrefixed"


    public static class tableProperties_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableProperties"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1940:1: tableProperties : LPAREN tablePropertiesList RPAREN -> ^( TOK_TABLEPROPERTIES tablePropertiesList ) ;
    public final HiveParser.tableProperties_return tableProperties() throws RecognitionException {
        HiveParser.tableProperties_return retval = new HiveParser.tableProperties_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token LPAREN716=null;
        Token RPAREN718=null;
        HiveParser.tablePropertiesList_return tablePropertiesList717 =null;


        ASTNode LPAREN716_tree=null;
        ASTNode RPAREN718_tree=null;
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleSubtreeStream stream_tablePropertiesList=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesList");
         pushMsg("table properties", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1943:5: ( LPAREN tablePropertiesList RPAREN -> ^( TOK_TABLEPROPERTIES tablePropertiesList ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1944:7: LPAREN tablePropertiesList RPAREN
            {
            LPAREN716=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableProperties11469); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN716);


            pushFollow(FOLLOW_tablePropertiesList_in_tableProperties11471);
            tablePropertiesList717=tablePropertiesList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tablePropertiesList.add(tablePropertiesList717.getTree());

            RPAREN718=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableProperties11473); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN718);


            // AST REWRITE
            // elements: tablePropertiesList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1944:41: -> ^( TOK_TABLEPROPERTIES tablePropertiesList )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1944:44: ^( TOK_TABLEPROPERTIES tablePropertiesList )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABLEPROPERTIES, "TOK_TABLEPROPERTIES")
                , root_1);

                adaptor.addChild(root_1, stream_tablePropertiesList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableProperties"


    public static class tablePropertiesList_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tablePropertiesList"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1947:1: tablePropertiesList : ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ ) | keyProperty ( COMMA keyProperty )* -> ^( TOK_TABLEPROPLIST ( keyProperty )+ ) );
    public final HiveParser.tablePropertiesList_return tablePropertiesList() throws RecognitionException {
        HiveParser.tablePropertiesList_return retval = new HiveParser.tablePropertiesList_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token COMMA720=null;
        Token COMMA723=null;
        HiveParser.keyValueProperty_return keyValueProperty719 =null;

        HiveParser.keyValueProperty_return keyValueProperty721 =null;

        HiveParser.keyProperty_return keyProperty722 =null;

        HiveParser.keyProperty_return keyProperty724 =null;


        ASTNode COMMA720_tree=null;
        ASTNode COMMA723_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_keyValueProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyValueProperty");
        RewriteRuleSubtreeStream stream_keyProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyProperty");
         pushMsg("table properties list", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1950:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ ) | keyProperty ( COMMA keyProperty )* -> ^( TOK_TABLEPROPLIST ( keyProperty )+ ) )
            int alt216=2;
            switch ( input.LA(1) ) {
            case StringLiteral:
                {
                switch ( input.LA(2) ) {
                case EQUAL:
                    {
                    alt216=1;
                    }
                    break;
                case COMMA:
                case RPAREN:
                    {
                    alt216=2;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 216, 1, input);

                    throw nvae;

                }

                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 216, 0, input);

                throw nvae;

            }

            switch (alt216) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1951:7: keyValueProperty ( COMMA keyValueProperty )*
                    {
                    pushFollow(FOLLOW_keyValueProperty_in_tablePropertiesList11514);
                    keyValueProperty719=keyValueProperty();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty719.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1951:24: ( COMMA keyValueProperty )*
                    loop214:
                    do {
                        int alt214=2;
                        switch ( input.LA(1) ) {
                        case COMMA:
                            {
                            alt214=1;
                            }
                            break;

                        }

                        switch (alt214) {
                    	case 1 :
                    	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1951:25: COMMA keyValueProperty
                    	    {
                    	    COMMA720=(Token)match(input,COMMA,FOLLOW_COMMA_in_tablePropertiesList11517); if (state.failed) return retval; 
                    	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA720);


                    	    pushFollow(FOLLOW_keyValueProperty_in_tablePropertiesList11519);
                    	    keyValueProperty721=keyValueProperty();

                    	    state._fsp--;
                    	    if (state.failed) return retval;
                    	    if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty721.getTree());

                    	    }
                    	    break;

                    	default :
                    	    break loop214;
                        }
                    } while (true);


                    // AST REWRITE
                    // elements: keyValueProperty
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1951:50: -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1951:53: ^( TOK_TABLEPROPLIST ( keyValueProperty )+ )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_TABLEPROPLIST, "TOK_TABLEPROPLIST")
                        , root_1);

                        if ( !(stream_keyValueProperty.hasNext()) ) {
                            throw new RewriteEarlyExitException();
                        }
                        while ( stream_keyValueProperty.hasNext() ) {
                            adaptor.addChild(root_1, stream_keyValueProperty.nextTree());

                        }
                        stream_keyValueProperty.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1953:7: keyProperty ( COMMA keyProperty )*
                    {
                    pushFollow(FOLLOW_keyProperty_in_tablePropertiesList11544);
                    keyProperty722=keyProperty();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_keyProperty.add(keyProperty722.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1953:19: ( COMMA keyProperty )*
                    loop215:
                    do {
                        int alt215=2;
                        switch ( input.LA(1) ) {
                        case COMMA:
                            {
                            alt215=1;
                            }
                            break;

                        }

                        switch (alt215) {
                    	case 1 :
                    	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1953:20: COMMA keyProperty
                    	    {
                    	    COMMA723=(Token)match(input,COMMA,FOLLOW_COMMA_in_tablePropertiesList11547); if (state.failed) return retval; 
                    	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA723);


                    	    pushFollow(FOLLOW_keyProperty_in_tablePropertiesList11549);
                    	    keyProperty724=keyProperty();

                    	    state._fsp--;
                    	    if (state.failed) return retval;
                    	    if ( state.backtracking==0 ) stream_keyProperty.add(keyProperty724.getTree());

                    	    }
                    	    break;

                    	default :
                    	    break loop215;
                        }
                    } while (true);


                    // AST REWRITE
                    // elements: keyProperty
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 1953:40: -> ^( TOK_TABLEPROPLIST ( keyProperty )+ )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1953:43: ^( TOK_TABLEPROPLIST ( keyProperty )+ )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_TABLEPROPLIST, "TOK_TABLEPROPLIST")
                        , root_1);

                        if ( !(stream_keyProperty.hasNext()) ) {
                            throw new RewriteEarlyExitException();
                        }
                        while ( stream_keyProperty.hasNext() ) {
                            adaptor.addChild(root_1, stream_keyProperty.nextTree());

                        }
                        stream_keyProperty.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tablePropertiesList"


    public static class keyValueProperty_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "keyValueProperty"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1956:1: keyValueProperty : key= StringLiteral EQUAL value= StringLiteral -> ^( TOK_TABLEPROPERTY $key $value) ;
    public final HiveParser.keyValueProperty_return keyValueProperty() throws RecognitionException {
        HiveParser.keyValueProperty_return retval = new HiveParser.keyValueProperty_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token key=null;
        Token value=null;
        Token EQUAL725=null;

        ASTNode key_tree=null;
        ASTNode value_tree=null;
        ASTNode EQUAL725_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_EQUAL=new RewriteRuleTokenStream(adaptor,"token EQUAL");

         pushMsg("specifying key/value property", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1959:5: (key= StringLiteral EQUAL value= StringLiteral -> ^( TOK_TABLEPROPERTY $key $value) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1960:7: key= StringLiteral EQUAL value= StringLiteral
            {
            key=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_keyValueProperty11595); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(key);


            EQUAL725=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_keyValueProperty11597); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_EQUAL.add(EQUAL725);


            value=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_keyValueProperty11601); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(value);


            // AST REWRITE
            // elements: value, key
            // token labels: value, key
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_value=new RewriteRuleTokenStream(adaptor,"token value",value);
            RewriteRuleTokenStream stream_key=new RewriteRuleTokenStream(adaptor,"token key",key);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1960:51: -> ^( TOK_TABLEPROPERTY $key $value)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1960:54: ^( TOK_TABLEPROPERTY $key $value)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABLEPROPERTY, "TOK_TABLEPROPERTY")
                , root_1);

                adaptor.addChild(root_1, stream_key.nextNode());

                adaptor.addChild(root_1, stream_value.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "keyValueProperty"


    public static class keyProperty_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "keyProperty"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1963:1: keyProperty : key= StringLiteral -> ^( TOK_TABLEPROPERTY $key TOK_NULL ) ;
    public final HiveParser.keyProperty_return keyProperty() throws RecognitionException {
        HiveParser.keyProperty_return retval = new HiveParser.keyProperty_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token key=null;

        ASTNode key_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");

         pushMsg("specifying key property", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1966:5: (key= StringLiteral -> ^( TOK_TABLEPROPERTY $key TOK_NULL ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1967:7: key= StringLiteral
            {
            key=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_keyProperty11648); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(key);


            // AST REWRITE
            // elements: key
            // token labels: key
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_key=new RewriteRuleTokenStream(adaptor,"token key",key);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1967:25: -> ^( TOK_TABLEPROPERTY $key TOK_NULL )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1967:28: ^( TOK_TABLEPROPERTY $key TOK_NULL )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABLEPROPERTY, "TOK_TABLEPROPERTY")
                , root_1);

                adaptor.addChild(root_1, stream_key.nextNode());

                adaptor.addChild(root_1, 
                (ASTNode)adaptor.create(TOK_NULL, "TOK_NULL")
                );

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "keyProperty"


    public static class tableRowFormatFieldIdentifier_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableRowFormatFieldIdentifier"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1970:1: tableRowFormatFieldIdentifier : KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )? -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? ) ;
    public final HiveParser.tableRowFormatFieldIdentifier_return tableRowFormatFieldIdentifier() throws RecognitionException {
        HiveParser.tableRowFormatFieldIdentifier_return retval = new HiveParser.tableRowFormatFieldIdentifier_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token fldIdnt=null;
        Token fldEscape=null;
        Token KW_FIELDS726=null;
        Token KW_TERMINATED727=null;
        Token KW_BY728=null;
        Token KW_ESCAPED729=null;
        Token KW_BY730=null;

        ASTNode fldIdnt_tree=null;
        ASTNode fldEscape_tree=null;
        ASTNode KW_FIELDS726_tree=null;
        ASTNode KW_TERMINATED727_tree=null;
        ASTNode KW_BY728_tree=null;
        ASTNode KW_ESCAPED729_tree=null;
        ASTNode KW_BY730_tree=null;
        RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
        RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_ESCAPED=new RewriteRuleTokenStream(adaptor,"token KW_ESCAPED");
        RewriteRuleTokenStream stream_KW_FIELDS=new RewriteRuleTokenStream(adaptor,"token KW_FIELDS");

         pushMsg("table row format's field separator", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1973:5: ( KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )? -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1974:7: KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )?
            {
            KW_FIELDS726=(Token)match(input,KW_FIELDS,FOLLOW_KW_FIELDS_in_tableRowFormatFieldIdentifier11692); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FIELDS.add(KW_FIELDS726);


            KW_TERMINATED727=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatFieldIdentifier11694); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TERMINATED.add(KW_TERMINATED727);


            KW_BY728=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier11696); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY728);


            fldIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier11700); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(fldIdnt);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1974:59: ( KW_ESCAPED KW_BY fldEscape= StringLiteral )?
            int alt217=2;
            switch ( input.LA(1) ) {
                case KW_ESCAPED:
                    {
                    alt217=1;
                    }
                    break;
            }

            switch (alt217) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1974:60: KW_ESCAPED KW_BY fldEscape= StringLiteral
                    {
                    KW_ESCAPED729=(Token)match(input,KW_ESCAPED,FOLLOW_KW_ESCAPED_in_tableRowFormatFieldIdentifier11703); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ESCAPED.add(KW_ESCAPED729);


                    KW_BY730=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier11705); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY730);


                    fldEscape=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier11709); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(fldEscape);


                    }
                    break;

            }


            // AST REWRITE
            // elements: fldIdnt, fldEscape
            // token labels: fldIdnt, fldEscape
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_fldIdnt=new RewriteRuleTokenStream(adaptor,"token fldIdnt",fldIdnt);
            RewriteRuleTokenStream stream_fldEscape=new RewriteRuleTokenStream(adaptor,"token fldEscape",fldEscape);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1975:5: -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1975:8: ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABLEROWFORMATFIELD, "TOK_TABLEROWFORMATFIELD")
                , root_1);

                adaptor.addChild(root_1, stream_fldIdnt.nextNode());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1975:44: ( $fldEscape)?
                if ( stream_fldEscape.hasNext() ) {
                    adaptor.addChild(root_1, stream_fldEscape.nextNode());

                }
                stream_fldEscape.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableRowFormatFieldIdentifier"


    public static class tableRowFormatCollItemsIdentifier_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableRowFormatCollItemsIdentifier"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1978:1: tableRowFormatCollItemsIdentifier : KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt) ;
    public final HiveParser.tableRowFormatCollItemsIdentifier_return tableRowFormatCollItemsIdentifier() throws RecognitionException {
        HiveParser.tableRowFormatCollItemsIdentifier_return retval = new HiveParser.tableRowFormatCollItemsIdentifier_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token collIdnt=null;
        Token KW_COLLECTION731=null;
        Token KW_ITEMS732=null;
        Token KW_TERMINATED733=null;
        Token KW_BY734=null;

        ASTNode collIdnt_tree=null;
        ASTNode KW_COLLECTION731_tree=null;
        ASTNode KW_ITEMS732_tree=null;
        ASTNode KW_TERMINATED733_tree=null;
        ASTNode KW_BY734_tree=null;
        RewriteRuleTokenStream stream_KW_COLLECTION=new RewriteRuleTokenStream(adaptor,"token KW_COLLECTION");
        RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
        RewriteRuleTokenStream stream_KW_ITEMS=new RewriteRuleTokenStream(adaptor,"token KW_ITEMS");
        RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");

         pushMsg("table row format's column separator", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1981:5: ( KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1982:7: KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral
            {
            KW_COLLECTION731=(Token)match(input,KW_COLLECTION,FOLLOW_KW_COLLECTION_in_tableRowFormatCollItemsIdentifier11761); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_COLLECTION.add(KW_COLLECTION731);


            KW_ITEMS732=(Token)match(input,KW_ITEMS,FOLLOW_KW_ITEMS_in_tableRowFormatCollItemsIdentifier11763); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ITEMS.add(KW_ITEMS732);


            KW_TERMINATED733=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatCollItemsIdentifier11765); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TERMINATED.add(KW_TERMINATED733);


            KW_BY734=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatCollItemsIdentifier11767); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY734);


            collIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatCollItemsIdentifier11771); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(collIdnt);


            // AST REWRITE
            // elements: collIdnt
            // token labels: collIdnt
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_collIdnt=new RewriteRuleTokenStream(adaptor,"token collIdnt",collIdnt);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1983:5: -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1983:8: ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABLEROWFORMATCOLLITEMS, "TOK_TABLEROWFORMATCOLLITEMS")
                , root_1);

                adaptor.addChild(root_1, stream_collIdnt.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableRowFormatCollItemsIdentifier"


    public static class tableRowFormatMapKeysIdentifier_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableRowFormatMapKeysIdentifier"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1986:1: tableRowFormatMapKeysIdentifier : KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt) ;
    public final HiveParser.tableRowFormatMapKeysIdentifier_return tableRowFormatMapKeysIdentifier() throws RecognitionException {
        HiveParser.tableRowFormatMapKeysIdentifier_return retval = new HiveParser.tableRowFormatMapKeysIdentifier_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token mapKeysIdnt=null;
        Token KW_MAP735=null;
        Token KW_KEYS736=null;
        Token KW_TERMINATED737=null;
        Token KW_BY738=null;

        ASTNode mapKeysIdnt_tree=null;
        ASTNode KW_MAP735_tree=null;
        ASTNode KW_KEYS736_tree=null;
        ASTNode KW_TERMINATED737_tree=null;
        ASTNode KW_BY738_tree=null;
        RewriteRuleTokenStream stream_KW_KEYS=new RewriteRuleTokenStream(adaptor,"token KW_KEYS");
        RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
        RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_MAP=new RewriteRuleTokenStream(adaptor,"token KW_MAP");

         pushMsg("table row format's map key separator", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1989:5: ( KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1990:7: KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral
            {
            KW_MAP735=(Token)match(input,KW_MAP,FOLLOW_KW_MAP_in_tableRowFormatMapKeysIdentifier11817); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_MAP.add(KW_MAP735);


            KW_KEYS736=(Token)match(input,KW_KEYS,FOLLOW_KW_KEYS_in_tableRowFormatMapKeysIdentifier11819); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_KEYS.add(KW_KEYS736);


            KW_TERMINATED737=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatMapKeysIdentifier11821); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TERMINATED.add(KW_TERMINATED737);


            KW_BY738=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatMapKeysIdentifier11823); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY738);


            mapKeysIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatMapKeysIdentifier11827); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(mapKeysIdnt);


            // AST REWRITE
            // elements: mapKeysIdnt
            // token labels: mapKeysIdnt
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_mapKeysIdnt=new RewriteRuleTokenStream(adaptor,"token mapKeysIdnt",mapKeysIdnt);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1991:5: -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1991:8: ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABLEROWFORMATMAPKEYS, "TOK_TABLEROWFORMATMAPKEYS")
                , root_1);

                adaptor.addChild(root_1, stream_mapKeysIdnt.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableRowFormatMapKeysIdentifier"


    public static class tableRowFormatLinesIdentifier_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableRowFormatLinesIdentifier"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:1994:1: tableRowFormatLinesIdentifier : KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATLINES $linesIdnt) ;
    public final HiveParser.tableRowFormatLinesIdentifier_return tableRowFormatLinesIdentifier() throws RecognitionException {
        HiveParser.tableRowFormatLinesIdentifier_return retval = new HiveParser.tableRowFormatLinesIdentifier_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token linesIdnt=null;
        Token KW_LINES739=null;
        Token KW_TERMINATED740=null;
        Token KW_BY741=null;

        ASTNode linesIdnt_tree=null;
        ASTNode KW_LINES739_tree=null;
        ASTNode KW_TERMINATED740_tree=null;
        ASTNode KW_BY741_tree=null;
        RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
        RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_LINES=new RewriteRuleTokenStream(adaptor,"token KW_LINES");

         pushMsg("table row format's line separator", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1997:5: ( KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATLINES $linesIdnt) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1998:7: KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral
            {
            KW_LINES739=(Token)match(input,KW_LINES,FOLLOW_KW_LINES_in_tableRowFormatLinesIdentifier11873); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_LINES.add(KW_LINES739);


            KW_TERMINATED740=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatLinesIdentifier11875); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TERMINATED.add(KW_TERMINATED740);


            KW_BY741=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatLinesIdentifier11877); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY741);


            linesIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatLinesIdentifier11881); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(linesIdnt);


            // AST REWRITE
            // elements: linesIdnt
            // token labels: linesIdnt
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_linesIdnt=new RewriteRuleTokenStream(adaptor,"token linesIdnt",linesIdnt);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 1999:5: -> ^( TOK_TABLEROWFORMATLINES $linesIdnt)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1999:8: ^( TOK_TABLEROWFORMATLINES $linesIdnt)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABLEROWFORMATLINES, "TOK_TABLEROWFORMATLINES")
                , root_1);

                adaptor.addChild(root_1, stream_linesIdnt.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableRowFormatLinesIdentifier"


    public static class tableRowNullFormat_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableRowNullFormat"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2002:1: tableRowNullFormat : KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATNULL $nullIdnt) ;
    public final HiveParser.tableRowNullFormat_return tableRowNullFormat() throws RecognitionException {
        HiveParser.tableRowNullFormat_return retval = new HiveParser.tableRowNullFormat_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token nullIdnt=null;
        Token KW_NULL742=null;
        Token KW_DEFINED743=null;
        Token KW_AS744=null;

        ASTNode nullIdnt_tree=null;
        ASTNode KW_NULL742_tree=null;
        ASTNode KW_DEFINED743_tree=null;
        ASTNode KW_AS744_tree=null;
        RewriteRuleTokenStream stream_KW_NULL=new RewriteRuleTokenStream(adaptor,"token KW_NULL");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleTokenStream stream_KW_DEFINED=new RewriteRuleTokenStream(adaptor,"token KW_DEFINED");

         pushMsg("table row format's null specifier", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2005:5: ( KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATNULL $nullIdnt) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2006:7: KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral
            {
            KW_NULL742=(Token)match(input,KW_NULL,FOLLOW_KW_NULL_in_tableRowNullFormat11927); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_NULL.add(KW_NULL742);


            KW_DEFINED743=(Token)match(input,KW_DEFINED,FOLLOW_KW_DEFINED_in_tableRowNullFormat11929); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DEFINED.add(KW_DEFINED743);


            KW_AS744=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableRowNullFormat11931); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS744);


            nullIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowNullFormat11935); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(nullIdnt);


            // AST REWRITE
            // elements: nullIdnt
            // token labels: nullIdnt
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_nullIdnt=new RewriteRuleTokenStream(adaptor,"token nullIdnt",nullIdnt);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2007:5: -> ^( TOK_TABLEROWFORMATNULL $nullIdnt)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2007:8: ^( TOK_TABLEROWFORMATNULL $nullIdnt)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABLEROWFORMATNULL, "TOK_TABLEROWFORMATNULL")
                , root_1);

                adaptor.addChild(root_1, stream_nullIdnt.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableRowNullFormat"


    public static class tableFileFormat_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableFileFormat"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2009:1: tableFileFormat : ( ( KW_STORED KW_AS KW_INPUTFORMAT )=> KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? ) | KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? ) | KW_STORED KW_AS genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) );
    public final HiveParser.tableFileFormat_return tableFileFormat() throws RecognitionException {
        HiveParser.tableFileFormat_return retval = new HiveParser.tableFileFormat_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token inFmt=null;
        Token outFmt=null;
        Token inDriver=null;
        Token outDriver=null;
        Token storageHandler=null;
        Token KW_STORED745=null;
        Token KW_AS746=null;
        Token KW_INPUTFORMAT747=null;
        Token KW_OUTPUTFORMAT748=null;
        Token KW_INPUTDRIVER749=null;
        Token KW_OUTPUTDRIVER750=null;
        Token KW_STORED751=null;
        Token KW_BY752=null;
        Token KW_WITH753=null;
        Token KW_SERDEPROPERTIES754=null;
        Token KW_STORED755=null;
        Token KW_AS756=null;
        HiveParser.tableProperties_return serdeprops =null;

        HiveParser_IdentifiersParser.identifier_return genericSpec =null;


        ASTNode inFmt_tree=null;
        ASTNode outFmt_tree=null;
        ASTNode inDriver_tree=null;
        ASTNode outDriver_tree=null;
        ASTNode storageHandler_tree=null;
        ASTNode KW_STORED745_tree=null;
        ASTNode KW_AS746_tree=null;
        ASTNode KW_INPUTFORMAT747_tree=null;
        ASTNode KW_OUTPUTFORMAT748_tree=null;
        ASTNode KW_INPUTDRIVER749_tree=null;
        ASTNode KW_OUTPUTDRIVER750_tree=null;
        ASTNode KW_STORED751_tree=null;
        ASTNode KW_BY752_tree=null;
        ASTNode KW_WITH753_tree=null;
        ASTNode KW_SERDEPROPERTIES754_tree=null;
        ASTNode KW_STORED755_tree=null;
        ASTNode KW_AS756_tree=null;
        RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
        RewriteRuleTokenStream stream_KW_INPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_INPUTFORMAT");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleTokenStream stream_KW_SERDEPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_SERDEPROPERTIES");
        RewriteRuleTokenStream stream_KW_INPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_INPUTDRIVER");
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleTokenStream stream_KW_OUTPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTFORMAT");
        RewriteRuleTokenStream stream_KW_STORED=new RewriteRuleTokenStream(adaptor,"token KW_STORED");
        RewriteRuleTokenStream stream_KW_OUTPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTDRIVER");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
         pushMsg("table file format specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2012:5: ( ( KW_STORED KW_AS KW_INPUTFORMAT )=> KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? ) | KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? ) | KW_STORED KW_AS genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) )
            int alt220=3;
            switch ( input.LA(1) ) {
            case KW_STORED:
                {
                switch ( input.LA(2) ) {
                case KW_AS:
                    {
                    switch ( input.LA(3) ) {
                    case KW_INPUTFORMAT:
                        {
                        int LA220_4 = input.LA(4);

                        if ( (synpred18_HiveParser()) ) {
                            alt220=1;
                        }
                        else if ( (true) ) {
                            alt220=3;
                        }
                        else {
                            if (state.backtracking>0) {state.failed=true; return retval;}
                            NoViableAltException nvae =
                                new NoViableAltException("", 220, 4, input);

                            throw nvae;

                        }
                        }
                        break;
                    case Identifier:
                    case KW_ABORT:
                    case KW_ADD:
                    case KW_ADMIN:
                    case KW_AFTER:
                    case KW_ALL:
                    case KW_ALTER:
                    case KW_ANALYZE:
                    case KW_ARCHIVE:
                    case KW_ARRAY:
                    case KW_AS:
                    case KW_ASC:
                    case KW_AUTHORIZATION:
                    case KW_AUTOCOMMIT:
                    case KW_BEFORE:
                    case KW_BETWEEN:
                    case KW_BIGINT:
                    case KW_BINARY:
                    case KW_BOOLEAN:
                    case KW_BOTH:
                    case KW_BUCKET:
                    case KW_BUCKETS:
                    case KW_BY:
                    case KW_CACHE:
                    case KW_CASCADE:
                    case KW_CHANGE:
                    case KW_CLUSTER:
                    case KW_CLUSTERED:
                    case KW_CLUSTERSTATUS:
                    case KW_COLLECTION:
                    case KW_COLUMNS:
                    case KW_COMMENT:
                    case KW_COMPACT:
                    case KW_COMPACTIONS:
                    case KW_COMPUTE:
                    case KW_CONCATENATE:
                    case KW_CONSTRAINT:
                    case KW_CONTINUE:
                    case KW_CREATE:
                    case KW_CUBE:
                    case KW_CURRENT_DATE:
                    case KW_CURRENT_TIMESTAMP:
                    case KW_CURSOR:
                    case KW_DATA:
                    case KW_DATABASES:
                    case KW_DATE:
                    case KW_DATETIME:
                    case KW_DAY:
                    case KW_DBPROPERTIES:
                    case KW_DECIMAL:
                    case KW_DEFERRED:
                    case KW_DEFINED:
                    case KW_DELETE:
                    case KW_DELIMITED:
                    case KW_DEPENDENCY:
                    case KW_DESC:
                    case KW_DESCRIBE:
                    case KW_DIRECTORIES:
                    case KW_DIRECTORY:
                    case KW_DISABLE:
                    case KW_DISTRIBUTE:
                    case KW_DOUBLE:
                    case KW_DOW:
                    case KW_DROP:
                    case KW_DUMP:
                    case KW_ELEM_TYPE:
                    case KW_ENABLE:
                    case KW_ESCAPED:
                    case KW_EXCLUSIVE:
                    case KW_EXISTS:
                    case KW_EXPLAIN:
                    case KW_EXPORT:
                    case KW_EXTERNAL:
                    case KW_FALSE:
                    case KW_FETCH:
                    case KW_FIELDS:
                    case KW_FILE:
                    case KW_FILEFORMAT:
                    case KW_FIRST:
                    case KW_FLOAT:
                    case KW_FOR:
                    case KW_FOREIGN:
                    case KW_FORMAT:
                    case KW_FORMATTED:
                    case KW_FULL:
                    case KW_FUNCTIONS:
                    case KW_GRANT:
                    case KW_GROUP:
                    case KW_GROUPING:
                    case KW_HOUR:
                    case KW_IDXPROPERTIES:
                    case KW_IMPORT:
                    case KW_IN:
                    case KW_INDEX:
                    case KW_INDEXES:
                    case KW_INNER:
                    case KW_INPATH:
                    case KW_INPUTDRIVER:
                    case KW_INSERT:
                    case KW_INT:
                    case KW_INTERSECT:
                    case KW_INTO:
                    case KW_IS:
                    case KW_ISOLATION:
                    case KW_ITEMS:
                    case KW_JAR:
                    case KW_KEY:
                    case KW_KEYS:
                    case KW_KEY_TYPE:
                    case KW_LAST:
                    case KW_LATERAL:
                    case KW_LEFT:
                    case KW_LEVEL:
                    case KW_LIKE:
                    case KW_LIMIT:
                    case KW_LINES:
                    case KW_LOAD:
                    case KW_LOCAL:
                    case KW_LOCATION:
                    case KW_LOCK:
                    case KW_LOCKS:
                    case KW_LOGICAL:
                    case KW_LONG:
                    case KW_MAPJOIN:
                    case KW_MATCHED:
                    case KW_MATERIALIZED:
                    case KW_MERGE:
                    case KW_METADATA:
                    case KW_MINUTE:
                    case KW_MONTH:
                    case KW_MSCK:
                    case KW_NONE:
                    case KW_NORELY:
                    case KW_NOSCAN:
                    case KW_NOVALIDATE:
                    case KW_NULL:
                    case KW_NULLS:
                    case KW_OF:
                    case KW_OFFSET:
                    case KW_OPTION:
                    case KW_ORDER:
                    case KW_OUT:
                    case KW_OUTER:
                    case KW_OUTPUTDRIVER:
                    case KW_OUTPUTFORMAT:
                    case KW_OVERWRITE:
                    case KW_OWNER:
                    case KW_PARTITION:
                    case KW_PARTITIONED:
                    case KW_PARTITIONS:
                    case KW_PERCENT:
                    case KW_PLUS:
                    case KW_PRETTY:
                    case KW_PRIMARY:
                    case KW_PRINCIPALS:
                    case KW_PROCEDURE:
                    case KW_PURGE:
                    case KW_QUARTER:
                    case KW_RANGE:
                    case KW_READ:
                    case KW_READS:
                    case KW_REBUILD:
                    case KW_RECORDREADER:
                    case KW_RECORDWRITER:
                    case KW_REFERENCES:
                    case KW_REGEXP:
                    case KW_RELOAD:
                    case KW_RELY:
                    case KW_RENAME:
                    case KW_REPAIR:
                    case KW_REPL:
                    case KW_REPLACE:
                    case KW_REPLICATION:
                    case KW_RESTRICT:
                    case KW_REVOKE:
                    case KW_REWRITE:
                    case KW_RIGHT:
                    case KW_RLIKE:
                    case KW_ROLE:
                    case KW_ROLES:
                    case KW_ROLLUP:
                    case KW_ROW:
                    case KW_ROWS:
                    case KW_SCHEMA:
                    case KW_SCHEMAS:
                    case KW_SECOND:
                    case KW_SEMI:
                    case KW_SERDE:
                    case KW_SERDEPROPERTIES:
                    case KW_SERVER:
                    case KW_SET:
                    case KW_SETS:
                    case KW_SHARED:
                    case KW_SHOW:
                    case KW_SHOW_DATABASE:
                    case KW_SKEWED:
                    case KW_SMALLINT:
                    case KW_SNAPSHOT:
                    case KW_SORT:
                    case KW_SORTED:
                    case KW_SSL:
                    case KW_STATISTICS:
                    case KW_STATUS:
                    case KW_STORED:
                    case KW_STREAMTABLE:
                    case KW_STRING:
                    case KW_STRUCT:
                    case KW_TABLE:
                    case KW_TABLES:
                    case KW_TBLPROPERTIES:
                    case KW_TEMPORARY:
                    case KW_TERMINATED:
                    case KW_TIMESTAMP:
                    case KW_TINYINT:
                    case KW_TO:
                    case KW_TOUCH:
                    case KW_TRANSACTION:
                    case KW_TRANSACTIONS:
                    case KW_TRIGGER:
                    case KW_TRUE:
                    case KW_TRUNCATE:
                    case KW_UNARCHIVE:
                    case KW_UNDO:
                    case KW_UNION:
                    case KW_UNIONTYPE:
                    case KW_UNLOCK:
                    case KW_UNSET:
                    case KW_UNSIGNED:
                    case KW_UPDATE:
                    case KW_URI:
                    case KW_USE:
                    case KW_USER:
                    case KW_USING:
                    case KW_UTC:
                    case KW_UTCTIMESTAMP:
                    case KW_VALIDATE:
                    case KW_VALUES:
                    case KW_VALUE_TYPE:
                    case KW_VIEW:
                    case KW_VIEWS:
                    case KW_WEEK:
                    case KW_WHILE:
                    case KW_WITH:
                    case KW_WORK:
                    case KW_WRITE:
                    case KW_YEAR:
                    case KW_BATCH:
                    case KW_DAYOFWEEK:
                    case KW_HOLD_DDLTIME:
                    case KW_IGNORE:
                    case KW_NO_DROP:
                    case KW_OFFLINE:
                    case KW_PROTECTION:
                    case KW_READONLY:
                        {
                        alt220=3;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 220, 2, input);

                        throw nvae;

                    }

                    }
                    break;
                case KW_BY:
                    {
                    alt220=2;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 220, 1, input);

                    throw nvae;

                }

                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 220, 0, input);

                throw nvae;

            }

            switch (alt220) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2013:7: ( KW_STORED KW_AS KW_INPUTFORMAT )=> KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
                    {
                    KW_STORED745=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat11990); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED745);


                    KW_AS746=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableFileFormat11992); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS746);


                    KW_INPUTFORMAT747=(Token)match(input,KW_INPUTFORMAT,FOLLOW_KW_INPUTFORMAT_in_tableFileFormat11994); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_INPUTFORMAT.add(KW_INPUTFORMAT747);


                    inFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat11998); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(inFmt);


                    KW_OUTPUTFORMAT748=(Token)match(input,KW_OUTPUTFORMAT,FOLLOW_KW_OUTPUTFORMAT_in_tableFileFormat12000); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_OUTPUTFORMAT.add(KW_OUTPUTFORMAT748);


                    outFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat12004); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(outFmt);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2013:131: ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
                    int alt218=2;
                    switch ( input.LA(1) ) {
                        case KW_INPUTDRIVER:
                            {
                            alt218=1;
                            }
                            break;
                    }

                    switch (alt218) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2013:132: KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral
                            {
                            KW_INPUTDRIVER749=(Token)match(input,KW_INPUTDRIVER,FOLLOW_KW_INPUTDRIVER_in_tableFileFormat12007); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_INPUTDRIVER.add(KW_INPUTDRIVER749);


                            inDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat12011); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_StringLiteral.add(inDriver);


                            KW_OUTPUTDRIVER750=(Token)match(input,KW_OUTPUTDRIVER,FOLLOW_KW_OUTPUTDRIVER_in_tableFileFormat12013); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_OUTPUTDRIVER.add(KW_OUTPUTDRIVER750);


                            outDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat12017); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_StringLiteral.add(outDriver);


                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: outDriver, outFmt, inDriver, inFmt
                    // token labels: inFmt, inDriver, outDriver, outFmt
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_inFmt=new RewriteRuleTokenStream(adaptor,"token inFmt",inFmt);
                    RewriteRuleTokenStream stream_inDriver=new RewriteRuleTokenStream(adaptor,"token inDriver",inDriver);
                    RewriteRuleTokenStream stream_outDriver=new RewriteRuleTokenStream(adaptor,"token outDriver",outDriver);
                    RewriteRuleTokenStream stream_outFmt=new RewriteRuleTokenStream(adaptor,"token outFmt",outFmt);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2014:7: -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2014:10: ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_TABLEFILEFORMAT, "TOK_TABLEFILEFORMAT")
                        , root_1);

                        adaptor.addChild(root_1, stream_inFmt.nextNode());

                        adaptor.addChild(root_1, stream_outFmt.nextNode());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2014:48: ( $inDriver)?
                        if ( stream_inDriver.hasNext() ) {
                            adaptor.addChild(root_1, stream_inDriver.nextNode());

                        }
                        stream_inDriver.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2014:59: ( $outDriver)?
                        if ( stream_outDriver.hasNext() ) {
                            adaptor.addChild(root_1, stream_outDriver.nextNode());

                        }
                        stream_outDriver.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2015:9: KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
                    {
                    KW_STORED751=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat12055); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED751);


                    KW_BY752=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableFileFormat12057); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY752);


                    storageHandler=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat12061); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(storageHandler);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2016:10: ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
                    int alt219=2;
                    switch ( input.LA(1) ) {
                        case KW_WITH:
                            {
                            alt219=1;
                            }
                            break;
                    }

                    switch (alt219) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2016:11: KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties
                            {
                            KW_WITH753=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_tableFileFormat12073); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH753);


                            KW_SERDEPROPERTIES754=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat12075); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES754);


                            pushFollow(FOLLOW_tableProperties_in_tableFileFormat12079);
                            serdeprops=tableProperties();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tableProperties.add(serdeprops.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: storageHandler, serdeprops
                    // token labels: storageHandler
                    // rule labels: serdeprops, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_storageHandler=new RewriteRuleTokenStream(adaptor,"token storageHandler",storageHandler);
                    RewriteRuleSubtreeStream stream_serdeprops=new RewriteRuleSubtreeStream(adaptor,"rule serdeprops",serdeprops!=null?serdeprops.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2017:7: -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2017:10: ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_STORAGEHANDLER, "TOK_STORAGEHANDLER")
                        , root_1);

                        adaptor.addChild(root_1, stream_storageHandler.nextNode());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2017:48: ( $serdeprops)?
                        if ( stream_serdeprops.hasNext() ) {
                            adaptor.addChild(root_1, stream_serdeprops.nextTree());

                        }
                        stream_serdeprops.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2018:9: KW_STORED KW_AS genericSpec= identifier
                    {
                    KW_STORED755=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat12110); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED755);


                    KW_AS756=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableFileFormat12112); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS756);


                    pushFollow(FOLLOW_identifier_in_tableFileFormat12116);
                    genericSpec=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_identifier.add(genericSpec.getTree());

                    // AST REWRITE
                    // elements: genericSpec
                    // token labels: 
                    // rule labels: genericSpec, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_genericSpec=new RewriteRuleSubtreeStream(adaptor,"rule genericSpec",genericSpec!=null?genericSpec.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2019:7: -> ^( TOK_FILEFORMAT_GENERIC $genericSpec)
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2019:10: ^( TOK_FILEFORMAT_GENERIC $genericSpec)
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_FILEFORMAT_GENERIC, "TOK_FILEFORMAT_GENERIC")
                        , root_1);

                        adaptor.addChild(root_1, stream_genericSpec.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableFileFormat"


    public static class tableLocation_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableLocation"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2022:1: tableLocation : KW_LOCATION locn= StringLiteral -> ^( TOK_TABLELOCATION $locn) ;
    public final HiveParser.tableLocation_return tableLocation() throws RecognitionException {
        HiveParser.tableLocation_return retval = new HiveParser.tableLocation_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token locn=null;
        Token KW_LOCATION757=null;

        ASTNode locn_tree=null;
        ASTNode KW_LOCATION757_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");

         pushMsg("table location specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2025:5: ( KW_LOCATION locn= StringLiteral -> ^( TOK_TABLELOCATION $locn) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2026:7: KW_LOCATION locn= StringLiteral
            {
            KW_LOCATION757=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_tableLocation12164); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION757);


            locn=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableLocation12168); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_StringLiteral.add(locn);


            // AST REWRITE
            // elements: locn
            // token labels: locn
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_locn=new RewriteRuleTokenStream(adaptor,"token locn",locn);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2026:38: -> ^( TOK_TABLELOCATION $locn)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2026:41: ^( TOK_TABLELOCATION $locn)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABLELOCATION, "TOK_TABLELOCATION")
                , root_1);

                adaptor.addChild(root_1, stream_locn.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableLocation"


    public static class columnNameTypeList_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameTypeList"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2029:1: columnNameTypeList : columnNameType ( COMMA columnNameType )* -> ^( TOK_TABCOLLIST ( columnNameType )+ ) ;
    public final HiveParser.columnNameTypeList_return columnNameTypeList() throws RecognitionException {
        HiveParser.columnNameTypeList_return retval = new HiveParser.columnNameTypeList_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token COMMA759=null;
        HiveParser.columnNameType_return columnNameType758 =null;

        HiveParser.columnNameType_return columnNameType760 =null;


        ASTNode COMMA759_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_columnNameType=new RewriteRuleSubtreeStream(adaptor,"rule columnNameType");
         pushMsg("column name type list", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2032:5: ( columnNameType ( COMMA columnNameType )* -> ^( TOK_TABCOLLIST ( columnNameType )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2032:7: columnNameType ( COMMA columnNameType )*
            {
            pushFollow(FOLLOW_columnNameType_in_columnNameTypeList12204);
            columnNameType758=columnNameType();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnNameType.add(columnNameType758.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2032:22: ( COMMA columnNameType )*
            loop221:
            do {
                int alt221=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt221=1;
                    }
                    break;

                }

                switch (alt221) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2032:23: COMMA columnNameType
            	    {
            	    COMMA759=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameTypeList12207); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA759);


            	    pushFollow(FOLLOW_columnNameType_in_columnNameTypeList12209);
            	    columnNameType760=columnNameType();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_columnNameType.add(columnNameType760.getTree());

            	    }
            	    break;

            	default :
            	    break loop221;
                }
            } while (true);


            // AST REWRITE
            // elements: columnNameType
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2032:46: -> ^( TOK_TABCOLLIST ( columnNameType )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2032:49: ^( TOK_TABCOLLIST ( columnNameType )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST")
                , root_1);

                if ( !(stream_columnNameType.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_columnNameType.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameType.nextTree());

                }
                stream_columnNameType.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameTypeList"


    public static class columnNameTypeOrPKOrFKList_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameTypeOrPKOrFKList"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2034:1: columnNameTypeOrPKOrFKList : columnNameTypeOrPKOrFK ( COMMA columnNameTypeOrPKOrFK )* -> ^( TOK_TABCOLLIST ( columnNameTypeOrPKOrFK )+ ) ;
    public final HiveParser.columnNameTypeOrPKOrFKList_return columnNameTypeOrPKOrFKList() throws RecognitionException {
        HiveParser.columnNameTypeOrPKOrFKList_return retval = new HiveParser.columnNameTypeOrPKOrFKList_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token COMMA762=null;
        HiveParser.columnNameTypeOrPKOrFK_return columnNameTypeOrPKOrFK761 =null;

        HiveParser.columnNameTypeOrPKOrFK_return columnNameTypeOrPKOrFK763 =null;


        ASTNode COMMA762_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_columnNameTypeOrPKOrFK=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeOrPKOrFK");
         pushMsg("column name type list with PK and FK", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2037:5: ( columnNameTypeOrPKOrFK ( COMMA columnNameTypeOrPKOrFK )* -> ^( TOK_TABCOLLIST ( columnNameTypeOrPKOrFK )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2037:7: columnNameTypeOrPKOrFK ( COMMA columnNameTypeOrPKOrFK )*
            {
            pushFollow(FOLLOW_columnNameTypeOrPKOrFK_in_columnNameTypeOrPKOrFKList12246);
            columnNameTypeOrPKOrFK761=columnNameTypeOrPKOrFK();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnNameTypeOrPKOrFK.add(columnNameTypeOrPKOrFK761.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2037:30: ( COMMA columnNameTypeOrPKOrFK )*
            loop222:
            do {
                int alt222=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt222=1;
                    }
                    break;

                }

                switch (alt222) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2037:31: COMMA columnNameTypeOrPKOrFK
            	    {
            	    COMMA762=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameTypeOrPKOrFKList12249); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA762);


            	    pushFollow(FOLLOW_columnNameTypeOrPKOrFK_in_columnNameTypeOrPKOrFKList12251);
            	    columnNameTypeOrPKOrFK763=columnNameTypeOrPKOrFK();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_columnNameTypeOrPKOrFK.add(columnNameTypeOrPKOrFK763.getTree());

            	    }
            	    break;

            	default :
            	    break loop222;
                }
            } while (true);


            // AST REWRITE
            // elements: columnNameTypeOrPKOrFK
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2037:62: -> ^( TOK_TABCOLLIST ( columnNameTypeOrPKOrFK )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2037:65: ^( TOK_TABCOLLIST ( columnNameTypeOrPKOrFK )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST")
                , root_1);

                if ( !(stream_columnNameTypeOrPKOrFK.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_columnNameTypeOrPKOrFK.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameTypeOrPKOrFK.nextTree());

                }
                stream_columnNameTypeOrPKOrFK.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameTypeOrPKOrFKList"


    public static class columnNameColonTypeList_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameColonTypeList"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2040:1: columnNameColonTypeList : columnNameColonType ( COMMA columnNameColonType )* -> ^( TOK_TABCOLLIST ( columnNameColonType )+ ) ;
    public final HiveParser.columnNameColonTypeList_return columnNameColonTypeList() throws RecognitionException {
        HiveParser.columnNameColonTypeList_return retval = new HiveParser.columnNameColonTypeList_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token COMMA765=null;
        HiveParser.columnNameColonType_return columnNameColonType764 =null;

        HiveParser.columnNameColonType_return columnNameColonType766 =null;


        ASTNode COMMA765_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_columnNameColonType=new RewriteRuleSubtreeStream(adaptor,"rule columnNameColonType");
         pushMsg("column name type list", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2043:5: ( columnNameColonType ( COMMA columnNameColonType )* -> ^( TOK_TABCOLLIST ( columnNameColonType )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2043:7: columnNameColonType ( COMMA columnNameColonType )*
            {
            pushFollow(FOLLOW_columnNameColonType_in_columnNameColonTypeList12289);
            columnNameColonType764=columnNameColonType();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnNameColonType.add(columnNameColonType764.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2043:27: ( COMMA columnNameColonType )*
            loop223:
            do {
                int alt223=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt223=1;
                    }
                    break;

                }

                switch (alt223) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2043:28: COMMA columnNameColonType
            	    {
            	    COMMA765=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameColonTypeList12292); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA765);


            	    pushFollow(FOLLOW_columnNameColonType_in_columnNameColonTypeList12294);
            	    columnNameColonType766=columnNameColonType();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_columnNameColonType.add(columnNameColonType766.getTree());

            	    }
            	    break;

            	default :
            	    break loop223;
                }
            } while (true);


            // AST REWRITE
            // elements: columnNameColonType
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2043:56: -> ^( TOK_TABCOLLIST ( columnNameColonType )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2043:59: ^( TOK_TABCOLLIST ( columnNameColonType )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST")
                , root_1);

                if ( !(stream_columnNameColonType.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_columnNameColonType.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameColonType.nextTree());

                }
                stream_columnNameColonType.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameColonTypeList"


    public static class columnNameList_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameList"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2046:1: columnNameList : columnName ( COMMA columnName )* -> ^( TOK_TABCOLNAME ( columnName )+ ) ;
    public final HiveParser.columnNameList_return columnNameList() throws RecognitionException {
        HiveParser.columnNameList_return retval = new HiveParser.columnNameList_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token COMMA768=null;
        HiveParser.columnName_return columnName767 =null;

        HiveParser.columnName_return columnName769 =null;


        ASTNode COMMA768_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_columnName=new RewriteRuleSubtreeStream(adaptor,"rule columnName");
         pushMsg("column name list", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2049:5: ( columnName ( COMMA columnName )* -> ^( TOK_TABCOLNAME ( columnName )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2049:7: columnName ( COMMA columnName )*
            {
            pushFollow(FOLLOW_columnName_in_columnNameList12332);
            columnName767=columnName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnName.add(columnName767.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2049:18: ( COMMA columnName )*
            loop224:
            do {
                int alt224=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt224=1;
                    }
                    break;

                }

                switch (alt224) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2049:19: COMMA columnName
            	    {
            	    COMMA768=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameList12335); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA768);


            	    pushFollow(FOLLOW_columnName_in_columnNameList12337);
            	    columnName769=columnName();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_columnName.add(columnName769.getTree());

            	    }
            	    break;

            	default :
            	    break loop224;
                }
            } while (true);


            // AST REWRITE
            // elements: columnName
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2049:38: -> ^( TOK_TABCOLNAME ( columnName )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2049:41: ^( TOK_TABCOLNAME ( columnName )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME")
                , root_1);

                if ( !(stream_columnName.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_columnName.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnName.nextTree());

                }
                stream_columnName.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameList"


    public static class columnName_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnName"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2052:1: columnName : identifier ;
    public final HiveParser.columnName_return columnName() throws RecognitionException {
        HiveParser.columnName_return retval = new HiveParser.columnName_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser_IdentifiersParser.identifier_return identifier770 =null;



         pushMsg("column name", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2055:5: ( identifier )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2056:7: identifier
            {
            root_0 = (ASTNode)adaptor.nil();


            pushFollow(FOLLOW_identifier_in_columnName12381);
            identifier770=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier770.getTree());

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnName"


    public static class extColumnName_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "extColumnName"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2059:1: extColumnName : identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* ;
    public final HiveParser.extColumnName_return extColumnName() throws RecognitionException {
        HiveParser.extColumnName_return retval = new HiveParser.extColumnName_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token DOT772=null;
        Token KW_ELEM_TYPE773=null;
        Token KW_KEY_TYPE774=null;
        Token KW_VALUE_TYPE775=null;
        HiveParser_IdentifiersParser.identifier_return identifier771 =null;

        HiveParser_IdentifiersParser.identifier_return identifier776 =null;


        ASTNode DOT772_tree=null;
        ASTNode KW_ELEM_TYPE773_tree=null;
        ASTNode KW_KEY_TYPE774_tree=null;
        ASTNode KW_VALUE_TYPE775_tree=null;

         pushMsg("column name for complex types", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2062:5: ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:7: identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )*
            {
            root_0 = (ASTNode)adaptor.nil();


            pushFollow(FOLLOW_identifier_in_extColumnName12414);
            identifier771=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier771.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:18: ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )*
            loop226:
            do {
                int alt226=2;
                switch ( input.LA(1) ) {
                case DOT:
                    {
                    alt226=1;
                    }
                    break;

                }

                switch (alt226) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:19: DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier )
            	    {
            	    DOT772=(Token)match(input,DOT,FOLLOW_DOT_in_extColumnName12417); if (state.failed) return retval;
            	    if ( state.backtracking==0 ) {
            	    DOT772_tree = 
            	    (ASTNode)adaptor.create(DOT772)
            	    ;
            	    root_0 = (ASTNode)adaptor.becomeRoot(DOT772_tree, root_0);
            	    }

            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:24: ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier )
            	    int alt225=4;
            	    switch ( input.LA(1) ) {
            	    case KW_ELEM_TYPE:
            	        {
            	        int LA225_1 = input.LA(2);

            	        if ( (synpred19_HiveParser()) ) {
            	            alt225=1;
            	        }
            	        else if ( (true) ) {
            	            alt225=4;
            	        }
            	        else {
            	            if (state.backtracking>0) {state.failed=true; return retval;}
            	            NoViableAltException nvae =
            	                new NoViableAltException("", 225, 1, input);

            	            throw nvae;

            	        }
            	        }
            	        break;
            	    case KW_KEY_TYPE:
            	        {
            	        int LA225_2 = input.LA(2);

            	        if ( (synpred20_HiveParser()) ) {
            	            alt225=2;
            	        }
            	        else if ( (true) ) {
            	            alt225=4;
            	        }
            	        else {
            	            if (state.backtracking>0) {state.failed=true; return retval;}
            	            NoViableAltException nvae =
            	                new NoViableAltException("", 225, 2, input);

            	            throw nvae;

            	        }
            	        }
            	        break;
            	    case KW_VALUE_TYPE:
            	        {
            	        int LA225_3 = input.LA(2);

            	        if ( (synpred21_HiveParser()) ) {
            	            alt225=3;
            	        }
            	        else if ( (true) ) {
            	            alt225=4;
            	        }
            	        else {
            	            if (state.backtracking>0) {state.failed=true; return retval;}
            	            NoViableAltException nvae =
            	                new NoViableAltException("", 225, 3, input);

            	            throw nvae;

            	        }
            	        }
            	        break;
            	    case Identifier:
            	    case KW_ABORT:
            	    case KW_ADD:
            	    case KW_ADMIN:
            	    case KW_AFTER:
            	    case KW_ALL:
            	    case KW_ALTER:
            	    case KW_ANALYZE:
            	    case KW_ARCHIVE:
            	    case KW_ARRAY:
            	    case KW_AS:
            	    case KW_ASC:
            	    case KW_AUTHORIZATION:
            	    case KW_AUTOCOMMIT:
            	    case KW_BEFORE:
            	    case KW_BETWEEN:
            	    case KW_BIGINT:
            	    case KW_BINARY:
            	    case KW_BOOLEAN:
            	    case KW_BOTH:
            	    case KW_BUCKET:
            	    case KW_BUCKETS:
            	    case KW_BY:
            	    case KW_CACHE:
            	    case KW_CASCADE:
            	    case KW_CHANGE:
            	    case KW_CLUSTER:
            	    case KW_CLUSTERED:
            	    case KW_CLUSTERSTATUS:
            	    case KW_COLLECTION:
            	    case KW_COLUMNS:
            	    case KW_COMMENT:
            	    case KW_COMPACT:
            	    case KW_COMPACTIONS:
            	    case KW_COMPUTE:
            	    case KW_CONCATENATE:
            	    case KW_CONSTRAINT:
            	    case KW_CONTINUE:
            	    case KW_CREATE:
            	    case KW_CUBE:
            	    case KW_CURRENT_DATE:
            	    case KW_CURRENT_TIMESTAMP:
            	    case KW_CURSOR:
            	    case KW_DATA:
            	    case KW_DATABASES:
            	    case KW_DATE:
            	    case KW_DATETIME:
            	    case KW_DAY:
            	    case KW_DBPROPERTIES:
            	    case KW_DECIMAL:
            	    case KW_DEFERRED:
            	    case KW_DEFINED:
            	    case KW_DELETE:
            	    case KW_DELIMITED:
            	    case KW_DEPENDENCY:
            	    case KW_DESC:
            	    case KW_DESCRIBE:
            	    case KW_DIRECTORIES:
            	    case KW_DIRECTORY:
            	    case KW_DISABLE:
            	    case KW_DISTRIBUTE:
            	    case KW_DOUBLE:
            	    case KW_DOW:
            	    case KW_DROP:
            	    case KW_DUMP:
            	    case KW_ENABLE:
            	    case KW_ESCAPED:
            	    case KW_EXCLUSIVE:
            	    case KW_EXISTS:
            	    case KW_EXPLAIN:
            	    case KW_EXPORT:
            	    case KW_EXTERNAL:
            	    case KW_FALSE:
            	    case KW_FETCH:
            	    case KW_FIELDS:
            	    case KW_FILE:
            	    case KW_FILEFORMAT:
            	    case KW_FIRST:
            	    case KW_FLOAT:
            	    case KW_FOR:
            	    case KW_FOREIGN:
            	    case KW_FORMAT:
            	    case KW_FORMATTED:
            	    case KW_FULL:
            	    case KW_FUNCTIONS:
            	    case KW_GRANT:
            	    case KW_GROUP:
            	    case KW_GROUPING:
            	    case KW_HOUR:
            	    case KW_IDXPROPERTIES:
            	    case KW_IMPORT:
            	    case KW_IN:
            	    case KW_INDEX:
            	    case KW_INDEXES:
            	    case KW_INNER:
            	    case KW_INPATH:
            	    case KW_INPUTDRIVER:
            	    case KW_INPUTFORMAT:
            	    case KW_INSERT:
            	    case KW_INT:
            	    case KW_INTERSECT:
            	    case KW_INTO:
            	    case KW_IS:
            	    case KW_ISOLATION:
            	    case KW_ITEMS:
            	    case KW_JAR:
            	    case KW_KEY:
            	    case KW_KEYS:
            	    case KW_LAST:
            	    case KW_LATERAL:
            	    case KW_LEFT:
            	    case KW_LEVEL:
            	    case KW_LIKE:
            	    case KW_LIMIT:
            	    case KW_LINES:
            	    case KW_LOAD:
            	    case KW_LOCAL:
            	    case KW_LOCATION:
            	    case KW_LOCK:
            	    case KW_LOCKS:
            	    case KW_LOGICAL:
            	    case KW_LONG:
            	    case KW_MAPJOIN:
            	    case KW_MATCHED:
            	    case KW_MATERIALIZED:
            	    case KW_MERGE:
            	    case KW_METADATA:
            	    case KW_MINUTE:
            	    case KW_MONTH:
            	    case KW_MSCK:
            	    case KW_NONE:
            	    case KW_NORELY:
            	    case KW_NOSCAN:
            	    case KW_NOVALIDATE:
            	    case KW_NULL:
            	    case KW_NULLS:
            	    case KW_OF:
            	    case KW_OFFSET:
            	    case KW_OPTION:
            	    case KW_ORDER:
            	    case KW_OUT:
            	    case KW_OUTER:
            	    case KW_OUTPUTDRIVER:
            	    case KW_OUTPUTFORMAT:
            	    case KW_OVERWRITE:
            	    case KW_OWNER:
            	    case KW_PARTITION:
            	    case KW_PARTITIONED:
            	    case KW_PARTITIONS:
            	    case KW_PERCENT:
            	    case KW_PLUS:
            	    case KW_PRETTY:
            	    case KW_PRIMARY:
            	    case KW_PRINCIPALS:
            	    case KW_PROCEDURE:
            	    case KW_PURGE:
            	    case KW_QUARTER:
            	    case KW_RANGE:
            	    case KW_READ:
            	    case KW_READS:
            	    case KW_REBUILD:
            	    case KW_RECORDREADER:
            	    case KW_RECORDWRITER:
            	    case KW_REFERENCES:
            	    case KW_REGEXP:
            	    case KW_RELOAD:
            	    case KW_RELY:
            	    case KW_RENAME:
            	    case KW_REPAIR:
            	    case KW_REPL:
            	    case KW_REPLACE:
            	    case KW_REPLICATION:
            	    case KW_RESTRICT:
            	    case KW_REVOKE:
            	    case KW_REWRITE:
            	    case KW_RIGHT:
            	    case KW_RLIKE:
            	    case KW_ROLE:
            	    case KW_ROLES:
            	    case KW_ROLLUP:
            	    case KW_ROW:
            	    case KW_ROWS:
            	    case KW_SCHEMA:
            	    case KW_SCHEMAS:
            	    case KW_SECOND:
            	    case KW_SEMI:
            	    case KW_SERDE:
            	    case KW_SERDEPROPERTIES:
            	    case KW_SERVER:
            	    case KW_SET:
            	    case KW_SETS:
            	    case KW_SHARED:
            	    case KW_SHOW:
            	    case KW_SHOW_DATABASE:
            	    case KW_SKEWED:
            	    case KW_SMALLINT:
            	    case KW_SNAPSHOT:
            	    case KW_SORT:
            	    case KW_SORTED:
            	    case KW_SSL:
            	    case KW_STATISTICS:
            	    case KW_STATUS:
            	    case KW_STORED:
            	    case KW_STREAMTABLE:
            	    case KW_STRING:
            	    case KW_STRUCT:
            	    case KW_TABLE:
            	    case KW_TABLES:
            	    case KW_TBLPROPERTIES:
            	    case KW_TEMPORARY:
            	    case KW_TERMINATED:
            	    case KW_TIMESTAMP:
            	    case KW_TINYINT:
            	    case KW_TO:
            	    case KW_TOUCH:
            	    case KW_TRANSACTION:
            	    case KW_TRANSACTIONS:
            	    case KW_TRIGGER:
            	    case KW_TRUE:
            	    case KW_TRUNCATE:
            	    case KW_UNARCHIVE:
            	    case KW_UNDO:
            	    case KW_UNION:
            	    case KW_UNIONTYPE:
            	    case KW_UNLOCK:
            	    case KW_UNSET:
            	    case KW_UNSIGNED:
            	    case KW_UPDATE:
            	    case KW_URI:
            	    case KW_USE:
            	    case KW_USER:
            	    case KW_USING:
            	    case KW_UTC:
            	    case KW_UTCTIMESTAMP:
            	    case KW_VALIDATE:
            	    case KW_VALUES:
            	    case KW_VIEW:
            	    case KW_VIEWS:
            	    case KW_WEEK:
            	    case KW_WHILE:
            	    case KW_WITH:
            	    case KW_WORK:
            	    case KW_WRITE:
            	    case KW_YEAR:
            	    case KW_BATCH:
            	    case KW_DAYOFWEEK:
            	    case KW_HOLD_DDLTIME:
            	    case KW_IGNORE:
            	    case KW_NO_DROP:
            	    case KW_OFFLINE:
            	    case KW_PROTECTION:
            	    case KW_READONLY:
            	        {
            	        alt225=4;
            	        }
            	        break;
            	    default:
            	        if (state.backtracking>0) {state.failed=true; return retval;}
            	        NoViableAltException nvae =
            	            new NoViableAltException("", 225, 0, input);

            	        throw nvae;

            	    }

            	    switch (alt225) {
            	        case 1 :
            	            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:25: ( KW_ELEM_TYPE )=> KW_ELEM_TYPE
            	            {
            	            KW_ELEM_TYPE773=(Token)match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_extColumnName12427); if (state.failed) return retval;
            	            if ( state.backtracking==0 ) {
            	            KW_ELEM_TYPE773_tree = 
            	            (ASTNode)adaptor.create(KW_ELEM_TYPE773)
            	            ;
            	            adaptor.addChild(root_0, KW_ELEM_TYPE773_tree);
            	            }

            	            }
            	            break;
            	        case 2 :
            	            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:58: ( KW_KEY_TYPE )=> KW_KEY_TYPE
            	            {
            	            KW_KEY_TYPE774=(Token)match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_extColumnName12437); if (state.failed) return retval;
            	            if ( state.backtracking==0 ) {
            	            KW_KEY_TYPE774_tree = 
            	            (ASTNode)adaptor.create(KW_KEY_TYPE774)
            	            ;
            	            adaptor.addChild(root_0, KW_KEY_TYPE774_tree);
            	            }

            	            }
            	            break;
            	        case 3 :
            	            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:89: ( KW_VALUE_TYPE )=> KW_VALUE_TYPE
            	            {
            	            KW_VALUE_TYPE775=(Token)match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_extColumnName12447); if (state.failed) return retval;
            	            if ( state.backtracking==0 ) {
            	            KW_VALUE_TYPE775_tree = 
            	            (ASTNode)adaptor.create(KW_VALUE_TYPE775)
            	            ;
            	            adaptor.addChild(root_0, KW_VALUE_TYPE775_tree);
            	            }

            	            }
            	            break;
            	        case 4 :
            	            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:124: identifier
            	            {
            	            pushFollow(FOLLOW_identifier_in_extColumnName12451);
            	            identifier776=identifier();

            	            state._fsp--;
            	            if (state.failed) return retval;
            	            if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier776.getTree());

            	            }
            	            break;

            	    }


            	    }
            	    break;

            	default :
            	    break loop226;
                }
            } while (true);


            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "extColumnName"


    public static class columnNameOrderList_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameOrderList"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2066:1: columnNameOrderList : columnNameOrder ( COMMA columnNameOrder )* -> ^( TOK_TABCOLNAME ( columnNameOrder )+ ) ;
    public final HiveParser.columnNameOrderList_return columnNameOrderList() throws RecognitionException {
        HiveParser.columnNameOrderList_return retval = new HiveParser.columnNameOrderList_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token COMMA778=null;
        HiveParser.columnNameOrder_return columnNameOrder777 =null;

        HiveParser.columnNameOrder_return columnNameOrder779 =null;


        ASTNode COMMA778_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_columnNameOrder=new RewriteRuleSubtreeStream(adaptor,"rule columnNameOrder");
         pushMsg("column name order list", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2069:5: ( columnNameOrder ( COMMA columnNameOrder )* -> ^( TOK_TABCOLNAME ( columnNameOrder )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2069:7: columnNameOrder ( COMMA columnNameOrder )*
            {
            pushFollow(FOLLOW_columnNameOrder_in_columnNameOrderList12481);
            columnNameOrder777=columnNameOrder();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnNameOrder.add(columnNameOrder777.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2069:23: ( COMMA columnNameOrder )*
            loop227:
            do {
                int alt227=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt227=1;
                    }
                    break;

                }

                switch (alt227) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2069:24: COMMA columnNameOrder
            	    {
            	    COMMA778=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameOrderList12484); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA778);


            	    pushFollow(FOLLOW_columnNameOrder_in_columnNameOrderList12486);
            	    columnNameOrder779=columnNameOrder();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_columnNameOrder.add(columnNameOrder779.getTree());

            	    }
            	    break;

            	default :
            	    break loop227;
                }
            } while (true);


            // AST REWRITE
            // elements: columnNameOrder
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2069:48: -> ^( TOK_TABCOLNAME ( columnNameOrder )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2069:51: ^( TOK_TABCOLNAME ( columnNameOrder )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME")
                , root_1);

                if ( !(stream_columnNameOrder.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_columnNameOrder.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameOrder.nextTree());

                }
                stream_columnNameOrder.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameOrderList"


    public static class columnParenthesesList_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnParenthesesList"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2072:1: columnParenthesesList : LPAREN columnNameList RPAREN ;
    public final HiveParser.columnParenthesesList_return columnParenthesesList() throws RecognitionException {
        HiveParser.columnParenthesesList_return retval = new HiveParser.columnParenthesesList_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token LPAREN780=null;
        Token RPAREN782=null;
        HiveParser.columnNameList_return columnNameList781 =null;


        ASTNode LPAREN780_tree=null;
        ASTNode RPAREN782_tree=null;

         pushMsg("column parentheses list", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2075:5: ( LPAREN columnNameList RPAREN )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2075:7: LPAREN columnNameList RPAREN
            {
            root_0 = (ASTNode)adaptor.nil();


            LPAREN780=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_columnParenthesesList12524); if (state.failed) return retval;
            if ( state.backtracking==0 ) {
            LPAREN780_tree = 
            (ASTNode)adaptor.create(LPAREN780)
            ;
            adaptor.addChild(root_0, LPAREN780_tree);
            }

            pushFollow(FOLLOW_columnNameList_in_columnParenthesesList12526);
            columnNameList781=columnNameList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) adaptor.addChild(root_0, columnNameList781.getTree());

            RPAREN782=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_columnParenthesesList12528); if (state.failed) return retval;
            if ( state.backtracking==0 ) {
            RPAREN782_tree = 
            (ASTNode)adaptor.create(RPAREN782)
            ;
            adaptor.addChild(root_0, RPAREN782_tree);
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnParenthesesList"


    public static class enableSpecification_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "enableSpecification"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2078:1: enableSpecification : ( KW_ENABLE -> ^( TOK_ENABLE ) | KW_DISABLE -> ^( TOK_DISABLE ) );
    public final HiveParser.enableSpecification_return enableSpecification() throws RecognitionException {
        HiveParser.enableSpecification_return retval = new HiveParser.enableSpecification_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_ENABLE783=null;
        Token KW_DISABLE784=null;

        ASTNode KW_ENABLE783_tree=null;
        ASTNode KW_DISABLE784_tree=null;
        RewriteRuleTokenStream stream_KW_DISABLE=new RewriteRuleTokenStream(adaptor,"token KW_DISABLE");
        RewriteRuleTokenStream stream_KW_ENABLE=new RewriteRuleTokenStream(adaptor,"token KW_ENABLE");

         pushMsg("enable specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2081:5: ( KW_ENABLE -> ^( TOK_ENABLE ) | KW_DISABLE -> ^( TOK_DISABLE ) )
            int alt228=2;
            switch ( input.LA(1) ) {
            case KW_ENABLE:
                {
                alt228=1;
                }
                break;
            case KW_DISABLE:
                {
                alt228=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 228, 0, input);

                throw nvae;

            }

            switch (alt228) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2081:7: KW_ENABLE
                    {
                    KW_ENABLE783=(Token)match(input,KW_ENABLE,FOLLOW_KW_ENABLE_in_enableSpecification12555); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ENABLE.add(KW_ENABLE783);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2081:17: -> ^( TOK_ENABLE )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2081:20: ^( TOK_ENABLE )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_ENABLE, "TOK_ENABLE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2082:7: KW_DISABLE
                    {
                    KW_DISABLE784=(Token)match(input,KW_DISABLE,FOLLOW_KW_DISABLE_in_enableSpecification12569); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_DISABLE.add(KW_DISABLE784);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2082:18: -> ^( TOK_DISABLE )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2082:21: ^( TOK_DISABLE )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_DISABLE, "TOK_DISABLE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "enableSpecification"


    public static class validateSpecification_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "validateSpecification"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2085:1: validateSpecification : ( KW_VALIDATE -> ^( TOK_VALIDATE ) | KW_NOVALIDATE -> ^( TOK_NOVALIDATE ) );
    public final HiveParser.validateSpecification_return validateSpecification() throws RecognitionException {
        HiveParser.validateSpecification_return retval = new HiveParser.validateSpecification_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_VALIDATE785=null;
        Token KW_NOVALIDATE786=null;

        ASTNode KW_VALIDATE785_tree=null;
        ASTNode KW_NOVALIDATE786_tree=null;
        RewriteRuleTokenStream stream_KW_VALIDATE=new RewriteRuleTokenStream(adaptor,"token KW_VALIDATE");
        RewriteRuleTokenStream stream_KW_NOVALIDATE=new RewriteRuleTokenStream(adaptor,"token KW_NOVALIDATE");

         pushMsg("validate specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2088:5: ( KW_VALIDATE -> ^( TOK_VALIDATE ) | KW_NOVALIDATE -> ^( TOK_NOVALIDATE ) )
            int alt229=2;
            switch ( input.LA(1) ) {
            case KW_VALIDATE:
                {
                alt229=1;
                }
                break;
            case KW_NOVALIDATE:
                {
                alt229=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 229, 0, input);

                throw nvae;

            }

            switch (alt229) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2088:7: KW_VALIDATE
                    {
                    KW_VALIDATE785=(Token)match(input,KW_VALIDATE,FOLLOW_KW_VALIDATE_in_validateSpecification12602); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_VALIDATE.add(KW_VALIDATE785);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2088:19: -> ^( TOK_VALIDATE )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2088:22: ^( TOK_VALIDATE )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_VALIDATE, "TOK_VALIDATE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2089:7: KW_NOVALIDATE
                    {
                    KW_NOVALIDATE786=(Token)match(input,KW_NOVALIDATE,FOLLOW_KW_NOVALIDATE_in_validateSpecification12616); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_NOVALIDATE.add(KW_NOVALIDATE786);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2089:21: -> ^( TOK_NOVALIDATE )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2089:24: ^( TOK_NOVALIDATE )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_NOVALIDATE, "TOK_NOVALIDATE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "validateSpecification"


    public static class relySpecification_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "relySpecification"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2092:1: relySpecification : ( KW_RELY -> ^( TOK_RELY ) | ( KW_NORELY )? -> ^( TOK_NORELY ) );
    public final HiveParser.relySpecification_return relySpecification() throws RecognitionException {
        HiveParser.relySpecification_return retval = new HiveParser.relySpecification_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_RELY787=null;
        Token KW_NORELY788=null;

        ASTNode KW_RELY787_tree=null;
        ASTNode KW_NORELY788_tree=null;
        RewriteRuleTokenStream stream_KW_NORELY=new RewriteRuleTokenStream(adaptor,"token KW_NORELY");
        RewriteRuleTokenStream stream_KW_RELY=new RewriteRuleTokenStream(adaptor,"token KW_RELY");

         pushMsg("rely specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2095:5: ( KW_RELY -> ^( TOK_RELY ) | ( KW_NORELY )? -> ^( TOK_NORELY ) )
            int alt231=2;
            switch ( input.LA(1) ) {
            case KW_RELY:
                {
                alt231=1;
                }
                break;
            case EOF:
            case COMMA:
            case KW_NORELY:
            case RPAREN:
                {
                alt231=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 231, 0, input);

                throw nvae;

            }

            switch (alt231) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2095:8: KW_RELY
                    {
                    KW_RELY787=(Token)match(input,KW_RELY,FOLLOW_KW_RELY_in_relySpecification12650); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_RELY.add(KW_RELY787);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2095:16: -> ^( TOK_RELY )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2095:19: ^( TOK_RELY )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_RELY, "TOK_RELY")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2096:8: ( KW_NORELY )?
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2096:8: ( KW_NORELY )?
                    int alt230=2;
                    switch ( input.LA(1) ) {
                        case KW_NORELY:
                            {
                            alt230=1;
                            }
                            break;
                    }

                    switch (alt230) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2096:9: KW_NORELY
                            {
                            KW_NORELY788=(Token)match(input,KW_NORELY,FOLLOW_KW_NORELY_in_relySpecification12666); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_NORELY.add(KW_NORELY788);


                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2096:21: -> ^( TOK_NORELY )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2096:24: ^( TOK_NORELY )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_NORELY, "TOK_NORELY")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "relySpecification"


    public static class primaryKeyWithoutName_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "primaryKeyWithoutName"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2099:1: primaryKeyWithoutName : KW_PRIMARY KW_KEY columnParenthesesList enableSpec= enableSpecification validateSpec= validateSpecification relySpec= relySpecification -> ^( TOK_PRIMARY_KEY columnParenthesesList $relySpec $enableSpec $validateSpec) ;
    public final HiveParser.primaryKeyWithoutName_return primaryKeyWithoutName() throws RecognitionException {
        HiveParser.primaryKeyWithoutName_return retval = new HiveParser.primaryKeyWithoutName_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_PRIMARY789=null;
        Token KW_KEY790=null;
        HiveParser.enableSpecification_return enableSpec =null;

        HiveParser.validateSpecification_return validateSpec =null;

        HiveParser.relySpecification_return relySpec =null;

        HiveParser.columnParenthesesList_return columnParenthesesList791 =null;


        ASTNode KW_PRIMARY789_tree=null;
        ASTNode KW_KEY790_tree=null;
        RewriteRuleTokenStream stream_KW_PRIMARY=new RewriteRuleTokenStream(adaptor,"token KW_PRIMARY");
        RewriteRuleTokenStream stream_KW_KEY=new RewriteRuleTokenStream(adaptor,"token KW_KEY");
        RewriteRuleSubtreeStream stream_enableSpecification=new RewriteRuleSubtreeStream(adaptor,"rule enableSpecification");
        RewriteRuleSubtreeStream stream_columnParenthesesList=new RewriteRuleSubtreeStream(adaptor,"rule columnParenthesesList");
        RewriteRuleSubtreeStream stream_relySpecification=new RewriteRuleSubtreeStream(adaptor,"rule relySpecification");
        RewriteRuleSubtreeStream stream_validateSpecification=new RewriteRuleSubtreeStream(adaptor,"rule validateSpecification");
         pushMsg("primary key without key name", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2102:5: ( KW_PRIMARY KW_KEY columnParenthesesList enableSpec= enableSpecification validateSpec= validateSpecification relySpec= relySpecification -> ^( TOK_PRIMARY_KEY columnParenthesesList $relySpec $enableSpec $validateSpec) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2102:7: KW_PRIMARY KW_KEY columnParenthesesList enableSpec= enableSpecification validateSpec= validateSpecification relySpec= relySpecification
            {
            KW_PRIMARY789=(Token)match(input,KW_PRIMARY,FOLLOW_KW_PRIMARY_in_primaryKeyWithoutName12701); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_PRIMARY.add(KW_PRIMARY789);


            KW_KEY790=(Token)match(input,KW_KEY,FOLLOW_KW_KEY_in_primaryKeyWithoutName12703); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_KEY.add(KW_KEY790);


            pushFollow(FOLLOW_columnParenthesesList_in_primaryKeyWithoutName12705);
            columnParenthesesList791=columnParenthesesList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnParenthesesList.add(columnParenthesesList791.getTree());

            pushFollow(FOLLOW_enableSpecification_in_primaryKeyWithoutName12709);
            enableSpec=enableSpecification();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_enableSpecification.add(enableSpec.getTree());

            pushFollow(FOLLOW_validateSpecification_in_primaryKeyWithoutName12713);
            validateSpec=validateSpecification();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_validateSpecification.add(validateSpec.getTree());

            pushFollow(FOLLOW_relySpecification_in_primaryKeyWithoutName12717);
            relySpec=relySpecification();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_relySpecification.add(relySpec.getTree());

            // AST REWRITE
            // elements: relySpec, columnParenthesesList, enableSpec, validateSpec
            // token labels: 
            // rule labels: validateSpec, enableSpec, relySpec, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_validateSpec=new RewriteRuleSubtreeStream(adaptor,"rule validateSpec",validateSpec!=null?validateSpec.tree:null);
            RewriteRuleSubtreeStream stream_enableSpec=new RewriteRuleSubtreeStream(adaptor,"rule enableSpec",enableSpec!=null?enableSpec.tree:null);
            RewriteRuleSubtreeStream stream_relySpec=new RewriteRuleSubtreeStream(adaptor,"rule relySpec",relySpec!=null?relySpec.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2103:5: -> ^( TOK_PRIMARY_KEY columnParenthesesList $relySpec $enableSpec $validateSpec)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2103:8: ^( TOK_PRIMARY_KEY columnParenthesesList $relySpec $enableSpec $validateSpec)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_PRIMARY_KEY, "TOK_PRIMARY_KEY")
                , root_1);

                adaptor.addChild(root_1, stream_columnParenthesesList.nextTree());

                adaptor.addChild(root_1, stream_relySpec.nextTree());

                adaptor.addChild(root_1, stream_enableSpec.nextTree());

                adaptor.addChild(root_1, stream_validateSpec.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "primaryKeyWithoutName"


    public static class primaryKeyWithName_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "primaryKeyWithName"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2106:1: primaryKeyWithName : KW_CONSTRAINT idfr= identifier KW_PRIMARY KW_KEY pkCols= columnParenthesesList enableSpec= enableSpecification validateSpec= validateSpecification relySpec= relySpecification -> ^( TOK_PRIMARY_KEY $pkCols $idfr $relySpec $enableSpec $validateSpec) ;
    public final HiveParser.primaryKeyWithName_return primaryKeyWithName() throws RecognitionException {
        HiveParser.primaryKeyWithName_return retval = new HiveParser.primaryKeyWithName_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_CONSTRAINT792=null;
        Token KW_PRIMARY793=null;
        Token KW_KEY794=null;
        HiveParser_IdentifiersParser.identifier_return idfr =null;

        HiveParser.columnParenthesesList_return pkCols =null;

        HiveParser.enableSpecification_return enableSpec =null;

        HiveParser.validateSpecification_return validateSpec =null;

        HiveParser.relySpecification_return relySpec =null;


        ASTNode KW_CONSTRAINT792_tree=null;
        ASTNode KW_PRIMARY793_tree=null;
        ASTNode KW_KEY794_tree=null;
        RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
        RewriteRuleTokenStream stream_KW_PRIMARY=new RewriteRuleTokenStream(adaptor,"token KW_PRIMARY");
        RewriteRuleTokenStream stream_KW_KEY=new RewriteRuleTokenStream(adaptor,"token KW_KEY");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_enableSpecification=new RewriteRuleSubtreeStream(adaptor,"rule enableSpecification");
        RewriteRuleSubtreeStream stream_columnParenthesesList=new RewriteRuleSubtreeStream(adaptor,"rule columnParenthesesList");
        RewriteRuleSubtreeStream stream_relySpecification=new RewriteRuleSubtreeStream(adaptor,"rule relySpecification");
        RewriteRuleSubtreeStream stream_validateSpecification=new RewriteRuleSubtreeStream(adaptor,"rule validateSpecification");
         pushMsg("primary key with key name", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2109:5: ( KW_CONSTRAINT idfr= identifier KW_PRIMARY KW_KEY pkCols= columnParenthesesList enableSpec= enableSpecification validateSpec= validateSpecification relySpec= relySpecification -> ^( TOK_PRIMARY_KEY $pkCols $idfr $relySpec $enableSpec $validateSpec) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2109:7: KW_CONSTRAINT idfr= identifier KW_PRIMARY KW_KEY pkCols= columnParenthesesList enableSpec= enableSpecification validateSpec= validateSpecification relySpec= relySpecification
            {
            KW_CONSTRAINT792=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_primaryKeyWithName12765); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT792);


            pushFollow(FOLLOW_identifier_in_primaryKeyWithName12769);
            idfr=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(idfr.getTree());

            KW_PRIMARY793=(Token)match(input,KW_PRIMARY,FOLLOW_KW_PRIMARY_in_primaryKeyWithName12771); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_PRIMARY.add(KW_PRIMARY793);


            KW_KEY794=(Token)match(input,KW_KEY,FOLLOW_KW_KEY_in_primaryKeyWithName12773); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_KEY.add(KW_KEY794);


            pushFollow(FOLLOW_columnParenthesesList_in_primaryKeyWithName12777);
            pkCols=columnParenthesesList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnParenthesesList.add(pkCols.getTree());

            pushFollow(FOLLOW_enableSpecification_in_primaryKeyWithName12781);
            enableSpec=enableSpecification();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_enableSpecification.add(enableSpec.getTree());

            pushFollow(FOLLOW_validateSpecification_in_primaryKeyWithName12785);
            validateSpec=validateSpecification();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_validateSpecification.add(validateSpec.getTree());

            pushFollow(FOLLOW_relySpecification_in_primaryKeyWithName12789);
            relySpec=relySpecification();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_relySpecification.add(relySpec.getTree());

            // AST REWRITE
            // elements: idfr, validateSpec, relySpec, pkCols, enableSpec
            // token labels: 
            // rule labels: validateSpec, idfr, enableSpec, relySpec, pkCols, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_validateSpec=new RewriteRuleSubtreeStream(adaptor,"rule validateSpec",validateSpec!=null?validateSpec.tree:null);
            RewriteRuleSubtreeStream stream_idfr=new RewriteRuleSubtreeStream(adaptor,"rule idfr",idfr!=null?idfr.tree:null);
            RewriteRuleSubtreeStream stream_enableSpec=new RewriteRuleSubtreeStream(adaptor,"rule enableSpec",enableSpec!=null?enableSpec.tree:null);
            RewriteRuleSubtreeStream stream_relySpec=new RewriteRuleSubtreeStream(adaptor,"rule relySpec",relySpec!=null?relySpec.tree:null);
            RewriteRuleSubtreeStream stream_pkCols=new RewriteRuleSubtreeStream(adaptor,"rule pkCols",pkCols!=null?pkCols.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2110:5: -> ^( TOK_PRIMARY_KEY $pkCols $idfr $relySpec $enableSpec $validateSpec)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2110:8: ^( TOK_PRIMARY_KEY $pkCols $idfr $relySpec $enableSpec $validateSpec)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_PRIMARY_KEY, "TOK_PRIMARY_KEY")
                , root_1);

                adaptor.addChild(root_1, stream_pkCols.nextTree());

                adaptor.addChild(root_1, stream_idfr.nextTree());

                adaptor.addChild(root_1, stream_relySpec.nextTree());

                adaptor.addChild(root_1, stream_enableSpec.nextTree());

                adaptor.addChild(root_1, stream_validateSpec.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "primaryKeyWithName"


    public static class foreignKeyWithName_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "foreignKeyWithName"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2113:1: foreignKeyWithName : KW_CONSTRAINT idfr= identifier KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList enableSpec= enableSpecification validateSpec= validateSpecification relySpec= relySpecification -> ^( TOK_FOREIGN_KEY $idfr $fkCols $tabName $parCols $relySpec $enableSpec $validateSpec) ;
    public final HiveParser.foreignKeyWithName_return foreignKeyWithName() throws RecognitionException {
        HiveParser.foreignKeyWithName_return retval = new HiveParser.foreignKeyWithName_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_CONSTRAINT795=null;
        Token KW_FOREIGN796=null;
        Token KW_KEY797=null;
        Token KW_REFERENCES798=null;
        HiveParser_IdentifiersParser.identifier_return idfr =null;

        HiveParser.columnParenthesesList_return fkCols =null;

        HiveParser_FromClauseParser.tableName_return tabName =null;

        HiveParser.columnParenthesesList_return parCols =null;

        HiveParser.enableSpecification_return enableSpec =null;

        HiveParser.validateSpecification_return validateSpec =null;

        HiveParser.relySpecification_return relySpec =null;


        ASTNode KW_CONSTRAINT795_tree=null;
        ASTNode KW_FOREIGN796_tree=null;
        ASTNode KW_KEY797_tree=null;
        ASTNode KW_REFERENCES798_tree=null;
        RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
        RewriteRuleTokenStream stream_KW_REFERENCES=new RewriteRuleTokenStream(adaptor,"token KW_REFERENCES");
        RewriteRuleTokenStream stream_KW_FOREIGN=new RewriteRuleTokenStream(adaptor,"token KW_FOREIGN");
        RewriteRuleTokenStream stream_KW_KEY=new RewriteRuleTokenStream(adaptor,"token KW_KEY");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_enableSpecification=new RewriteRuleSubtreeStream(adaptor,"rule enableSpecification");
        RewriteRuleSubtreeStream stream_columnParenthesesList=new RewriteRuleSubtreeStream(adaptor,"rule columnParenthesesList");
        RewriteRuleSubtreeStream stream_relySpecification=new RewriteRuleSubtreeStream(adaptor,"rule relySpecification");
        RewriteRuleSubtreeStream stream_validateSpecification=new RewriteRuleSubtreeStream(adaptor,"rule validateSpecification");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("foreign key with key name", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2116:5: ( KW_CONSTRAINT idfr= identifier KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList enableSpec= enableSpecification validateSpec= validateSpecification relySpec= relySpecification -> ^( TOK_FOREIGN_KEY $idfr $fkCols $tabName $parCols $relySpec $enableSpec $validateSpec) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2116:7: KW_CONSTRAINT idfr= identifier KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList enableSpec= enableSpecification validateSpec= validateSpecification relySpec= relySpecification
            {
            KW_CONSTRAINT795=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_foreignKeyWithName12841); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT795);


            pushFollow(FOLLOW_identifier_in_foreignKeyWithName12845);
            idfr=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(idfr.getTree());

            KW_FOREIGN796=(Token)match(input,KW_FOREIGN,FOLLOW_KW_FOREIGN_in_foreignKeyWithName12847); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FOREIGN.add(KW_FOREIGN796);


            KW_KEY797=(Token)match(input,KW_KEY,FOLLOW_KW_KEY_in_foreignKeyWithName12849); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_KEY.add(KW_KEY797);


            pushFollow(FOLLOW_columnParenthesesList_in_foreignKeyWithName12853);
            fkCols=columnParenthesesList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnParenthesesList.add(fkCols.getTree());

            KW_REFERENCES798=(Token)match(input,KW_REFERENCES,FOLLOW_KW_REFERENCES_in_foreignKeyWithName12856); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_REFERENCES.add(KW_REFERENCES798);


            pushFollow(FOLLOW_tableName_in_foreignKeyWithName12860);
            tabName=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());

            pushFollow(FOLLOW_columnParenthesesList_in_foreignKeyWithName12864);
            parCols=columnParenthesesList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnParenthesesList.add(parCols.getTree());

            pushFollow(FOLLOW_enableSpecification_in_foreignKeyWithName12868);
            enableSpec=enableSpecification();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_enableSpecification.add(enableSpec.getTree());

            pushFollow(FOLLOW_validateSpecification_in_foreignKeyWithName12872);
            validateSpec=validateSpecification();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_validateSpecification.add(validateSpec.getTree());

            pushFollow(FOLLOW_relySpecification_in_foreignKeyWithName12876);
            relySpec=relySpecification();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_relySpecification.add(relySpec.getTree());

            // AST REWRITE
            // elements: validateSpec, idfr, fkCols, parCols, tabName, relySpec, enableSpec
            // token labels: 
            // rule labels: parCols, tabName, validateSpec, idfr, enableSpec, fkCols, relySpec, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_parCols=new RewriteRuleSubtreeStream(adaptor,"rule parCols",parCols!=null?parCols.tree:null);
            RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.tree:null);
            RewriteRuleSubtreeStream stream_validateSpec=new RewriteRuleSubtreeStream(adaptor,"rule validateSpec",validateSpec!=null?validateSpec.tree:null);
            RewriteRuleSubtreeStream stream_idfr=new RewriteRuleSubtreeStream(adaptor,"rule idfr",idfr!=null?idfr.tree:null);
            RewriteRuleSubtreeStream stream_enableSpec=new RewriteRuleSubtreeStream(adaptor,"rule enableSpec",enableSpec!=null?enableSpec.tree:null);
            RewriteRuleSubtreeStream stream_fkCols=new RewriteRuleSubtreeStream(adaptor,"rule fkCols",fkCols!=null?fkCols.tree:null);
            RewriteRuleSubtreeStream stream_relySpec=new RewriteRuleSubtreeStream(adaptor,"rule relySpec",relySpec!=null?relySpec.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2117:5: -> ^( TOK_FOREIGN_KEY $idfr $fkCols $tabName $parCols $relySpec $enableSpec $validateSpec)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:8: ^( TOK_FOREIGN_KEY $idfr $fkCols $tabName $parCols $relySpec $enableSpec $validateSpec)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY")
                , root_1);

                adaptor.addChild(root_1, stream_idfr.nextTree());

                adaptor.addChild(root_1, stream_fkCols.nextTree());

                adaptor.addChild(root_1, stream_tabName.nextTree());

                adaptor.addChild(root_1, stream_parCols.nextTree());

                adaptor.addChild(root_1, stream_relySpec.nextTree());

                adaptor.addChild(root_1, stream_enableSpec.nextTree());

                adaptor.addChild(root_1, stream_validateSpec.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "foreignKeyWithName"


    public static class foreignKeyWithoutName_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "foreignKeyWithoutName"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2120:1: foreignKeyWithoutName : KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList enableSpec= enableSpecification validateSpec= validateSpecification relySpec= relySpecification -> ^( TOK_FOREIGN_KEY $fkCols $tabName $parCols $relySpec $enableSpec $validateSpec) ;
    public final HiveParser.foreignKeyWithoutName_return foreignKeyWithoutName() throws RecognitionException {
        HiveParser.foreignKeyWithoutName_return retval = new HiveParser.foreignKeyWithoutName_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_FOREIGN799=null;
        Token KW_KEY800=null;
        Token KW_REFERENCES801=null;
        HiveParser.columnParenthesesList_return fkCols =null;

        HiveParser_FromClauseParser.tableName_return tabName =null;

        HiveParser.columnParenthesesList_return parCols =null;

        HiveParser.enableSpecification_return enableSpec =null;

        HiveParser.validateSpecification_return validateSpec =null;

        HiveParser.relySpecification_return relySpec =null;


        ASTNode KW_FOREIGN799_tree=null;
        ASTNode KW_KEY800_tree=null;
        ASTNode KW_REFERENCES801_tree=null;
        RewriteRuleTokenStream stream_KW_REFERENCES=new RewriteRuleTokenStream(adaptor,"token KW_REFERENCES");
        RewriteRuleTokenStream stream_KW_FOREIGN=new RewriteRuleTokenStream(adaptor,"token KW_FOREIGN");
        RewriteRuleTokenStream stream_KW_KEY=new RewriteRuleTokenStream(adaptor,"token KW_KEY");
        RewriteRuleSubtreeStream stream_enableSpecification=new RewriteRuleSubtreeStream(adaptor,"rule enableSpecification");
        RewriteRuleSubtreeStream stream_columnParenthesesList=new RewriteRuleSubtreeStream(adaptor,"rule columnParenthesesList");
        RewriteRuleSubtreeStream stream_relySpecification=new RewriteRuleSubtreeStream(adaptor,"rule relySpecification");
        RewriteRuleSubtreeStream stream_validateSpecification=new RewriteRuleSubtreeStream(adaptor,"rule validateSpecification");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("foreign key without key name", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2123:5: ( KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList enableSpec= enableSpecification validateSpec= validateSpecification relySpec= relySpecification -> ^( TOK_FOREIGN_KEY $fkCols $tabName $parCols $relySpec $enableSpec $validateSpec) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2123:7: KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList enableSpec= enableSpecification validateSpec= validateSpecification relySpec= relySpecification
            {
            KW_FOREIGN799=(Token)match(input,KW_FOREIGN,FOLLOW_KW_FOREIGN_in_foreignKeyWithoutName12934); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FOREIGN.add(KW_FOREIGN799);


            KW_KEY800=(Token)match(input,KW_KEY,FOLLOW_KW_KEY_in_foreignKeyWithoutName12936); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_KEY.add(KW_KEY800);


            pushFollow(FOLLOW_columnParenthesesList_in_foreignKeyWithoutName12940);
            fkCols=columnParenthesesList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnParenthesesList.add(fkCols.getTree());

            KW_REFERENCES801=(Token)match(input,KW_REFERENCES,FOLLOW_KW_REFERENCES_in_foreignKeyWithoutName12943); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_REFERENCES.add(KW_REFERENCES801);


            pushFollow(FOLLOW_tableName_in_foreignKeyWithoutName12947);
            tabName=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());

            pushFollow(FOLLOW_columnParenthesesList_in_foreignKeyWithoutName12951);
            parCols=columnParenthesesList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnParenthesesList.add(parCols.getTree());

            pushFollow(FOLLOW_enableSpecification_in_foreignKeyWithoutName12955);
            enableSpec=enableSpecification();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_enableSpecification.add(enableSpec.getTree());

            pushFollow(FOLLOW_validateSpecification_in_foreignKeyWithoutName12959);
            validateSpec=validateSpecification();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_validateSpecification.add(validateSpec.getTree());

            pushFollow(FOLLOW_relySpecification_in_foreignKeyWithoutName12963);
            relySpec=relySpecification();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_relySpecification.add(relySpec.getTree());

            // AST REWRITE
            // elements: tabName, validateSpec, enableSpec, parCols, fkCols, relySpec
            // token labels: 
            // rule labels: tabName, parCols, validateSpec, enableSpec, fkCols, relySpec, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.tree:null);
            RewriteRuleSubtreeStream stream_parCols=new RewriteRuleSubtreeStream(adaptor,"rule parCols",parCols!=null?parCols.tree:null);
            RewriteRuleSubtreeStream stream_validateSpec=new RewriteRuleSubtreeStream(adaptor,"rule validateSpec",validateSpec!=null?validateSpec.tree:null);
            RewriteRuleSubtreeStream stream_enableSpec=new RewriteRuleSubtreeStream(adaptor,"rule enableSpec",enableSpec!=null?enableSpec.tree:null);
            RewriteRuleSubtreeStream stream_fkCols=new RewriteRuleSubtreeStream(adaptor,"rule fkCols",fkCols!=null?fkCols.tree:null);
            RewriteRuleSubtreeStream stream_relySpec=new RewriteRuleSubtreeStream(adaptor,"rule relySpec",relySpec!=null?relySpec.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2124:5: -> ^( TOK_FOREIGN_KEY $fkCols $tabName $parCols $relySpec $enableSpec $validateSpec)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2124:8: ^( TOK_FOREIGN_KEY $fkCols $tabName $parCols $relySpec $enableSpec $validateSpec)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY")
                , root_1);

                adaptor.addChild(root_1, stream_fkCols.nextTree());

                adaptor.addChild(root_1, stream_tabName.nextTree());

                adaptor.addChild(root_1, stream_parCols.nextTree());

                adaptor.addChild(root_1, stream_relySpec.nextTree());

                adaptor.addChild(root_1, stream_enableSpec.nextTree());

                adaptor.addChild(root_1, stream_validateSpec.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "foreignKeyWithoutName"


    public static class skewedValueElement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedValueElement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2127:1: skewedValueElement : ( skewedColumnValues | skewedColumnValuePairList );
    public final HiveParser.skewedValueElement_return skewedValueElement() throws RecognitionException {
        HiveParser.skewedValueElement_return retval = new HiveParser.skewedValueElement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.skewedColumnValues_return skewedColumnValues802 =null;

        HiveParser.skewedColumnValuePairList_return skewedColumnValuePairList803 =null;



         pushMsg("skewed value element", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2130:5: ( skewedColumnValues | skewedColumnValuePairList )
            int alt232=2;
            switch ( input.LA(1) ) {
            case BigintLiteral:
            case CharSetName:
            case DecimalLiteral:
            case KW_CURRENT_DATE:
            case KW_CURRENT_TIMESTAMP:
            case KW_DATE:
            case KW_FALSE:
            case KW_NULL:
            case KW_TIMESTAMP:
            case KW_TRUE:
            case Number:
            case SmallintLiteral:
            case StringLiteral:
            case TinyintLiteral:
                {
                alt232=1;
                }
                break;
            case LPAREN:
                {
                alt232=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 232, 0, input);

                throw nvae;

            }

            switch (alt232) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2131:7: skewedColumnValues
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_skewedColumnValues_in_skewedValueElement13026);
                    skewedColumnValues802=skewedColumnValues();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, skewedColumnValues802.getTree());

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2132:8: skewedColumnValuePairList
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_skewedColumnValuePairList_in_skewedValueElement13035);
                    skewedColumnValuePairList803=skewedColumnValuePairList();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, skewedColumnValuePairList803.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedValueElement"


    public static class skewedColumnValuePairList_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedColumnValuePairList"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2135:1: skewedColumnValuePairList : skewedColumnValuePair ( COMMA skewedColumnValuePair )* -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ ) ;
    public final HiveParser.skewedColumnValuePairList_return skewedColumnValuePairList() throws RecognitionException {
        HiveParser.skewedColumnValuePairList_return retval = new HiveParser.skewedColumnValuePairList_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token COMMA805=null;
        HiveParser.skewedColumnValuePair_return skewedColumnValuePair804 =null;

        HiveParser.skewedColumnValuePair_return skewedColumnValuePair806 =null;


        ASTNode COMMA805_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_skewedColumnValuePair=new RewriteRuleSubtreeStream(adaptor,"rule skewedColumnValuePair");
         pushMsg("column value pair list", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2138:5: ( skewedColumnValuePair ( COMMA skewedColumnValuePair )* -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2138:7: skewedColumnValuePair ( COMMA skewedColumnValuePair )*
            {
            pushFollow(FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList13062);
            skewedColumnValuePair804=skewedColumnValuePair();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_skewedColumnValuePair.add(skewedColumnValuePair804.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2138:29: ( COMMA skewedColumnValuePair )*
            loop233:
            do {
                int alt233=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt233=1;
                    }
                    break;

                }

                switch (alt233) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2138:30: COMMA skewedColumnValuePair
            	    {
            	    COMMA805=(Token)match(input,COMMA,FOLLOW_COMMA_in_skewedColumnValuePairList13065); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA805);


            	    pushFollow(FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList13067);
            	    skewedColumnValuePair806=skewedColumnValuePair();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_skewedColumnValuePair.add(skewedColumnValuePair806.getTree());

            	    }
            	    break;

            	default :
            	    break loop233;
                }
            } while (true);


            // AST REWRITE
            // elements: skewedColumnValuePair
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2138:60: -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2138:63: ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABCOLVALUE_PAIR, "TOK_TABCOLVALUE_PAIR")
                , root_1);

                if ( !(stream_skewedColumnValuePair.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_skewedColumnValuePair.hasNext() ) {
                    adaptor.addChild(root_1, stream_skewedColumnValuePair.nextTree());

                }
                stream_skewedColumnValuePair.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedColumnValuePairList"


    public static class skewedColumnValuePair_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedColumnValuePair"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2141:1: skewedColumnValuePair : LPAREN colValues= skewedColumnValues RPAREN -> ^( TOK_TABCOLVALUES $colValues) ;
    public final HiveParser.skewedColumnValuePair_return skewedColumnValuePair() throws RecognitionException {
        HiveParser.skewedColumnValuePair_return retval = new HiveParser.skewedColumnValuePair_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token LPAREN807=null;
        Token RPAREN808=null;
        HiveParser.skewedColumnValues_return colValues =null;


        ASTNode LPAREN807_tree=null;
        ASTNode RPAREN808_tree=null;
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleSubtreeStream stream_skewedColumnValues=new RewriteRuleSubtreeStream(adaptor,"rule skewedColumnValues");
         pushMsg("column value pair", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2144:5: ( LPAREN colValues= skewedColumnValues RPAREN -> ^( TOK_TABCOLVALUES $colValues) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2145:7: LPAREN colValues= skewedColumnValues RPAREN
            {
            LPAREN807=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_skewedColumnValuePair13112); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN807);


            pushFollow(FOLLOW_skewedColumnValues_in_skewedColumnValuePair13116);
            colValues=skewedColumnValues();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_skewedColumnValues.add(colValues.getTree());

            RPAREN808=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_skewedColumnValuePair13118); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN808);


            // AST REWRITE
            // elements: colValues
            // token labels: 
            // rule labels: colValues, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_colValues=new RewriteRuleSubtreeStream(adaptor,"rule colValues",colValues!=null?colValues.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2146:7: -> ^( TOK_TABCOLVALUES $colValues)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2146:10: ^( TOK_TABCOLVALUES $colValues)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABCOLVALUES, "TOK_TABCOLVALUES")
                , root_1);

                adaptor.addChild(root_1, stream_colValues.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedColumnValuePair"


    public static class skewedColumnValues_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedColumnValues"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2149:1: skewedColumnValues : skewedColumnValue ( COMMA skewedColumnValue )* -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ ) ;
    public final HiveParser.skewedColumnValues_return skewedColumnValues() throws RecognitionException {
        HiveParser.skewedColumnValues_return retval = new HiveParser.skewedColumnValues_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token COMMA810=null;
        HiveParser.skewedColumnValue_return skewedColumnValue809 =null;

        HiveParser.skewedColumnValue_return skewedColumnValue811 =null;


        ASTNode COMMA810_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_skewedColumnValue=new RewriteRuleSubtreeStream(adaptor,"rule skewedColumnValue");
         pushMsg("column values", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2152:5: ( skewedColumnValue ( COMMA skewedColumnValue )* -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2152:7: skewedColumnValue ( COMMA skewedColumnValue )*
            {
            pushFollow(FOLLOW_skewedColumnValue_in_skewedColumnValues13161);
            skewedColumnValue809=skewedColumnValue();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_skewedColumnValue.add(skewedColumnValue809.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2152:25: ( COMMA skewedColumnValue )*
            loop234:
            do {
                int alt234=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt234=1;
                    }
                    break;

                }

                switch (alt234) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2152:26: COMMA skewedColumnValue
            	    {
            	    COMMA810=(Token)match(input,COMMA,FOLLOW_COMMA_in_skewedColumnValues13164); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA810);


            	    pushFollow(FOLLOW_skewedColumnValue_in_skewedColumnValues13166);
            	    skewedColumnValue811=skewedColumnValue();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_skewedColumnValue.add(skewedColumnValue811.getTree());

            	    }
            	    break;

            	default :
            	    break loop234;
                }
            } while (true);


            // AST REWRITE
            // elements: skewedColumnValue
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2152:52: -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2152:55: ^( TOK_TABCOLVALUE ( skewedColumnValue )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABCOLVALUE, "TOK_TABCOLVALUE")
                , root_1);

                if ( !(stream_skewedColumnValue.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_skewedColumnValue.hasNext() ) {
                    adaptor.addChild(root_1, stream_skewedColumnValue.nextTree());

                }
                stream_skewedColumnValue.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedColumnValues"


    public static class skewedColumnValue_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedColumnValue"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2155:1: skewedColumnValue : constant ;
    public final HiveParser.skewedColumnValue_return skewedColumnValue() throws RecognitionException {
        HiveParser.skewedColumnValue_return retval = new HiveParser.skewedColumnValue_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser_IdentifiersParser.constant_return constant812 =null;



         pushMsg("column value", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2158:5: ( constant )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2159:7: constant
            {
            root_0 = (ASTNode)adaptor.nil();


            pushFollow(FOLLOW_constant_in_skewedColumnValue13210);
            constant812=constant();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) adaptor.addChild(root_0, constant812.getTree());

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedColumnValue"


    public static class skewedValueLocationElement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedValueLocationElement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2162:1: skewedValueLocationElement : ( skewedColumnValue | skewedColumnValuePair );
    public final HiveParser.skewedValueLocationElement_return skewedValueLocationElement() throws RecognitionException {
        HiveParser.skewedValueLocationElement_return retval = new HiveParser.skewedValueLocationElement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.skewedColumnValue_return skewedColumnValue813 =null;

        HiveParser.skewedColumnValuePair_return skewedColumnValuePair814 =null;



         pushMsg("skewed value location element", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2165:5: ( skewedColumnValue | skewedColumnValuePair )
            int alt235=2;
            switch ( input.LA(1) ) {
            case BigintLiteral:
            case CharSetName:
            case DecimalLiteral:
            case KW_CURRENT_DATE:
            case KW_CURRENT_TIMESTAMP:
            case KW_DATE:
            case KW_FALSE:
            case KW_NULL:
            case KW_TIMESTAMP:
            case KW_TRUE:
            case Number:
            case SmallintLiteral:
            case StringLiteral:
            case TinyintLiteral:
                {
                alt235=1;
                }
                break;
            case LPAREN:
                {
                alt235=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 235, 0, input);

                throw nvae;

            }

            switch (alt235) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2166:7: skewedColumnValue
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_skewedColumnValue_in_skewedValueLocationElement13244);
                    skewedColumnValue813=skewedColumnValue();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, skewedColumnValue813.getTree());

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2167:8: skewedColumnValuePair
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_skewedColumnValuePair_in_skewedValueLocationElement13253);
                    skewedColumnValuePair814=skewedColumnValuePair();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, skewedColumnValuePair814.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedValueLocationElement"


    public static class orderSpecification_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "orderSpecification"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2170:1: orderSpecification : ( KW_ASC | KW_DESC );
    public final HiveParser.orderSpecification_return orderSpecification() throws RecognitionException {
        HiveParser.orderSpecification_return retval = new HiveParser.orderSpecification_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token set815=null;

        ASTNode set815_tree=null;

         pushMsg("order specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2173:5: ( KW_ASC | KW_DESC )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:
            {
            root_0 = (ASTNode)adaptor.nil();


            set815=(Token)input.LT(1);

            if ( input.LA(1)==KW_ASC||input.LA(1)==KW_DESC ) {
                input.consume();
                if ( state.backtracking==0 ) adaptor.addChild(root_0, 
                (ASTNode)adaptor.create(set815)
                );
                state.errorRecovery=false;
                state.failed=false;
            }
            else {
                if (state.backtracking>0) {state.failed=true; return retval;}
                MismatchedSetException mse = new MismatchedSetException(null,input);
                throw mse;
            }


            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "orderSpecification"


    public static class nullOrdering_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "nullOrdering"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2175:1: nullOrdering : ( KW_NULLS KW_FIRST -> ^( TOK_NULLS_FIRST ) | KW_NULLS KW_LAST -> ^( TOK_NULLS_LAST ) );
    public final HiveParser.nullOrdering_return nullOrdering() throws RecognitionException {
        HiveParser.nullOrdering_return retval = new HiveParser.nullOrdering_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_NULLS816=null;
        Token KW_FIRST817=null;
        Token KW_NULLS818=null;
        Token KW_LAST819=null;

        ASTNode KW_NULLS816_tree=null;
        ASTNode KW_FIRST817_tree=null;
        ASTNode KW_NULLS818_tree=null;
        ASTNode KW_LAST819_tree=null;
        RewriteRuleTokenStream stream_KW_FIRST=new RewriteRuleTokenStream(adaptor,"token KW_FIRST");
        RewriteRuleTokenStream stream_KW_NULLS=new RewriteRuleTokenStream(adaptor,"token KW_NULLS");
        RewriteRuleTokenStream stream_KW_LAST=new RewriteRuleTokenStream(adaptor,"token KW_LAST");

         pushMsg("nulls ordering", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2178:5: ( KW_NULLS KW_FIRST -> ^( TOK_NULLS_FIRST ) | KW_NULLS KW_LAST -> ^( TOK_NULLS_LAST ) )
            int alt236=2;
            switch ( input.LA(1) ) {
            case KW_NULLS:
                {
                switch ( input.LA(2) ) {
                case KW_FIRST:
                    {
                    alt236=1;
                    }
                    break;
                case KW_LAST:
                    {
                    alt236=2;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 236, 1, input);

                    throw nvae;

                }

                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 236, 0, input);

                throw nvae;

            }

            switch (alt236) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2178:7: KW_NULLS KW_FIRST
                    {
                    KW_NULLS816=(Token)match(input,KW_NULLS,FOLLOW_KW_NULLS_in_nullOrdering13307); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_NULLS.add(KW_NULLS816);


                    KW_FIRST817=(Token)match(input,KW_FIRST,FOLLOW_KW_FIRST_in_nullOrdering13309); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_FIRST.add(KW_FIRST817);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2178:25: -> ^( TOK_NULLS_FIRST )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2178:28: ^( TOK_NULLS_FIRST )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2179:7: KW_NULLS KW_LAST
                    {
                    KW_NULLS818=(Token)match(input,KW_NULLS,FOLLOW_KW_NULLS_in_nullOrdering13323); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_NULLS.add(KW_NULLS818);


                    KW_LAST819=(Token)match(input,KW_LAST,FOLLOW_KW_LAST_in_nullOrdering13325); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_LAST.add(KW_LAST819);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2179:24: -> ^( TOK_NULLS_LAST )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2179:27: ^( TOK_NULLS_LAST )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_NULLS_LAST, "TOK_NULLS_LAST")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "nullOrdering"


    public static class columnNameOrder_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameOrder"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2182:1: columnNameOrder : identifier (orderSpec= orderSpecification )? (nullSpec= nullOrdering )? -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) ) -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_DESC}? ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST identifier ) ) -> {$orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) ) -> ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec identifier ) ) ;
    public final HiveParser.columnNameOrder_return columnNameOrder() throws RecognitionException {
        HiveParser.columnNameOrder_return retval = new HiveParser.columnNameOrder_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.orderSpecification_return orderSpec =null;

        HiveParser.nullOrdering_return nullSpec =null;

        HiveParser_IdentifiersParser.identifier_return identifier820 =null;


        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_nullOrdering=new RewriteRuleSubtreeStream(adaptor,"rule nullOrdering");
        RewriteRuleSubtreeStream stream_orderSpecification=new RewriteRuleSubtreeStream(adaptor,"rule orderSpecification");
         pushMsg("column name order", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:5: ( identifier (orderSpec= orderSpecification )? (nullSpec= nullOrdering )? -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) ) -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_DESC}? ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST identifier ) ) -> {$orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) ) -> ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec identifier ) ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:7: identifier (orderSpec= orderSpecification )? (nullSpec= nullOrdering )?
            {
            pushFollow(FOLLOW_identifier_in_columnNameOrder13358);
            identifier820=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(identifier820.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:27: (orderSpec= orderSpecification )?
            int alt237=2;
            switch ( input.LA(1) ) {
                case KW_ASC:
                case KW_DESC:
                    {
                    alt237=1;
                    }
                    break;
            }

            switch (alt237) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:27: orderSpec= orderSpecification
                    {
                    pushFollow(FOLLOW_orderSpecification_in_columnNameOrder13362);
                    orderSpec=orderSpecification();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_orderSpecification.add(orderSpec.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:56: (nullSpec= nullOrdering )?
            int alt238=2;
            switch ( input.LA(1) ) {
                case KW_NULLS:
                    {
                    alt238=1;
                    }
                    break;
            }

            switch (alt238) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:56: nullSpec= nullOrdering
                    {
                    pushFollow(FOLLOW_nullOrdering_in_columnNameOrder13367);
                    nullSpec=nullOrdering();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_nullOrdering.add(nullSpec.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: identifier, identifier, identifier, nullSpec, identifier, nullSpec, identifier, nullSpec, identifier
            // token labels: 
            // rule labels: nullSpec, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_nullSpec=new RewriteRuleSubtreeStream(adaptor,"rule nullSpec",nullSpec!=null?nullSpec.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2186:5: -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) )
            if ((orderSpec!=null?((ASTNode)orderSpec.tree):null) == null && (nullSpec!=null?((ASTNode)nullSpec.tree):null) == null) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2187:13: ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2187:37: ^( TOK_NULLS_FIRST identifier )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST")
                , root_2);

                adaptor.addChild(root_2, stream_identifier.nextTree());

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 2188:5: -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) )
            if ((orderSpec!=null?((ASTNode)orderSpec.tree):null) == null) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2189:13: ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2189:37: ^( $nullSpec identifier )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);

                adaptor.addChild(root_2, stream_identifier.nextTree());

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 2190:5: -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) )
            if ((nullSpec!=null?((ASTNode)nullSpec.tree):null) == null && (orderSpec!=null?((ASTNode)orderSpec.tree):null).getType()==HiveParser.KW_ASC) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2191:13: ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2191:37: ^( TOK_NULLS_FIRST identifier )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST")
                , root_2);

                adaptor.addChild(root_2, stream_identifier.nextTree());

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 2192:5: -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_DESC}? ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST identifier ) )
            if ((nullSpec!=null?((ASTNode)nullSpec.tree):null) == null && (orderSpec!=null?((ASTNode)orderSpec.tree):null).getType()==HiveParser.KW_DESC) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2193:13: ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST identifier ) )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2193:38: ^( TOK_NULLS_LAST identifier )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_NULLS_LAST, "TOK_NULLS_LAST")
                , root_2);

                adaptor.addChild(root_2, stream_identifier.nextTree());

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 2194:5: -> {$orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) )
            if ((orderSpec!=null?((ASTNode)orderSpec.tree):null).getType()==HiveParser.KW_ASC) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2195:13: ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2195:37: ^( $nullSpec identifier )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);

                adaptor.addChild(root_2, stream_identifier.nextTree());

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 2196:5: -> ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec identifier ) )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2196:8: ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec identifier ) )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2196:33: ^( $nullSpec identifier )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);

                adaptor.addChild(root_2, stream_identifier.nextTree());

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameOrder"


    public static class columnNameCommentList_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameCommentList"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2199:1: columnNameCommentList : columnNameComment ( COMMA columnNameComment )* -> ^( TOK_TABCOLNAME ( columnNameComment )+ ) ;
    public final HiveParser.columnNameCommentList_return columnNameCommentList() throws RecognitionException {
        HiveParser.columnNameCommentList_return retval = new HiveParser.columnNameCommentList_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token COMMA822=null;
        HiveParser.columnNameComment_return columnNameComment821 =null;

        HiveParser.columnNameComment_return columnNameComment823 =null;


        ASTNode COMMA822_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_columnNameComment=new RewriteRuleSubtreeStream(adaptor,"rule columnNameComment");
         pushMsg("column name comment list", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2202:5: ( columnNameComment ( COMMA columnNameComment )* -> ^( TOK_TABCOLNAME ( columnNameComment )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2202:7: columnNameComment ( COMMA columnNameComment )*
            {
            pushFollow(FOLLOW_columnNameComment_in_columnNameCommentList13564);
            columnNameComment821=columnNameComment();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnNameComment.add(columnNameComment821.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2202:25: ( COMMA columnNameComment )*
            loop239:
            do {
                int alt239=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt239=1;
                    }
                    break;

                }

                switch (alt239) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2202:26: COMMA columnNameComment
            	    {
            	    COMMA822=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameCommentList13567); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA822);


            	    pushFollow(FOLLOW_columnNameComment_in_columnNameCommentList13569);
            	    columnNameComment823=columnNameComment();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_columnNameComment.add(columnNameComment823.getTree());

            	    }
            	    break;

            	default :
            	    break loop239;
                }
            } while (true);


            // AST REWRITE
            // elements: columnNameComment
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2202:52: -> ^( TOK_TABCOLNAME ( columnNameComment )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2202:55: ^( TOK_TABCOLNAME ( columnNameComment )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME")
                , root_1);

                if ( !(stream_columnNameComment.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_columnNameComment.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameComment.nextTree());

                }
                stream_columnNameComment.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameCommentList"


    public static class columnNameComment_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameComment"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2205:1: columnNameComment : colName= identifier ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? ) ;
    public final HiveParser.columnNameComment_return columnNameComment() throws RecognitionException {
        HiveParser.columnNameComment_return retval = new HiveParser.columnNameComment_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token comment=null;
        Token KW_COMMENT824=null;
        HiveParser_IdentifiersParser.identifier_return colName =null;


        ASTNode comment_tree=null;
        ASTNode KW_COMMENT824_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         pushMsg("column name comment", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2208:5: (colName= identifier ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2208:7: colName= identifier ( KW_COMMENT comment= StringLiteral )?
            {
            pushFollow(FOLLOW_identifier_in_columnNameComment13609);
            colName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2208:26: ( KW_COMMENT comment= StringLiteral )?
            int alt240=2;
            switch ( input.LA(1) ) {
                case KW_COMMENT:
                    {
                    alt240=1;
                    }
                    break;
            }

            switch (alt240) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2208:27: KW_COMMENT comment= StringLiteral
                    {
                    KW_COMMENT824=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameComment13612); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT824);


                    comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameComment13616); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(comment);


                    }
                    break;

            }


            // AST REWRITE
            // elements: colName, comment
            // token labels: comment
            // rule labels: colName, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
            RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2209:5: -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2209:8: ^( TOK_TABCOL $colName TOK_NULL ( $comment)? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL")
                , root_1);

                adaptor.addChild(root_1, stream_colName.nextTree());

                adaptor.addChild(root_1, 
                (ASTNode)adaptor.create(TOK_NULL, "TOK_NULL")
                );

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2209:40: ( $comment)?
                if ( stream_comment.hasNext() ) {
                    adaptor.addChild(root_1, stream_comment.nextNode());

                }
                stream_comment.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameComment"


    public static class columnRefOrder_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnRefOrder"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2212:1: columnRefOrder : expression (orderSpec= orderSpecification )? (nullSpec= nullOrdering )? -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) ) -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_DESC}? ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST expression ) ) -> {$orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) ) -> ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec expression ) ) ;
    public final HiveParser.columnRefOrder_return columnRefOrder() throws RecognitionException {
        HiveParser.columnRefOrder_return retval = new HiveParser.columnRefOrder_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.orderSpecification_return orderSpec =null;

        HiveParser.nullOrdering_return nullSpec =null;

        HiveParser_IdentifiersParser.expression_return expression825 =null;


        RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
        RewriteRuleSubtreeStream stream_nullOrdering=new RewriteRuleSubtreeStream(adaptor,"rule nullOrdering");
        RewriteRuleSubtreeStream stream_orderSpecification=new RewriteRuleSubtreeStream(adaptor,"rule orderSpecification");
         pushMsg("column order", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:5: ( expression (orderSpec= orderSpecification )? (nullSpec= nullOrdering )? -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) ) -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_DESC}? ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST expression ) ) -> {$orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) ) -> ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec expression ) ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:7: expression (orderSpec= orderSpecification )? (nullSpec= nullOrdering )?
            {
            pushFollow(FOLLOW_expression_in_columnRefOrder13664);
            expression825=expression();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_expression.add(expression825.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:27: (orderSpec= orderSpecification )?
            int alt241=2;
            switch ( input.LA(1) ) {
                case KW_ASC:
                case KW_DESC:
                    {
                    alt241=1;
                    }
                    break;
            }

            switch (alt241) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:27: orderSpec= orderSpecification
                    {
                    pushFollow(FOLLOW_orderSpecification_in_columnRefOrder13668);
                    orderSpec=orderSpecification();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_orderSpecification.add(orderSpec.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:56: (nullSpec= nullOrdering )?
            int alt242=2;
            switch ( input.LA(1) ) {
                case KW_NULLS:
                    {
                    alt242=1;
                    }
                    break;
            }

            switch (alt242) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:56: nullSpec= nullOrdering
                    {
                    pushFollow(FOLLOW_nullOrdering_in_columnRefOrder13673);
                    nullSpec=nullOrdering();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_nullOrdering.add(nullSpec.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: expression, expression, nullSpec, expression, nullSpec, expression, expression, expression, nullSpec
            // token labels: 
            // rule labels: nullSpec, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_nullSpec=new RewriteRuleSubtreeStream(adaptor,"rule nullSpec",nullSpec!=null?nullSpec.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2216:5: -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) )
            if ((orderSpec!=null?((ASTNode)orderSpec.tree):null) == null && (nullSpec!=null?((ASTNode)nullSpec.tree):null) == null) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2217:13: ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2217:37: ^( TOK_NULLS_FIRST expression )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST")
                , root_2);

                adaptor.addChild(root_2, stream_expression.nextTree());

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 2218:5: -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) )
            if ((orderSpec!=null?((ASTNode)orderSpec.tree):null) == null) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2219:13: ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2219:37: ^( $nullSpec expression )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);

                adaptor.addChild(root_2, stream_expression.nextTree());

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 2220:5: -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) )
            if ((nullSpec!=null?((ASTNode)nullSpec.tree):null) == null && (orderSpec!=null?((ASTNode)orderSpec.tree):null).getType()==HiveParser.KW_ASC) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2221:13: ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2221:37: ^( TOK_NULLS_FIRST expression )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST")
                , root_2);

                adaptor.addChild(root_2, stream_expression.nextTree());

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 2222:5: -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_DESC}? ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST expression ) )
            if ((nullSpec!=null?((ASTNode)nullSpec.tree):null) == null && (orderSpec!=null?((ASTNode)orderSpec.tree):null).getType()==HiveParser.KW_DESC) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2223:13: ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST expression ) )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2223:38: ^( TOK_NULLS_LAST expression )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_NULLS_LAST, "TOK_NULLS_LAST")
                , root_2);

                adaptor.addChild(root_2, stream_expression.nextTree());

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 2224:5: -> {$orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) )
            if ((orderSpec!=null?((ASTNode)orderSpec.tree):null).getType()==HiveParser.KW_ASC) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2225:13: ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2225:37: ^( $nullSpec expression )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);

                adaptor.addChild(root_2, stream_expression.nextTree());

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 2226:5: -> ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec expression ) )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2226:8: ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec expression ) )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2226:33: ^( $nullSpec expression )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);

                adaptor.addChild(root_2, stream_expression.nextTree());

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnRefOrder"


    public static class columnNameType_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameType"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2229:1: columnNameType : colName= identifier colType ( KW_COMMENT comment= StringLiteral )? -> {containExcludedCharForCreateTableColumnName($colName.text)}? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) ;
    public final HiveParser.columnNameType_return columnNameType() throws RecognitionException {
        HiveParser.columnNameType_return retval = new HiveParser.columnNameType_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token comment=null;
        Token KW_COMMENT827=null;
        HiveParser_IdentifiersParser.identifier_return colName =null;

        HiveParser.colType_return colType826 =null;


        ASTNode comment_tree=null;
        ASTNode KW_COMMENT827_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");
         pushMsg("column specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2232:5: (colName= identifier colType ( KW_COMMENT comment= StringLiteral )? -> {containExcludedCharForCreateTableColumnName($colName.text)}? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2232:7: colName= identifier colType ( KW_COMMENT comment= StringLiteral )?
            {
            pushFollow(FOLLOW_identifier_in_columnNameType13872);
            colName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());

            pushFollow(FOLLOW_colType_in_columnNameType13874);
            colType826=colType();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_colType.add(colType826.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2232:34: ( KW_COMMENT comment= StringLiteral )?
            int alt243=2;
            switch ( input.LA(1) ) {
                case KW_COMMENT:
                    {
                    alt243=1;
                    }
                    break;
            }

            switch (alt243) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2232:35: KW_COMMENT comment= StringLiteral
                    {
                    KW_COMMENT827=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameType13877); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT827);


                    comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameType13881); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(comment);


                    }
                    break;

            }


            // AST REWRITE
            // elements: colType, colType, comment, colName, colName
            // token labels: comment
            // rule labels: colName, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
            RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2233:5: -> {containExcludedCharForCreateTableColumnName($colName.text)}?
            if (containExcludedCharForCreateTableColumnName((colName!=null?input.toString(colName.start,colName.stop):null))) {
                adaptor.addChild(root_0, throwColumnNameException());

            }

            else // 2234:5: -> {$comment == null}? ^( TOK_TABCOL $colName colType )
            if (comment == null) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2234:28: ^( TOK_TABCOL $colName colType )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL")
                , root_1);

                adaptor.addChild(root_1, stream_colName.nextTree());

                adaptor.addChild(root_1, stream_colType.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 2235:5: -> ^( TOK_TABCOL $colName colType $comment)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2235:28: ^( TOK_TABCOL $colName colType $comment)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL")
                , root_1);

                adaptor.addChild(root_1, stream_colName.nextTree());

                adaptor.addChild(root_1, stream_colType.nextTree());

                adaptor.addChild(root_1, stream_comment.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameType"


    public static class columnNameTypeOrPKOrFK_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameTypeOrPKOrFK"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2238:1: columnNameTypeOrPKOrFK : ( ( foreignKeyWithName ) | ( primaryKeyWithName ) | ( primaryKeyWithoutName ) | ( foreignKeyWithoutName ) | ( columnNameType ) );
    public final HiveParser.columnNameTypeOrPKOrFK_return columnNameTypeOrPKOrFK() throws RecognitionException {
        HiveParser.columnNameTypeOrPKOrFK_return retval = new HiveParser.columnNameTypeOrPKOrFK_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.foreignKeyWithName_return foreignKeyWithName828 =null;

        HiveParser.primaryKeyWithName_return primaryKeyWithName829 =null;

        HiveParser.primaryKeyWithoutName_return primaryKeyWithoutName830 =null;

        HiveParser.foreignKeyWithoutName_return foreignKeyWithoutName831 =null;

        HiveParser.columnNameType_return columnNameType832 =null;



         pushMsg("column name or primary key or foreign key", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2241:5: ( ( foreignKeyWithName ) | ( primaryKeyWithName ) | ( primaryKeyWithoutName ) | ( foreignKeyWithoutName ) | ( columnNameType ) )
            int alt244=5;
            alt244 = dfa244.predict(input);
            switch (alt244) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2241:7: ( foreignKeyWithName )
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2241:7: ( foreignKeyWithName )
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2241:9: foreignKeyWithName
                    {
                    pushFollow(FOLLOW_foreignKeyWithName_in_columnNameTypeOrPKOrFK13977);
                    foreignKeyWithName828=foreignKeyWithName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, foreignKeyWithName828.getTree());

                    }


                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2242:7: ( primaryKeyWithName )
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2242:7: ( primaryKeyWithName )
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2242:9: primaryKeyWithName
                    {
                    pushFollow(FOLLOW_primaryKeyWithName_in_columnNameTypeOrPKOrFK13989);
                    primaryKeyWithName829=primaryKeyWithName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, primaryKeyWithName829.getTree());

                    }


                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2243:7: ( primaryKeyWithoutName )
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2243:7: ( primaryKeyWithoutName )
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2243:9: primaryKeyWithoutName
                    {
                    pushFollow(FOLLOW_primaryKeyWithoutName_in_columnNameTypeOrPKOrFK14001);
                    primaryKeyWithoutName830=primaryKeyWithoutName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, primaryKeyWithoutName830.getTree());

                    }


                    }
                    break;
                case 4 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2244:7: ( foreignKeyWithoutName )
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2244:7: ( foreignKeyWithoutName )
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2244:9: foreignKeyWithoutName
                    {
                    pushFollow(FOLLOW_foreignKeyWithoutName_in_columnNameTypeOrPKOrFK14013);
                    foreignKeyWithoutName831=foreignKeyWithoutName();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, foreignKeyWithoutName831.getTree());

                    }


                    }
                    break;
                case 5 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:7: ( columnNameType )
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:7: ( columnNameType )
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:9: columnNameType
                    {
                    pushFollow(FOLLOW_columnNameType_in_columnNameTypeOrPKOrFK14025);
                    columnNameType832=columnNameType();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, columnNameType832.getTree());

                    }


                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameTypeOrPKOrFK"


    public static class columnNameColonType_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameColonType"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2248:1: columnNameColonType : colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) ;
    public final HiveParser.columnNameColonType_return columnNameColonType() throws RecognitionException {
        HiveParser.columnNameColonType_return retval = new HiveParser.columnNameColonType_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token comment=null;
        Token COLON833=null;
        Token KW_COMMENT835=null;
        HiveParser_IdentifiersParser.identifier_return colName =null;

        HiveParser.colType_return colType834 =null;


        ASTNode comment_tree=null;
        ASTNode COLON833_tree=null;
        ASTNode KW_COMMENT835_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_COLON=new RewriteRuleTokenStream(adaptor,"token COLON");
        RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");
         pushMsg("column specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2251:5: (colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2251:7: colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )?
            {
            pushFollow(FOLLOW_identifier_in_columnNameColonType14056);
            colName=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());

            COLON833=(Token)match(input,COLON,FOLLOW_COLON_in_columnNameColonType14058); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_COLON.add(COLON833);


            pushFollow(FOLLOW_colType_in_columnNameColonType14060);
            colType834=colType();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_colType.add(colType834.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2251:40: ( KW_COMMENT comment= StringLiteral )?
            int alt245=2;
            switch ( input.LA(1) ) {
                case KW_COMMENT:
                    {
                    alt245=1;
                    }
                    break;
            }

            switch (alt245) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2251:41: KW_COMMENT comment= StringLiteral
                    {
                    KW_COMMENT835=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameColonType14063); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT835);


                    comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameColonType14067); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(comment);


                    }
                    break;

            }


            // AST REWRITE
            // elements: colName, colType, colType, comment, colName
            // token labels: comment
            // rule labels: colName, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
            RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2252:5: -> {$comment == null}? ^( TOK_TABCOL $colName colType )
            if (comment == null) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2252:28: ^( TOK_TABCOL $colName colType )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL")
                , root_1);

                adaptor.addChild(root_1, stream_colName.nextTree());

                adaptor.addChild(root_1, stream_colType.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 2253:5: -> ^( TOK_TABCOL $colName colType $comment)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2253:28: ^( TOK_TABCOL $colName colType $comment)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL")
                , root_1);

                adaptor.addChild(root_1, stream_colName.nextTree());

                adaptor.addChild(root_1, stream_colType.nextTree());

                adaptor.addChild(root_1, stream_comment.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameColonType"


    public static class colType_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "colType"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2256:1: colType : type ;
    public final HiveParser.colType_return colType() throws RecognitionException {
        HiveParser.colType_return retval = new HiveParser.colType_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.type_return type836 =null;



         pushMsg("column type", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2259:5: ( type )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2259:7: type
            {
            root_0 = (ASTNode)adaptor.nil();


            pushFollow(FOLLOW_type_in_colType14151);
            type836=type();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) adaptor.addChild(root_0, type836.getTree());

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "colType"


    public static class colTypeList_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "colTypeList"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:1: colTypeList : colType ( COMMA colType )* -> ^( TOK_COLTYPELIST ( colType )+ ) ;
    public final HiveParser.colTypeList_return colTypeList() throws RecognitionException {
        HiveParser.colTypeList_return retval = new HiveParser.colTypeList_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token COMMA838=null;
        HiveParser.colType_return colType837 =null;

        HiveParser.colType_return colType839 =null;


        ASTNode COMMA838_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");
         pushMsg("column type list", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2265:5: ( colType ( COMMA colType )* -> ^( TOK_COLTYPELIST ( colType )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2265:7: colType ( COMMA colType )*
            {
            pushFollow(FOLLOW_colType_in_colTypeList14178);
            colType837=colType();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_colType.add(colType837.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2265:15: ( COMMA colType )*
            loop246:
            do {
                int alt246=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt246=1;
                    }
                    break;

                }

                switch (alt246) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2265:16: COMMA colType
            	    {
            	    COMMA838=(Token)match(input,COMMA,FOLLOW_COMMA_in_colTypeList14181); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA838);


            	    pushFollow(FOLLOW_colType_in_colTypeList14183);
            	    colType839=colType();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_colType.add(colType839.getTree());

            	    }
            	    break;

            	default :
            	    break loop246;
                }
            } while (true);


            // AST REWRITE
            // elements: colType
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2265:32: -> ^( TOK_COLTYPELIST ( colType )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2265:35: ^( TOK_COLTYPELIST ( colType )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_COLTYPELIST, "TOK_COLTYPELIST")
                , root_1);

                if ( !(stream_colType.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_colType.hasNext() ) {
                    adaptor.addChild(root_1, stream_colType.nextTree());

                }
                stream_colType.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "colTypeList"


    public static class type_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "type"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2268:1: type : ( primitiveType | listType | structType | mapType | unionType );
    public final HiveParser.type_return type() throws RecognitionException {
        HiveParser.type_return retval = new HiveParser.type_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.primitiveType_return primitiveType840 =null;

        HiveParser.listType_return listType841 =null;

        HiveParser.structType_return structType842 =null;

        HiveParser.mapType_return mapType843 =null;

        HiveParser.unionType_return unionType844 =null;



        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2269:5: ( primitiveType | listType | structType | mapType | unionType )
            int alt247=5;
            switch ( input.LA(1) ) {
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_CHAR:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DECIMAL:
            case KW_DOUBLE:
            case KW_FLOAT:
            case KW_INT:
            case KW_SMALLINT:
            case KW_STRING:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_VARCHAR:
                {
                alt247=1;
                }
                break;
            case KW_ARRAY:
                {
                alt247=2;
                }
                break;
            case KW_STRUCT:
                {
                alt247=3;
                }
                break;
            case KW_MAP:
                {
                alt247=4;
                }
                break;
            case KW_UNIONTYPE:
                {
                alt247=5;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 247, 0, input);

                throw nvae;

            }

            switch (alt247) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2269:7: primitiveType
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_primitiveType_in_type14211);
                    primitiveType840=primitiveType();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, primitiveType840.getTree());

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2270:7: listType
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_listType_in_type14219);
                    listType841=listType();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, listType841.getTree());

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2271:7: structType
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_structType_in_type14227);
                    structType842=structType();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, structType842.getTree());

                    }
                    break;
                case 4 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2272:7: mapType
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_mapType_in_type14235);
                    mapType843=mapType();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, mapType843.getTree());

                    }
                    break;
                case 5 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2273:7: unionType
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_unionType_in_type14243);
                    unionType844=unionType();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, unionType844.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "type"


    public static class primitiveType_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "primitiveType"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2275:1: primitiveType : ( KW_TINYINT -> TOK_TINYINT | KW_SMALLINT -> TOK_SMALLINT | KW_INT -> TOK_INT | KW_BIGINT -> TOK_BIGINT | KW_BOOLEAN -> TOK_BOOLEAN | KW_FLOAT -> TOK_FLOAT | KW_DOUBLE -> TOK_DOUBLE | KW_DATE -> TOK_DATE | KW_DATETIME -> TOK_DATETIME | KW_TIMESTAMP -> TOK_TIMESTAMP | KW_STRING -> TOK_STRING | KW_BINARY -> TOK_BINARY | KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )? -> ^( TOK_DECIMAL ( $prec)? ( $scale)? ) | KW_VARCHAR LPAREN length= Number RPAREN -> ^( TOK_VARCHAR $length) | KW_CHAR LPAREN length= Number RPAREN -> ^( TOK_CHAR $length) );
    public final HiveParser.primitiveType_return primitiveType() throws RecognitionException {
        HiveParser.primitiveType_return retval = new HiveParser.primitiveType_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token prec=null;
        Token scale=null;
        Token length=null;
        Token KW_TINYINT845=null;
        Token KW_SMALLINT846=null;
        Token KW_INT847=null;
        Token KW_BIGINT848=null;
        Token KW_BOOLEAN849=null;
        Token KW_FLOAT850=null;
        Token KW_DOUBLE851=null;
        Token KW_DATE852=null;
        Token KW_DATETIME853=null;
        Token KW_TIMESTAMP854=null;
        Token KW_STRING855=null;
        Token KW_BINARY856=null;
        Token KW_DECIMAL857=null;
        Token LPAREN858=null;
        Token COMMA859=null;
        Token RPAREN860=null;
        Token KW_VARCHAR861=null;
        Token LPAREN862=null;
        Token RPAREN863=null;
        Token KW_CHAR864=null;
        Token LPAREN865=null;
        Token RPAREN866=null;

        ASTNode prec_tree=null;
        ASTNode scale_tree=null;
        ASTNode length_tree=null;
        ASTNode KW_TINYINT845_tree=null;
        ASTNode KW_SMALLINT846_tree=null;
        ASTNode KW_INT847_tree=null;
        ASTNode KW_BIGINT848_tree=null;
        ASTNode KW_BOOLEAN849_tree=null;
        ASTNode KW_FLOAT850_tree=null;
        ASTNode KW_DOUBLE851_tree=null;
        ASTNode KW_DATE852_tree=null;
        ASTNode KW_DATETIME853_tree=null;
        ASTNode KW_TIMESTAMP854_tree=null;
        ASTNode KW_STRING855_tree=null;
        ASTNode KW_BINARY856_tree=null;
        ASTNode KW_DECIMAL857_tree=null;
        ASTNode LPAREN858_tree=null;
        ASTNode COMMA859_tree=null;
        ASTNode RPAREN860_tree=null;
        ASTNode KW_VARCHAR861_tree=null;
        ASTNode LPAREN862_tree=null;
        ASTNode RPAREN863_tree=null;
        ASTNode KW_CHAR864_tree=null;
        ASTNode LPAREN865_tree=null;
        ASTNode RPAREN866_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleTokenStream stream_KW_SMALLINT=new RewriteRuleTokenStream(adaptor,"token KW_SMALLINT");
        RewriteRuleTokenStream stream_KW_DATE=new RewriteRuleTokenStream(adaptor,"token KW_DATE");
        RewriteRuleTokenStream stream_KW_DATETIME=new RewriteRuleTokenStream(adaptor,"token KW_DATETIME");
        RewriteRuleTokenStream stream_KW_TIMESTAMP=new RewriteRuleTokenStream(adaptor,"token KW_TIMESTAMP");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_KW_BOOLEAN=new RewriteRuleTokenStream(adaptor,"token KW_BOOLEAN");
        RewriteRuleTokenStream stream_KW_DOUBLE=new RewriteRuleTokenStream(adaptor,"token KW_DOUBLE");
        RewriteRuleTokenStream stream_KW_BIGINT=new RewriteRuleTokenStream(adaptor,"token KW_BIGINT");
        RewriteRuleTokenStream stream_KW_CHAR=new RewriteRuleTokenStream(adaptor,"token KW_CHAR");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_INT=new RewriteRuleTokenStream(adaptor,"token KW_INT");
        RewriteRuleTokenStream stream_KW_STRING=new RewriteRuleTokenStream(adaptor,"token KW_STRING");
        RewriteRuleTokenStream stream_KW_DECIMAL=new RewriteRuleTokenStream(adaptor,"token KW_DECIMAL");
        RewriteRuleTokenStream stream_KW_VARCHAR=new RewriteRuleTokenStream(adaptor,"token KW_VARCHAR");
        RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
        RewriteRuleTokenStream stream_KW_FLOAT=new RewriteRuleTokenStream(adaptor,"token KW_FLOAT");
        RewriteRuleTokenStream stream_KW_TINYINT=new RewriteRuleTokenStream(adaptor,"token KW_TINYINT");
        RewriteRuleTokenStream stream_KW_BINARY=new RewriteRuleTokenStream(adaptor,"token KW_BINARY");

         pushMsg("primitive type specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2278:5: ( KW_TINYINT -> TOK_TINYINT | KW_SMALLINT -> TOK_SMALLINT | KW_INT -> TOK_INT | KW_BIGINT -> TOK_BIGINT | KW_BOOLEAN -> TOK_BOOLEAN | KW_FLOAT -> TOK_FLOAT | KW_DOUBLE -> TOK_DOUBLE | KW_DATE -> TOK_DATE | KW_DATETIME -> TOK_DATETIME | KW_TIMESTAMP -> TOK_TIMESTAMP | KW_STRING -> TOK_STRING | KW_BINARY -> TOK_BINARY | KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )? -> ^( TOK_DECIMAL ( $prec)? ( $scale)? ) | KW_VARCHAR LPAREN length= Number RPAREN -> ^( TOK_VARCHAR $length) | KW_CHAR LPAREN length= Number RPAREN -> ^( TOK_CHAR $length) )
            int alt250=15;
            switch ( input.LA(1) ) {
            case KW_TINYINT:
                {
                alt250=1;
                }
                break;
            case KW_SMALLINT:
                {
                alt250=2;
                }
                break;
            case KW_INT:
                {
                alt250=3;
                }
                break;
            case KW_BIGINT:
                {
                alt250=4;
                }
                break;
            case KW_BOOLEAN:
                {
                alt250=5;
                }
                break;
            case KW_FLOAT:
                {
                alt250=6;
                }
                break;
            case KW_DOUBLE:
                {
                alt250=7;
                }
                break;
            case KW_DATE:
                {
                alt250=8;
                }
                break;
            case KW_DATETIME:
                {
                alt250=9;
                }
                break;
            case KW_TIMESTAMP:
                {
                alt250=10;
                }
                break;
            case KW_STRING:
                {
                alt250=11;
                }
                break;
            case KW_BINARY:
                {
                alt250=12;
                }
                break;
            case KW_DECIMAL:
                {
                alt250=13;
                }
                break;
            case KW_VARCHAR:
                {
                alt250=14;
                }
                break;
            case KW_CHAR:
                {
                alt250=15;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 250, 0, input);

                throw nvae;

            }

            switch (alt250) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2278:7: KW_TINYINT
                    {
                    KW_TINYINT845=(Token)match(input,KW_TINYINT,FOLLOW_KW_TINYINT_in_primitiveType14265); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TINYINT.add(KW_TINYINT845);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2278:24: -> TOK_TINYINT
                    {
                        adaptor.addChild(root_0, 
                        (ASTNode)adaptor.create(TOK_TINYINT, "TOK_TINYINT")
                        );

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2279:7: KW_SMALLINT
                    {
                    KW_SMALLINT846=(Token)match(input,KW_SMALLINT,FOLLOW_KW_SMALLINT_in_primitiveType14286); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_SMALLINT.add(KW_SMALLINT846);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2279:24: -> TOK_SMALLINT
                    {
                        adaptor.addChild(root_0, 
                        (ASTNode)adaptor.create(TOK_SMALLINT, "TOK_SMALLINT")
                        );

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2280:7: KW_INT
                    {
                    KW_INT847=(Token)match(input,KW_INT,FOLLOW_KW_INT_in_primitiveType14306); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_INT.add(KW_INT847);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2280:24: -> TOK_INT
                    {
                        adaptor.addChild(root_0, 
                        (ASTNode)adaptor.create(TOK_INT, "TOK_INT")
                        );

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 4 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2281:7: KW_BIGINT
                    {
                    KW_BIGINT848=(Token)match(input,KW_BIGINT,FOLLOW_KW_BIGINT_in_primitiveType14331); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_BIGINT.add(KW_BIGINT848);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2281:24: -> TOK_BIGINT
                    {
                        adaptor.addChild(root_0, 
                        (ASTNode)adaptor.create(TOK_BIGINT, "TOK_BIGINT")
                        );

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 5 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2282:7: KW_BOOLEAN
                    {
                    KW_BOOLEAN849=(Token)match(input,KW_BOOLEAN,FOLLOW_KW_BOOLEAN_in_primitiveType14353); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_BOOLEAN.add(KW_BOOLEAN849);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2282:24: -> TOK_BOOLEAN
                    {
                        adaptor.addChild(root_0, 
                        (ASTNode)adaptor.create(TOK_BOOLEAN, "TOK_BOOLEAN")
                        );

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 6 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2283:7: KW_FLOAT
                    {
                    KW_FLOAT850=(Token)match(input,KW_FLOAT,FOLLOW_KW_FLOAT_in_primitiveType14374); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_FLOAT.add(KW_FLOAT850);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2283:24: -> TOK_FLOAT
                    {
                        adaptor.addChild(root_0, 
                        (ASTNode)adaptor.create(TOK_FLOAT, "TOK_FLOAT")
                        );

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 7 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2284:7: KW_DOUBLE
                    {
                    KW_DOUBLE851=(Token)match(input,KW_DOUBLE,FOLLOW_KW_DOUBLE_in_primitiveType14397); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_DOUBLE.add(KW_DOUBLE851);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2284:24: -> TOK_DOUBLE
                    {
                        adaptor.addChild(root_0, 
                        (ASTNode)adaptor.create(TOK_DOUBLE, "TOK_DOUBLE")
                        );

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 8 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2285:7: KW_DATE
                    {
                    KW_DATE852=(Token)match(input,KW_DATE,FOLLOW_KW_DATE_in_primitiveType14419); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_DATE.add(KW_DATE852);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2285:24: -> TOK_DATE
                    {
                        adaptor.addChild(root_0, 
                        (ASTNode)adaptor.create(TOK_DATE, "TOK_DATE")
                        );

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 9 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2286:7: KW_DATETIME
                    {
                    KW_DATETIME853=(Token)match(input,KW_DATETIME,FOLLOW_KW_DATETIME_in_primitiveType14443); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_DATETIME.add(KW_DATETIME853);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2286:24: -> TOK_DATETIME
                    {
                        adaptor.addChild(root_0, 
                        (ASTNode)adaptor.create(TOK_DATETIME, "TOK_DATETIME")
                        );

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 10 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2287:7: KW_TIMESTAMP
                    {
                    KW_TIMESTAMP854=(Token)match(input,KW_TIMESTAMP,FOLLOW_KW_TIMESTAMP_in_primitiveType14463); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TIMESTAMP.add(KW_TIMESTAMP854);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2287:24: -> TOK_TIMESTAMP
                    {
                        adaptor.addChild(root_0, 
                        (ASTNode)adaptor.create(TOK_TIMESTAMP, "TOK_TIMESTAMP")
                        );

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 11 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2291:7: KW_STRING
                    {
                    KW_STRING855=(Token)match(input,KW_STRING,FOLLOW_KW_STRING_in_primitiveType14497); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_STRING.add(KW_STRING855);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2291:24: -> TOK_STRING
                    {
                        adaptor.addChild(root_0, 
                        (ASTNode)adaptor.create(TOK_STRING, "TOK_STRING")
                        );

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 12 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2292:7: KW_BINARY
                    {
                    KW_BINARY856=(Token)match(input,KW_BINARY,FOLLOW_KW_BINARY_in_primitiveType14519); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_BINARY.add(KW_BINARY856);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2292:24: -> TOK_BINARY
                    {
                        adaptor.addChild(root_0, 
                        (ASTNode)adaptor.create(TOK_BINARY, "TOK_BINARY")
                        );

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 13 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:7: KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )?
                    {
                    KW_DECIMAL857=(Token)match(input,KW_DECIMAL,FOLLOW_KW_DECIMAL_in_primitiveType14541); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_DECIMAL.add(KW_DECIMAL857);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:18: ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )?
                    int alt249=2;
                    switch ( input.LA(1) ) {
                        case LPAREN:
                            {
                            alt249=1;
                            }
                            break;
                    }

                    switch (alt249) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:19: LPAREN prec= Number ( COMMA scale= Number )? RPAREN
                            {
                            LPAREN858=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_primitiveType14544); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN858);


                            prec=(Token)match(input,Number,FOLLOW_Number_in_primitiveType14548); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_Number.add(prec);


                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:38: ( COMMA scale= Number )?
                            int alt248=2;
                            switch ( input.LA(1) ) {
                                case COMMA:
                                    {
                                    alt248=1;
                                    }
                                    break;
                            }

                            switch (alt248) {
                                case 1 :
                                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:39: COMMA scale= Number
                                    {
                                    COMMA859=(Token)match(input,COMMA,FOLLOW_COMMA_in_primitiveType14551); if (state.failed) return retval; 
                                    if ( state.backtracking==0 ) stream_COMMA.add(COMMA859);


                                    scale=(Token)match(input,Number,FOLLOW_Number_in_primitiveType14555); if (state.failed) return retval; 
                                    if ( state.backtracking==0 ) stream_Number.add(scale);


                                    }
                                    break;

                            }


                            RPAREN860=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_primitiveType14559); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN860);


                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: scale, prec
                    // token labels: prec, scale
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_prec=new RewriteRuleTokenStream(adaptor,"token prec",prec);
                    RewriteRuleTokenStream stream_scale=new RewriteRuleTokenStream(adaptor,"token scale",scale);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2293:69: -> ^( TOK_DECIMAL ( $prec)? ( $scale)? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:72: ^( TOK_DECIMAL ( $prec)? ( $scale)? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_DECIMAL, "TOK_DECIMAL")
                        , root_1);

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:87: ( $prec)?
                        if ( stream_prec.hasNext() ) {
                            adaptor.addChild(root_1, stream_prec.nextNode());

                        }
                        stream_prec.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:94: ( $scale)?
                        if ( stream_scale.hasNext() ) {
                            adaptor.addChild(root_1, stream_scale.nextNode());

                        }
                        stream_scale.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 14 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2294:7: KW_VARCHAR LPAREN length= Number RPAREN
                    {
                    KW_VARCHAR861=(Token)match(input,KW_VARCHAR,FOLLOW_KW_VARCHAR_in_primitiveType14583); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_VARCHAR.add(KW_VARCHAR861);


                    LPAREN862=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_primitiveType14585); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN862);


                    length=(Token)match(input,Number,FOLLOW_Number_in_primitiveType14589); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_Number.add(length);


                    RPAREN863=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_primitiveType14591); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN863);


                    // AST REWRITE
                    // elements: length
                    // token labels: length
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_length=new RewriteRuleTokenStream(adaptor,"token length",length);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2294:51: -> ^( TOK_VARCHAR $length)
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2294:57: ^( TOK_VARCHAR $length)
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_VARCHAR, "TOK_VARCHAR")
                        , root_1);

                        adaptor.addChild(root_1, stream_length.nextNode());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 15 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2295:7: KW_CHAR LPAREN length= Number RPAREN
                    {
                    KW_CHAR864=(Token)match(input,KW_CHAR,FOLLOW_KW_CHAR_in_primitiveType14616); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_CHAR.add(KW_CHAR864);


                    LPAREN865=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_primitiveType14618); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN865);


                    length=(Token)match(input,Number,FOLLOW_Number_in_primitiveType14622); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_Number.add(length);


                    RPAREN866=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_primitiveType14624); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN866);


                    // AST REWRITE
                    // elements: length
                    // token labels: length
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_length=new RewriteRuleTokenStream(adaptor,"token length",length);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2295:48: -> ^( TOK_CHAR $length)
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2295:54: ^( TOK_CHAR $length)
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_CHAR, "TOK_CHAR")
                        , root_1);

                        adaptor.addChild(root_1, stream_length.nextNode());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "primitiveType"


    public static class listType_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "listType"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2298:1: listType : KW_ARRAY LESSTHAN type GREATERTHAN -> ^( TOK_LIST type ) ;
    public final HiveParser.listType_return listType() throws RecognitionException {
        HiveParser.listType_return retval = new HiveParser.listType_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_ARRAY867=null;
        Token LESSTHAN868=null;
        Token GREATERTHAN870=null;
        HiveParser.type_return type869 =null;


        ASTNode KW_ARRAY867_tree=null;
        ASTNode LESSTHAN868_tree=null;
        ASTNode GREATERTHAN870_tree=null;
        RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
        RewriteRuleTokenStream stream_KW_ARRAY=new RewriteRuleTokenStream(adaptor,"token KW_ARRAY");
        RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
        RewriteRuleSubtreeStream stream_type=new RewriteRuleSubtreeStream(adaptor,"rule type");
         pushMsg("list type", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2301:5: ( KW_ARRAY LESSTHAN type GREATERTHAN -> ^( TOK_LIST type ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2301:7: KW_ARRAY LESSTHAN type GREATERTHAN
            {
            KW_ARRAY867=(Token)match(input,KW_ARRAY,FOLLOW_KW_ARRAY_in_listType14668); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ARRAY.add(KW_ARRAY867);


            LESSTHAN868=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_listType14670); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LESSTHAN.add(LESSTHAN868);


            pushFollow(FOLLOW_type_in_listType14672);
            type869=type();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_type.add(type869.getTree());

            GREATERTHAN870=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_listType14674); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_GREATERTHAN.add(GREATERTHAN870);


            // AST REWRITE
            // elements: type
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2301:44: -> ^( TOK_LIST type )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2301:47: ^( TOK_LIST type )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_LIST, "TOK_LIST")
                , root_1);

                adaptor.addChild(root_1, stream_type.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "listType"


    public static class structType_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "structType"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2304:1: structType : KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN -> ^( TOK_STRUCT columnNameColonTypeList ) ;
    public final HiveParser.structType_return structType() throws RecognitionException {
        HiveParser.structType_return retval = new HiveParser.structType_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_STRUCT871=null;
        Token LESSTHAN872=null;
        Token GREATERTHAN874=null;
        HiveParser.columnNameColonTypeList_return columnNameColonTypeList873 =null;


        ASTNode KW_STRUCT871_tree=null;
        ASTNode LESSTHAN872_tree=null;
        ASTNode GREATERTHAN874_tree=null;
        RewriteRuleTokenStream stream_KW_STRUCT=new RewriteRuleTokenStream(adaptor,"token KW_STRUCT");
        RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
        RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
        RewriteRuleSubtreeStream stream_columnNameColonTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameColonTypeList");
         pushMsg("struct type", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2307:5: ( KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN -> ^( TOK_STRUCT columnNameColonTypeList ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2307:7: KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN
            {
            KW_STRUCT871=(Token)match(input,KW_STRUCT,FOLLOW_KW_STRUCT_in_structType14711); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_STRUCT.add(KW_STRUCT871);


            LESSTHAN872=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_structType14713); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LESSTHAN.add(LESSTHAN872);


            pushFollow(FOLLOW_columnNameColonTypeList_in_structType14715);
            columnNameColonTypeList873=columnNameColonTypeList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnNameColonTypeList.add(columnNameColonTypeList873.getTree());

            GREATERTHAN874=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_structType14717); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_GREATERTHAN.add(GREATERTHAN874);


            // AST REWRITE
            // elements: columnNameColonTypeList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2307:62: -> ^( TOK_STRUCT columnNameColonTypeList )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2307:65: ^( TOK_STRUCT columnNameColonTypeList )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_STRUCT, "TOK_STRUCT")
                , root_1);

                adaptor.addChild(root_1, stream_columnNameColonTypeList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "structType"


    public static class mapType_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "mapType"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2310:1: mapType : KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN -> ^( TOK_MAP $left $right) ;
    public final HiveParser.mapType_return mapType() throws RecognitionException {
        HiveParser.mapType_return retval = new HiveParser.mapType_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_MAP875=null;
        Token LESSTHAN876=null;
        Token COMMA877=null;
        Token GREATERTHAN878=null;
        HiveParser.primitiveType_return left =null;

        HiveParser.type_return right =null;


        ASTNode KW_MAP875_tree=null;
        ASTNode LESSTHAN876_tree=null;
        ASTNode COMMA877_tree=null;
        ASTNode GREATERTHAN878_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleTokenStream stream_KW_MAP=new RewriteRuleTokenStream(adaptor,"token KW_MAP");
        RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
        RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
        RewriteRuleSubtreeStream stream_type=new RewriteRuleSubtreeStream(adaptor,"rule type");
        RewriteRuleSubtreeStream stream_primitiveType=new RewriteRuleSubtreeStream(adaptor,"rule primitiveType");
         pushMsg("map type", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2313:5: ( KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN -> ^( TOK_MAP $left $right) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2313:7: KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN
            {
            KW_MAP875=(Token)match(input,KW_MAP,FOLLOW_KW_MAP_in_mapType14752); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_MAP.add(KW_MAP875);


            LESSTHAN876=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_mapType14754); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LESSTHAN.add(LESSTHAN876);


            pushFollow(FOLLOW_primitiveType_in_mapType14758);
            left=primitiveType();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_primitiveType.add(left.getTree());

            COMMA877=(Token)match(input,COMMA,FOLLOW_COMMA_in_mapType14760); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_COMMA.add(COMMA877);


            pushFollow(FOLLOW_type_in_mapType14764);
            right=type();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_type.add(right.getTree());

            GREATERTHAN878=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_mapType14766); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_GREATERTHAN.add(GREATERTHAN878);


            // AST REWRITE
            // elements: left, right
            // token labels: 
            // rule labels: left, right, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_left=new RewriteRuleSubtreeStream(adaptor,"rule left",left!=null?left.tree:null);
            RewriteRuleSubtreeStream stream_right=new RewriteRuleSubtreeStream(adaptor,"rule right",right!=null?right.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2314:5: -> ^( TOK_MAP $left $right)
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2314:8: ^( TOK_MAP $left $right)
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_MAP, "TOK_MAP")
                , root_1);

                adaptor.addChild(root_1, stream_left.nextTree());

                adaptor.addChild(root_1, stream_right.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "mapType"


    public static class unionType_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "unionType"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2317:1: unionType : KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN -> ^( TOK_UNIONTYPE colTypeList ) ;
    public final HiveParser.unionType_return unionType() throws RecognitionException {
        HiveParser.unionType_return retval = new HiveParser.unionType_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_UNIONTYPE879=null;
        Token LESSTHAN880=null;
        Token GREATERTHAN882=null;
        HiveParser.colTypeList_return colTypeList881 =null;


        ASTNode KW_UNIONTYPE879_tree=null;
        ASTNode LESSTHAN880_tree=null;
        ASTNode GREATERTHAN882_tree=null;
        RewriteRuleTokenStream stream_KW_UNIONTYPE=new RewriteRuleTokenStream(adaptor,"token KW_UNIONTYPE");
        RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
        RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
        RewriteRuleSubtreeStream stream_colTypeList=new RewriteRuleSubtreeStream(adaptor,"rule colTypeList");
         pushMsg("uniontype type", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2320:5: ( KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN -> ^( TOK_UNIONTYPE colTypeList ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2320:7: KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN
            {
            KW_UNIONTYPE879=(Token)match(input,KW_UNIONTYPE,FOLLOW_KW_UNIONTYPE_in_unionType14809); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_UNIONTYPE.add(KW_UNIONTYPE879);


            LESSTHAN880=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_unionType14811); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LESSTHAN.add(LESSTHAN880);


            pushFollow(FOLLOW_colTypeList_in_unionType14813);
            colTypeList881=colTypeList();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_colTypeList.add(colTypeList881.getTree());

            GREATERTHAN882=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_unionType14815); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_GREATERTHAN.add(GREATERTHAN882);


            // AST REWRITE
            // elements: colTypeList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2320:53: -> ^( TOK_UNIONTYPE colTypeList )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2320:56: ^( TOK_UNIONTYPE colTypeList )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_UNIONTYPE, "TOK_UNIONTYPE")
                , root_1);

                adaptor.addChild(root_1, stream_colTypeList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "unionType"


    public static class setOperator_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "setOperator"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2323:1: setOperator : ( KW_UNION KW_ALL -> ^( TOK_UNIONALL ) | KW_UNION ( KW_DISTINCT )? -> ^( TOK_UNIONDISTINCT ) | KW_INTERSECT KW_ALL -> ^( TOK_INTERSECTALL ) | KW_INTERSECT ( KW_DISTINCT )? -> ^( TOK_INTERSECTDISTINCT ) | KW_EXCEPT KW_ALL -> ^( TOK_EXCEPTALL ) | KW_EXCEPT ( KW_DISTINCT )? -> ^( TOK_EXCEPTDISTINCT ) | KW_MINUS KW_ALL -> ^( TOK_EXCEPTALL ) | KW_MINUS ( KW_DISTINCT )? -> ^( TOK_EXCEPTDISTINCT ) );
    public final HiveParser.setOperator_return setOperator() throws RecognitionException {
        HiveParser.setOperator_return retval = new HiveParser.setOperator_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_UNION883=null;
        Token KW_ALL884=null;
        Token KW_UNION885=null;
        Token KW_DISTINCT886=null;
        Token KW_INTERSECT887=null;
        Token KW_ALL888=null;
        Token KW_INTERSECT889=null;
        Token KW_DISTINCT890=null;
        Token KW_EXCEPT891=null;
        Token KW_ALL892=null;
        Token KW_EXCEPT893=null;
        Token KW_DISTINCT894=null;
        Token KW_MINUS895=null;
        Token KW_ALL896=null;
        Token KW_MINUS897=null;
        Token KW_DISTINCT898=null;

        ASTNode KW_UNION883_tree=null;
        ASTNode KW_ALL884_tree=null;
        ASTNode KW_UNION885_tree=null;
        ASTNode KW_DISTINCT886_tree=null;
        ASTNode KW_INTERSECT887_tree=null;
        ASTNode KW_ALL888_tree=null;
        ASTNode KW_INTERSECT889_tree=null;
        ASTNode KW_DISTINCT890_tree=null;
        ASTNode KW_EXCEPT891_tree=null;
        ASTNode KW_ALL892_tree=null;
        ASTNode KW_EXCEPT893_tree=null;
        ASTNode KW_DISTINCT894_tree=null;
        ASTNode KW_MINUS895_tree=null;
        ASTNode KW_ALL896_tree=null;
        ASTNode KW_MINUS897_tree=null;
        ASTNode KW_DISTINCT898_tree=null;
        RewriteRuleTokenStream stream_KW_INTERSECT=new RewriteRuleTokenStream(adaptor,"token KW_INTERSECT");
        RewriteRuleTokenStream stream_KW_EXCEPT=new RewriteRuleTokenStream(adaptor,"token KW_EXCEPT");
        RewriteRuleTokenStream stream_KW_UNION=new RewriteRuleTokenStream(adaptor,"token KW_UNION");
        RewriteRuleTokenStream stream_KW_DISTINCT=new RewriteRuleTokenStream(adaptor,"token KW_DISTINCT");
        RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");
        RewriteRuleTokenStream stream_KW_MINUS=new RewriteRuleTokenStream(adaptor,"token KW_MINUS");

         pushMsg("set operator", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2326:5: ( KW_UNION KW_ALL -> ^( TOK_UNIONALL ) | KW_UNION ( KW_DISTINCT )? -> ^( TOK_UNIONDISTINCT ) | KW_INTERSECT KW_ALL -> ^( TOK_INTERSECTALL ) | KW_INTERSECT ( KW_DISTINCT )? -> ^( TOK_INTERSECTDISTINCT ) | KW_EXCEPT KW_ALL -> ^( TOK_EXCEPTALL ) | KW_EXCEPT ( KW_DISTINCT )? -> ^( TOK_EXCEPTDISTINCT ) | KW_MINUS KW_ALL -> ^( TOK_EXCEPTALL ) | KW_MINUS ( KW_DISTINCT )? -> ^( TOK_EXCEPTDISTINCT ) )
            int alt255=8;
            switch ( input.LA(1) ) {
            case KW_UNION:
                {
                switch ( input.LA(2) ) {
                case KW_ALL:
                    {
                    alt255=1;
                    }
                    break;
                case KW_DISTINCT:
                case KW_FROM:
                case KW_MAP:
                case KW_REDUCE:
                case KW_SELECT:
                case LPAREN:
                    {
                    alt255=2;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 255, 1, input);

                    throw nvae;

                }

                }
                break;
            case KW_INTERSECT:
                {
                switch ( input.LA(2) ) {
                case KW_ALL:
                    {
                    alt255=3;
                    }
                    break;
                case KW_DISTINCT:
                case KW_FROM:
                case KW_MAP:
                case KW_REDUCE:
                case KW_SELECT:
                case LPAREN:
                    {
                    alt255=4;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 255, 2, input);

                    throw nvae;

                }

                }
                break;
            case KW_EXCEPT:
                {
                switch ( input.LA(2) ) {
                case KW_ALL:
                    {
                    alt255=5;
                    }
                    break;
                case KW_DISTINCT:
                case KW_FROM:
                case KW_MAP:
                case KW_REDUCE:
                case KW_SELECT:
                case LPAREN:
                    {
                    alt255=6;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 255, 3, input);

                    throw nvae;

                }

                }
                break;
            case KW_MINUS:
                {
                switch ( input.LA(2) ) {
                case KW_ALL:
                    {
                    alt255=7;
                    }
                    break;
                case KW_DISTINCT:
                case KW_FROM:
                case KW_MAP:
                case KW_REDUCE:
                case KW_SELECT:
                case LPAREN:
                    {
                    alt255=8;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 255, 4, input);

                    throw nvae;

                }

                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 255, 0, input);

                throw nvae;

            }

            switch (alt255) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2326:7: KW_UNION KW_ALL
                    {
                    KW_UNION883=(Token)match(input,KW_UNION,FOLLOW_KW_UNION_in_setOperator14850); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_UNION.add(KW_UNION883);


                    KW_ALL884=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setOperator14852); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL884);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2326:23: -> ^( TOK_UNIONALL )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2326:26: ^( TOK_UNIONALL )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_UNIONALL, "TOK_UNIONALL")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2327:7: KW_UNION ( KW_DISTINCT )?
                    {
                    KW_UNION885=(Token)match(input,KW_UNION,FOLLOW_KW_UNION_in_setOperator14866); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_UNION.add(KW_UNION885);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2327:16: ( KW_DISTINCT )?
                    int alt251=2;
                    switch ( input.LA(1) ) {
                        case KW_DISTINCT:
                            {
                            alt251=1;
                            }
                            break;
                    }

                    switch (alt251) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2327:16: KW_DISTINCT
                            {
                            KW_DISTINCT886=(Token)match(input,KW_DISTINCT,FOLLOW_KW_DISTINCT_in_setOperator14868); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_DISTINCT.add(KW_DISTINCT886);


                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2327:29: -> ^( TOK_UNIONDISTINCT )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2327:32: ^( TOK_UNIONDISTINCT )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_UNIONDISTINCT, "TOK_UNIONDISTINCT")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2328:7: KW_INTERSECT KW_ALL
                    {
                    KW_INTERSECT887=(Token)match(input,KW_INTERSECT,FOLLOW_KW_INTERSECT_in_setOperator14883); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_INTERSECT.add(KW_INTERSECT887);


                    KW_ALL888=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setOperator14885); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL888);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2328:27: -> ^( TOK_INTERSECTALL )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2328:30: ^( TOK_INTERSECTALL )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_INTERSECTALL, "TOK_INTERSECTALL")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 4 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2329:7: KW_INTERSECT ( KW_DISTINCT )?
                    {
                    KW_INTERSECT889=(Token)match(input,KW_INTERSECT,FOLLOW_KW_INTERSECT_in_setOperator14899); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_INTERSECT.add(KW_INTERSECT889);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2329:20: ( KW_DISTINCT )?
                    int alt252=2;
                    switch ( input.LA(1) ) {
                        case KW_DISTINCT:
                            {
                            alt252=1;
                            }
                            break;
                    }

                    switch (alt252) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2329:20: KW_DISTINCT
                            {
                            KW_DISTINCT890=(Token)match(input,KW_DISTINCT,FOLLOW_KW_DISTINCT_in_setOperator14901); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_DISTINCT.add(KW_DISTINCT890);


                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2329:33: -> ^( TOK_INTERSECTDISTINCT )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2329:36: ^( TOK_INTERSECTDISTINCT )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_INTERSECTDISTINCT, "TOK_INTERSECTDISTINCT")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 5 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2330:7: KW_EXCEPT KW_ALL
                    {
                    KW_EXCEPT891=(Token)match(input,KW_EXCEPT,FOLLOW_KW_EXCEPT_in_setOperator14916); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_EXCEPT.add(KW_EXCEPT891);


                    KW_ALL892=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setOperator14918); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL892);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2330:24: -> ^( TOK_EXCEPTALL )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2330:27: ^( TOK_EXCEPTALL )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_EXCEPTALL, "TOK_EXCEPTALL")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 6 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2331:7: KW_EXCEPT ( KW_DISTINCT )?
                    {
                    KW_EXCEPT893=(Token)match(input,KW_EXCEPT,FOLLOW_KW_EXCEPT_in_setOperator14932); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_EXCEPT.add(KW_EXCEPT893);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2331:17: ( KW_DISTINCT )?
                    int alt253=2;
                    switch ( input.LA(1) ) {
                        case KW_DISTINCT:
                            {
                            alt253=1;
                            }
                            break;
                    }

                    switch (alt253) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2331:17: KW_DISTINCT
                            {
                            KW_DISTINCT894=(Token)match(input,KW_DISTINCT,FOLLOW_KW_DISTINCT_in_setOperator14934); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_DISTINCT.add(KW_DISTINCT894);


                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2331:30: -> ^( TOK_EXCEPTDISTINCT )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2331:33: ^( TOK_EXCEPTDISTINCT )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_EXCEPTDISTINCT, "TOK_EXCEPTDISTINCT")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 7 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2332:7: KW_MINUS KW_ALL
                    {
                    KW_MINUS895=(Token)match(input,KW_MINUS,FOLLOW_KW_MINUS_in_setOperator14949); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_MINUS.add(KW_MINUS895);


                    KW_ALL896=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setOperator14951); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL896);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2332:23: -> ^( TOK_EXCEPTALL )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2332:26: ^( TOK_EXCEPTALL )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_EXCEPTALL, "TOK_EXCEPTALL")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 8 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2333:7: KW_MINUS ( KW_DISTINCT )?
                    {
                    KW_MINUS897=(Token)match(input,KW_MINUS,FOLLOW_KW_MINUS_in_setOperator14965); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_MINUS.add(KW_MINUS897);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2333:16: ( KW_DISTINCT )?
                    int alt254=2;
                    switch ( input.LA(1) ) {
                        case KW_DISTINCT:
                            {
                            alt254=1;
                            }
                            break;
                    }

                    switch (alt254) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2333:16: KW_DISTINCT
                            {
                            KW_DISTINCT898=(Token)match(input,KW_DISTINCT,FOLLOW_KW_DISTINCT_in_setOperator14967); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_DISTINCT.add(KW_DISTINCT898);


                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2333:29: -> ^( TOK_EXCEPTDISTINCT )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2333:32: ^( TOK_EXCEPTDISTINCT )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_EXCEPTDISTINCT, "TOK_EXCEPTDISTINCT")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "setOperator"


    public static class queryStatementExpression_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "queryStatementExpression"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2336:1: queryStatementExpression : (w= withClause )? queryStatementExpressionBody -> queryStatementExpressionBody ;
    public final HiveParser.queryStatementExpression_return queryStatementExpression() throws RecognitionException {
        HiveParser.queryStatementExpression_return retval = new HiveParser.queryStatementExpression_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.withClause_return w =null;

        HiveParser.queryStatementExpressionBody_return queryStatementExpressionBody899 =null;


        RewriteRuleSubtreeStream stream_withClause=new RewriteRuleSubtreeStream(adaptor,"rule withClause");
        RewriteRuleSubtreeStream stream_queryStatementExpressionBody=new RewriteRuleSubtreeStream(adaptor,"rule queryStatementExpressionBody");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2337:5: ( (w= withClause )? queryStatementExpressionBody -> queryStatementExpressionBody )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2342:5: (w= withClause )? queryStatementExpressionBody
            {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2342:5: (w= withClause )?
            int alt256=2;
            switch ( input.LA(1) ) {
                case KW_WITH:
                    {
                    alt256=1;
                    }
                    break;
            }

            switch (alt256) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2342:6: w= withClause
                    {
                    pushFollow(FOLLOW_withClause_in_queryStatementExpression15004);
                    w=withClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_withClause.add(w.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_queryStatementExpressionBody_in_queryStatementExpression15012);
            queryStatementExpressionBody899=queryStatementExpressionBody();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_queryStatementExpressionBody.add(queryStatementExpressionBody899.getTree());

            if ( state.backtracking==0 ) {
                  if ((w!=null?((ASTNode)w.tree):null) != null) {
                  (queryStatementExpressionBody899!=null?((ASTNode)queryStatementExpressionBody899.tree):null).insertChild(0, (w!=null?((ASTNode)w.tree):null));
                  }
                }

            // AST REWRITE
            // elements: queryStatementExpressionBody
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2348:5: -> queryStatementExpressionBody
            {
                adaptor.addChild(root_0, stream_queryStatementExpressionBody.nextTree());

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "queryStatementExpression"


    public static class queryStatementExpressionBody_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "queryStatementExpressionBody"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2351:1: queryStatementExpressionBody : ( fromStatement | regularBody );
    public final HiveParser.queryStatementExpressionBody_return queryStatementExpressionBody() throws RecognitionException {
        HiveParser.queryStatementExpressionBody_return retval = new HiveParser.queryStatementExpressionBody_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.fromStatement_return fromStatement900 =null;

        HiveParser.regularBody_return regularBody901 =null;



        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2352:5: ( fromStatement | regularBody )
            int alt257=2;
            switch ( input.LA(1) ) {
            case KW_FROM:
                {
                alt257=1;
                }
                break;
            case KW_INSERT:
            case KW_MAP:
            case KW_REDUCE:
            case KW_SELECT:
            case LPAREN:
                {
                alt257=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 257, 0, input);

                throw nvae;

            }

            switch (alt257) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2353:5: fromStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_fromStatement_in_queryStatementExpressionBody15044);
                    fromStatement900=fromStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, fromStatement900.getTree());

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2354:7: regularBody
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_regularBody_in_queryStatementExpressionBody15052);
                    regularBody901=regularBody();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, regularBody901.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "queryStatementExpressionBody"


    public static class withClause_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "withClause"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2357:1: withClause : KW_WITH cteStatement ( COMMA cteStatement )* -> ^( TOK_CTE ( cteStatement )+ ) ;
    public final HiveParser.withClause_return withClause() throws RecognitionException {
        HiveParser.withClause_return retval = new HiveParser.withClause_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_WITH902=null;
        Token COMMA904=null;
        HiveParser.cteStatement_return cteStatement903 =null;

        HiveParser.cteStatement_return cteStatement905 =null;


        ASTNode KW_WITH902_tree=null;
        ASTNode COMMA904_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleSubtreeStream stream_cteStatement=new RewriteRuleSubtreeStream(adaptor,"rule cteStatement");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2358:3: ( KW_WITH cteStatement ( COMMA cteStatement )* -> ^( TOK_CTE ( cteStatement )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2359:3: KW_WITH cteStatement ( COMMA cteStatement )*
            {
            KW_WITH902=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_withClause15069); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH902);


            pushFollow(FOLLOW_cteStatement_in_withClause15071);
            cteStatement903=cteStatement();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_cteStatement.add(cteStatement903.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2359:24: ( COMMA cteStatement )*
            loop258:
            do {
                int alt258=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt258=1;
                    }
                    break;

                }

                switch (alt258) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2359:25: COMMA cteStatement
            	    {
            	    COMMA904=(Token)match(input,COMMA,FOLLOW_COMMA_in_withClause15074); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA904);


            	    pushFollow(FOLLOW_cteStatement_in_withClause15076);
            	    cteStatement905=cteStatement();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_cteStatement.add(cteStatement905.getTree());

            	    }
            	    break;

            	default :
            	    break loop258;
                }
            } while (true);


            // AST REWRITE
            // elements: cteStatement
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2359:46: -> ^( TOK_CTE ( cteStatement )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2359:49: ^( TOK_CTE ( cteStatement )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_CTE, "TOK_CTE")
                , root_1);

                if ( !(stream_cteStatement.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_cteStatement.hasNext() ) {
                    adaptor.addChild(root_1, stream_cteStatement.nextTree());

                }
                stream_cteStatement.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "withClause"


    public static class cteStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "cteStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2362:1: cteStatement : identifier KW_AS LPAREN queryStatementExpression RPAREN -> ^( TOK_SUBQUERY queryStatementExpression identifier ) ;
    public final HiveParser.cteStatement_return cteStatement() throws RecognitionException {
        HiveParser.cteStatement_return retval = new HiveParser.cteStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_AS907=null;
        Token LPAREN908=null;
        Token RPAREN910=null;
        HiveParser_IdentifiersParser.identifier_return identifier906 =null;

        HiveParser.queryStatementExpression_return queryStatementExpression909 =null;


        ASTNode KW_AS907_tree=null;
        ASTNode LPAREN908_tree=null;
        ASTNode RPAREN910_tree=null;
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_queryStatementExpression=new RewriteRuleSubtreeStream(adaptor,"rule queryStatementExpression");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2363:4: ( identifier KW_AS LPAREN queryStatementExpression RPAREN -> ^( TOK_SUBQUERY queryStatementExpression identifier ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2364:4: identifier KW_AS LPAREN queryStatementExpression RPAREN
            {
            pushFollow(FOLLOW_identifier_in_cteStatement15102);
            identifier906=identifier();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_identifier.add(identifier906.getTree());

            KW_AS907=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_cteStatement15104); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS907);


            LPAREN908=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_cteStatement15106); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN908);


            pushFollow(FOLLOW_queryStatementExpression_in_cteStatement15108);
            queryStatementExpression909=queryStatementExpression();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_queryStatementExpression.add(queryStatementExpression909.getTree());

            RPAREN910=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_cteStatement15110); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN910);


            // AST REWRITE
            // elements: queryStatementExpression, identifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2365:4: -> ^( TOK_SUBQUERY queryStatementExpression identifier )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2365:7: ^( TOK_SUBQUERY queryStatementExpression identifier )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY")
                , root_1);

                adaptor.addChild(root_1, stream_queryStatementExpression.nextTree());

                adaptor.addChild(root_1, stream_identifier.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "cteStatement"


    public static class fromStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "fromStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2368:1: fromStatement : ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )* -> {u != null}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) ->;
    public final HiveParser.fromStatement_return fromStatement() throws RecognitionException {
        HiveParser.fromStatement_return retval = new HiveParser.fromStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.setOperator_return u =null;

        HiveParser.singleFromStatement_return r =null;

        HiveParser.singleFromStatement_return singleFromStatement911 =null;


        RewriteRuleSubtreeStream stream_setOperator=new RewriteRuleSubtreeStream(adaptor,"rule setOperator");
        RewriteRuleSubtreeStream stream_singleFromStatement=new RewriteRuleSubtreeStream(adaptor,"rule singleFromStatement");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2369:3: ( ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )* -> {u != null}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) ->)
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2369:3: ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )*
            {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2369:3: ( singleFromStatement -> singleFromStatement )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2369:4: singleFromStatement
            {
            pushFollow(FOLLOW_singleFromStatement_in_fromStatement15133);
            singleFromStatement911=singleFromStatement();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_singleFromStatement.add(singleFromStatement911.getTree());

            // AST REWRITE
            // elements: singleFromStatement
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2369:25: -> singleFromStatement
            {
                adaptor.addChild(root_0, stream_singleFromStatement.nextTree());

            }


            retval.tree = root_0;
            }

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2370:2: (u= setOperator r= singleFromStatement -> ^( $u $r) )*
            loop259:
            do {
                int alt259=2;
                switch ( input.LA(1) ) {
                case KW_EXCEPT:
                case KW_INTERSECT:
                case KW_MINUS:
                case KW_UNION:
                    {
                    alt259=1;
                    }
                    break;

                }

                switch (alt259) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2370:3: u= setOperator r= singleFromStatement
            	    {
            	    pushFollow(FOLLOW_setOperator_in_fromStatement15145);
            	    u=setOperator();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_setOperator.add(u.getTree());

            	    pushFollow(FOLLOW_singleFromStatement_in_fromStatement15149);
            	    r=singleFromStatement();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_singleFromStatement.add(r.getTree());

            	    // AST REWRITE
            	    // elements: r, u
            	    // token labels: 
            	    // rule labels: r, u, retval
            	    // token list labels: 
            	    // rule list labels: 
            	    // wildcard labels: 
            	    if ( state.backtracking==0 ) {

            	    retval.tree = root_0;
            	    RewriteRuleSubtreeStream stream_r=new RewriteRuleSubtreeStream(adaptor,"rule r",r!=null?r.tree:null);
            	    RewriteRuleSubtreeStream stream_u=new RewriteRuleSubtreeStream(adaptor,"rule u",u!=null?u.tree:null);
            	    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            	    root_0 = (ASTNode)adaptor.nil();
            	    // 2371:4: -> ^( $u $r)
            	    {
            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2371:7: ^( $u $r)
            	        {
            	        ASTNode root_1 = (ASTNode)adaptor.nil();
            	        root_1 = (ASTNode)adaptor.becomeRoot(stream_u.nextNode(), root_1);

            	        adaptor.addChild(root_1, ((ASTNode)retval.tree));

            	        adaptor.addChild(root_1, stream_r.nextTree());

            	        adaptor.addChild(root_0, root_1);
            	        }

            	    }


            	    retval.tree = root_0;
            	    }

            	    }
            	    break;

            	default :
            	    break loop259;
                }
            } while (true);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2373:3: -> {u != null}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
            if (u != null) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2373:19: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2374:9: ^( TOK_FROM ^( TOK_SUBQUERY ) )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM")
                , root_2);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2375:11: ^( TOK_SUBQUERY )
                {
                ASTNode root_3 = (ASTNode)adaptor.nil();
                root_3 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY")
                , root_3);

                adaptor.addChild(root_3, ((ASTNode)retval.tree));

                adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));

                adaptor.addChild(root_2, root_3);
                }

                adaptor.addChild(root_1, root_2);
                }

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2380:9: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT")
                , root_2);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2381:12: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
                {
                ASTNode root_3 = (ASTNode)adaptor.nil();
                root_3 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION")
                , root_3);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2381:30: ^( TOK_DIR TOK_TMP_FILE )
                {
                ASTNode root_4 = (ASTNode)adaptor.nil();
                root_4 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DIR, "TOK_DIR")
                , root_4);

                adaptor.addChild(root_4, 
                (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE")
                );

                adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
                }

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2382:12: ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) )
                {
                ASTNode root_3 = (ASTNode)adaptor.nil();
                root_3 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SELECT, "TOK_SELECT")
                , root_3);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2382:25: ^( TOK_SELEXPR TOK_SETCOLREF )
                {
                ASTNode root_4 = (ASTNode)adaptor.nil();
                root_4 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR")
                , root_4);

                adaptor.addChild(root_4, 
                (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF")
                );

                adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
                }

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 2385:5: ->
            {
                adaptor.addChild(root_0, ((ASTNode)retval.tree));

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "fromStatement"


    public static class singleFromStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "singleFromStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2389:1: singleFromStatement : fromClause (b+= body )+ -> ^( TOK_QUERY fromClause ( body )+ ) ;
    public final HiveParser.singleFromStatement_return singleFromStatement() throws RecognitionException {
        HiveParser.singleFromStatement_return retval = new HiveParser.singleFromStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        List list_b=null;
        HiveParser_FromClauseParser.fromClause_return fromClause912 =null;

        RuleReturnScope b = null;
        RewriteRuleSubtreeStream stream_fromClause=new RewriteRuleSubtreeStream(adaptor,"rule fromClause");
        RewriteRuleSubtreeStream stream_body=new RewriteRuleSubtreeStream(adaptor,"rule body");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2390:5: ( fromClause (b+= body )+ -> ^( TOK_QUERY fromClause ( body )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2391:5: fromClause (b+= body )+
            {
            pushFollow(FOLLOW_fromClause_in_singleFromStatement15356);
            fromClause912=fromClause();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_fromClause.add(fromClause912.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2392:5: (b+= body )+
            int cnt260=0;
            loop260:
            do {
                int alt260=2;
                switch ( input.LA(1) ) {
                case KW_INSERT:
                case KW_MAP:
                case KW_REDUCE:
                case KW_SELECT:
                    {
                    alt260=1;
                    }
                    break;

                }

                switch (alt260) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2392:7: b+= body
            	    {
            	    pushFollow(FOLLOW_body_in_singleFromStatement15366);
            	    b=body();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_body.add(b.getTree());
            	    if (list_b==null) list_b=new ArrayList();
            	    list_b.add(b.getTree());


            	    }
            	    break;

            	default :
            	    if ( cnt260 >= 1 ) break loop260;
            	    if (state.backtracking>0) {state.failed=true; return retval;}
                        EarlyExitException eee =
                            new EarlyExitException(260, input);
                        throw eee;
                }
                cnt260++;
            } while (true);


            // AST REWRITE
            // elements: body, fromClause
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2392:18: -> ^( TOK_QUERY fromClause ( body )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2392:21: ^( TOK_QUERY fromClause ( body )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY")
                , root_1);

                adaptor.addChild(root_1, stream_fromClause.nextTree());

                if ( !(stream_body.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_body.hasNext() ) {
                    adaptor.addChild(root_1, stream_body.nextTree());

                }
                stream_body.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "singleFromStatement"


    public static class regularBody_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "regularBody"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2402:1: regularBody : (i= insertClause (s= selectStatement ->| valuesClause -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) ) | selectStatement );
    public final HiveParser.regularBody_return regularBody() throws RecognitionException {
        HiveParser.regularBody_return retval = new HiveParser.regularBody_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.insertClause_return i =null;

        HiveParser.selectStatement_return s =null;

        HiveParser_FromClauseParser.valuesClause_return valuesClause913 =null;

        HiveParser.selectStatement_return selectStatement914 =null;


        RewriteRuleSubtreeStream stream_insertClause=new RewriteRuleSubtreeStream(adaptor,"rule insertClause");
        RewriteRuleSubtreeStream stream_valuesClause=new RewriteRuleSubtreeStream(adaptor,"rule valuesClause");
        RewriteRuleSubtreeStream stream_selectStatement=new RewriteRuleSubtreeStream(adaptor,"rule selectStatement");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2403:4: (i= insertClause (s= selectStatement ->| valuesClause -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) ) | selectStatement )
            int alt262=2;
            switch ( input.LA(1) ) {
            case KW_INSERT:
                {
                alt262=1;
                }
                break;
            case KW_MAP:
            case KW_REDUCE:
            case KW_SELECT:
            case LPAREN:
                {
                alt262=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 262, 0, input);

                throw nvae;

            }

            switch (alt262) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2404:4: i= insertClause (s= selectStatement ->| valuesClause -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) )
                    {
                    pushFollow(FOLLOW_insertClause_in_regularBody15403);
                    i=insertClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_insertClause.add(i.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2405:4: (s= selectStatement ->| valuesClause -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) )
                    int alt261=2;
                    switch ( input.LA(1) ) {
                    case KW_MAP:
                    case KW_REDUCE:
                    case KW_SELECT:
                    case LPAREN:
                        {
                        alt261=1;
                        }
                        break;
                    case KW_VALUES:
                        {
                        alt261=2;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 261, 0, input);

                        throw nvae;

                    }

                    switch (alt261) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2406:4: s= selectStatement
                            {
                            pushFollow(FOLLOW_selectStatement_in_regularBody15415);
                            s=selectStatement();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_selectStatement.add(s.getTree());

                            if ( state.backtracking==0 ) {(s!=null?((ASTNode)s.tree):null).getFirstChildWithType(TOK_INSERT).replaceChildren(0, 0, (i!=null?((ASTNode)i.tree):null));}

                            // AST REWRITE
                            // elements: 
                            // token labels: 
                            // rule labels: retval
                            // token list labels: 
                            // rule list labels: 
                            // wildcard labels: 
                            if ( state.backtracking==0 ) {

                            retval.tree = root_0;
                            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                            root_0 = (ASTNode)adaptor.nil();
                            // 2407:82: ->
                            {
                                adaptor.addChild(root_0, (s!=null?((ASTNode)s.tree):null));

                            }


                            retval.tree = root_0;
                            }

                            }
                            break;
                        case 2 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2409:6: valuesClause
                            {
                            pushFollow(FOLLOW_valuesClause_in_regularBody15440);
                            valuesClause913=valuesClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_valuesClause.add(valuesClause913.getTree());

                            // AST REWRITE
                            // elements: valuesClause
                            // token labels: 
                            // rule labels: retval
                            // token list labels: 
                            // rule list labels: 
                            // wildcard labels: 
                            if ( state.backtracking==0 ) {

                            retval.tree = root_0;
                            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                            root_0 = (ASTNode)adaptor.nil();
                            // 2410:7: -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) )
                            {
                                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2410:10: ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) )
                                {
                                ASTNode root_1 = (ASTNode)adaptor.nil();
                                root_1 = (ASTNode)adaptor.becomeRoot(
                                (ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY")
                                , root_1);

                                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2411:13: ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) )
                                {
                                ASTNode root_2 = (ASTNode)adaptor.nil();
                                root_2 = (ASTNode)adaptor.becomeRoot(
                                (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM")
                                , root_2);

                                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2412:15: ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause )
                                {
                                ASTNode root_3 = (ASTNode)adaptor.nil();
                                root_3 = (ASTNode)adaptor.becomeRoot(
                                (ASTNode)adaptor.create(TOK_VIRTUAL_TABLE, "TOK_VIRTUAL_TABLE")
                                , root_3);

                                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2412:35: ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) )
                                {
                                ASTNode root_4 = (ASTNode)adaptor.nil();
                                root_4 = (ASTNode)adaptor.becomeRoot(
                                (ASTNode)adaptor.create(TOK_VIRTUAL_TABREF, "TOK_VIRTUAL_TABREF")
                                , root_4);

                                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2412:56: ^( TOK_ANONYMOUS )
                                {
                                ASTNode root_5 = (ASTNode)adaptor.nil();
                                root_5 = (ASTNode)adaptor.becomeRoot(
                                (ASTNode)adaptor.create(TOK_ANONYMOUS, "TOK_ANONYMOUS")
                                , root_5);

                                adaptor.addChild(root_4, root_5);
                                }

                                adaptor.addChild(root_3, root_4);
                                }

                                adaptor.addChild(root_3, stream_valuesClause.nextTree());

                                adaptor.addChild(root_2, root_3);
                                }

                                adaptor.addChild(root_1, root_2);
                                }

                                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2414:13: ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) )
                                {
                                ASTNode root_2 = (ASTNode)adaptor.nil();
                                root_2 = (ASTNode)adaptor.becomeRoot(
                                (ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT")
                                , root_2);

                                adaptor.addChild(root_2, (i!=null?((ASTNode)i.tree):null));

                                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2414:36: ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) )
                                {
                                ASTNode root_3 = (ASTNode)adaptor.nil();
                                root_3 = (ASTNode)adaptor.becomeRoot(
                                (ASTNode)adaptor.create(TOK_SELECT, "TOK_SELECT")
                                , root_3);

                                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2414:49: ^( TOK_SELEXPR TOK_ALLCOLREF )
                                {
                                ASTNode root_4 = (ASTNode)adaptor.nil();
                                root_4 = (ASTNode)adaptor.becomeRoot(
                                (ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR")
                                , root_4);

                                adaptor.addChild(root_4, 
                                (ASTNode)adaptor.create(TOK_ALLCOLREF, "TOK_ALLCOLREF")
                                );

                                adaptor.addChild(root_3, root_4);
                                }

                                adaptor.addChild(root_2, root_3);
                                }

                                adaptor.addChild(root_1, root_2);
                                }

                                adaptor.addChild(root_0, root_1);
                                }

                            }


                            retval.tree = root_0;
                            }

                            }
                            break;

                    }


                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2418:4: selectStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_selectStatement_in_regularBody15564);
                    selectStatement914=selectStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, selectStatement914.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "regularBody"


    public static class atomSelectStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "atomSelectStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2421:1: atomSelectStatement : (s= selectClause (f= fromClause )? (w= whereClause )? (g= groupByClause )? (h= havingClause )? (win= window_clause )? -> ^( TOK_QUERY ( $f)? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ) ) | LPAREN ! selectStatement RPAREN !);
    public final HiveParser.atomSelectStatement_return atomSelectStatement() throws RecognitionException {
        HiveParser.atomSelectStatement_return retval = new HiveParser.atomSelectStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token LPAREN915=null;
        Token RPAREN917=null;
        HiveParser_SelectClauseParser.selectClause_return s =null;

        HiveParser_FromClauseParser.fromClause_return f =null;

        HiveParser_FromClauseParser.whereClause_return w =null;

        HiveParser_IdentifiersParser.groupByClause_return g =null;

        HiveParser_IdentifiersParser.havingClause_return h =null;

        HiveParser_SelectClauseParser.window_clause_return win =null;

        HiveParser.selectStatement_return selectStatement916 =null;


        ASTNode LPAREN915_tree=null;
        ASTNode RPAREN917_tree=null;
        RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
        RewriteRuleSubtreeStream stream_havingClause=new RewriteRuleSubtreeStream(adaptor,"rule havingClause");
        RewriteRuleSubtreeStream stream_fromClause=new RewriteRuleSubtreeStream(adaptor,"rule fromClause");
        RewriteRuleSubtreeStream stream_selectClause=new RewriteRuleSubtreeStream(adaptor,"rule selectClause");
        RewriteRuleSubtreeStream stream_groupByClause=new RewriteRuleSubtreeStream(adaptor,"rule groupByClause");
        RewriteRuleSubtreeStream stream_window_clause=new RewriteRuleSubtreeStream(adaptor,"rule window_clause");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2422:4: (s= selectClause (f= fromClause )? (w= whereClause )? (g= groupByClause )? (h= havingClause )? (win= window_clause )? -> ^( TOK_QUERY ( $f)? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ) ) | LPAREN ! selectStatement RPAREN !)
            int alt268=2;
            switch ( input.LA(1) ) {
            case KW_MAP:
            case KW_REDUCE:
            case KW_SELECT:
                {
                alt268=1;
                }
                break;
            case LPAREN:
                {
                alt268=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 268, 0, input);

                throw nvae;

            }

            switch (alt268) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2423:4: s= selectClause (f= fromClause )? (w= whereClause )? (g= groupByClause )? (h= havingClause )? (win= window_clause )?
                    {
                    pushFollow(FOLLOW_selectClause_in_atomSelectStatement15584);
                    s=selectClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_selectClause.add(s.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2424:5: (f= fromClause )?
                    int alt263=2;
                    switch ( input.LA(1) ) {
                        case KW_FROM:
                            {
                            alt263=1;
                            }
                            break;
                    }

                    switch (alt263) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2424:5: f= fromClause
                            {
                            pushFollow(FOLLOW_fromClause_in_atomSelectStatement15591);
                            f=fromClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_fromClause.add(f.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2425:5: (w= whereClause )?
                    int alt264=2;
                    switch ( input.LA(1) ) {
                        case KW_WHERE:
                            {
                            alt264=1;
                            }
                            break;
                    }

                    switch (alt264) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2425:5: w= whereClause
                            {
                            pushFollow(FOLLOW_whereClause_in_atomSelectStatement15599);
                            w=whereClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_whereClause.add(w.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2426:5: (g= groupByClause )?
                    int alt265=2;
                    switch ( input.LA(1) ) {
                        case KW_GROUP:
                            {
                            alt265=1;
                            }
                            break;
                    }

                    switch (alt265) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2426:5: g= groupByClause
                            {
                            pushFollow(FOLLOW_groupByClause_in_atomSelectStatement15607);
                            g=groupByClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_groupByClause.add(g.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2427:5: (h= havingClause )?
                    int alt266=2;
                    switch ( input.LA(1) ) {
                        case KW_HAVING:
                            {
                            alt266=1;
                            }
                            break;
                    }

                    switch (alt266) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2427:5: h= havingClause
                            {
                            pushFollow(FOLLOW_havingClause_in_atomSelectStatement15615);
                            h=havingClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_havingClause.add(h.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2428:7: (win= window_clause )?
                    int alt267=2;
                    switch ( input.LA(1) ) {
                        case KW_WINDOW:
                            {
                            alt267=1;
                            }
                            break;
                    }

                    switch (alt267) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2428:7: win= window_clause
                            {
                            pushFollow(FOLLOW_window_clause_in_atomSelectStatement15623);
                            win=window_clause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_window_clause.add(win.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: s, w, h, win, f, g
                    // token labels: 
                    // rule labels: s, f, w, g, h, win, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_s=new RewriteRuleSubtreeStream(adaptor,"rule s",s!=null?s.tree:null);
                    RewriteRuleSubtreeStream stream_f=new RewriteRuleSubtreeStream(adaptor,"rule f",f!=null?f.tree:null);
                    RewriteRuleSubtreeStream stream_w=new RewriteRuleSubtreeStream(adaptor,"rule w",w!=null?w.tree:null);
                    RewriteRuleSubtreeStream stream_g=new RewriteRuleSubtreeStream(adaptor,"rule g",g!=null?g.tree:null);
                    RewriteRuleSubtreeStream stream_h=new RewriteRuleSubtreeStream(adaptor,"rule h",h!=null?h.tree:null);
                    RewriteRuleSubtreeStream stream_win=new RewriteRuleSubtreeStream(adaptor,"rule win",win!=null?win.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2429:4: -> ^( TOK_QUERY ( $f)? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ) )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2429:7: ^( TOK_QUERY ( $f)? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ) )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY")
                        , root_1);

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2429:20: ( $f)?
                        if ( stream_f.hasNext() ) {
                            adaptor.addChild(root_1, stream_f.nextTree());

                        }
                        stream_f.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2429:23: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? )
                        {
                        ASTNode root_2 = (ASTNode)adaptor.nil();
                        root_2 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT")
                        , root_2);

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2429:36: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
                        {
                        ASTNode root_3 = (ASTNode)adaptor.nil();
                        root_3 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION")
                        , root_3);

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2429:54: ^( TOK_DIR TOK_TMP_FILE )
                        {
                        ASTNode root_4 = (ASTNode)adaptor.nil();
                        root_4 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_DIR, "TOK_DIR")
                        , root_4);

                        adaptor.addChild(root_4, 
                        (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE")
                        );

                        adaptor.addChild(root_3, root_4);
                        }

                        adaptor.addChild(root_2, root_3);
                        }

                        adaptor.addChild(root_2, stream_s.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2430:26: ( $w)?
                        if ( stream_w.hasNext() ) {
                            adaptor.addChild(root_2, stream_w.nextTree());

                        }
                        stream_w.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2430:30: ( $g)?
                        if ( stream_g.hasNext() ) {
                            adaptor.addChild(root_2, stream_g.nextTree());

                        }
                        stream_g.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2430:34: ( $h)?
                        if ( stream_h.hasNext() ) {
                            adaptor.addChild(root_2, stream_h.nextTree());

                        }
                        stream_h.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2430:38: ( $win)?
                        if ( stream_win.hasNext() ) {
                            adaptor.addChild(root_2, stream_win.nextTree());

                        }
                        stream_win.reset();

                        adaptor.addChild(root_1, root_2);
                        }

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2432:4: LPAREN ! selectStatement RPAREN !
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    LPAREN915=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_atomSelectStatement15701); if (state.failed) return retval;

                    pushFollow(FOLLOW_selectStatement_in_atomSelectStatement15704);
                    selectStatement916=selectStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, selectStatement916.getTree());

                    RPAREN917=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_atomSelectStatement15706); if (state.failed) return retval;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "atomSelectStatement"


    public static class selectStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "selectStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2435:1: selectStatement : a= atomSelectStatement (set= setOpSelectStatement[$atomSelectStatement.tree] )? (o= orderByClause )? (c= clusterByClause )? (d= distributeByClause )? (sort= sortByClause )? (l= limitClause )? -> {set == null}? -> {o==null && c==null && d==null && sort==null && l==null}? -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? ) ) ;
    public final HiveParser.selectStatement_return selectStatement() throws RecognitionException {
        HiveParser.selectStatement_return retval = new HiveParser.selectStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.atomSelectStatement_return a =null;

        HiveParser.setOpSelectStatement_return set =null;

        HiveParser_IdentifiersParser.orderByClause_return o =null;

        HiveParser_IdentifiersParser.clusterByClause_return c =null;

        HiveParser_IdentifiersParser.distributeByClause_return d =null;

        HiveParser_IdentifiersParser.sortByClause_return sort =null;

        HiveParser.limitClause_return l =null;


        RewriteRuleSubtreeStream stream_clusterByClause=new RewriteRuleSubtreeStream(adaptor,"rule clusterByClause");
        RewriteRuleSubtreeStream stream_setOpSelectStatement=new RewriteRuleSubtreeStream(adaptor,"rule setOpSelectStatement");
        RewriteRuleSubtreeStream stream_sortByClause=new RewriteRuleSubtreeStream(adaptor,"rule sortByClause");
        RewriteRuleSubtreeStream stream_distributeByClause=new RewriteRuleSubtreeStream(adaptor,"rule distributeByClause");
        RewriteRuleSubtreeStream stream_limitClause=new RewriteRuleSubtreeStream(adaptor,"rule limitClause");
        RewriteRuleSubtreeStream stream_atomSelectStatement=new RewriteRuleSubtreeStream(adaptor,"rule atomSelectStatement");
        RewriteRuleSubtreeStream stream_orderByClause=new RewriteRuleSubtreeStream(adaptor,"rule orderByClause");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2436:4: (a= atomSelectStatement (set= setOpSelectStatement[$atomSelectStatement.tree] )? (o= orderByClause )? (c= clusterByClause )? (d= distributeByClause )? (sort= sortByClause )? (l= limitClause )? -> {set == null}? -> {o==null && c==null && d==null && sort==null && l==null}? -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? ) ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2437:4: a= atomSelectStatement (set= setOpSelectStatement[$atomSelectStatement.tree] )? (o= orderByClause )? (c= clusterByClause )? (d= distributeByClause )? (sort= sortByClause )? (l= limitClause )?
            {
            pushFollow(FOLLOW_atomSelectStatement_in_selectStatement15727);
            a=atomSelectStatement();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_atomSelectStatement.add(a.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2438:7: (set= setOpSelectStatement[$atomSelectStatement.tree] )?
            int alt269=2;
            switch ( input.LA(1) ) {
                case KW_EXCEPT:
                case KW_INTERSECT:
                case KW_MINUS:
                case KW_UNION:
                    {
                    alt269=1;
                    }
                    break;
            }

            switch (alt269) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2438:7: set= setOpSelectStatement[$atomSelectStatement.tree]
                    {
                    pushFollow(FOLLOW_setOpSelectStatement_in_selectStatement15734);
                    set=setOpSelectStatement((a!=null?((ASTNode)a.tree):null));

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_setOpSelectStatement.add(set.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2439:5: (o= orderByClause )?
            int alt270=2;
            switch ( input.LA(1) ) {
                case KW_ORDER:
                    {
                    alt270=1;
                    }
                    break;
            }

            switch (alt270) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2439:5: o= orderByClause
                    {
                    pushFollow(FOLLOW_orderByClause_in_selectStatement15743);
                    o=orderByClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_orderByClause.add(o.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2440:5: (c= clusterByClause )?
            int alt271=2;
            switch ( input.LA(1) ) {
                case KW_CLUSTER:
                    {
                    alt271=1;
                    }
                    break;
            }

            switch (alt271) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2440:5: c= clusterByClause
                    {
                    pushFollow(FOLLOW_clusterByClause_in_selectStatement15751);
                    c=clusterByClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_clusterByClause.add(c.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2441:5: (d= distributeByClause )?
            int alt272=2;
            switch ( input.LA(1) ) {
                case KW_DISTRIBUTE:
                    {
                    alt272=1;
                    }
                    break;
            }

            switch (alt272) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2441:5: d= distributeByClause
                    {
                    pushFollow(FOLLOW_distributeByClause_in_selectStatement15759);
                    d=distributeByClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_distributeByClause.add(d.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2442:8: (sort= sortByClause )?
            int alt273=2;
            switch ( input.LA(1) ) {
                case KW_SORT:
                    {
                    alt273=1;
                    }
                    break;
            }

            switch (alt273) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2442:8: sort= sortByClause
                    {
                    pushFollow(FOLLOW_sortByClause_in_selectStatement15767);
                    sort=sortByClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_sortByClause.add(sort.getTree());

                    }
                    break;

            }


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2443:5: (l= limitClause )?
            int alt274=2;
            switch ( input.LA(1) ) {
                case KW_LIMIT:
                    {
                    alt274=1;
                    }
                    break;
            }

            switch (alt274) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2443:5: l= limitClause
                    {
                    pushFollow(FOLLOW_limitClause_in_selectStatement15775);
                    l=limitClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_limitClause.add(l.getTree());

                    }
                    break;

            }


            if ( state.backtracking==0 ) {
               if(set == null){
               (a!=null?((ASTNode)a.tree):null).getFirstChildWithType(TOK_INSERT).addChild((o!=null?((ASTNode)o.tree):null));
               (a!=null?((ASTNode)a.tree):null).getFirstChildWithType(TOK_INSERT).addChild((c!=null?((ASTNode)c.tree):null));
               (a!=null?((ASTNode)a.tree):null).getFirstChildWithType(TOK_INSERT).addChild((d!=null?((ASTNode)d.tree):null));
               (a!=null?((ASTNode)a.tree):null).getFirstChildWithType(TOK_INSERT).addChild((sort!=null?((ASTNode)sort.tree):null));
               (a!=null?((ASTNode)a.tree):null).getFirstChildWithType(TOK_INSERT).addChild((l!=null?((ASTNode)l.tree):null));
               }
               }

            // AST REWRITE
            // elements: l, d, c, o, sort
            // token labels: 
            // rule labels: c, d, sort, l, retval, o
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_c=new RewriteRuleSubtreeStream(adaptor,"rule c",c!=null?c.tree:null);
            RewriteRuleSubtreeStream stream_d=new RewriteRuleSubtreeStream(adaptor,"rule d",d!=null?d.tree:null);
            RewriteRuleSubtreeStream stream_sort=new RewriteRuleSubtreeStream(adaptor,"rule sort",sort!=null?sort.tree:null);
            RewriteRuleSubtreeStream stream_l=new RewriteRuleSubtreeStream(adaptor,"rule l",l!=null?l.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_o=new RewriteRuleSubtreeStream(adaptor,"rule o",o!=null?o.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2453:4: -> {set == null}?
            if (set == null) {
                adaptor.addChild(root_0, (a!=null?((ASTNode)a.tree):null));

            }

            else // 2455:4: -> {o==null && c==null && d==null && sort==null && l==null}?
            if (o==null && c==null && d==null && sort==null && l==null) {
                adaptor.addChild(root_0, (set!=null?((ASTNode)set.tree):null));

            }

            else // 2457:4: -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? ) )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2457:7: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? ) )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2458:11: ^( TOK_FROM ^( TOK_SUBQUERY ) )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM")
                , root_2);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2459:13: ^( TOK_SUBQUERY )
                {
                ASTNode root_3 = (ASTNode)adaptor.nil();
                root_3 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY")
                , root_3);

                adaptor.addChild(root_3, (set!=null?((ASTNode)set.tree):null));

                adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));

                adaptor.addChild(root_2, root_3);
                }

                adaptor.addChild(root_1, root_2);
                }

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2464:11: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT")
                , root_2);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2465:14: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
                {
                ASTNode root_3 = (ASTNode)adaptor.nil();
                root_3 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION")
                , root_3);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2465:32: ^( TOK_DIR TOK_TMP_FILE )
                {
                ASTNode root_4 = (ASTNode)adaptor.nil();
                root_4 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DIR, "TOK_DIR")
                , root_4);

                adaptor.addChild(root_4, 
                (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE")
                );

                adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
                }

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2466:14: ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) )
                {
                ASTNode root_3 = (ASTNode)adaptor.nil();
                root_3 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SELECT, "TOK_SELECT")
                , root_3);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2466:27: ^( TOK_SELEXPR TOK_SETCOLREF )
                {
                ASTNode root_4 = (ASTNode)adaptor.nil();
                root_4 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR")
                , root_4);

                adaptor.addChild(root_4, 
                (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF")
                );

                adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
                }

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2467:15: ( $o)?
                if ( stream_o.hasNext() ) {
                    adaptor.addChild(root_2, stream_o.nextTree());

                }
                stream_o.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2467:19: ( $c)?
                if ( stream_c.hasNext() ) {
                    adaptor.addChild(root_2, stream_c.nextTree());

                }
                stream_c.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2467:23: ( $d)?
                if ( stream_d.hasNext() ) {
                    adaptor.addChild(root_2, stream_d.nextTree());

                }
                stream_d.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2467:27: ( $sort)?
                if ( stream_sort.hasNext() ) {
                    adaptor.addChild(root_2, stream_sort.nextTree());

                }
                stream_sort.reset();

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2467:34: ( $l)?
                if ( stream_l.hasNext() ) {
                    adaptor.addChild(root_2, stream_l.nextTree());

                }
                stream_l.reset();

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "selectStatement"


    public static class setOpSelectStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "setOpSelectStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2472:1: setOpSelectStatement[CommonTree t] : (u= setOperator b= atomSelectStatement -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b) -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> ^( $u $b) )+ -> {$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_UNIONALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTALL}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) ->;
    public final HiveParser.setOpSelectStatement_return setOpSelectStatement(CommonTree t) throws RecognitionException {
        HiveParser.setOpSelectStatement_return retval = new HiveParser.setOpSelectStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.setOperator_return u =null;

        HiveParser.atomSelectStatement_return b =null;


        RewriteRuleSubtreeStream stream_setOperator=new RewriteRuleSubtreeStream(adaptor,"rule setOperator");
        RewriteRuleSubtreeStream stream_atomSelectStatement=new RewriteRuleSubtreeStream(adaptor,"rule atomSelectStatement");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2473:4: ( (u= setOperator b= atomSelectStatement -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b) -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> ^( $u $b) )+ -> {$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_UNIONALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTALL}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) ->)
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2474:4: (u= setOperator b= atomSelectStatement -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b) -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> ^( $u $b) )+
            {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2474:4: (u= setOperator b= atomSelectStatement -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b) -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> ^( $u $b) )+
            int cnt275=0;
            loop275:
            do {
                int alt275=2;
                switch ( input.LA(1) ) {
                case KW_EXCEPT:
                case KW_INTERSECT:
                case KW_MINUS:
                case KW_UNION:
                    {
                    alt275=1;
                    }
                    break;

                }

                switch (alt275) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2474:5: u= setOperator b= atomSelectStatement
            	    {
            	    pushFollow(FOLLOW_setOperator_in_setOpSelectStatement16040);
            	    u=setOperator();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_setOperator.add(u.getTree());

            	    pushFollow(FOLLOW_atomSelectStatement_in_setOpSelectStatement16044);
            	    b=atomSelectStatement();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_atomSelectStatement.add(b.getTree());

            	    // AST REWRITE
            	    // elements: b, b, u, b, u, b
            	    // token labels: 
            	    // rule labels: b, u, retval
            	    // token list labels: 
            	    // rule list labels: 
            	    // wildcard labels: 
            	    if ( state.backtracking==0 ) {

            	    retval.tree = root_0;
            	    RewriteRuleSubtreeStream stream_b=new RewriteRuleSubtreeStream(adaptor,"rule b",b!=null?b.tree:null);
            	    RewriteRuleSubtreeStream stream_u=new RewriteRuleSubtreeStream(adaptor,"rule u",u!=null?u.tree:null);
            	    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            	    root_0 = (ASTNode)adaptor.nil();
            	    // 2475:4: -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
            	    if (((ASTNode)retval.tree) != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT) {
            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2476:7: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
            	        {
            	        ASTNode root_1 = (ASTNode)adaptor.nil();
            	        root_1 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY")
            	        , root_1);

            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2477:11: ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) )
            	        {
            	        ASTNode root_2 = (ASTNode)adaptor.nil();
            	        root_2 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM")
            	        , root_2);

            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2478:13: ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) )
            	        {
            	        ASTNode root_3 = (ASTNode)adaptor.nil();
            	        root_3 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY")
            	        , root_3);

            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2479:15: ^( TOK_UNIONALL $b)
            	        {
            	        ASTNode root_4 = (ASTNode)adaptor.nil();
            	        root_4 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_UNIONALL, "TOK_UNIONALL")
            	        , root_4);

            	        adaptor.addChild(root_4, ((ASTNode)retval.tree));

            	        adaptor.addChild(root_4, stream_b.nextTree());

            	        adaptor.addChild(root_3, root_4);
            	        }

            	        adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));

            	        adaptor.addChild(root_2, root_3);
            	        }

            	        adaptor.addChild(root_1, root_2);
            	        }

            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2483:11: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) )
            	        {
            	        ASTNode root_2 = (ASTNode)adaptor.nil();
            	        root_2 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT")
            	        , root_2);

            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2484:14: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
            	        {
            	        ASTNode root_3 = (ASTNode)adaptor.nil();
            	        root_3 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION")
            	        , root_3);

            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2484:32: ^( TOK_DIR TOK_TMP_FILE )
            	        {
            	        ASTNode root_4 = (ASTNode)adaptor.nil();
            	        root_4 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_DIR, "TOK_DIR")
            	        , root_4);

            	        adaptor.addChild(root_4, 
            	        (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE")
            	        );

            	        adaptor.addChild(root_3, root_4);
            	        }

            	        adaptor.addChild(root_2, root_3);
            	        }

            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2485:14: ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) )
            	        {
            	        ASTNode root_3 = (ASTNode)adaptor.nil();
            	        root_3 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_SELECTDI, "TOK_SELECTDI")
            	        , root_3);

            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2485:29: ^( TOK_SELEXPR TOK_SETCOLREF )
            	        {
            	        ASTNode root_4 = (ASTNode)adaptor.nil();
            	        root_4 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR")
            	        , root_4);

            	        adaptor.addChild(root_4, 
            	        (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF")
            	        );

            	        adaptor.addChild(root_3, root_4);
            	        }

            	        adaptor.addChild(root_2, root_3);
            	        }

            	        adaptor.addChild(root_1, root_2);
            	        }

            	        adaptor.addChild(root_0, root_1);
            	        }

            	    }

            	    else // 2488:4: -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b)
            	    if (((ASTNode)retval.tree) != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT) {
            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2489:7: ^( $u $b)
            	        {
            	        ASTNode root_1 = (ASTNode)adaptor.nil();
            	        root_1 = (ASTNode)adaptor.becomeRoot(stream_u.nextNode(), root_1);

            	        adaptor.addChild(root_1, ((ASTNode)retval.tree));

            	        adaptor.addChild(root_1, stream_b.nextTree());

            	        adaptor.addChild(root_0, root_1);
            	        }

            	    }

            	    else // 2490:4: -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
            	    if (((ASTNode)retval.tree) == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT) {
            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2491:7: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
            	        {
            	        ASTNode root_1 = (ASTNode)adaptor.nil();
            	        root_1 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY")
            	        , root_1);

            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2492:11: ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) )
            	        {
            	        ASTNode root_2 = (ASTNode)adaptor.nil();
            	        root_2 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM")
            	        , root_2);

            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2493:13: ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) )
            	        {
            	        ASTNode root_3 = (ASTNode)adaptor.nil();
            	        root_3 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY")
            	        , root_3);

            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2494:15: ^( TOK_UNIONALL $b)
            	        {
            	        ASTNode root_4 = (ASTNode)adaptor.nil();
            	        root_4 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_UNIONALL, "TOK_UNIONALL")
            	        , root_4);

            	        adaptor.addChild(root_4, t);

            	        adaptor.addChild(root_4, stream_b.nextTree());

            	        adaptor.addChild(root_3, root_4);
            	        }

            	        adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));

            	        adaptor.addChild(root_2, root_3);
            	        }

            	        adaptor.addChild(root_1, root_2);
            	        }

            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2498:11: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) )
            	        {
            	        ASTNode root_2 = (ASTNode)adaptor.nil();
            	        root_2 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT")
            	        , root_2);

            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2499:13: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
            	        {
            	        ASTNode root_3 = (ASTNode)adaptor.nil();
            	        root_3 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION")
            	        , root_3);

            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2499:31: ^( TOK_DIR TOK_TMP_FILE )
            	        {
            	        ASTNode root_4 = (ASTNode)adaptor.nil();
            	        root_4 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_DIR, "TOK_DIR")
            	        , root_4);

            	        adaptor.addChild(root_4, 
            	        (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE")
            	        );

            	        adaptor.addChild(root_3, root_4);
            	        }

            	        adaptor.addChild(root_2, root_3);
            	        }

            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2500:13: ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) )
            	        {
            	        ASTNode root_3 = (ASTNode)adaptor.nil();
            	        root_3 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_SELECTDI, "TOK_SELECTDI")
            	        , root_3);

            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2500:28: ^( TOK_SELEXPR TOK_SETCOLREF )
            	        {
            	        ASTNode root_4 = (ASTNode)adaptor.nil();
            	        root_4 = (ASTNode)adaptor.becomeRoot(
            	        (ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR")
            	        , root_4);

            	        adaptor.addChild(root_4, 
            	        (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF")
            	        );

            	        adaptor.addChild(root_3, root_4);
            	        }

            	        adaptor.addChild(root_2, root_3);
            	        }

            	        adaptor.addChild(root_1, root_2);
            	        }

            	        adaptor.addChild(root_0, root_1);
            	        }

            	    }

            	    else // 2503:4: -> ^( $u $b)
            	    {
            	        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2503:7: ^( $u $b)
            	        {
            	        ASTNode root_1 = (ASTNode)adaptor.nil();
            	        root_1 = (ASTNode)adaptor.becomeRoot(stream_u.nextNode(), root_1);

            	        adaptor.addChild(root_1, t);

            	        adaptor.addChild(root_1, stream_b.nextTree());

            	        adaptor.addChild(root_0, root_1);
            	        }

            	    }


            	    retval.tree = root_0;
            	    }

            	    }
            	    break;

            	default :
            	    if ( cnt275 >= 1 ) break loop275;
            	    if (state.backtracking>0) {state.failed=true; return retval;}
                        EarlyExitException eee =
                            new EarlyExitException(275, input);
                        throw eee;
                }
                cnt275++;
            } while (true);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2505:4: -> {$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_UNIONALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTALL}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
            if (((ASTNode)retval.tree).getChild(0).getType()==HiveParser.TOK_UNIONALL
               ||((ASTNode)retval.tree).getChild(0).getType()==HiveParser.TOK_INTERSECTDISTINCT
               ||((ASTNode)retval.tree).getChild(0).getType()==HiveParser.TOK_INTERSECTALL
               ||((ASTNode)retval.tree).getChild(0).getType()==HiveParser.TOK_EXCEPTDISTINCT
               ||((ASTNode)retval.tree).getChild(0).getType()==HiveParser.TOK_EXCEPTALL) {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2510:7: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2511:11: ^( TOK_FROM ^( TOK_SUBQUERY ) )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM")
                , root_2);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2512:13: ^( TOK_SUBQUERY )
                {
                ASTNode root_3 = (ASTNode)adaptor.nil();
                root_3 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY")
                , root_3);

                adaptor.addChild(root_3, ((ASTNode)retval.tree));

                adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));

                adaptor.addChild(root_2, root_3);
                }

                adaptor.addChild(root_1, root_2);
                }

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2517:11: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT")
                , root_2);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2518:14: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
                {
                ASTNode root_3 = (ASTNode)adaptor.nil();
                root_3 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION")
                , root_3);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2518:32: ^( TOK_DIR TOK_TMP_FILE )
                {
                ASTNode root_4 = (ASTNode)adaptor.nil();
                root_4 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DIR, "TOK_DIR")
                , root_4);

                adaptor.addChild(root_4, 
                (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE")
                );

                adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
                }

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2519:14: ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) )
                {
                ASTNode root_3 = (ASTNode)adaptor.nil();
                root_3 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SELECT, "TOK_SELECT")
                , root_3);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2519:27: ^( TOK_SELEXPR TOK_SETCOLREF )
                {
                ASTNode root_4 = (ASTNode)adaptor.nil();
                root_4 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR")
                , root_4);

                adaptor.addChild(root_4, 
                (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF")
                );

                adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
                }

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 2522:4: ->
            {
                adaptor.addChild(root_0, ((ASTNode)retval.tree));

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "setOpSelectStatement"


    public static class selectStatementWithCTE_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "selectStatementWithCTE"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2525:1: selectStatementWithCTE : (w= withClause )? selectStatement -> selectStatement ;
    public final HiveParser.selectStatementWithCTE_return selectStatementWithCTE() throws RecognitionException {
        HiveParser.selectStatementWithCTE_return retval = new HiveParser.selectStatementWithCTE_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.withClause_return w =null;

        HiveParser.selectStatement_return selectStatement918 =null;


        RewriteRuleSubtreeStream stream_withClause=new RewriteRuleSubtreeStream(adaptor,"rule withClause");
        RewriteRuleSubtreeStream stream_selectStatement=new RewriteRuleSubtreeStream(adaptor,"rule selectStatement");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2526:5: ( (w= withClause )? selectStatement -> selectStatement )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2527:5: (w= withClause )? selectStatement
            {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2527:5: (w= withClause )?
            int alt276=2;
            switch ( input.LA(1) ) {
                case KW_WITH:
                    {
                    alt276=1;
                    }
                    break;
            }

            switch (alt276) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2527:6: w= withClause
                    {
                    pushFollow(FOLLOW_withClause_in_selectStatementWithCTE16679);
                    w=withClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_withClause.add(w.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_selectStatement_in_selectStatementWithCTE16687);
            selectStatement918=selectStatement();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_selectStatement.add(selectStatement918.getTree());

            if ( state.backtracking==0 ) {
                  if ((w!=null?((ASTNode)w.tree):null) != null) {
                  (selectStatement918!=null?((ASTNode)selectStatement918.tree):null).insertChild(0, (w!=null?((ASTNode)w.tree):null));
                  }
                }

            // AST REWRITE
            // elements: selectStatement
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2533:5: -> selectStatement
            {
                adaptor.addChild(root_0, stream_selectStatement.nextTree());

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "selectStatementWithCTE"


    public static class body_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "body"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2536:1: body : ( insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )? -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) | selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )? -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) );
    public final HiveParser.body_return body() throws RecognitionException {
        HiveParser.body_return retval = new HiveParser.body_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.insertClause_return insertClause919 =null;

        HiveParser_SelectClauseParser.selectClause_return selectClause920 =null;

        HiveParser_FromClauseParser.lateralView_return lateralView921 =null;

        HiveParser_FromClauseParser.whereClause_return whereClause922 =null;

        HiveParser_IdentifiersParser.groupByClause_return groupByClause923 =null;

        HiveParser_IdentifiersParser.havingClause_return havingClause924 =null;

        HiveParser_SelectClauseParser.window_clause_return window_clause925 =null;

        HiveParser_IdentifiersParser.orderByClause_return orderByClause926 =null;

        HiveParser_IdentifiersParser.clusterByClause_return clusterByClause927 =null;

        HiveParser_IdentifiersParser.distributeByClause_return distributeByClause928 =null;

        HiveParser_IdentifiersParser.sortByClause_return sortByClause929 =null;

        HiveParser.limitClause_return limitClause930 =null;

        HiveParser_SelectClauseParser.selectClause_return selectClause931 =null;

        HiveParser_FromClauseParser.lateralView_return lateralView932 =null;

        HiveParser_FromClauseParser.whereClause_return whereClause933 =null;

        HiveParser_IdentifiersParser.groupByClause_return groupByClause934 =null;

        HiveParser_IdentifiersParser.havingClause_return havingClause935 =null;

        HiveParser_SelectClauseParser.window_clause_return window_clause936 =null;

        HiveParser_IdentifiersParser.orderByClause_return orderByClause937 =null;

        HiveParser_IdentifiersParser.clusterByClause_return clusterByClause938 =null;

        HiveParser_IdentifiersParser.distributeByClause_return distributeByClause939 =null;

        HiveParser_IdentifiersParser.sortByClause_return sortByClause940 =null;

        HiveParser.limitClause_return limitClause941 =null;


        RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
        RewriteRuleSubtreeStream stream_havingClause=new RewriteRuleSubtreeStream(adaptor,"rule havingClause");
        RewriteRuleSubtreeStream stream_clusterByClause=new RewriteRuleSubtreeStream(adaptor,"rule clusterByClause");
        RewriteRuleSubtreeStream stream_lateralView=new RewriteRuleSubtreeStream(adaptor,"rule lateralView");
        RewriteRuleSubtreeStream stream_insertClause=new RewriteRuleSubtreeStream(adaptor,"rule insertClause");
        RewriteRuleSubtreeStream stream_selectClause=new RewriteRuleSubtreeStream(adaptor,"rule selectClause");
        RewriteRuleSubtreeStream stream_sortByClause=new RewriteRuleSubtreeStream(adaptor,"rule sortByClause");
        RewriteRuleSubtreeStream stream_groupByClause=new RewriteRuleSubtreeStream(adaptor,"rule groupByClause");
        RewriteRuleSubtreeStream stream_distributeByClause=new RewriteRuleSubtreeStream(adaptor,"rule distributeByClause");
        RewriteRuleSubtreeStream stream_limitClause=new RewriteRuleSubtreeStream(adaptor,"rule limitClause");
        RewriteRuleSubtreeStream stream_orderByClause=new RewriteRuleSubtreeStream(adaptor,"rule orderByClause");
        RewriteRuleSubtreeStream stream_window_clause=new RewriteRuleSubtreeStream(adaptor,"rule window_clause");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2537:4: ( insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )? -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) | selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )? -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) )
            int alt297=2;
            switch ( input.LA(1) ) {
            case KW_INSERT:
                {
                alt297=1;
                }
                break;
            case KW_MAP:
            case KW_REDUCE:
            case KW_SELECT:
                {
                alt297=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 297, 0, input);

                throw nvae;

            }

            switch (alt297) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2538:4: insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )?
                    {
                    pushFollow(FOLLOW_insertClause_in_body16717);
                    insertClause919=insertClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_insertClause.add(insertClause919.getTree());

                    pushFollow(FOLLOW_selectClause_in_body16722);
                    selectClause920=selectClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_selectClause.add(selectClause920.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2540:4: ( lateralView )?
                    int alt277=2;
                    switch ( input.LA(1) ) {
                        case KW_LATERAL:
                            {
                            alt277=1;
                            }
                            break;
                    }

                    switch (alt277) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2540:4: lateralView
                            {
                            pushFollow(FOLLOW_lateralView_in_body16727);
                            lateralView921=lateralView();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_lateralView.add(lateralView921.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2541:4: ( whereClause )?
                    int alt278=2;
                    switch ( input.LA(1) ) {
                        case KW_WHERE:
                            {
                            alt278=1;
                            }
                            break;
                    }

                    switch (alt278) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2541:4: whereClause
                            {
                            pushFollow(FOLLOW_whereClause_in_body16733);
                            whereClause922=whereClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_whereClause.add(whereClause922.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2542:4: ( groupByClause )?
                    int alt279=2;
                    switch ( input.LA(1) ) {
                        case KW_GROUP:
                            {
                            alt279=1;
                            }
                            break;
                    }

                    switch (alt279) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2542:4: groupByClause
                            {
                            pushFollow(FOLLOW_groupByClause_in_body16739);
                            groupByClause923=groupByClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_groupByClause.add(groupByClause923.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2543:4: ( havingClause )?
                    int alt280=2;
                    switch ( input.LA(1) ) {
                        case KW_HAVING:
                            {
                            alt280=1;
                            }
                            break;
                    }

                    switch (alt280) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2543:4: havingClause
                            {
                            pushFollow(FOLLOW_havingClause_in_body16745);
                            havingClause924=havingClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_havingClause.add(havingClause924.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2544:4: ( window_clause )?
                    int alt281=2;
                    switch ( input.LA(1) ) {
                        case KW_WINDOW:
                            {
                            alt281=1;
                            }
                            break;
                    }

                    switch (alt281) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2544:4: window_clause
                            {
                            pushFollow(FOLLOW_window_clause_in_body16751);
                            window_clause925=window_clause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_window_clause.add(window_clause925.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2545:4: ( orderByClause )?
                    int alt282=2;
                    switch ( input.LA(1) ) {
                        case KW_ORDER:
                            {
                            alt282=1;
                            }
                            break;
                    }

                    switch (alt282) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2545:4: orderByClause
                            {
                            pushFollow(FOLLOW_orderByClause_in_body16757);
                            orderByClause926=orderByClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_orderByClause.add(orderByClause926.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2546:4: ( clusterByClause )?
                    int alt283=2;
                    switch ( input.LA(1) ) {
                        case KW_CLUSTER:
                            {
                            alt283=1;
                            }
                            break;
                    }

                    switch (alt283) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2546:4: clusterByClause
                            {
                            pushFollow(FOLLOW_clusterByClause_in_body16763);
                            clusterByClause927=clusterByClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_clusterByClause.add(clusterByClause927.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2547:4: ( distributeByClause )?
                    int alt284=2;
                    switch ( input.LA(1) ) {
                        case KW_DISTRIBUTE:
                            {
                            alt284=1;
                            }
                            break;
                    }

                    switch (alt284) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2547:4: distributeByClause
                            {
                            pushFollow(FOLLOW_distributeByClause_in_body16769);
                            distributeByClause928=distributeByClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_distributeByClause.add(distributeByClause928.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2548:4: ( sortByClause )?
                    int alt285=2;
                    switch ( input.LA(1) ) {
                        case KW_SORT:
                            {
                            alt285=1;
                            }
                            break;
                    }

                    switch (alt285) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2548:4: sortByClause
                            {
                            pushFollow(FOLLOW_sortByClause_in_body16775);
                            sortByClause929=sortByClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_sortByClause.add(sortByClause929.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2549:4: ( limitClause )?
                    int alt286=2;
                    switch ( input.LA(1) ) {
                        case KW_LIMIT:
                            {
                            alt286=1;
                            }
                            break;
                    }

                    switch (alt286) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2549:4: limitClause
                            {
                            pushFollow(FOLLOW_limitClause_in_body16781);
                            limitClause930=limitClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_limitClause.add(limitClause930.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: insertClause, sortByClause, window_clause, lateralView, selectClause, whereClause, havingClause, orderByClause, groupByClause, distributeByClause, clusterByClause, limitClause
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2549:17: -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2549:20: ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT")
                        , root_1);

                        adaptor.addChild(root_1, stream_insertClause.nextTree());

                        adaptor.addChild(root_1, stream_selectClause.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2550:35: ( lateralView )?
                        if ( stream_lateralView.hasNext() ) {
                            adaptor.addChild(root_1, stream_lateralView.nextTree());

                        }
                        stream_lateralView.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2550:48: ( whereClause )?
                        if ( stream_whereClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_whereClause.nextTree());

                        }
                        stream_whereClause.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2550:61: ( groupByClause )?
                        if ( stream_groupByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_groupByClause.nextTree());

                        }
                        stream_groupByClause.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2550:76: ( havingClause )?
                        if ( stream_havingClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_havingClause.nextTree());

                        }
                        stream_havingClause.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2550:90: ( orderByClause )?
                        if ( stream_orderByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_orderByClause.nextTree());

                        }
                        stream_orderByClause.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2550:105: ( clusterByClause )?
                        if ( stream_clusterByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_clusterByClause.nextTree());

                        }
                        stream_clusterByClause.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2551:22: ( distributeByClause )?
                        if ( stream_distributeByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_distributeByClause.nextTree());

                        }
                        stream_distributeByClause.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2551:42: ( sortByClause )?
                        if ( stream_sortByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_sortByClause.nextTree());

                        }
                        stream_sortByClause.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2551:56: ( window_clause )?
                        if ( stream_window_clause.hasNext() ) {
                            adaptor.addChild(root_1, stream_window_clause.nextTree());

                        }
                        stream_window_clause.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2551:71: ( limitClause )?
                        if ( stream_limitClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_limitClause.nextTree());

                        }
                        stream_limitClause.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2553:4: selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )?
                    {
                    pushFollow(FOLLOW_selectClause_in_body16874);
                    selectClause931=selectClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_selectClause.add(selectClause931.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2554:4: ( lateralView )?
                    int alt287=2;
                    switch ( input.LA(1) ) {
                        case KW_LATERAL:
                            {
                            alt287=1;
                            }
                            break;
                    }

                    switch (alt287) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2554:4: lateralView
                            {
                            pushFollow(FOLLOW_lateralView_in_body16879);
                            lateralView932=lateralView();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_lateralView.add(lateralView932.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2555:4: ( whereClause )?
                    int alt288=2;
                    switch ( input.LA(1) ) {
                        case KW_WHERE:
                            {
                            alt288=1;
                            }
                            break;
                    }

                    switch (alt288) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2555:4: whereClause
                            {
                            pushFollow(FOLLOW_whereClause_in_body16885);
                            whereClause933=whereClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_whereClause.add(whereClause933.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2556:4: ( groupByClause )?
                    int alt289=2;
                    switch ( input.LA(1) ) {
                        case KW_GROUP:
                            {
                            alt289=1;
                            }
                            break;
                    }

                    switch (alt289) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2556:4: groupByClause
                            {
                            pushFollow(FOLLOW_groupByClause_in_body16891);
                            groupByClause934=groupByClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_groupByClause.add(groupByClause934.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2557:4: ( havingClause )?
                    int alt290=2;
                    switch ( input.LA(1) ) {
                        case KW_HAVING:
                            {
                            alt290=1;
                            }
                            break;
                    }

                    switch (alt290) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2557:4: havingClause
                            {
                            pushFollow(FOLLOW_havingClause_in_body16897);
                            havingClause935=havingClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_havingClause.add(havingClause935.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2558:4: ( window_clause )?
                    int alt291=2;
                    switch ( input.LA(1) ) {
                        case KW_WINDOW:
                            {
                            alt291=1;
                            }
                            break;
                    }

                    switch (alt291) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2558:4: window_clause
                            {
                            pushFollow(FOLLOW_window_clause_in_body16903);
                            window_clause936=window_clause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_window_clause.add(window_clause936.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2559:4: ( orderByClause )?
                    int alt292=2;
                    switch ( input.LA(1) ) {
                        case KW_ORDER:
                            {
                            alt292=1;
                            }
                            break;
                    }

                    switch (alt292) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2559:4: orderByClause
                            {
                            pushFollow(FOLLOW_orderByClause_in_body16909);
                            orderByClause937=orderByClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_orderByClause.add(orderByClause937.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2560:4: ( clusterByClause )?
                    int alt293=2;
                    switch ( input.LA(1) ) {
                        case KW_CLUSTER:
                            {
                            alt293=1;
                            }
                            break;
                    }

                    switch (alt293) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2560:4: clusterByClause
                            {
                            pushFollow(FOLLOW_clusterByClause_in_body16915);
                            clusterByClause938=clusterByClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_clusterByClause.add(clusterByClause938.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2561:4: ( distributeByClause )?
                    int alt294=2;
                    switch ( input.LA(1) ) {
                        case KW_DISTRIBUTE:
                            {
                            alt294=1;
                            }
                            break;
                    }

                    switch (alt294) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2561:4: distributeByClause
                            {
                            pushFollow(FOLLOW_distributeByClause_in_body16921);
                            distributeByClause939=distributeByClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_distributeByClause.add(distributeByClause939.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2562:4: ( sortByClause )?
                    int alt295=2;
                    switch ( input.LA(1) ) {
                        case KW_SORT:
                            {
                            alt295=1;
                            }
                            break;
                    }

                    switch (alt295) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2562:4: sortByClause
                            {
                            pushFollow(FOLLOW_sortByClause_in_body16927);
                            sortByClause940=sortByClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_sortByClause.add(sortByClause940.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2563:4: ( limitClause )?
                    int alt296=2;
                    switch ( input.LA(1) ) {
                        case KW_LIMIT:
                            {
                            alt296=1;
                            }
                            break;
                    }

                    switch (alt296) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2563:4: limitClause
                            {
                            pushFollow(FOLLOW_limitClause_in_body16933);
                            limitClause941=limitClause();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_limitClause.add(limitClause941.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: orderByClause, clusterByClause, selectClause, lateralView, distributeByClause, window_clause, havingClause, sortByClause, groupByClause, whereClause, limitClause
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2563:17: -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2563:20: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT")
                        , root_1);

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2563:33: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
                        {
                        ASTNode root_2 = (ASTNode)adaptor.nil();
                        root_2 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION")
                        , root_2);

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2563:51: ^( TOK_DIR TOK_TMP_FILE )
                        {
                        ASTNode root_3 = (ASTNode)adaptor.nil();
                        root_3 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_DIR, "TOK_DIR")
                        , root_3);

                        adaptor.addChild(root_3, 
                        (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE")
                        );

                        adaptor.addChild(root_2, root_3);
                        }

                        adaptor.addChild(root_1, root_2);
                        }

                        adaptor.addChild(root_1, stream_selectClause.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2564:35: ( lateralView )?
                        if ( stream_lateralView.hasNext() ) {
                            adaptor.addChild(root_1, stream_lateralView.nextTree());

                        }
                        stream_lateralView.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2564:48: ( whereClause )?
                        if ( stream_whereClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_whereClause.nextTree());

                        }
                        stream_whereClause.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2564:61: ( groupByClause )?
                        if ( stream_groupByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_groupByClause.nextTree());

                        }
                        stream_groupByClause.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2564:76: ( havingClause )?
                        if ( stream_havingClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_havingClause.nextTree());

                        }
                        stream_havingClause.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2564:90: ( orderByClause )?
                        if ( stream_orderByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_orderByClause.nextTree());

                        }
                        stream_orderByClause.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2564:105: ( clusterByClause )?
                        if ( stream_clusterByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_clusterByClause.nextTree());

                        }
                        stream_clusterByClause.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:22: ( distributeByClause )?
                        if ( stream_distributeByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_distributeByClause.nextTree());

                        }
                        stream_distributeByClause.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:42: ( sortByClause )?
                        if ( stream_sortByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_sortByClause.nextTree());

                        }
                        stream_sortByClause.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:56: ( window_clause )?
                        if ( stream_window_clause.hasNext() ) {
                            adaptor.addChild(root_1, stream_window_clause.nextTree());

                        }
                        stream_window_clause.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:71: ( limitClause )?
                        if ( stream_limitClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_limitClause.nextTree());

                        }
                        stream_limitClause.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "body"


    public static class insertClause_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "insertClause"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2568:1: insertClause : ( KW_INSERT KW_OVERWRITE destination ( ifNotExists )? -> ^( TOK_DESTINATION destination ( ifNotExists )? ) | KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition ( LPAREN targetCols= columnNameList RPAREN )? -> ^( TOK_INSERT_INTO tableOrPartition ( $targetCols)? ) );
    public final HiveParser.insertClause_return insertClause() throws RecognitionException {
        HiveParser.insertClause_return retval = new HiveParser.insertClause_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_INSERT942=null;
        Token KW_OVERWRITE943=null;
        Token KW_INSERT946=null;
        Token KW_INTO947=null;
        Token KW_TABLE948=null;
        Token LPAREN950=null;
        Token RPAREN951=null;
        HiveParser.columnNameList_return targetCols =null;

        HiveParser.destination_return destination944 =null;

        HiveParser.ifNotExists_return ifNotExists945 =null;

        HiveParser_IdentifiersParser.tableOrPartition_return tableOrPartition949 =null;


        ASTNode KW_INSERT942_tree=null;
        ASTNode KW_OVERWRITE943_tree=null;
        ASTNode KW_INSERT946_tree=null;
        ASTNode KW_INTO947_tree=null;
        ASTNode KW_TABLE948_tree=null;
        ASTNode LPAREN950_tree=null;
        ASTNode RPAREN951_tree=null;
        RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_KW_INSERT=new RewriteRuleTokenStream(adaptor,"token KW_INSERT");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_OVERWRITE=new RewriteRuleTokenStream(adaptor,"token KW_OVERWRITE");
        RewriteRuleSubtreeStream stream_destination=new RewriteRuleSubtreeStream(adaptor,"rule destination");
        RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
        RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
         pushMsg("insert clause", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2571:4: ( KW_INSERT KW_OVERWRITE destination ( ifNotExists )? -> ^( TOK_DESTINATION destination ( ifNotExists )? ) | KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition ( LPAREN targetCols= columnNameList RPAREN )? -> ^( TOK_INSERT_INTO tableOrPartition ( $targetCols)? ) )
            int alt301=2;
            switch ( input.LA(1) ) {
            case KW_INSERT:
                {
                switch ( input.LA(2) ) {
                case KW_OVERWRITE:
                    {
                    alt301=1;
                    }
                    break;
                case KW_INTO:
                    {
                    alt301=2;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 301, 1, input);

                    throw nvae;

                }

                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 301, 0, input);

                throw nvae;

            }

            switch (alt301) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2572:6: KW_INSERT KW_OVERWRITE destination ( ifNotExists )?
                    {
                    KW_INSERT942=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_insertClause17054); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_INSERT.add(KW_INSERT942);


                    KW_OVERWRITE943=(Token)match(input,KW_OVERWRITE,FOLLOW_KW_OVERWRITE_in_insertClause17056); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_OVERWRITE.add(KW_OVERWRITE943);


                    pushFollow(FOLLOW_destination_in_insertClause17058);
                    destination944=destination();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_destination.add(destination944.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2572:41: ( ifNotExists )?
                    int alt298=2;
                    switch ( input.LA(1) ) {
                        case KW_IF:
                            {
                            alt298=1;
                            }
                            break;
                    }

                    switch (alt298) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2572:41: ifNotExists
                            {
                            pushFollow(FOLLOW_ifNotExists_in_insertClause17060);
                            ifNotExists945=ifNotExists();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists945.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: ifNotExists, destination
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2572:54: -> ^( TOK_DESTINATION destination ( ifNotExists )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2572:57: ^( TOK_DESTINATION destination ( ifNotExists )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION")
                        , root_1);

                        adaptor.addChild(root_1, stream_destination.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2572:87: ( ifNotExists )?
                        if ( stream_ifNotExists.hasNext() ) {
                            adaptor.addChild(root_1, stream_ifNotExists.nextTree());

                        }
                        stream_ifNotExists.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2573:6: KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition ( LPAREN targetCols= columnNameList RPAREN )?
                    {
                    KW_INSERT946=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_insertClause17079); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_INSERT.add(KW_INSERT946);


                    KW_INTO947=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_insertClause17081); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO947);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2573:24: ( KW_TABLE )?
                    int alt299=2;
                    switch ( input.LA(1) ) {
                        case KW_TABLE:
                            {
                            switch ( input.LA(2) ) {
                                case Identifier:
                                case KW_ABORT:
                                case KW_ADD:
                                case KW_ADMIN:
                                case KW_AFTER:
                                case KW_ALL:
                                case KW_ALTER:
                                case KW_ANALYZE:
                                case KW_ARCHIVE:
                                case KW_ARRAY:
                                case KW_AS:
                                case KW_ASC:
                                case KW_AUTHORIZATION:
                                case KW_AUTOCOMMIT:
                                case KW_BEFORE:
                                case KW_BETWEEN:
                                case KW_BIGINT:
                                case KW_BINARY:
                                case KW_BOOLEAN:
                                case KW_BOTH:
                                case KW_BUCKET:
                                case KW_BUCKETS:
                                case KW_BY:
                                case KW_CACHE:
                                case KW_CASCADE:
                                case KW_CHANGE:
                                case KW_CLUSTER:
                                case KW_CLUSTERED:
                                case KW_CLUSTERSTATUS:
                                case KW_COLLECTION:
                                case KW_COLUMNS:
                                case KW_COMMENT:
                                case KW_COMPACT:
                                case KW_COMPACTIONS:
                                case KW_COMPUTE:
                                case KW_CONCATENATE:
                                case KW_CONSTRAINT:
                                case KW_CONTINUE:
                                case KW_CREATE:
                                case KW_CUBE:
                                case KW_CURRENT_DATE:
                                case KW_CURRENT_TIMESTAMP:
                                case KW_CURSOR:
                                case KW_DATA:
                                case KW_DATABASES:
                                case KW_DATE:
                                case KW_DATETIME:
                                case KW_DAY:
                                case KW_DBPROPERTIES:
                                case KW_DECIMAL:
                                case KW_DEFERRED:
                                case KW_DEFINED:
                                case KW_DELETE:
                                case KW_DELIMITED:
                                case KW_DEPENDENCY:
                                case KW_DESC:
                                case KW_DESCRIBE:
                                case KW_DIRECTORIES:
                                case KW_DIRECTORY:
                                case KW_DISABLE:
                                case KW_DISTRIBUTE:
                                case KW_DOUBLE:
                                case KW_DOW:
                                case KW_DROP:
                                case KW_DUMP:
                                case KW_ELEM_TYPE:
                                case KW_ENABLE:
                                case KW_ESCAPED:
                                case KW_EXCLUSIVE:
                                case KW_EXISTS:
                                case KW_EXPLAIN:
                                case KW_EXPORT:
                                case KW_EXTERNAL:
                                case KW_FALSE:
                                case KW_FETCH:
                                case KW_FIELDS:
                                case KW_FILE:
                                case KW_FILEFORMAT:
                                case KW_FIRST:
                                case KW_FLOAT:
                                case KW_FOR:
                                case KW_FOREIGN:
                                case KW_FORMAT:
                                case KW_FORMATTED:
                                case KW_FULL:
                                case KW_FUNCTIONS:
                                case KW_GRANT:
                                case KW_GROUP:
                                case KW_GROUPING:
                                case KW_HOUR:
                                case KW_IDXPROPERTIES:
                                case KW_IMPORT:
                                case KW_IN:
                                case KW_INDEX:
                                case KW_INDEXES:
                                case KW_INNER:
                                case KW_INPATH:
                                case KW_INPUTDRIVER:
                                case KW_INPUTFORMAT:
                                case KW_INSERT:
                                case KW_INT:
                                case KW_INTERSECT:
                                case KW_INTO:
                                case KW_IS:
                                case KW_ISOLATION:
                                case KW_ITEMS:
                                case KW_JAR:
                                case KW_KEY:
                                case KW_KEYS:
                                case KW_KEY_TYPE:
                                case KW_LAST:
                                case KW_LATERAL:
                                case KW_LEFT:
                                case KW_LEVEL:
                                case KW_LIKE:
                                case KW_LIMIT:
                                case KW_LINES:
                                case KW_LOAD:
                                case KW_LOCAL:
                                case KW_LOCATION:
                                case KW_LOCK:
                                case KW_LOCKS:
                                case KW_LOGICAL:
                                case KW_LONG:
                                case KW_MAPJOIN:
                                case KW_MATCHED:
                                case KW_MATERIALIZED:
                                case KW_MERGE:
                                case KW_METADATA:
                                case KW_MINUTE:
                                case KW_MONTH:
                                case KW_MSCK:
                                case KW_NONE:
                                case KW_NORELY:
                                case KW_NOSCAN:
                                case KW_NOVALIDATE:
                                case KW_NULL:
                                case KW_NULLS:
                                case KW_OF:
                                case KW_OFFSET:
                                case KW_OPTION:
                                case KW_ORDER:
                                case KW_OUT:
                                case KW_OUTER:
                                case KW_OUTPUTDRIVER:
                                case KW_OUTPUTFORMAT:
                                case KW_OVERWRITE:
                                case KW_OWNER:
                                case KW_PARTITIONED:
                                case KW_PARTITIONS:
                                case KW_PERCENT:
                                case KW_PLUS:
                                case KW_PRETTY:
                                case KW_PRIMARY:
                                case KW_PRINCIPALS:
                                case KW_PROCEDURE:
                                case KW_PURGE:
                                case KW_QUARTER:
                                case KW_RANGE:
                                case KW_READ:
                                case KW_READS:
                                case KW_REBUILD:
                                case KW_RECORDREADER:
                                case KW_RECORDWRITER:
                                case KW_REFERENCES:
                                case KW_REGEXP:
                                case KW_RELOAD:
                                case KW_RELY:
                                case KW_RENAME:
                                case KW_REPAIR:
                                case KW_REPL:
                                case KW_REPLACE:
                                case KW_REPLICATION:
                                case KW_RESTRICT:
                                case KW_REVOKE:
                                case KW_REWRITE:
                                case KW_RIGHT:
                                case KW_RLIKE:
                                case KW_ROLE:
                                case KW_ROLES:
                                case KW_ROLLUP:
                                case KW_ROW:
                                case KW_ROWS:
                                case KW_SCHEMA:
                                case KW_SCHEMAS:
                                case KW_SECOND:
                                case KW_SEMI:
                                case KW_SERDE:
                                case KW_SERDEPROPERTIES:
                                case KW_SERVER:
                                case KW_SET:
                                case KW_SETS:
                                case KW_SHARED:
                                case KW_SHOW:
                                case KW_SHOW_DATABASE:
                                case KW_SKEWED:
                                case KW_SMALLINT:
                                case KW_SNAPSHOT:
                                case KW_SORT:
                                case KW_SORTED:
                                case KW_SSL:
                                case KW_STATISTICS:
                                case KW_STATUS:
                                case KW_STORED:
                                case KW_STREAMTABLE:
                                case KW_STRING:
                                case KW_STRUCT:
                                case KW_TABLE:
                                case KW_TABLES:
                                case KW_TBLPROPERTIES:
                                case KW_TEMPORARY:
                                case KW_TERMINATED:
                                case KW_TIMESTAMP:
                                case KW_TINYINT:
                                case KW_TO:
                                case KW_TOUCH:
                                case KW_TRANSACTION:
                                case KW_TRANSACTIONS:
                                case KW_TRIGGER:
                                case KW_TRUE:
                                case KW_TRUNCATE:
                                case KW_UNARCHIVE:
                                case KW_UNDO:
                                case KW_UNION:
                                case KW_UNIONTYPE:
                                case KW_UNLOCK:
                                case KW_UNSET:
                                case KW_UNSIGNED:
                                case KW_UPDATE:
                                case KW_URI:
                                case KW_USE:
                                case KW_USER:
                                case KW_USING:
                                case KW_UTC:
                                case KW_UTCTIMESTAMP:
                                case KW_VALIDATE:
                                case KW_VALUE_TYPE:
                                case KW_VIEW:
                                case KW_VIEWS:
                                case KW_WEEK:
                                case KW_WHILE:
                                case KW_WITH:
                                case KW_WORK:
                                case KW_WRITE:
                                case KW_YEAR:
                                case KW_BATCH:
                                case KW_DAYOFWEEK:
                                case KW_HOLD_DDLTIME:
                                case KW_IGNORE:
                                case KW_NO_DROP:
                                case KW_OFFLINE:
                                case KW_PROTECTION:
                                case KW_READONLY:
                                    {
                                    alt299=1;
                                    }
                                    break;
                                case KW_PARTITION:
                                    {
                                    switch ( input.LA(3) ) {
                                        case LPAREN:
                                            {
                                            int LA299_16 = input.LA(4);

                                            if ( (!(((useSQL11ReservedKeywordsForIdentifier())))) ) {
                                                alt299=1;
                                            }
                                            }
                                            break;
                                        case DOT:
                                        case KW_MAP:
                                        case KW_PARTITION:
                                        case KW_REDUCE:
                                        case KW_SELECT:
                                        case KW_VALUES:
                                            {
                                            alt299=1;
                                            }
                                            break;
                                    }

                                    }
                                    break;
                                case KW_VALUES:
                                    {
                                    switch ( input.LA(3) ) {
                                        case DOT:
                                        case KW_MAP:
                                        case KW_PARTITION:
                                        case KW_REDUCE:
                                        case KW_SELECT:
                                        case KW_VALUES:
                                            {
                                            alt299=1;
                                            }
                                            break;
                                        case LPAREN:
                                            {
                                            int LA299_27 = input.LA(4);

                                            if ( (!(((useSQL11ReservedKeywordsForIdentifier())))) ) {
                                                alt299=1;
                                            }
                                            }
                                            break;
                                    }

                                    }
                                    break;
                            }

                            }
                            break;
                    }

                    switch (alt299) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2573:24: KW_TABLE
                            {
                            KW_TABLE948=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_insertClause17083); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE948);


                            }
                            break;

                    }


                    pushFollow(FOLLOW_tableOrPartition_in_insertClause17086);
                    tableOrPartition949=tableOrPartition();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableOrPartition.add(tableOrPartition949.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2573:51: ( LPAREN targetCols= columnNameList RPAREN )?
                    int alt300=2;
                    switch ( input.LA(1) ) {
                        case LPAREN:
                            {
                            switch ( input.LA(2) ) {
                                case Identifier:
                                case KW_ABORT:
                                case KW_ADD:
                                case KW_ADMIN:
                                case KW_AFTER:
                                case KW_ALL:
                                case KW_ALTER:
                                case KW_ANALYZE:
                                case KW_ARCHIVE:
                                case KW_ARRAY:
                                case KW_AS:
                                case KW_ASC:
                                case KW_AUTHORIZATION:
                                case KW_AUTOCOMMIT:
                                case KW_BEFORE:
                                case KW_BETWEEN:
                                case KW_BIGINT:
                                case KW_BINARY:
                                case KW_BOOLEAN:
                                case KW_BOTH:
                                case KW_BUCKET:
                                case KW_BUCKETS:
                                case KW_BY:
                                case KW_CACHE:
                                case KW_CASCADE:
                                case KW_CHANGE:
                                case KW_CLUSTER:
                                case KW_CLUSTERED:
                                case KW_CLUSTERSTATUS:
                                case KW_COLLECTION:
                                case KW_COLUMNS:
                                case KW_COMMENT:
                                case KW_COMPACT:
                                case KW_COMPACTIONS:
                                case KW_COMPUTE:
                                case KW_CONCATENATE:
                                case KW_CONSTRAINT:
                                case KW_CONTINUE:
                                case KW_CREATE:
                                case KW_CUBE:
                                case KW_CURRENT_DATE:
                                case KW_CURRENT_TIMESTAMP:
                                case KW_CURSOR:
                                case KW_DATA:
                                case KW_DATABASES:
                                case KW_DATE:
                                case KW_DATETIME:
                                case KW_DAY:
                                case KW_DBPROPERTIES:
                                case KW_DECIMAL:
                                case KW_DEFERRED:
                                case KW_DEFINED:
                                case KW_DELETE:
                                case KW_DELIMITED:
                                case KW_DEPENDENCY:
                                case KW_DESC:
                                case KW_DESCRIBE:
                                case KW_DIRECTORIES:
                                case KW_DIRECTORY:
                                case KW_DISABLE:
                                case KW_DISTRIBUTE:
                                case KW_DOUBLE:
                                case KW_DOW:
                                case KW_DROP:
                                case KW_DUMP:
                                case KW_ELEM_TYPE:
                                case KW_ENABLE:
                                case KW_ESCAPED:
                                case KW_EXCLUSIVE:
                                case KW_EXISTS:
                                case KW_EXPLAIN:
                                case KW_EXPORT:
                                case KW_EXTERNAL:
                                case KW_FALSE:
                                case KW_FETCH:
                                case KW_FIELDS:
                                case KW_FILE:
                                case KW_FILEFORMAT:
                                case KW_FIRST:
                                case KW_FLOAT:
                                case KW_FOR:
                                case KW_FOREIGN:
                                case KW_FORMAT:
                                case KW_FORMATTED:
                                case KW_FULL:
                                case KW_FUNCTIONS:
                                case KW_GRANT:
                                case KW_GROUP:
                                case KW_GROUPING:
                                case KW_HOUR:
                                case KW_IDXPROPERTIES:
                                case KW_IMPORT:
                                case KW_IN:
                                case KW_INDEX:
                                case KW_INDEXES:
                                case KW_INNER:
                                case KW_INPATH:
                                case KW_INPUTDRIVER:
                                case KW_INPUTFORMAT:
                                case KW_INSERT:
                                case KW_INT:
                                case KW_INTERSECT:
                                case KW_INTO:
                                case KW_IS:
                                case KW_ISOLATION:
                                case KW_ITEMS:
                                case KW_JAR:
                                case KW_KEY:
                                case KW_KEYS:
                                case KW_KEY_TYPE:
                                case KW_LAST:
                                case KW_LATERAL:
                                case KW_LEFT:
                                case KW_LEVEL:
                                case KW_LIKE:
                                case KW_LIMIT:
                                case KW_LINES:
                                case KW_LOAD:
                                case KW_LOCAL:
                                case KW_LOCATION:
                                case KW_LOCK:
                                case KW_LOCKS:
                                case KW_LOGICAL:
                                case KW_LONG:
                                case KW_MAPJOIN:
                                case KW_MATCHED:
                                case KW_MATERIALIZED:
                                case KW_MERGE:
                                case KW_METADATA:
                                case KW_MINUTE:
                                case KW_MONTH:
                                case KW_MSCK:
                                case KW_NONE:
                                case KW_NORELY:
                                case KW_NOSCAN:
                                case KW_NOVALIDATE:
                                case KW_NULL:
                                case KW_NULLS:
                                case KW_OF:
                                case KW_OFFSET:
                                case KW_OPTION:
                                case KW_ORDER:
                                case KW_OUT:
                                case KW_OUTER:
                                case KW_OUTPUTDRIVER:
                                case KW_OUTPUTFORMAT:
                                case KW_OVERWRITE:
                                case KW_OWNER:
                                case KW_PARTITION:
                                case KW_PARTITIONED:
                                case KW_PARTITIONS:
                                case KW_PERCENT:
                                case KW_PLUS:
                                case KW_PRETTY:
                                case KW_PRIMARY:
                                case KW_PRINCIPALS:
                                case KW_PROCEDURE:
                                case KW_PURGE:
                                case KW_QUARTER:
                                case KW_RANGE:
                                case KW_READ:
                                case KW_READS:
                                case KW_REBUILD:
                                case KW_RECORDREADER:
                                case KW_RECORDWRITER:
                                case KW_REFERENCES:
                                case KW_REGEXP:
                                case KW_RELOAD:
                                case KW_RELY:
                                case KW_RENAME:
                                case KW_REPAIR:
                                case KW_REPL:
                                case KW_REPLACE:
                                case KW_REPLICATION:
                                case KW_RESTRICT:
                                case KW_REVOKE:
                                case KW_REWRITE:
                                case KW_RIGHT:
                                case KW_RLIKE:
                                case KW_ROLE:
                                case KW_ROLES:
                                case KW_ROLLUP:
                                case KW_ROW:
                                case KW_ROWS:
                                case KW_SCHEMA:
                                case KW_SCHEMAS:
                                case KW_SECOND:
                                case KW_SEMI:
                                case KW_SERDE:
                                case KW_SERDEPROPERTIES:
                                case KW_SERVER:
                                case KW_SET:
                                case KW_SETS:
                                case KW_SHARED:
                                case KW_SHOW:
                                case KW_SHOW_DATABASE:
                                case KW_SKEWED:
                                case KW_SMALLINT:
                                case KW_SNAPSHOT:
                                case KW_SORT:
                                case KW_SORTED:
                                case KW_SSL:
                                case KW_STATISTICS:
                                case KW_STATUS:
                                case KW_STORED:
                                case KW_STREAMTABLE:
                                case KW_STRING:
                                case KW_STRUCT:
                                case KW_TABLE:
                                case KW_TABLES:
                                case KW_TBLPROPERTIES:
                                case KW_TEMPORARY:
                                case KW_TERMINATED:
                                case KW_TIMESTAMP:
                                case KW_TINYINT:
                                case KW_TO:
                                case KW_TOUCH:
                                case KW_TRANSACTION:
                                case KW_TRANSACTIONS:
                                case KW_TRIGGER:
                                case KW_TRUE:
                                case KW_TRUNCATE:
                                case KW_UNARCHIVE:
                                case KW_UNDO:
                                case KW_UNION:
                                case KW_UNIONTYPE:
                                case KW_UNLOCK:
                                case KW_UNSET:
                                case KW_UNSIGNED:
                                case KW_UPDATE:
                                case KW_URI:
                                case KW_USE:
                                case KW_USER:
                                case KW_USING:
                                case KW_UTC:
                                case KW_UTCTIMESTAMP:
                                case KW_VALIDATE:
                                case KW_VALUES:
                                case KW_VALUE_TYPE:
                                case KW_VIEW:
                                case KW_VIEWS:
                                case KW_WEEK:
                                case KW_WHILE:
                                case KW_WITH:
                                case KW_WORK:
                                case KW_WRITE:
                                case KW_YEAR:
                                case KW_BATCH:
                                case KW_DAYOFWEEK:
                                case KW_HOLD_DDLTIME:
                                case KW_IGNORE:
                                case KW_NO_DROP:
                                case KW_OFFLINE:
                                case KW_PROTECTION:
                                case KW_READONLY:
                                    {
                                    alt300=1;
                                    }
                                    break;
                            }

                            }
                            break;
                    }

                    switch (alt300) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2573:52: LPAREN targetCols= columnNameList RPAREN
                            {
                            LPAREN950=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_insertClause17089); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN950);


                            pushFollow(FOLLOW_columnNameList_in_insertClause17093);
                            targetCols=columnNameList();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_columnNameList.add(targetCols.getTree());

                            RPAREN951=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_insertClause17095); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN951);


                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: tableOrPartition, targetCols
                    // token labels: 
                    // rule labels: targetCols, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_targetCols=new RewriteRuleSubtreeStream(adaptor,"rule targetCols",targetCols!=null?targetCols.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2574:8: -> ^( TOK_INSERT_INTO tableOrPartition ( $targetCols)? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2574:11: ^( TOK_INSERT_INTO tableOrPartition ( $targetCols)? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_INSERT_INTO, "TOK_INSERT_INTO")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableOrPartition.nextTree());

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2574:47: ( $targetCols)?
                        if ( stream_targetCols.hasNext() ) {
                            adaptor.addChild(root_1, stream_targetCols.nextTree());

                        }
                        stream_targetCols.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "insertClause"


    public static class destination_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "destination"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2577:1: destination : ( (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )? -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? ) | KW_TABLE tableOrPartition -> tableOrPartition );
    public final HiveParser.destination_return destination() throws RecognitionException {
        HiveParser.destination_return retval = new HiveParser.destination_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token local=null;
        Token KW_DIRECTORY952=null;
        Token StringLiteral953=null;
        Token KW_TABLE956=null;
        HiveParser.tableRowFormat_return tableRowFormat954 =null;

        HiveParser.tableFileFormat_return tableFileFormat955 =null;

        HiveParser_IdentifiersParser.tableOrPartition_return tableOrPartition957 =null;


        ASTNode local_tree=null;
        ASTNode KW_DIRECTORY952_tree=null;
        ASTNode StringLiteral953_tree=null;
        ASTNode KW_TABLE956_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_DIRECTORY=new RewriteRuleTokenStream(adaptor,"token KW_DIRECTORY");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_KW_LOCAL=new RewriteRuleTokenStream(adaptor,"token KW_LOCAL");
        RewriteRuleSubtreeStream stream_tableRowFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormat");
        RewriteRuleSubtreeStream stream_tableFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableFileFormat");
        RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
         pushMsg("destination specification", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2580:4: ( (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )? -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? ) | KW_TABLE tableOrPartition -> tableOrPartition )
            int alt305=2;
            switch ( input.LA(1) ) {
            case KW_DIRECTORY:
            case KW_LOCAL:
                {
                alt305=1;
                }
                break;
            case KW_TABLE:
                {
                alt305=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 305, 0, input);

                throw nvae;

            }

            switch (alt305) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2581:6: (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )?
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2581:6: (local= KW_LOCAL )?
                    int alt302=2;
                    switch ( input.LA(1) ) {
                        case KW_LOCAL:
                            {
                            alt302=1;
                            }
                            break;
                    }

                    switch (alt302) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2581:7: local= KW_LOCAL
                            {
                            local=(Token)match(input,KW_LOCAL,FOLLOW_KW_LOCAL_in_destination17151); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_LOCAL.add(local);


                            }
                            break;

                    }


                    KW_DIRECTORY952=(Token)match(input,KW_DIRECTORY,FOLLOW_KW_DIRECTORY_in_destination17155); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_DIRECTORY.add(KW_DIRECTORY952);


                    StringLiteral953=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_destination17157); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral953);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2581:53: ( tableRowFormat )?
                    int alt303=2;
                    switch ( input.LA(1) ) {
                        case KW_ROW:
                            {
                            alt303=1;
                            }
                            break;
                    }

                    switch (alt303) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2581:53: tableRowFormat
                            {
                            pushFollow(FOLLOW_tableRowFormat_in_destination17159);
                            tableRowFormat954=tableRowFormat();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tableRowFormat.add(tableRowFormat954.getTree());

                            }
                            break;

                    }


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2581:69: ( tableFileFormat )?
                    int alt304=2;
                    switch ( input.LA(1) ) {
                        case KW_STORED:
                            {
                            alt304=1;
                            }
                            break;
                    }

                    switch (alt304) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2581:69: tableFileFormat
                            {
                            pushFollow(FOLLOW_tableFileFormat_in_destination17162);
                            tableFileFormat955=tableFileFormat();

                            state._fsp--;
                            if (state.failed) return retval;
                            if ( state.backtracking==0 ) stream_tableFileFormat.add(tableFileFormat955.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: local, tableFileFormat, StringLiteral, tableRowFormat
                    // token labels: local
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_local=new RewriteRuleTokenStream(adaptor,"token local",local);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2582:8: -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2582:11: ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_DIR, "TOK_DIR")
                        , root_1);

                        adaptor.addChild(root_1, 
                        stream_StringLiteral.nextNode()
                        );

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2582:36: ( $local)?
                        if ( stream_local.hasNext() ) {
                            adaptor.addChild(root_1, stream_local.nextNode());

                        }
                        stream_local.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2582:43: ( tableRowFormat )?
                        if ( stream_tableRowFormat.hasNext() ) {
                            adaptor.addChild(root_1, stream_tableRowFormat.nextTree());

                        }
                        stream_tableRowFormat.reset();

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2582:59: ( tableFileFormat )?
                        if ( stream_tableFileFormat.hasNext() ) {
                            adaptor.addChild(root_1, stream_tableFileFormat.nextTree());

                        }
                        stream_tableFileFormat.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2583:6: KW_TABLE tableOrPartition
                    {
                    KW_TABLE956=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_destination17195); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE956);


                    pushFollow(FOLLOW_tableOrPartition_in_destination17197);
                    tableOrPartition957=tableOrPartition();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_tableOrPartition.add(tableOrPartition957.getTree());

                    // AST REWRITE
                    // elements: tableOrPartition
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2583:32: -> tableOrPartition
                    {
                        adaptor.addChild(root_0, stream_tableOrPartition.nextTree());

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "destination"


    public static class limitClause_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "limitClause"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2586:1: limitClause : ( KW_LIMIT ( (offset= Number COMMA )? num= Number ) -> ^( TOK_LIMIT ( $offset)? $num) | KW_LIMIT num= Number KW_OFFSET offset= Number -> ^( TOK_LIMIT ( $offset)? $num) );
    public final HiveParser.limitClause_return limitClause() throws RecognitionException {
        HiveParser.limitClause_return retval = new HiveParser.limitClause_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token offset=null;
        Token num=null;
        Token KW_LIMIT958=null;
        Token COMMA959=null;
        Token KW_LIMIT960=null;
        Token KW_OFFSET961=null;

        ASTNode offset_tree=null;
        ASTNode num_tree=null;
        ASTNode KW_LIMIT958_tree=null;
        ASTNode COMMA959_tree=null;
        ASTNode KW_LIMIT960_tree=null;
        ASTNode KW_OFFSET961_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
        RewriteRuleTokenStream stream_KW_LIMIT=new RewriteRuleTokenStream(adaptor,"token KW_LIMIT");
        RewriteRuleTokenStream stream_KW_OFFSET=new RewriteRuleTokenStream(adaptor,"token KW_OFFSET");

         pushMsg("limit clause", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2589:4: ( KW_LIMIT ( (offset= Number COMMA )? num= Number ) -> ^( TOK_LIMIT ( $offset)? $num) | KW_LIMIT num= Number KW_OFFSET offset= Number -> ^( TOK_LIMIT ( $offset)? $num) )
            int alt307=2;
            switch ( input.LA(1) ) {
            case KW_LIMIT:
                {
                switch ( input.LA(2) ) {
                case Number:
                    {
                    switch ( input.LA(3) ) {
                    case KW_OFFSET:
                        {
                        alt307=2;
                        }
                        break;
                    case EOF:
                    case COMMA:
                    case KW_EXCEPT:
                    case KW_INSERT:
                    case KW_INTERSECT:
                    case KW_MAP:
                    case KW_MINUS:
                    case KW_REDUCE:
                    case KW_SELECT:
                    case KW_UNION:
                    case RPAREN:
                        {
                        alt307=1;
                        }
                        break;
                    default:
                        if (state.backtracking>0) {state.failed=true; return retval;}
                        NoViableAltException nvae =
                            new NoViableAltException("", 307, 2, input);

                        throw nvae;

                    }

                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 307, 1, input);

                    throw nvae;

                }

                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 307, 0, input);

                throw nvae;

            }

            switch (alt307) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2590:4: KW_LIMIT ( (offset= Number COMMA )? num= Number )
                    {
                    KW_LIMIT958=(Token)match(input,KW_LIMIT,FOLLOW_KW_LIMIT_in_limitClause17229); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_LIMIT.add(KW_LIMIT958);


                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2590:13: ( (offset= Number COMMA )? num= Number )
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2590:14: (offset= Number COMMA )? num= Number
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2590:14: (offset= Number COMMA )?
                    int alt306=2;
                    switch ( input.LA(1) ) {
                        case Number:
                            {
                            switch ( input.LA(2) ) {
                                case COMMA:
                                    {
                                    alt306=1;
                                    }
                                    break;
                            }

                            }
                            break;
                    }

                    switch (alt306) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2590:15: offset= Number COMMA
                            {
                            offset=(Token)match(input,Number,FOLLOW_Number_in_limitClause17235); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_Number.add(offset);


                            COMMA959=(Token)match(input,COMMA,FOLLOW_COMMA_in_limitClause17237); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_COMMA.add(COMMA959);


                            }
                            break;

                    }


                    num=(Token)match(input,Number,FOLLOW_Number_in_limitClause17243); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_Number.add(num);


                    }


                    // AST REWRITE
                    // elements: num, offset
                    // token labels: offset, num
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_offset=new RewriteRuleTokenStream(adaptor,"token offset",offset);
                    RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2590:49: -> ^( TOK_LIMIT ( $offset)? $num)
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2590:52: ^( TOK_LIMIT ( $offset)? $num)
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_LIMIT, "TOK_LIMIT")
                        , root_1);

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2590:64: ( $offset)?
                        if ( stream_offset.hasNext() ) {
                            adaptor.addChild(root_1, stream_offset.nextNode());

                        }
                        stream_offset.reset();

                        adaptor.addChild(root_1, stream_num.nextNode());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2591:6: KW_LIMIT num= Number KW_OFFSET offset= Number
                    {
                    KW_LIMIT960=(Token)match(input,KW_LIMIT,FOLLOW_KW_LIMIT_in_limitClause17266); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_LIMIT.add(KW_LIMIT960);


                    num=(Token)match(input,Number,FOLLOW_Number_in_limitClause17270); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_Number.add(num);


                    KW_OFFSET961=(Token)match(input,KW_OFFSET,FOLLOW_KW_OFFSET_in_limitClause17272); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_OFFSET.add(KW_OFFSET961);


                    offset=(Token)match(input,Number,FOLLOW_Number_in_limitClause17276); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_Number.add(offset);


                    // AST REWRITE
                    // elements: offset, num
                    // token labels: offset, num
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_offset=new RewriteRuleTokenStream(adaptor,"token offset",offset);
                    RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2591:50: -> ^( TOK_LIMIT ( $offset)? $num)
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2591:53: ^( TOK_LIMIT ( $offset)? $num)
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_LIMIT, "TOK_LIMIT")
                        , root_1);

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2591:65: ( $offset)?
                        if ( stream_offset.hasNext() ) {
                            adaptor.addChild(root_1, stream_offset.nextNode());

                        }
                        stream_offset.reset();

                        adaptor.addChild(root_1, stream_num.nextNode());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "limitClause"


    public static class deleteStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "deleteStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2595:1: deleteStatement : KW_DELETE KW_FROM tableName ( whereClause )? -> ^( TOK_DELETE_FROM tableName ( whereClause )? ) ;
    public final HiveParser.deleteStatement_return deleteStatement() throws RecognitionException {
        HiveParser.deleteStatement_return retval = new HiveParser.deleteStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_DELETE962=null;
        Token KW_FROM963=null;
        HiveParser_FromClauseParser.tableName_return tableName964 =null;

        HiveParser_FromClauseParser.whereClause_return whereClause965 =null;


        ASTNode KW_DELETE962_tree=null;
        ASTNode KW_FROM963_tree=null;
        RewriteRuleTokenStream stream_KW_DELETE=new RewriteRuleTokenStream(adaptor,"token KW_DELETE");
        RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
        RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("delete statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2598:4: ( KW_DELETE KW_FROM tableName ( whereClause )? -> ^( TOK_DELETE_FROM tableName ( whereClause )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2599:4: KW_DELETE KW_FROM tableName ( whereClause )?
            {
            KW_DELETE962=(Token)match(input,KW_DELETE,FOLLOW_KW_DELETE_in_deleteStatement17320); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_DELETE.add(KW_DELETE962);


            KW_FROM963=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_deleteStatement17322); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM963);


            pushFollow(FOLLOW_tableName_in_deleteStatement17324);
            tableName964=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(tableName964.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2599:32: ( whereClause )?
            int alt308=2;
            switch ( input.LA(1) ) {
                case KW_WHERE:
                    {
                    alt308=1;
                    }
                    break;
            }

            switch (alt308) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2599:33: whereClause
                    {
                    pushFollow(FOLLOW_whereClause_in_deleteStatement17327);
                    whereClause965=whereClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_whereClause.add(whereClause965.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: whereClause, tableName
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2599:47: -> ^( TOK_DELETE_FROM tableName ( whereClause )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2599:50: ^( TOK_DELETE_FROM tableName ( whereClause )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_DELETE_FROM, "TOK_DELETE_FROM")
                , root_1);

                adaptor.addChild(root_1, stream_tableName.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2599:78: ( whereClause )?
                if ( stream_whereClause.hasNext() ) {
                    adaptor.addChild(root_1, stream_whereClause.nextTree());

                }
                stream_whereClause.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "deleteStatement"


    public static class columnAssignmentClause_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnAssignmentClause"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2603:1: columnAssignmentClause : tableOrColumn EQUAL ^ precedencePlusExpression ;
    public final HiveParser.columnAssignmentClause_return columnAssignmentClause() throws RecognitionException {
        HiveParser.columnAssignmentClause_return retval = new HiveParser.columnAssignmentClause_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token EQUAL967=null;
        HiveParser_FromClauseParser.tableOrColumn_return tableOrColumn966 =null;

        HiveParser_IdentifiersParser.precedencePlusExpression_return precedencePlusExpression968 =null;


        ASTNode EQUAL967_tree=null;

        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2604:4: ( tableOrColumn EQUAL ^ precedencePlusExpression )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2605:4: tableOrColumn EQUAL ^ precedencePlusExpression
            {
            root_0 = (ASTNode)adaptor.nil();


            pushFollow(FOLLOW_tableOrColumn_in_columnAssignmentClause17360);
            tableOrColumn966=tableOrColumn();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) adaptor.addChild(root_0, tableOrColumn966.getTree());

            EQUAL967=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_columnAssignmentClause17362); if (state.failed) return retval;
            if ( state.backtracking==0 ) {
            EQUAL967_tree = 
            (ASTNode)adaptor.create(EQUAL967)
            ;
            root_0 = (ASTNode)adaptor.becomeRoot(EQUAL967_tree, root_0);
            }

            pushFollow(FOLLOW_precedencePlusExpression_in_columnAssignmentClause17365);
            precedencePlusExpression968=precedencePlusExpression();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) adaptor.addChild(root_0, precedencePlusExpression968.getTree());

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnAssignmentClause"


    public static class setColumnsClause_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "setColumnsClause"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2609:1: setColumnsClause : KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )* -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* ) ;
    public final HiveParser.setColumnsClause_return setColumnsClause() throws RecognitionException {
        HiveParser.setColumnsClause_return retval = new HiveParser.setColumnsClause_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_SET969=null;
        Token COMMA971=null;
        HiveParser.columnAssignmentClause_return columnAssignmentClause970 =null;

        HiveParser.columnAssignmentClause_return columnAssignmentClause972 =null;


        ASTNode KW_SET969_tree=null;
        ASTNode COMMA971_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleSubtreeStream stream_columnAssignmentClause=new RewriteRuleSubtreeStream(adaptor,"rule columnAssignmentClause");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2610:4: ( KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )* -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2611:4: KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )*
            {
            KW_SET969=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_setColumnsClause17385); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET969);


            pushFollow(FOLLOW_columnAssignmentClause_in_setColumnsClause17387);
            columnAssignmentClause970=columnAssignmentClause();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_columnAssignmentClause.add(columnAssignmentClause970.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2611:34: ( COMMA columnAssignmentClause )*
            loop309:
            do {
                int alt309=2;
                switch ( input.LA(1) ) {
                case COMMA:
                    {
                    alt309=1;
                    }
                    break;

                }

                switch (alt309) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2611:35: COMMA columnAssignmentClause
            	    {
            	    COMMA971=(Token)match(input,COMMA,FOLLOW_COMMA_in_setColumnsClause17390); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA971);


            	    pushFollow(FOLLOW_columnAssignmentClause_in_setColumnsClause17392);
            	    columnAssignmentClause972=columnAssignmentClause();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) stream_columnAssignmentClause.add(columnAssignmentClause972.getTree());

            	    }
            	    break;

            	default :
            	    break loop309;
                }
            } while (true);


            // AST REWRITE
            // elements: columnAssignmentClause
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2611:66: -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2611:69: ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SET_COLUMNS_CLAUSE, "TOK_SET_COLUMNS_CLAUSE")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2611:94: ( columnAssignmentClause )*
                while ( stream_columnAssignmentClause.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnAssignmentClause.nextTree());

                }
                stream_columnAssignmentClause.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "setColumnsClause"


    public static class updateStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "updateStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2618:1: updateStatement : KW_UPDATE tableName setColumnsClause ( whereClause )? -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? ) ;
    public final HiveParser.updateStatement_return updateStatement() throws RecognitionException {
        HiveParser.updateStatement_return retval = new HiveParser.updateStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_UPDATE973=null;
        HiveParser_FromClauseParser.tableName_return tableName974 =null;

        HiveParser.setColumnsClause_return setColumnsClause975 =null;

        HiveParser_FromClauseParser.whereClause_return whereClause976 =null;


        ASTNode KW_UPDATE973_tree=null;
        RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
        RewriteRuleSubtreeStream stream_setColumnsClause=new RewriteRuleSubtreeStream(adaptor,"rule setColumnsClause");
        RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         pushMsg("update statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2621:4: ( KW_UPDATE tableName setColumnsClause ( whereClause )? -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2622:4: KW_UPDATE tableName setColumnsClause ( whereClause )?
            {
            KW_UPDATE973=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_updateStatement17434); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE973);


            pushFollow(FOLLOW_tableName_in_updateStatement17436);
            tableName974=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(tableName974.getTree());

            pushFollow(FOLLOW_setColumnsClause_in_updateStatement17438);
            setColumnsClause975=setColumnsClause();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_setColumnsClause.add(setColumnsClause975.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2622:41: ( whereClause )?
            int alt310=2;
            switch ( input.LA(1) ) {
                case KW_WHERE:
                    {
                    alt310=1;
                    }
                    break;
            }

            switch (alt310) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2622:41: whereClause
                    {
                    pushFollow(FOLLOW_whereClause_in_updateStatement17440);
                    whereClause976=whereClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_whereClause.add(whereClause976.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: tableName, setColumnsClause, whereClause
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2622:54: -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2622:57: ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_UPDATE_TABLE, "TOK_UPDATE_TABLE")
                , root_1);

                adaptor.addChild(root_1, stream_tableName.nextTree());

                adaptor.addChild(root_1, stream_setColumnsClause.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2622:103: ( whereClause )?
                if ( stream_whereClause.hasNext() ) {
                    adaptor.addChild(root_1, stream_whereClause.nextTree());

                }
                stream_whereClause.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "updateStatement"


    public static class sqlTransactionStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "sqlTransactionStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2629:1: sqlTransactionStatement : ( startTransactionStatement | commitStatement | rollbackStatement | setAutoCommitStatement );
    public final HiveParser.sqlTransactionStatement_return sqlTransactionStatement() throws RecognitionException {
        HiveParser.sqlTransactionStatement_return retval = new HiveParser.sqlTransactionStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.startTransactionStatement_return startTransactionStatement977 =null;

        HiveParser.commitStatement_return commitStatement978 =null;

        HiveParser.rollbackStatement_return rollbackStatement979 =null;

        HiveParser.setAutoCommitStatement_return setAutoCommitStatement980 =null;



         pushMsg("transaction statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2632:3: ( startTransactionStatement | commitStatement | rollbackStatement | setAutoCommitStatement )
            int alt311=4;
            switch ( input.LA(1) ) {
            case KW_START:
                {
                alt311=1;
                }
                break;
            case KW_COMMIT:
                {
                alt311=2;
                }
                break;
            case KW_ROLLBACK:
                {
                alt311=3;
                }
                break;
            case KW_SET:
                {
                alt311=4;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 311, 0, input);

                throw nvae;

            }

            switch (alt311) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2633:3: startTransactionStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_startTransactionStatement_in_sqlTransactionStatement17482);
                    startTransactionStatement977=startTransactionStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, startTransactionStatement977.getTree());

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2634:4: commitStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_commitStatement_in_sqlTransactionStatement17487);
                    commitStatement978=commitStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, commitStatement978.getTree());

                    }
                    break;
                case 3 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2635:4: rollbackStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_rollbackStatement_in_sqlTransactionStatement17492);
                    rollbackStatement979=rollbackStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, rollbackStatement979.getTree());

                    }
                    break;
                case 4 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2636:4: setAutoCommitStatement
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_setAutoCommitStatement_in_sqlTransactionStatement17497);
                    setAutoCommitStatement980=setAutoCommitStatement();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, setAutoCommitStatement980.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "sqlTransactionStatement"


    public static class startTransactionStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "startTransactionStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2639:1: startTransactionStatement : KW_START KW_TRANSACTION ( transactionMode ( COMMA transactionMode )* )? -> ^( TOK_START_TRANSACTION ( transactionMode )* ) ;
    public final HiveParser.startTransactionStatement_return startTransactionStatement() throws RecognitionException {
        HiveParser.startTransactionStatement_return retval = new HiveParser.startTransactionStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_START981=null;
        Token KW_TRANSACTION982=null;
        Token COMMA984=null;
        HiveParser.transactionMode_return transactionMode983 =null;

        HiveParser.transactionMode_return transactionMode985 =null;


        ASTNode KW_START981_tree=null;
        ASTNode KW_TRANSACTION982_tree=null;
        ASTNode COMMA984_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleTokenStream stream_KW_START=new RewriteRuleTokenStream(adaptor,"token KW_START");
        RewriteRuleTokenStream stream_KW_TRANSACTION=new RewriteRuleTokenStream(adaptor,"token KW_TRANSACTION");
        RewriteRuleSubtreeStream stream_transactionMode=new RewriteRuleSubtreeStream(adaptor,"rule transactionMode");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2640:3: ( KW_START KW_TRANSACTION ( transactionMode ( COMMA transactionMode )* )? -> ^( TOK_START_TRANSACTION ( transactionMode )* ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2641:3: KW_START KW_TRANSACTION ( transactionMode ( COMMA transactionMode )* )?
            {
            KW_START981=(Token)match(input,KW_START,FOLLOW_KW_START_in_startTransactionStatement17511); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_START.add(KW_START981);


            KW_TRANSACTION982=(Token)match(input,KW_TRANSACTION,FOLLOW_KW_TRANSACTION_in_startTransactionStatement17513); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TRANSACTION.add(KW_TRANSACTION982);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2641:27: ( transactionMode ( COMMA transactionMode )* )?
            int alt313=2;
            switch ( input.LA(1) ) {
                case KW_ISOLATION:
                case KW_READ:
                    {
                    alt313=1;
                    }
                    break;
            }

            switch (alt313) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2641:29: transactionMode ( COMMA transactionMode )*
                    {
                    pushFollow(FOLLOW_transactionMode_in_startTransactionStatement17517);
                    transactionMode983=transactionMode();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_transactionMode.add(transactionMode983.getTree());

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2641:46: ( COMMA transactionMode )*
                    loop312:
                    do {
                        int alt312=2;
                        switch ( input.LA(1) ) {
                        case COMMA:
                            {
                            alt312=1;
                            }
                            break;

                        }

                        switch (alt312) {
                    	case 1 :
                    	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2641:48: COMMA transactionMode
                    	    {
                    	    COMMA984=(Token)match(input,COMMA,FOLLOW_COMMA_in_startTransactionStatement17522); if (state.failed) return retval; 
                    	    if ( state.backtracking==0 ) stream_COMMA.add(COMMA984);


                    	    pushFollow(FOLLOW_transactionMode_in_startTransactionStatement17524);
                    	    transactionMode985=transactionMode();

                    	    state._fsp--;
                    	    if (state.failed) return retval;
                    	    if ( state.backtracking==0 ) stream_transactionMode.add(transactionMode985.getTree());

                    	    }
                    	    break;

                    	default :
                    	    break loop312;
                        }
                    } while (true);


                    }
                    break;

            }


            // AST REWRITE
            // elements: transactionMode
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2641:77: -> ^( TOK_START_TRANSACTION ( transactionMode )* )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2641:80: ^( TOK_START_TRANSACTION ( transactionMode )* )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_START_TRANSACTION, "TOK_START_TRANSACTION")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2641:104: ( transactionMode )*
                while ( stream_transactionMode.hasNext() ) {
                    adaptor.addChild(root_1, stream_transactionMode.nextTree());

                }
                stream_transactionMode.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "startTransactionStatement"


    public static class transactionMode_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "transactionMode"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2644:1: transactionMode : ( isolationLevel | transactionAccessMode -> ^( TOK_TXN_ACCESS_MODE transactionAccessMode ) );
    public final HiveParser.transactionMode_return transactionMode() throws RecognitionException {
        HiveParser.transactionMode_return retval = new HiveParser.transactionMode_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.isolationLevel_return isolationLevel986 =null;

        HiveParser.transactionAccessMode_return transactionAccessMode987 =null;


        RewriteRuleSubtreeStream stream_transactionAccessMode=new RewriteRuleSubtreeStream(adaptor,"rule transactionAccessMode");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2645:3: ( isolationLevel | transactionAccessMode -> ^( TOK_TXN_ACCESS_MODE transactionAccessMode ) )
            int alt314=2;
            switch ( input.LA(1) ) {
            case KW_ISOLATION:
                {
                alt314=1;
                }
                break;
            case KW_READ:
                {
                alt314=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 314, 0, input);

                throw nvae;

            }

            switch (alt314) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2646:3: isolationLevel
                    {
                    root_0 = (ASTNode)adaptor.nil();


                    pushFollow(FOLLOW_isolationLevel_in_transactionMode17555);
                    isolationLevel986=isolationLevel();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, isolationLevel986.getTree());

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2647:5: transactionAccessMode
                    {
                    pushFollow(FOLLOW_transactionAccessMode_in_transactionMode17561);
                    transactionAccessMode987=transactionAccessMode();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_transactionAccessMode.add(transactionAccessMode987.getTree());

                    // AST REWRITE
                    // elements: transactionAccessMode
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2647:27: -> ^( TOK_TXN_ACCESS_MODE transactionAccessMode )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2647:30: ^( TOK_TXN_ACCESS_MODE transactionAccessMode )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_TXN_ACCESS_MODE, "TOK_TXN_ACCESS_MODE")
                        , root_1);

                        adaptor.addChild(root_1, stream_transactionAccessMode.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "transactionMode"


    public static class transactionAccessMode_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "transactionAccessMode"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2650:1: transactionAccessMode : ( KW_READ KW_ONLY -> TOK_TXN_READ_ONLY | KW_READ KW_WRITE -> TOK_TXN_READ_WRITE );
    public final HiveParser.transactionAccessMode_return transactionAccessMode() throws RecognitionException {
        HiveParser.transactionAccessMode_return retval = new HiveParser.transactionAccessMode_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_READ988=null;
        Token KW_ONLY989=null;
        Token KW_READ990=null;
        Token KW_WRITE991=null;

        ASTNode KW_READ988_tree=null;
        ASTNode KW_ONLY989_tree=null;
        ASTNode KW_READ990_tree=null;
        ASTNode KW_WRITE991_tree=null;
        RewriteRuleTokenStream stream_KW_READ=new RewriteRuleTokenStream(adaptor,"token KW_READ");
        RewriteRuleTokenStream stream_KW_ONLY=new RewriteRuleTokenStream(adaptor,"token KW_ONLY");
        RewriteRuleTokenStream stream_KW_WRITE=new RewriteRuleTokenStream(adaptor,"token KW_WRITE");

        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2651:3: ( KW_READ KW_ONLY -> TOK_TXN_READ_ONLY | KW_READ KW_WRITE -> TOK_TXN_READ_WRITE )
            int alt315=2;
            switch ( input.LA(1) ) {
            case KW_READ:
                {
                switch ( input.LA(2) ) {
                case KW_ONLY:
                    {
                    alt315=1;
                    }
                    break;
                case KW_WRITE:
                    {
                    alt315=2;
                    }
                    break;
                default:
                    if (state.backtracking>0) {state.failed=true; return retval;}
                    NoViableAltException nvae =
                        new NoViableAltException("", 315, 1, input);

                    throw nvae;

                }

                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 315, 0, input);

                throw nvae;

            }

            switch (alt315) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2652:3: KW_READ KW_ONLY
                    {
                    KW_READ988=(Token)match(input,KW_READ,FOLLOW_KW_READ_in_transactionAccessMode17584); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_READ.add(KW_READ988);


                    KW_ONLY989=(Token)match(input,KW_ONLY,FOLLOW_KW_ONLY_in_transactionAccessMode17586); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_ONLY.add(KW_ONLY989);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2652:19: -> TOK_TXN_READ_ONLY
                    {
                        adaptor.addChild(root_0, 
                        (ASTNode)adaptor.create(TOK_TXN_READ_ONLY, "TOK_TXN_READ_ONLY")
                        );

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2653:5: KW_READ KW_WRITE
                    {
                    KW_READ990=(Token)match(input,KW_READ,FOLLOW_KW_READ_in_transactionAccessMode17596); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_READ.add(KW_READ990);


                    KW_WRITE991=(Token)match(input,KW_WRITE,FOLLOW_KW_WRITE_in_transactionAccessMode17598); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_WRITE.add(KW_WRITE991);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2653:22: -> TOK_TXN_READ_WRITE
                    {
                        adaptor.addChild(root_0, 
                        (ASTNode)adaptor.create(TOK_TXN_READ_WRITE, "TOK_TXN_READ_WRITE")
                        );

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "transactionAccessMode"


    public static class isolationLevel_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "isolationLevel"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2656:1: isolationLevel : KW_ISOLATION KW_LEVEL levelOfIsolation -> ^( TOK_ISOLATION_LEVEL levelOfIsolation ) ;
    public final HiveParser.isolationLevel_return isolationLevel() throws RecognitionException {
        HiveParser.isolationLevel_return retval = new HiveParser.isolationLevel_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_ISOLATION992=null;
        Token KW_LEVEL993=null;
        HiveParser.levelOfIsolation_return levelOfIsolation994 =null;


        ASTNode KW_ISOLATION992_tree=null;
        ASTNode KW_LEVEL993_tree=null;
        RewriteRuleTokenStream stream_KW_LEVEL=new RewriteRuleTokenStream(adaptor,"token KW_LEVEL");
        RewriteRuleTokenStream stream_KW_ISOLATION=new RewriteRuleTokenStream(adaptor,"token KW_ISOLATION");
        RewriteRuleSubtreeStream stream_levelOfIsolation=new RewriteRuleSubtreeStream(adaptor,"rule levelOfIsolation");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2657:3: ( KW_ISOLATION KW_LEVEL levelOfIsolation -> ^( TOK_ISOLATION_LEVEL levelOfIsolation ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2658:3: KW_ISOLATION KW_LEVEL levelOfIsolation
            {
            KW_ISOLATION992=(Token)match(input,KW_ISOLATION,FOLLOW_KW_ISOLATION_in_isolationLevel17617); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ISOLATION.add(KW_ISOLATION992);


            KW_LEVEL993=(Token)match(input,KW_LEVEL,FOLLOW_KW_LEVEL_in_isolationLevel17619); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_LEVEL.add(KW_LEVEL993);


            pushFollow(FOLLOW_levelOfIsolation_in_isolationLevel17621);
            levelOfIsolation994=levelOfIsolation();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_levelOfIsolation.add(levelOfIsolation994.getTree());

            // AST REWRITE
            // elements: levelOfIsolation
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2658:42: -> ^( TOK_ISOLATION_LEVEL levelOfIsolation )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2658:45: ^( TOK_ISOLATION_LEVEL levelOfIsolation )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ISOLATION_LEVEL, "TOK_ISOLATION_LEVEL")
                , root_1);

                adaptor.addChild(root_1, stream_levelOfIsolation.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "isolationLevel"


    public static class levelOfIsolation_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "levelOfIsolation"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2662:1: levelOfIsolation : KW_SNAPSHOT -> TOK_ISOLATION_SNAPSHOT ;
    public final HiveParser.levelOfIsolation_return levelOfIsolation() throws RecognitionException {
        HiveParser.levelOfIsolation_return retval = new HiveParser.levelOfIsolation_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_SNAPSHOT995=null;

        ASTNode KW_SNAPSHOT995_tree=null;
        RewriteRuleTokenStream stream_KW_SNAPSHOT=new RewriteRuleTokenStream(adaptor,"token KW_SNAPSHOT");

        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2663:3: ( KW_SNAPSHOT -> TOK_ISOLATION_SNAPSHOT )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2664:3: KW_SNAPSHOT
            {
            KW_SNAPSHOT995=(Token)match(input,KW_SNAPSHOT,FOLLOW_KW_SNAPSHOT_in_levelOfIsolation17646); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SNAPSHOT.add(KW_SNAPSHOT995);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2664:15: -> TOK_ISOLATION_SNAPSHOT
            {
                adaptor.addChild(root_0, 
                (ASTNode)adaptor.create(TOK_ISOLATION_SNAPSHOT, "TOK_ISOLATION_SNAPSHOT")
                );

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "levelOfIsolation"


    public static class commitStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "commitStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2667:1: commitStatement : KW_COMMIT ( KW_WORK )? -> TOK_COMMIT ;
    public final HiveParser.commitStatement_return commitStatement() throws RecognitionException {
        HiveParser.commitStatement_return retval = new HiveParser.commitStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_COMMIT996=null;
        Token KW_WORK997=null;

        ASTNode KW_COMMIT996_tree=null;
        ASTNode KW_WORK997_tree=null;
        RewriteRuleTokenStream stream_KW_WORK=new RewriteRuleTokenStream(adaptor,"token KW_WORK");
        RewriteRuleTokenStream stream_KW_COMMIT=new RewriteRuleTokenStream(adaptor,"token KW_COMMIT");

        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2668:3: ( KW_COMMIT ( KW_WORK )? -> TOK_COMMIT )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2669:3: KW_COMMIT ( KW_WORK )?
            {
            KW_COMMIT996=(Token)match(input,KW_COMMIT,FOLLOW_KW_COMMIT_in_commitStatement17665); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_COMMIT.add(KW_COMMIT996);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2669:13: ( KW_WORK )?
            int alt316=2;
            switch ( input.LA(1) ) {
                case KW_WORK:
                    {
                    alt316=1;
                    }
                    break;
            }

            switch (alt316) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2669:15: KW_WORK
                    {
                    KW_WORK997=(Token)match(input,KW_WORK,FOLLOW_KW_WORK_in_commitStatement17669); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_WORK.add(KW_WORK997);


                    }
                    break;

            }


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2669:26: -> TOK_COMMIT
            {
                adaptor.addChild(root_0, 
                (ASTNode)adaptor.create(TOK_COMMIT, "TOK_COMMIT")
                );

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "commitStatement"


    public static class rollbackStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "rollbackStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2672:1: rollbackStatement : KW_ROLLBACK ( KW_WORK )? -> TOK_ROLLBACK ;
    public final HiveParser.rollbackStatement_return rollbackStatement() throws RecognitionException {
        HiveParser.rollbackStatement_return retval = new HiveParser.rollbackStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_ROLLBACK998=null;
        Token KW_WORK999=null;

        ASTNode KW_ROLLBACK998_tree=null;
        ASTNode KW_WORK999_tree=null;
        RewriteRuleTokenStream stream_KW_ROLLBACK=new RewriteRuleTokenStream(adaptor,"token KW_ROLLBACK");
        RewriteRuleTokenStream stream_KW_WORK=new RewriteRuleTokenStream(adaptor,"token KW_WORK");

        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2673:3: ( KW_ROLLBACK ( KW_WORK )? -> TOK_ROLLBACK )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2674:3: KW_ROLLBACK ( KW_WORK )?
            {
            KW_ROLLBACK998=(Token)match(input,KW_ROLLBACK,FOLLOW_KW_ROLLBACK_in_rollbackStatement17691); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ROLLBACK.add(KW_ROLLBACK998);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2674:15: ( KW_WORK )?
            int alt317=2;
            switch ( input.LA(1) ) {
                case KW_WORK:
                    {
                    alt317=1;
                    }
                    break;
            }

            switch (alt317) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2674:17: KW_WORK
                    {
                    KW_WORK999=(Token)match(input,KW_WORK,FOLLOW_KW_WORK_in_rollbackStatement17695); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_WORK.add(KW_WORK999);


                    }
                    break;

            }


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2674:28: -> TOK_ROLLBACK
            {
                adaptor.addChild(root_0, 
                (ASTNode)adaptor.create(TOK_ROLLBACK, "TOK_ROLLBACK")
                );

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "rollbackStatement"


    public static class setAutoCommitStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "setAutoCommitStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2676:1: setAutoCommitStatement : KW_SET KW_AUTOCOMMIT booleanValueTok -> ^( TOK_SET_AUTOCOMMIT booleanValueTok ) ;
    public final HiveParser.setAutoCommitStatement_return setAutoCommitStatement() throws RecognitionException {
        HiveParser.setAutoCommitStatement_return retval = new HiveParser.setAutoCommitStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_SET1000=null;
        Token KW_AUTOCOMMIT1001=null;
        HiveParser_IdentifiersParser.booleanValueTok_return booleanValueTok1002 =null;


        ASTNode KW_SET1000_tree=null;
        ASTNode KW_AUTOCOMMIT1001_tree=null;
        RewriteRuleTokenStream stream_KW_AUTOCOMMIT=new RewriteRuleTokenStream(adaptor,"token KW_AUTOCOMMIT");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleSubtreeStream stream_booleanValueTok=new RewriteRuleSubtreeStream(adaptor,"rule booleanValueTok");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2677:3: ( KW_SET KW_AUTOCOMMIT booleanValueTok -> ^( TOK_SET_AUTOCOMMIT booleanValueTok ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2678:3: KW_SET KW_AUTOCOMMIT booleanValueTok
            {
            KW_SET1000=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_setAutoCommitStatement17716); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET1000);


            KW_AUTOCOMMIT1001=(Token)match(input,KW_AUTOCOMMIT,FOLLOW_KW_AUTOCOMMIT_in_setAutoCommitStatement17718); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_AUTOCOMMIT.add(KW_AUTOCOMMIT1001);


            pushFollow(FOLLOW_booleanValueTok_in_setAutoCommitStatement17720);
            booleanValueTok1002=booleanValueTok();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_booleanValueTok.add(booleanValueTok1002.getTree());

            // AST REWRITE
            // elements: booleanValueTok
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2678:40: -> ^( TOK_SET_AUTOCOMMIT booleanValueTok )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2678:43: ^( TOK_SET_AUTOCOMMIT booleanValueTok )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_SET_AUTOCOMMIT, "TOK_SET_AUTOCOMMIT")
                , root_1);

                adaptor.addChild(root_1, stream_booleanValueTok.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "setAutoCommitStatement"


    public static class abortTransactionStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "abortTransactionStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2684:1: abortTransactionStatement : KW_ABORT KW_TRANSACTIONS ( Number )+ -> ^( TOK_ABORT_TRANSACTIONS ( Number )+ ) ;
    public final HiveParser.abortTransactionStatement_return abortTransactionStatement() throws RecognitionException {
        HiveParser.abortTransactionStatement_return retval = new HiveParser.abortTransactionStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_ABORT1003=null;
        Token KW_TRANSACTIONS1004=null;
        Token Number1005=null;

        ASTNode KW_ABORT1003_tree=null;
        ASTNode KW_TRANSACTIONS1004_tree=null;
        ASTNode Number1005_tree=null;
        RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
        RewriteRuleTokenStream stream_KW_TRANSACTIONS=new RewriteRuleTokenStream(adaptor,"token KW_TRANSACTIONS");
        RewriteRuleTokenStream stream_KW_ABORT=new RewriteRuleTokenStream(adaptor,"token KW_ABORT");

         pushMsg("abort transactions statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2687:3: ( KW_ABORT KW_TRANSACTIONS ( Number )+ -> ^( TOK_ABORT_TRANSACTIONS ( Number )+ ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2688:3: KW_ABORT KW_TRANSACTIONS ( Number )+
            {
            KW_ABORT1003=(Token)match(input,KW_ABORT,FOLLOW_KW_ABORT_in_abortTransactionStatement17755); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ABORT.add(KW_ABORT1003);


            KW_TRANSACTIONS1004=(Token)match(input,KW_TRANSACTIONS,FOLLOW_KW_TRANSACTIONS_in_abortTransactionStatement17757); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_TRANSACTIONS.add(KW_TRANSACTIONS1004);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2688:28: ( Number )+
            int cnt318=0;
            loop318:
            do {
                int alt318=2;
                switch ( input.LA(1) ) {
                case Number:
                    {
                    alt318=1;
                    }
                    break;

                }

                switch (alt318) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2688:30: Number
            	    {
            	    Number1005=(Token)match(input,Number,FOLLOW_Number_in_abortTransactionStatement17761); if (state.failed) return retval; 
            	    if ( state.backtracking==0 ) stream_Number.add(Number1005);


            	    }
            	    break;

            	default :
            	    if ( cnt318 >= 1 ) break loop318;
            	    if (state.backtracking>0) {state.failed=true; return retval;}
                        EarlyExitException eee =
                            new EarlyExitException(318, input);
                        throw eee;
                }
                cnt318++;
            } while (true);


            // AST REWRITE
            // elements: Number
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2688:40: -> ^( TOK_ABORT_TRANSACTIONS ( Number )+ )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2688:43: ^( TOK_ABORT_TRANSACTIONS ( Number )+ )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_ABORT_TRANSACTIONS, "TOK_ABORT_TRANSACTIONS")
                , root_1);

                if ( !(stream_Number.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_Number.hasNext() ) {
                    adaptor.addChild(root_1, 
                    stream_Number.nextNode()
                    );

                }
                stream_Number.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "abortTransactionStatement"


    public static class mergeStatement_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "mergeStatement"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2695:1: mergeStatement : KW_MERGE KW_INTO tableName ( ( KW_AS )? identifier )? KW_USING joinSourcePart KW_ON expression whenClauses -> ^( TOK_MERGE ^( TOK_TABREF tableName ( identifier )? ) joinSourcePart expression whenClauses ) ;
    public final HiveParser.mergeStatement_return mergeStatement() throws RecognitionException {
        HiveParser.mergeStatement_return retval = new HiveParser.mergeStatement_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_MERGE1006=null;
        Token KW_INTO1007=null;
        Token KW_AS1009=null;
        Token KW_USING1011=null;
        Token KW_ON1013=null;
        HiveParser_FromClauseParser.tableName_return tableName1008 =null;

        HiveParser_IdentifiersParser.identifier_return identifier1010 =null;

        HiveParser_FromClauseParser.joinSourcePart_return joinSourcePart1012 =null;

        HiveParser_IdentifiersParser.expression_return expression1014 =null;

        HiveParser.whenClauses_return whenClauses1015 =null;


        ASTNode KW_MERGE1006_tree=null;
        ASTNode KW_INTO1007_tree=null;
        ASTNode KW_AS1009_tree=null;
        ASTNode KW_USING1011_tree=null;
        ASTNode KW_ON1013_tree=null;
        RewriteRuleTokenStream stream_KW_MERGE=new RewriteRuleTokenStream(adaptor,"token KW_MERGE");
        RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
        RewriteRuleTokenStream stream_KW_USING=new RewriteRuleTokenStream(adaptor,"token KW_USING");
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
        RewriteRuleSubtreeStream stream_whenClauses=new RewriteRuleSubtreeStream(adaptor,"rule whenClauses");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
        RewriteRuleSubtreeStream stream_joinSourcePart=new RewriteRuleSubtreeStream(adaptor,"rule joinSourcePart");
         pushMsg("MERGE statement", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2698:4: ( KW_MERGE KW_INTO tableName ( ( KW_AS )? identifier )? KW_USING joinSourcePart KW_ON expression whenClauses -> ^( TOK_MERGE ^( TOK_TABREF tableName ( identifier )? ) joinSourcePart expression whenClauses ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2699:4: KW_MERGE KW_INTO tableName ( ( KW_AS )? identifier )? KW_USING joinSourcePart KW_ON expression whenClauses
            {
            KW_MERGE1006=(Token)match(input,KW_MERGE,FOLLOW_KW_MERGE_in_mergeStatement17807); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_MERGE.add(KW_MERGE1006);


            KW_INTO1007=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_mergeStatement17809); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO1007);


            pushFollow(FOLLOW_tableName_in_mergeStatement17811);
            tableName1008=tableName();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_tableName.add(tableName1008.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2699:31: ( ( KW_AS )? identifier )?
            int alt320=2;
            switch ( input.LA(1) ) {
                case Identifier:
                case KW_ABORT:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_AUTOCOMMIT:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CACHE:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONSTRAINT:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURRENT_DATE:
                case KW_CURRENT_TIMESTAMP:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DAY:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DOW:
                case KW_DROP:
                case KW_DUMP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FOREIGN:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOUR:
                case KW_IDXPROPERTIES:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ISOLATION:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEY:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LAST:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LEVEL:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATCHED:
                case KW_MATERIALIZED:
                case KW_MERGE:
                case KW_METADATA:
                case KW_MINUTE:
                case KW_MONTH:
                case KW_MSCK:
                case KW_NONE:
                case KW_NORELY:
                case KW_NOSCAN:
                case KW_NOVALIDATE:
                case KW_NULL:
                case KW_NULLS:
                case KW_OF:
                case KW_OFFSET:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRIMARY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PURGE:
                case KW_QUARTER:
                case KW_RANGE:
                case KW_READ:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REFERENCES:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RELY:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPL:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SECOND:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SNAPSHOT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STATUS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTION:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALIDATE:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_VIEWS:
                case KW_WEEK:
                case KW_WHILE:
                case KW_WITH:
                case KW_WORK:
                case KW_WRITE:
                case KW_YEAR:
                case KW_BATCH:
                case KW_DAYOFWEEK:
                case KW_HOLD_DDLTIME:
                case KW_IGNORE:
                case KW_NO_DROP:
                case KW_OFFLINE:
                case KW_PROTECTION:
                case KW_READONLY:
                    {
                    alt320=1;
                    }
                    break;
                case KW_USING:
                    {
                    switch ( input.LA(2) ) {
                        case KW_USING:
                            {
                            switch ( input.LA(3) ) {
                                case Identifier:
                                    {
                                    int LA320_11 = input.LA(4);

                                    if ( ((useSQL11ReservedKeywordsForIdentifier())) ) {
                                        alt320=1;
                                    }
                                    }
                                    break;
                                case KW_ABORT:
                                case KW_ADD:
                                case KW_ADMIN:
                                case KW_AFTER:
                                case KW_ANALYZE:
                                case KW_ARCHIVE:
                                case KW_ASC:
                                case KW_AUTOCOMMIT:
                                case KW_BEFORE:
                                case KW_BUCKET:
                                case KW_BUCKETS:
                                case KW_CACHE:
                                case KW_CASCADE:
                                case KW_CHANGE:
                                case KW_CLUSTER:
                                case KW_CLUSTERED:
                                case KW_CLUSTERSTATUS:
                                case KW_COLLECTION:
                                case KW_COLUMNS:
                                case KW_COMMENT:
                                case KW_COMPACT:
                                case KW_COMPACTIONS:
                                case KW_COMPUTE:
                                case KW_CONCATENATE:
                                case KW_CONTINUE:
                                case KW_DATA:
                                case KW_DATABASES:
                                case KW_DATETIME:
                                case KW_DAY:
                                case KW_DBPROPERTIES:
                                case KW_DEFERRED:
                                case KW_DEFINED:
                                case KW_DELIMITED:
                                case KW_DEPENDENCY:
                                case KW_DESC:
                                case KW_DIRECTORIES:
                                case KW_DIRECTORY:
                                case KW_DISABLE:
                                case KW_DISTRIBUTE:
                                case KW_DOW:
                                case KW_DUMP:
                                case KW_ELEM_TYPE:
                                case KW_ENABLE:
                                case KW_ESCAPED:
                                case KW_EXCLUSIVE:
                                case KW_EXPLAIN:
                                case KW_EXPORT:
                                case KW_FIELDS:
                                case KW_FILE:
                                case KW_FILEFORMAT:
                                case KW_FIRST:
                                case KW_FORMAT:
                                case KW_FORMATTED:
                                case KW_FUNCTIONS:
                                case KW_HOUR:
                                case KW_IDXPROPERTIES:
                                case KW_INDEX:
                                case KW_INDEXES:
                                case KW_INPATH:
                                case KW_INPUTDRIVER:
                                case KW_INPUTFORMAT:
                                case KW_ISOLATION:
                                case KW_ITEMS:
                                case KW_JAR:
                                case KW_KEY:
                                case KW_KEYS:
                                case KW_KEY_TYPE:
                                case KW_LAST:
                                case KW_LEVEL:
                                case KW_LIMIT:
                                case KW_LINES:
                                case KW_LOAD:
                                case KW_LOCATION:
                                case KW_LOCK:
                                case KW_LOCKS:
                                case KW_LOGICAL:
                                case KW_LONG:
                                case KW_MAPJOIN:
                                case KW_MATCHED:
                                case KW_MATERIALIZED:
                                case KW_MERGE:
                                case KW_METADATA:
                                case KW_MINUTE:
                                case KW_MONTH:
                                case KW_MSCK:
                                case KW_NORELY:
                                case KW_NOSCAN:
                                case KW_NOVALIDATE:
                                case KW_NULLS:
                                case KW_OFFSET:
                                case KW_OPTION:
                                case KW_OUTPUTDRIVER:
                                case KW_OUTPUTFORMAT:
                                case KW_OVERWRITE:
                                case KW_OWNER:
                                case KW_PARTITIONED:
                                case KW_PARTITIONS:
                                case KW_PLUS:
                                case KW_PRETTY:
                                case KW_PRINCIPALS:
                                case KW_PURGE:
                                case KW_QUARTER:
                                case KW_READ:
                                case KW_REBUILD:
                                case KW_RECORDREADER:
                                case KW_RECORDWRITER:
                                case KW_RELOAD:
                                case KW_RELY:
                                case KW_RENAME:
                                case KW_REPAIR:
                                case KW_REPL:
                                case KW_REPLACE:
                                case KW_REPLICATION:
                                case KW_RESTRICT:
                                case KW_REWRITE:
                                case KW_ROLE:
                                case KW_ROLES:
                                case KW_SCHEMA:
                                case KW_SCHEMAS:
                                case KW_SECOND:
                                case KW_SEMI:
                                case KW_SERDE:
                                case KW_SERDEPROPERTIES:
                                case KW_SERVER:
                                case KW_SETS:
                                case KW_SHARED:
                                case KW_SHOW:
                                case KW_SHOW_DATABASE:
                                case KW_SKEWED:
                                case KW_SNAPSHOT:
                                case KW_SORT:
                                case KW_SORTED:
                                case KW_SSL:
                                case KW_STATISTICS:
                                case KW_STATUS:
                                case KW_STORED:
                                case KW_STREAMTABLE:
                                case KW_STRING:
                                case KW_STRUCT:
                                case KW_TABLES:
                                case KW_TBLPROPERTIES:
                                case KW_TEMPORARY:
                                case KW_TERMINATED:
                                case KW_TINYINT:
                                case KW_TOUCH:
                                case KW_TRANSACTION:
                                case KW_TRANSACTIONS:
                                case KW_UNARCHIVE:
                                case KW_UNDO:
                                case KW_UNIONTYPE:
                                case KW_UNLOCK:
                                case KW_UNSET:
                                case KW_UNSIGNED:
                                case KW_URI:
                                case KW_USE:
                                case KW_UTC:
                                case KW_UTCTIMESTAMP:
                                case KW_VALIDATE:
                                case KW_VALUE_TYPE:
                                case KW_VIEW:
                                case KW_VIEWS:
                                case KW_WEEK:
                                case KW_WHILE:
                                case KW_WORK:
                                case KW_WRITE:
                                case KW_YEAR:
                                case KW_BATCH:
                                case KW_DAYOFWEEK:
                                case KW_HOLD_DDLTIME:
                                case KW_IGNORE:
                                case KW_NO_DROP:
                                case KW_OFFLINE:
                                case KW_PROTECTION:
                                case KW_READONLY:
                                    {
                                    int LA320_12 = input.LA(4);

                                    if ( ((useSQL11ReservedKeywordsForIdentifier())) ) {
                                        alt320=1;
                                    }
                                    }
                                    break;
                                case KW_AS:
                                    {
                                    int LA320_13 = input.LA(4);

                                    if ( ((useSQL11ReservedKeywordsForIdentifier())) ) {
                                        alt320=1;
                                    }
                                    }
                                    break;
                                case LPAREN:
                                    {
                                    int LA320_14 = input.LA(4);

                                    if ( ((useSQL11ReservedKeywordsForIdentifier())) ) {
                                        alt320=1;
                                    }
                                    }
                                    break;
                                case KW_LATERAL:
                                    {
                                    int LA320_17 = input.LA(4);

                                    if ( ((useSQL11ReservedKeywordsForIdentifier())) ) {
                                        alt320=1;
                                    }
                                    }
                                    break;
                                case KW_ALL:
                                case KW_ALTER:
                                case KW_ARRAY:
                                case KW_AUTHORIZATION:
                                case KW_BETWEEN:
                                case KW_BIGINT:
                                case KW_BINARY:
                                case KW_BOOLEAN:
                                case KW_BOTH:
                                case KW_BY:
                                case KW_CONSTRAINT:
                                case KW_CREATE:
                                case KW_CUBE:
                                case KW_CURRENT_DATE:
                                case KW_CURRENT_TIMESTAMP:
                                case KW_CURSOR:
                                case KW_DATE:
                                case KW_DECIMAL:
                                case KW_DELETE:
                                case KW_DESCRIBE:
                                case KW_DOUBLE:
                                case KW_DROP:
                                case KW_EXISTS:
                                case KW_EXTERNAL:
                                case KW_FALSE:
                                case KW_FETCH:
                                case KW_FLOAT:
                                case KW_FOR:
                                case KW_FOREIGN:
                                case KW_FULL:
                                case KW_GRANT:
                                case KW_GROUP:
                                case KW_GROUPING:
                                case KW_IMPORT:
                                case KW_IN:
                                case KW_INNER:
                                case KW_INSERT:
                                case KW_INT:
                                case KW_INTERSECT:
                                case KW_INTO:
                                case KW_IS:
                                case KW_LEFT:
                                case KW_LIKE:
                                case KW_LOCAL:
                                case KW_NONE:
                                case KW_NULL:
                                case KW_OF:
                                case KW_ORDER:
                                case KW_OUT:
                                case KW_OUTER:
                                case KW_PARTITION:
                                case KW_PERCENT:
                                case KW_PRIMARY:
                                case KW_PROCEDURE:
                                case KW_RANGE:
                                case KW_READS:
                                case KW_REFERENCES:
                                case KW_REGEXP:
                                case KW_REVOKE:
                                case KW_RIGHT:
                                case KW_RLIKE:
                                case KW_ROLLUP:
                                case KW_ROW:
                                case KW_ROWS:
                                case KW_SET:
                                case KW_SMALLINT:
                                case KW_TABLE:
                                case KW_TIMESTAMP:
                                case KW_TO:
                                case KW_TRIGGER:
                                case KW_TRUE:
                                case KW_TRUNCATE:
                                case KW_UNION:
                                case KW_UPDATE:
                                case KW_USER:
                                case KW_USING:
                                case KW_VALUES:
                                case KW_WITH:
                                    {
                                    int LA320_18 = input.LA(4);

                                    if ( ((useSQL11ReservedKeywordsForIdentifier())) ) {
                                        alt320=1;
                                    }
                                    }
                                    break;
                            }

                            }
                            break;
                    }

                    }
                    break;
            }

            switch (alt320) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2699:32: ( KW_AS )? identifier
                    {
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2699:32: ( KW_AS )?
                    int alt319=2;
                    switch ( input.LA(1) ) {
                        case KW_AS:
                            {
                            switch ( input.LA(2) ) {
                                case Identifier:
                                case KW_ABORT:
                                case KW_ADD:
                                case KW_ADMIN:
                                case KW_AFTER:
                                case KW_ALL:
                                case KW_ALTER:
                                case KW_ANALYZE:
                                case KW_ARCHIVE:
                                case KW_ARRAY:
                                case KW_AS:
                                case KW_ASC:
                                case KW_AUTHORIZATION:
                                case KW_AUTOCOMMIT:
                                case KW_BEFORE:
                                case KW_BETWEEN:
                                case KW_BIGINT:
                                case KW_BINARY:
                                case KW_BOOLEAN:
                                case KW_BOTH:
                                case KW_BUCKET:
                                case KW_BUCKETS:
                                case KW_BY:
                                case KW_CACHE:
                                case KW_CASCADE:
                                case KW_CHANGE:
                                case KW_CLUSTER:
                                case KW_CLUSTERED:
                                case KW_CLUSTERSTATUS:
                                case KW_COLLECTION:
                                case KW_COLUMNS:
                                case KW_COMMENT:
                                case KW_COMPACT:
                                case KW_COMPACTIONS:
                                case KW_COMPUTE:
                                case KW_CONCATENATE:
                                case KW_CONSTRAINT:
                                case KW_CONTINUE:
                                case KW_CREATE:
                                case KW_CUBE:
                                case KW_CURRENT_DATE:
                                case KW_CURRENT_TIMESTAMP:
                                case KW_CURSOR:
                                case KW_DATA:
                                case KW_DATABASES:
                                case KW_DATE:
                                case KW_DATETIME:
                                case KW_DAY:
                                case KW_DBPROPERTIES:
                                case KW_DECIMAL:
                                case KW_DEFERRED:
                                case KW_DEFINED:
                                case KW_DELETE:
                                case KW_DELIMITED:
                                case KW_DEPENDENCY:
                                case KW_DESC:
                                case KW_DESCRIBE:
                                case KW_DIRECTORIES:
                                case KW_DIRECTORY:
                                case KW_DISABLE:
                                case KW_DISTRIBUTE:
                                case KW_DOUBLE:
                                case KW_DOW:
                                case KW_DROP:
                                case KW_DUMP:
                                case KW_ELEM_TYPE:
                                case KW_ENABLE:
                                case KW_ESCAPED:
                                case KW_EXCLUSIVE:
                                case KW_EXISTS:
                                case KW_EXPLAIN:
                                case KW_EXPORT:
                                case KW_EXTERNAL:
                                case KW_FALSE:
                                case KW_FETCH:
                                case KW_FIELDS:
                                case KW_FILE:
                                case KW_FILEFORMAT:
                                case KW_FIRST:
                                case KW_FLOAT:
                                case KW_FOR:
                                case KW_FOREIGN:
                                case KW_FORMAT:
                                case KW_FORMATTED:
                                case KW_FULL:
                                case KW_FUNCTIONS:
                                case KW_GRANT:
                                case KW_GROUP:
                                case KW_GROUPING:
                                case KW_HOUR:
                                case KW_IDXPROPERTIES:
                                case KW_IMPORT:
                                case KW_IN:
                                case KW_INDEX:
                                case KW_INDEXES:
                                case KW_INNER:
                                case KW_INPATH:
                                case KW_INPUTDRIVER:
                                case KW_INPUTFORMAT:
                                case KW_INSERT:
                                case KW_INT:
                                case KW_INTERSECT:
                                case KW_INTO:
                                case KW_IS:
                                case KW_ISOLATION:
                                case KW_ITEMS:
                                case KW_JAR:
                                case KW_KEY:
                                case KW_KEYS:
                                case KW_KEY_TYPE:
                                case KW_LAST:
                                case KW_LATERAL:
                                case KW_LEFT:
                                case KW_LEVEL:
                                case KW_LIKE:
                                case KW_LIMIT:
                                case KW_LINES:
                                case KW_LOAD:
                                case KW_LOCAL:
                                case KW_LOCATION:
                                case KW_LOCK:
                                case KW_LOCKS:
                                case KW_LOGICAL:
                                case KW_LONG:
                                case KW_MAPJOIN:
                                case KW_MATCHED:
                                case KW_MATERIALIZED:
                                case KW_MERGE:
                                case KW_METADATA:
                                case KW_MINUTE:
                                case KW_MONTH:
                                case KW_MSCK:
                                case KW_NONE:
                                case KW_NORELY:
                                case KW_NOSCAN:
                                case KW_NOVALIDATE:
                                case KW_NULL:
                                case KW_NULLS:
                                case KW_OF:
                                case KW_OFFSET:
                                case KW_OPTION:
                                case KW_ORDER:
                                case KW_OUT:
                                case KW_OUTER:
                                case KW_OUTPUTDRIVER:
                                case KW_OUTPUTFORMAT:
                                case KW_OVERWRITE:
                                case KW_OWNER:
                                case KW_PARTITION:
                                case KW_PARTITIONED:
                                case KW_PARTITIONS:
                                case KW_PERCENT:
                                case KW_PLUS:
                                case KW_PRETTY:
                                case KW_PRIMARY:
                                case KW_PRINCIPALS:
                                case KW_PROCEDURE:
                                case KW_PURGE:
                                case KW_QUARTER:
                                case KW_RANGE:
                                case KW_READ:
                                case KW_READS:
                                case KW_REBUILD:
                                case KW_RECORDREADER:
                                case KW_RECORDWRITER:
                                case KW_REFERENCES:
                                case KW_REGEXP:
                                case KW_RELOAD:
                                case KW_RELY:
                                case KW_RENAME:
                                case KW_REPAIR:
                                case KW_REPL:
                                case KW_REPLACE:
                                case KW_REPLICATION:
                                case KW_RESTRICT:
                                case KW_REVOKE:
                                case KW_REWRITE:
                                case KW_RIGHT:
                                case KW_RLIKE:
                                case KW_ROLE:
                                case KW_ROLES:
                                case KW_ROLLUP:
                                case KW_ROW:
                                case KW_ROWS:
                                case KW_SCHEMA:
                                case KW_SCHEMAS:
                                case KW_SECOND:
                                case KW_SEMI:
                                case KW_SERDE:
                                case KW_SERDEPROPERTIES:
                                case KW_SERVER:
                                case KW_SET:
                                case KW_SETS:
                                case KW_SHARED:
                                case KW_SHOW:
                                case KW_SHOW_DATABASE:
                                case KW_SKEWED:
                                case KW_SMALLINT:
                                case KW_SNAPSHOT:
                                case KW_SORT:
                                case KW_SORTED:
                                case KW_SSL:
                                case KW_STATISTICS:
                                case KW_STATUS:
                                case KW_STORED:
                                case KW_STREAMTABLE:
                                case KW_STRING:
                                case KW_STRUCT:
                                case KW_TABLE:
                                case KW_TABLES:
                                case KW_TBLPROPERTIES:
                                case KW_TEMPORARY:
                                case KW_TERMINATED:
                                case KW_TIMESTAMP:
                                case KW_TINYINT:
                                case KW_TO:
                                case KW_TOUCH:
                                case KW_TRANSACTION:
                                case KW_TRANSACTIONS:
                                case KW_TRIGGER:
                                case KW_TRUE:
                                case KW_TRUNCATE:
                                case KW_UNARCHIVE:
                                case KW_UNDO:
                                case KW_UNION:
                                case KW_UNIONTYPE:
                                case KW_UNLOCK:
                                case KW_UNSET:
                                case KW_UNSIGNED:
                                case KW_UPDATE:
                                case KW_URI:
                                case KW_USE:
                                case KW_USER:
                                case KW_UTC:
                                case KW_UTCTIMESTAMP:
                                case KW_VALIDATE:
                                case KW_VALUES:
                                case KW_VALUE_TYPE:
                                case KW_VIEW:
                                case KW_VIEWS:
                                case KW_WEEK:
                                case KW_WHILE:
                                case KW_WITH:
                                case KW_WORK:
                                case KW_WRITE:
                                case KW_YEAR:
                                case KW_BATCH:
                                case KW_DAYOFWEEK:
                                case KW_HOLD_DDLTIME:
                                case KW_IGNORE:
                                case KW_NO_DROP:
                                case KW_OFFLINE:
                                case KW_PROTECTION:
                                case KW_READONLY:
                                    {
                                    alt319=1;
                                    }
                                    break;
                                case KW_USING:
                                    {
                                    switch ( input.LA(3) ) {
                                        case KW_USING:
                                            {
                                            int LA319_9 = input.LA(4);

                                            if ( (!(((useSQL11ReservedKeywordsForIdentifier())))) ) {
                                                alt319=1;
                                            }
                                            }
                                            break;
                                    }

                                    }
                                    break;
                            }

                            }
                            break;
                    }

                    switch (alt319) {
                        case 1 :
                            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2699:32: KW_AS
                            {
                            KW_AS1009=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_mergeStatement17814); if (state.failed) return retval; 
                            if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS1009);


                            }
                            break;

                    }


                    pushFollow(FOLLOW_identifier_in_mergeStatement17817);
                    identifier1010=identifier();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_identifier.add(identifier1010.getTree());

                    }
                    break;

            }


            KW_USING1011=(Token)match(input,KW_USING,FOLLOW_KW_USING_in_mergeStatement17821); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_USING.add(KW_USING1011);


            pushFollow(FOLLOW_joinSourcePart_in_mergeStatement17823);
            joinSourcePart1012=joinSourcePart();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_joinSourcePart.add(joinSourcePart1012.getTree());

            KW_ON1013=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_mergeStatement17825); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON1013);


            pushFollow(FOLLOW_expression_in_mergeStatement17827);
            expression1014=expression();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_expression.add(expression1014.getTree());

            pushFollow(FOLLOW_whenClauses_in_mergeStatement17829);
            whenClauses1015=whenClauses();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_whenClauses.add(whenClauses1015.getTree());

            // AST REWRITE
            // elements: expression, whenClauses, identifier, tableName, joinSourcePart
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2699:105: -> ^( TOK_MERGE ^( TOK_TABREF tableName ( identifier )? ) joinSourcePart expression whenClauses )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2700:5: ^( TOK_MERGE ^( TOK_TABREF tableName ( identifier )? ) joinSourcePart expression whenClauses )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_MERGE, "TOK_MERGE")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2700:17: ^( TOK_TABREF tableName ( identifier )? )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_TABREF, "TOK_TABREF")
                , root_2);

                adaptor.addChild(root_2, stream_tableName.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2700:40: ( identifier )?
                if ( stream_identifier.hasNext() ) {
                    adaptor.addChild(root_2, stream_identifier.nextTree());

                }
                stream_identifier.reset();

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_1, stream_joinSourcePart.nextTree());

                adaptor.addChild(root_1, stream_expression.nextTree());

                adaptor.addChild(root_1, stream_whenClauses.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "mergeStatement"


    public static class whenClauses_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "whenClauses"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2708:1: whenClauses : ( whenMatchedAndClause | whenMatchedThenClause )* ( whenNotMatchedClause )? ;
    public final HiveParser.whenClauses_return whenClauses() throws RecognitionException {
        HiveParser.whenClauses_return retval = new HiveParser.whenClauses_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        HiveParser.whenMatchedAndClause_return whenMatchedAndClause1016 =null;

        HiveParser.whenMatchedThenClause_return whenMatchedThenClause1017 =null;

        HiveParser.whenNotMatchedClause_return whenNotMatchedClause1018 =null;



        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2709:4: ( ( whenMatchedAndClause | whenMatchedThenClause )* ( whenNotMatchedClause )? )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2710:4: ( whenMatchedAndClause | whenMatchedThenClause )* ( whenNotMatchedClause )?
            {
            root_0 = (ASTNode)adaptor.nil();


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2710:4: ( whenMatchedAndClause | whenMatchedThenClause )*
            loop321:
            do {
                int alt321=3;
                switch ( input.LA(1) ) {
                case KW_WHEN:
                    {
                    switch ( input.LA(2) ) {
                    case KW_MATCHED:
                        {
                        switch ( input.LA(3) ) {
                        case KW_AND:
                            {
                            alt321=1;
                            }
                            break;
                        case KW_THEN:
                            {
                            alt321=2;
                            }
                            break;

                        }

                        }
                        break;

                    }

                    }
                    break;

                }

                switch (alt321) {
            	case 1 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2710:5: whenMatchedAndClause
            	    {
            	    pushFollow(FOLLOW_whenMatchedAndClause_in_whenClauses17874);
            	    whenMatchedAndClause1016=whenMatchedAndClause();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) adaptor.addChild(root_0, whenMatchedAndClause1016.getTree());

            	    }
            	    break;
            	case 2 :
            	    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2710:26: whenMatchedThenClause
            	    {
            	    pushFollow(FOLLOW_whenMatchedThenClause_in_whenClauses17876);
            	    whenMatchedThenClause1017=whenMatchedThenClause();

            	    state._fsp--;
            	    if (state.failed) return retval;
            	    if ( state.backtracking==0 ) adaptor.addChild(root_0, whenMatchedThenClause1017.getTree());

            	    }
            	    break;

            	default :
            	    break loop321;
                }
            } while (true);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2710:50: ( whenNotMatchedClause )?
            int alt322=2;
            switch ( input.LA(1) ) {
                case KW_WHEN:
                    {
                    alt322=1;
                    }
                    break;
            }

            switch (alt322) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2710:50: whenNotMatchedClause
                    {
                    pushFollow(FOLLOW_whenNotMatchedClause_in_whenClauses17880);
                    whenNotMatchedClause1018=whenNotMatchedClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) adaptor.addChild(root_0, whenNotMatchedClause1018.getTree());

                    }
                    break;

            }


            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "whenClauses"


    public static class whenNotMatchedClause_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "whenNotMatchedClause"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2712:1: whenNotMatchedClause : KW_WHEN KW_NOT KW_MATCHED ( KW_AND expression )? KW_THEN KW_INSERT KW_VALUES valueRowConstructor -> ^( TOK_NOT_MATCHED ^( TOK_INSERT valueRowConstructor ) ( expression )? ) ;
    public final HiveParser.whenNotMatchedClause_return whenNotMatchedClause() throws RecognitionException {
        HiveParser.whenNotMatchedClause_return retval = new HiveParser.whenNotMatchedClause_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_WHEN1019=null;
        Token KW_NOT1020=null;
        Token KW_MATCHED1021=null;
        Token KW_AND1022=null;
        Token KW_THEN1024=null;
        Token KW_INSERT1025=null;
        Token KW_VALUES1026=null;
        HiveParser_IdentifiersParser.expression_return expression1023 =null;

        HiveParser_FromClauseParser.valueRowConstructor_return valueRowConstructor1027 =null;


        ASTNode KW_WHEN1019_tree=null;
        ASTNode KW_NOT1020_tree=null;
        ASTNode KW_MATCHED1021_tree=null;
        ASTNode KW_AND1022_tree=null;
        ASTNode KW_THEN1024_tree=null;
        ASTNode KW_INSERT1025_tree=null;
        ASTNode KW_VALUES1026_tree=null;
        RewriteRuleTokenStream stream_KW_WHEN=new RewriteRuleTokenStream(adaptor,"token KW_WHEN");
        RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
        RewriteRuleTokenStream stream_KW_AND=new RewriteRuleTokenStream(adaptor,"token KW_AND");
        RewriteRuleTokenStream stream_KW_THEN=new RewriteRuleTokenStream(adaptor,"token KW_THEN");
        RewriteRuleTokenStream stream_KW_INSERT=new RewriteRuleTokenStream(adaptor,"token KW_INSERT");
        RewriteRuleTokenStream stream_KW_MATCHED=new RewriteRuleTokenStream(adaptor,"token KW_MATCHED");
        RewriteRuleTokenStream stream_KW_VALUES=new RewriteRuleTokenStream(adaptor,"token KW_VALUES");
        RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
        RewriteRuleSubtreeStream stream_valueRowConstructor=new RewriteRuleSubtreeStream(adaptor,"rule valueRowConstructor");
         pushMsg("WHEN NOT MATCHED clause", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2715:4: ( KW_WHEN KW_NOT KW_MATCHED ( KW_AND expression )? KW_THEN KW_INSERT KW_VALUES valueRowConstructor -> ^( TOK_NOT_MATCHED ^( TOK_INSERT valueRowConstructor ) ( expression )? ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2716:3: KW_WHEN KW_NOT KW_MATCHED ( KW_AND expression )? KW_THEN KW_INSERT KW_VALUES valueRowConstructor
            {
            KW_WHEN1019=(Token)match(input,KW_WHEN,FOLLOW_KW_WHEN_in_whenNotMatchedClause17907); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_WHEN.add(KW_WHEN1019);


            KW_NOT1020=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_whenNotMatchedClause17909); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT1020);


            KW_MATCHED1021=(Token)match(input,KW_MATCHED,FOLLOW_KW_MATCHED_in_whenNotMatchedClause17911); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_MATCHED.add(KW_MATCHED1021);


            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2716:29: ( KW_AND expression )?
            int alt323=2;
            switch ( input.LA(1) ) {
                case KW_AND:
                    {
                    alt323=1;
                    }
                    break;
            }

            switch (alt323) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2716:30: KW_AND expression
                    {
                    KW_AND1022=(Token)match(input,KW_AND,FOLLOW_KW_AND_in_whenNotMatchedClause17914); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_AND.add(KW_AND1022);


                    pushFollow(FOLLOW_expression_in_whenNotMatchedClause17916);
                    expression1023=expression();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_expression.add(expression1023.getTree());

                    }
                    break;

            }


            KW_THEN1024=(Token)match(input,KW_THEN,FOLLOW_KW_THEN_in_whenNotMatchedClause17920); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_THEN.add(KW_THEN1024);


            KW_INSERT1025=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_whenNotMatchedClause17922); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_INSERT.add(KW_INSERT1025);


            KW_VALUES1026=(Token)match(input,KW_VALUES,FOLLOW_KW_VALUES_in_whenNotMatchedClause17924); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_VALUES.add(KW_VALUES1026);


            pushFollow(FOLLOW_valueRowConstructor_in_whenNotMatchedClause17926);
            valueRowConstructor1027=valueRowConstructor();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_valueRowConstructor.add(valueRowConstructor1027.getTree());

            // AST REWRITE
            // elements: valueRowConstructor, expression
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2716:98: -> ^( TOK_NOT_MATCHED ^( TOK_INSERT valueRowConstructor ) ( expression )? )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2717:5: ^( TOK_NOT_MATCHED ^( TOK_INSERT valueRowConstructor ) ( expression )? )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_NOT_MATCHED, "TOK_NOT_MATCHED")
                , root_1);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2717:23: ^( TOK_INSERT valueRowConstructor )
                {
                ASTNode root_2 = (ASTNode)adaptor.nil();
                root_2 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT")
                , root_2);

                adaptor.addChild(root_2, stream_valueRowConstructor.nextTree());

                adaptor.addChild(root_1, root_2);
                }

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2717:57: ( expression )?
                if ( stream_expression.hasNext() ) {
                    adaptor.addChild(root_1, stream_expression.nextTree());

                }
                stream_expression.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "whenNotMatchedClause"


    public static class whenMatchedAndClause_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "whenMatchedAndClause"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2719:1: whenMatchedAndClause : KW_WHEN KW_MATCHED KW_AND expression KW_THEN updateOrDelete -> ^( TOK_MATCHED updateOrDelete expression ) ;
    public final HiveParser.whenMatchedAndClause_return whenMatchedAndClause() throws RecognitionException {
        HiveParser.whenMatchedAndClause_return retval = new HiveParser.whenMatchedAndClause_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_WHEN1028=null;
        Token KW_MATCHED1029=null;
        Token KW_AND1030=null;
        Token KW_THEN1032=null;
        HiveParser_IdentifiersParser.expression_return expression1031 =null;

        HiveParser.updateOrDelete_return updateOrDelete1033 =null;


        ASTNode KW_WHEN1028_tree=null;
        ASTNode KW_MATCHED1029_tree=null;
        ASTNode KW_AND1030_tree=null;
        ASTNode KW_THEN1032_tree=null;
        RewriteRuleTokenStream stream_KW_WHEN=new RewriteRuleTokenStream(adaptor,"token KW_WHEN");
        RewriteRuleTokenStream stream_KW_AND=new RewriteRuleTokenStream(adaptor,"token KW_AND");
        RewriteRuleTokenStream stream_KW_THEN=new RewriteRuleTokenStream(adaptor,"token KW_THEN");
        RewriteRuleTokenStream stream_KW_MATCHED=new RewriteRuleTokenStream(adaptor,"token KW_MATCHED");
        RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
        RewriteRuleSubtreeStream stream_updateOrDelete=new RewriteRuleSubtreeStream(adaptor,"rule updateOrDelete");
         pushMsg("WHEN MATCHED AND clause", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2722:3: ( KW_WHEN KW_MATCHED KW_AND expression KW_THEN updateOrDelete -> ^( TOK_MATCHED updateOrDelete expression ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2723:3: KW_WHEN KW_MATCHED KW_AND expression KW_THEN updateOrDelete
            {
            KW_WHEN1028=(Token)match(input,KW_WHEN,FOLLOW_KW_WHEN_in_whenMatchedAndClause17969); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_WHEN.add(KW_WHEN1028);


            KW_MATCHED1029=(Token)match(input,KW_MATCHED,FOLLOW_KW_MATCHED_in_whenMatchedAndClause17971); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_MATCHED.add(KW_MATCHED1029);


            KW_AND1030=(Token)match(input,KW_AND,FOLLOW_KW_AND_in_whenMatchedAndClause17973); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_AND.add(KW_AND1030);


            pushFollow(FOLLOW_expression_in_whenMatchedAndClause17975);
            expression1031=expression();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_expression.add(expression1031.getTree());

            KW_THEN1032=(Token)match(input,KW_THEN,FOLLOW_KW_THEN_in_whenMatchedAndClause17977); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_THEN.add(KW_THEN1032);


            pushFollow(FOLLOW_updateOrDelete_in_whenMatchedAndClause17979);
            updateOrDelete1033=updateOrDelete();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_updateOrDelete.add(updateOrDelete1033.getTree());

            // AST REWRITE
            // elements: updateOrDelete, expression
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2723:63: -> ^( TOK_MATCHED updateOrDelete expression )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2724:5: ^( TOK_MATCHED updateOrDelete expression )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_MATCHED, "TOK_MATCHED")
                , root_1);

                adaptor.addChild(root_1, stream_updateOrDelete.nextTree());

                adaptor.addChild(root_1, stream_expression.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "whenMatchedAndClause"


    public static class whenMatchedThenClause_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "whenMatchedThenClause"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2726:1: whenMatchedThenClause : KW_WHEN KW_MATCHED KW_THEN updateOrDelete -> ^( TOK_MATCHED updateOrDelete ) ;
    public final HiveParser.whenMatchedThenClause_return whenMatchedThenClause() throws RecognitionException {
        HiveParser.whenMatchedThenClause_return retval = new HiveParser.whenMatchedThenClause_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_WHEN1034=null;
        Token KW_MATCHED1035=null;
        Token KW_THEN1036=null;
        HiveParser.updateOrDelete_return updateOrDelete1037 =null;


        ASTNode KW_WHEN1034_tree=null;
        ASTNode KW_MATCHED1035_tree=null;
        ASTNode KW_THEN1036_tree=null;
        RewriteRuleTokenStream stream_KW_WHEN=new RewriteRuleTokenStream(adaptor,"token KW_WHEN");
        RewriteRuleTokenStream stream_KW_THEN=new RewriteRuleTokenStream(adaptor,"token KW_THEN");
        RewriteRuleTokenStream stream_KW_MATCHED=new RewriteRuleTokenStream(adaptor,"token KW_MATCHED");
        RewriteRuleSubtreeStream stream_updateOrDelete=new RewriteRuleSubtreeStream(adaptor,"rule updateOrDelete");
         pushMsg("WHEN MATCHED THEN clause", state); 
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2729:3: ( KW_WHEN KW_MATCHED KW_THEN updateOrDelete -> ^( TOK_MATCHED updateOrDelete ) )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2730:3: KW_WHEN KW_MATCHED KW_THEN updateOrDelete
            {
            KW_WHEN1034=(Token)match(input,KW_WHEN,FOLLOW_KW_WHEN_in_whenMatchedThenClause18017); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_WHEN.add(KW_WHEN1034);


            KW_MATCHED1035=(Token)match(input,KW_MATCHED,FOLLOW_KW_MATCHED_in_whenMatchedThenClause18019); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_MATCHED.add(KW_MATCHED1035);


            KW_THEN1036=(Token)match(input,KW_THEN,FOLLOW_KW_THEN_in_whenMatchedThenClause18021); if (state.failed) return retval; 
            if ( state.backtracking==0 ) stream_KW_THEN.add(KW_THEN1036);


            pushFollow(FOLLOW_updateOrDelete_in_whenMatchedThenClause18023);
            updateOrDelete1037=updateOrDelete();

            state._fsp--;
            if (state.failed) return retval;
            if ( state.backtracking==0 ) stream_updateOrDelete.add(updateOrDelete1037.getTree());

            // AST REWRITE
            // elements: updateOrDelete
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            if ( state.backtracking==0 ) {

            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (ASTNode)adaptor.nil();
            // 2730:45: -> ^( TOK_MATCHED updateOrDelete )
            {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2731:6: ^( TOK_MATCHED updateOrDelete )
                {
                ASTNode root_1 = (ASTNode)adaptor.nil();
                root_1 = (ASTNode)adaptor.becomeRoot(
                (ASTNode)adaptor.create(TOK_MATCHED, "TOK_MATCHED")
                , root_1);

                adaptor.addChild(root_1, stream_updateOrDelete.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;
            }

            }

            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
            if ( state.backtracking==0 ) { popMsg(state); }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "whenMatchedThenClause"


    public static class updateOrDelete_return extends ParserRuleReturnScope {
        ASTNode tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "updateOrDelete"
    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2733:1: updateOrDelete : ( KW_UPDATE setColumnsClause -> ^( TOK_UPDATE setColumnsClause ) | KW_DELETE -> TOK_DELETE );
    public final HiveParser.updateOrDelete_return updateOrDelete() throws RecognitionException {
        HiveParser.updateOrDelete_return retval = new HiveParser.updateOrDelete_return();
        retval.start = input.LT(1);


        ASTNode root_0 = null;

        Token KW_UPDATE1038=null;
        Token KW_DELETE1040=null;
        HiveParser.setColumnsClause_return setColumnsClause1039 =null;


        ASTNode KW_UPDATE1038_tree=null;
        ASTNode KW_DELETE1040_tree=null;
        RewriteRuleTokenStream stream_KW_DELETE=new RewriteRuleTokenStream(adaptor,"token KW_DELETE");
        RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
        RewriteRuleSubtreeStream stream_setColumnsClause=new RewriteRuleSubtreeStream(adaptor,"rule setColumnsClause");
        try {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2734:4: ( KW_UPDATE setColumnsClause -> ^( TOK_UPDATE setColumnsClause ) | KW_DELETE -> TOK_DELETE )
            int alt324=2;
            switch ( input.LA(1) ) {
            case KW_UPDATE:
                {
                alt324=1;
                }
                break;
            case KW_DELETE:
                {
                alt324=2;
                }
                break;
            default:
                if (state.backtracking>0) {state.failed=true; return retval;}
                NoViableAltException nvae =
                    new NoViableAltException("", 324, 0, input);

                throw nvae;

            }

            switch (alt324) {
                case 1 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2735:4: KW_UPDATE setColumnsClause
                    {
                    KW_UPDATE1038=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_updateOrDelete18052); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE1038);


                    pushFollow(FOLLOW_setColumnsClause_in_updateOrDelete18054);
                    setColumnsClause1039=setColumnsClause();

                    state._fsp--;
                    if (state.failed) return retval;
                    if ( state.backtracking==0 ) stream_setColumnsClause.add(setColumnsClause1039.getTree());

                    // AST REWRITE
                    // elements: setColumnsClause
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2735:31: -> ^( TOK_UPDATE setColumnsClause )
                    {
                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2735:34: ^( TOK_UPDATE setColumnsClause )
                        {
                        ASTNode root_1 = (ASTNode)adaptor.nil();
                        root_1 = (ASTNode)adaptor.becomeRoot(
                        (ASTNode)adaptor.create(TOK_UPDATE, "TOK_UPDATE")
                        , root_1);

                        adaptor.addChild(root_1, stream_setColumnsClause.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;
                case 2 :
                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2737:4: KW_DELETE
                    {
                    KW_DELETE1040=(Token)match(input,KW_DELETE,FOLLOW_KW_DELETE_in_updateOrDelete18072); if (state.failed) return retval; 
                    if ( state.backtracking==0 ) stream_KW_DELETE.add(KW_DELETE1040);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    if ( state.backtracking==0 ) {

                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (ASTNode)adaptor.nil();
                    // 2737:14: -> TOK_DELETE
                    {
                        adaptor.addChild(root_0, 
                        (ASTNode)adaptor.create(TOK_DELETE, "TOK_DELETE")
                        );

                    }


                    retval.tree = root_0;
                    }

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            if ( state.backtracking==0 ) {

            retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
            }
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "updateOrDelete"

    // $ANTLR start synpred1_HiveParser
    public final void synpred1_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:850:7: ( grantPrivileges )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:850:8: grantPrivileges
        {
        pushFollow(FOLLOW_grantPrivileges_in_synpred1_HiveParser2324);
        grantPrivileges();

        state._fsp--;
        if (state.failed) return ;

        }

    }
    // $ANTLR end synpred1_HiveParser

    // $ANTLR start synpred2_HiveParser
    public final void synpred2_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:851:7: ( revokePrivileges )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:851:8: revokePrivileges
        {
        pushFollow(FOLLOW_revokePrivileges_in_synpred2_HiveParser2338);
        revokePrivileges();

        state._fsp--;
        if (state.failed) return ;

        }

    }
    // $ANTLR end synpred2_HiveParser

    // $ANTLR start synpred3_HiveParser
    public final void synpred3_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1088:7: ( alterStatementSuffixRename[true] )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1088:8: alterStatementSuffixRename[true]
        {
        pushFollow(FOLLOW_alterStatementSuffixRename_in_synpred3_HiveParser4294);
        alterStatementSuffixRename(true);

        state._fsp--;
        if (state.failed) return ;

        }

    }
    // $ANTLR end synpred3_HiveParser

    // $ANTLR start synpred4_HiveParser
    public final void synpred4_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:4: ( KW_ELEM_TYPE )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:5: KW_ELEM_TYPE
        {
        match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_synpred4_HiveParser6886); if (state.failed) return ;

        }

    }
    // $ANTLR end synpred4_HiveParser

    // $ANTLR start synpred5_HiveParser
    public final void synpred5_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1436:4: ( KW_KEY_TYPE )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1436:5: KW_KEY_TYPE
        {
        match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_synpred5_HiveParser6903); if (state.failed) return ;

        }

    }
    // $ANTLR end synpred5_HiveParser

    // $ANTLR start synpred6_HiveParser
    public final void synpred6_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:4: ( KW_VALUE_TYPE )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:5: KW_VALUE_TYPE
        {
        match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_synpred6_HiveParser6920); if (state.failed) return ;

        }

    }
    // $ANTLR end synpred6_HiveParser

    // $ANTLR start synpred7_HiveParser
    public final void synpred7_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1462:5: ( KW_DATABASE | KW_SCHEMA )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:
        {
        if ( input.LA(1)==KW_DATABASE||input.LA(1)==KW_SCHEMA ) {
            input.consume();
            state.errorRecovery=false;
            state.failed=false;
        }
        else {
            if (state.backtracking>0) {state.failed=true; return ;}
            MismatchedSetException mse = new MismatchedSetException(null,input);
            throw mse;
        }


        }

    }
    // $ANTLR end synpred7_HiveParser

    // $ANTLR start synpred8_HiveParser
    public final void synpred8_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1464:5: ( KW_FUNCTION )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1464:6: KW_FUNCTION
        {
        match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_synpred8_HiveParser7128); if (state.failed) return ;

        }

    }
    // $ANTLR end synpred8_HiveParser

    // $ANTLR start synpred9_HiveParser
    public final void synpred9_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1466:5: ( KW_FORMATTED | KW_EXTENDED | KW_PRETTY )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:
        {
        if ( input.LA(1)==KW_EXTENDED||input.LA(1)==KW_FORMATTED||input.LA(1)==KW_PRETTY ) {
            input.consume();
            state.errorRecovery=false;
            state.failed=false;
        }
        else {
            if (state.backtracking>0) {state.failed=true; return ;}
            MismatchedSetException mse = new MismatchedSetException(null,input);
            throw mse;
        }


        }

    }
    // $ANTLR end synpred9_HiveParser

    // $ANTLR start synpred10_HiveParser
    public final void synpred10_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:7: ( KW_COMPUTE )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:8: KW_COMPUTE
        {
        match(input,KW_COMPUTE,FOLLOW_KW_COMPUTE_in_synpred10_HiveParser7287); if (state.failed) return ;

        }

    }
    // $ANTLR end synpred10_HiveParser

    // $ANTLR start synpred11_HiveParser
    public final void synpred11_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1481:7: ( KW_CACHE )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1481:8: KW_CACHE
        {
        match(input,KW_CACHE,FOLLOW_KW_CACHE_in_synpred11_HiveParser7427); if (state.failed) return ;

        }

    }
    // $ANTLR end synpred11_HiveParser

    // $ANTLR start synpred12_HiveParser
    public final void synpred12_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1495:9: ( KW_DATABASE | KW_SCHEMA )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:
        {
        if ( input.LA(1)==KW_DATABASE||input.LA(1)==KW_SCHEMA ) {
            input.consume();
            state.errorRecovery=false;
            state.failed=false;
        }
        else {
            if (state.backtracking>0) {state.failed=true; return ;}
            MismatchedSetException mse = new MismatchedSetException(null,input);
            throw mse;
        }


        }

    }
    // $ANTLR end synpred12_HiveParser

    // $ANTLR start synpred13_HiveParser
    public final void synpred13_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:7: ( KW_DATABASE | KW_SCHEMA )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:
        {
        if ( input.LA(1)==KW_DATABASE||input.LA(1)==KW_SCHEMA ) {
            input.consume();
            state.errorRecovery=false;
            state.failed=false;
        }
        else {
            if (state.backtracking>0) {state.failed=true; return ;}
            MismatchedSetException mse = new MismatchedSetException(null,input);
            throw mse;
        }


        }

    }
    // $ANTLR end synpred13_HiveParser

    // $ANTLR start synpred14_HiveParser
    public final void synpred14_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:5: ( KW_ALL )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:6: KW_ALL
        {
        match(input,KW_ALL,FOLLOW_KW_ALL_in_synpred14_HiveParser8812); if (state.failed) return ;

        }

    }
    // $ANTLR end synpred14_HiveParser

    // $ANTLR start synpred15_HiveParser
    public final void synpred15_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1619:5: ( KW_NONE )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1619:6: KW_NONE
        {
        match(input,KW_NONE,FOLLOW_KW_NONE_in_synpred15_HiveParser8843); if (state.failed) return ;

        }

    }
    // $ANTLR end synpred15_HiveParser

    // $ANTLR start synpred16_HiveParser
    public final void synpred16_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1643:7: ( KW_ALL )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1643:8: KW_ALL
        {
        match(input,KW_ALL,FOLLOW_KW_ALL_in_synpred16_HiveParser9017); if (state.failed) return ;

        }

    }
    // $ANTLR end synpred16_HiveParser

    // $ANTLR start synpred17_HiveParser
    public final void synpred17_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1882:117: ( storedAsDirs )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1882:118: storedAsDirs
        {
        pushFollow(FOLLOW_storedAsDirs_in_synpred17_HiveParser11000);
        storedAsDirs();

        state._fsp--;
        if (state.failed) return ;

        }

    }
    // $ANTLR end synpred17_HiveParser

    // $ANTLR start synpred18_HiveParser
    public final void synpred18_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2013:7: ( KW_STORED KW_AS KW_INPUTFORMAT )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2013:8: KW_STORED KW_AS KW_INPUTFORMAT
        {
        match(input,KW_STORED,FOLLOW_KW_STORED_in_synpred18_HiveParser11981); if (state.failed) return ;

        match(input,KW_AS,FOLLOW_KW_AS_in_synpred18_HiveParser11983); if (state.failed) return ;

        match(input,KW_INPUTFORMAT,FOLLOW_KW_INPUTFORMAT_in_synpred18_HiveParser11985); if (state.failed) return ;

        }

    }
    // $ANTLR end synpred18_HiveParser

    // $ANTLR start synpred19_HiveParser
    public final void synpred19_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:25: ( KW_ELEM_TYPE )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:26: KW_ELEM_TYPE
        {
        match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_synpred19_HiveParser12422); if (state.failed) return ;

        }

    }
    // $ANTLR end synpred19_HiveParser

    // $ANTLR start synpred20_HiveParser
    public final void synpred20_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:58: ( KW_KEY_TYPE )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:59: KW_KEY_TYPE
        {
        match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_synpred20_HiveParser12432); if (state.failed) return ;

        }

    }
    // $ANTLR end synpred20_HiveParser

    // $ANTLR start synpred21_HiveParser
    public final void synpred21_HiveParser_fragment() throws RecognitionException {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:89: ( KW_VALUE_TYPE )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:90: KW_VALUE_TYPE
        {
        match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_synpred21_HiveParser12442); if (state.failed) return ;

        }

    }
    // $ANTLR end synpred21_HiveParser

    // Delegated rules
    public HiveParser_IdentifiersParser.castExpression_return castExpression() throws RecognitionException { return gIdentifiersParser.castExpression(); }
    public HiveParser_IdentifiersParser.distributeByClause_return distributeByClause() throws RecognitionException { return gIdentifiersParser.distributeByClause(); }
    public HiveParser_IdentifiersParser.rollupStandard_return rollupStandard() throws RecognitionException { return gIdentifiersParser.rollupStandard(); }
    public HiveParser_IdentifiersParser.precedenceUnaryOperator_return precedenceUnaryOperator() throws RecognitionException { return gIdentifiersParser.precedenceUnaryOperator(); }
    public HiveParser_SelectClauseParser.hintArgs_return hintArgs() throws RecognitionException { return gSelectClauseParser.hintArgs(); }
    public HiveParser_SelectClauseParser.window_value_expression_return window_value_expression() throws RecognitionException { return gSelectClauseParser.window_value_expression(); }
    public HiveParser_FromClauseParser.tableSample_return tableSample() throws RecognitionException { return gFromClauseParser.tableSample(); }
    public HiveParser_IdentifiersParser.functionIdentifier_return functionIdentifier() throws RecognitionException { return gIdentifiersParser.functionIdentifier(); }
    public HiveParser_IdentifiersParser.partitionSpec_return partitionSpec() throws RecognitionException { return gIdentifiersParser.partitionSpec(); }
    public HiveParser_SelectClauseParser.selectClause_return selectClause() throws RecognitionException { return gSelectClauseParser.selectClause(); }
    public HiveParser_IdentifiersParser.groupingSetExpressionMultiple_return groupingSetExpressionMultiple() throws RecognitionException { return gIdentifiersParser.groupingSetExpressionMultiple(); }
    public HiveParser_IdentifiersParser.dropPartitionSpec_return dropPartitionSpec() throws RecognitionException { return gIdentifiersParser.dropPartitionSpec(); }
    public HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression_return precedenceUnaryPrefixExpression() throws RecognitionException { return gIdentifiersParser.precedenceUnaryPrefixExpression(); }
    public HiveParser_FromClauseParser.partitionedTableFunction_return partitionedTableFunction() throws RecognitionException { return gFromClauseParser.partitionedTableFunction(); }
    public HiveParser_IdentifiersParser.precedenceStarOperator_return precedenceStarOperator() throws RecognitionException { return gIdentifiersParser.precedenceStarOperator(); }
    public HiveParser_SelectClauseParser.hintList_return hintList() throws RecognitionException { return gSelectClauseParser.hintList(); }
    public HiveParser_IdentifiersParser.rollupOldSyntax_return rollupOldSyntax() throws RecognitionException { return gIdentifiersParser.rollupOldSyntax(); }
    public HiveParser_IdentifiersParser.precedencePlusExpression_return precedencePlusExpression() throws RecognitionException { return gIdentifiersParser.precedencePlusExpression(); }
    public HiveParser_IdentifiersParser.groupByClause_return groupByClause() throws RecognitionException { return gIdentifiersParser.groupByClause(); }
    public HiveParser_IdentifiersParser.dropPartitionVal_return dropPartitionVal() throws RecognitionException { return gIdentifiersParser.dropPartitionVal(); }
    public HiveParser_SelectClauseParser.hintItem_return hintItem() throws RecognitionException { return gSelectClauseParser.hintItem(); }
    public HiveParser_IdentifiersParser.nullCondition_return nullCondition() throws RecognitionException { return gIdentifiersParser.nullCondition(); }
    public HiveParser_IdentifiersParser.havingClause_return havingClause() throws RecognitionException { return gIdentifiersParser.havingClause(); }
    public HiveParser_FromClauseParser.tableSource_return tableSource() throws RecognitionException { return gFromClauseParser.tableSource(); }
    public HiveParser_FromClauseParser.splitSample_return splitSample() throws RecognitionException { return gFromClauseParser.splitSample(); }
    public HiveParser_IdentifiersParser.intervalLiteral_return intervalLiteral() throws RecognitionException { return gIdentifiersParser.intervalLiteral(); }
    public HiveParser_IdentifiersParser.precedenceAndExpression_return precedenceAndExpression() throws RecognitionException { return gIdentifiersParser.precedenceAndExpression(); }
    public HiveParser_IdentifiersParser.expressionsNotInParenthesis_return expressionsNotInParenthesis(boolean isStruct) throws RecognitionException { return gIdentifiersParser.expressionsNotInParenthesis(isStruct); }
    public HiveParser_IdentifiersParser.clusterByClause_return clusterByClause() throws RecognitionException { return gIdentifiersParser.clusterByClause(); }
    public HiveParser_IdentifiersParser.atomExpression_return atomExpression() throws RecognitionException { return gIdentifiersParser.atomExpression(); }
    public HiveParser_IdentifiersParser.expression_return expression() throws RecognitionException { return gIdentifiersParser.expression(); }
    public HiveParser_IdentifiersParser.sysFuncNames_return sysFuncNames() throws RecognitionException { return gIdentifiersParser.sysFuncNames(); }
    public HiveParser_IdentifiersParser.precedenceBitwiseOrExpression_return precedenceBitwiseOrExpression() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseOrExpression(); }
    public HiveParser_IdentifiersParser.columnRefOrderNotInParenthesis_return columnRefOrderNotInParenthesis() throws RecognitionException { return gIdentifiersParser.columnRefOrderNotInParenthesis(); }
    public HiveParser_FromClauseParser.uniqueJoinExpr_return uniqueJoinExpr() throws RecognitionException { return gFromClauseParser.uniqueJoinExpr(); }
    public HiveParser_IdentifiersParser.precedenceStarExpression_return precedenceStarExpression() throws RecognitionException { return gIdentifiersParser.precedenceStarExpression(); }
    public HiveParser_FromClauseParser.atomjoinSource_return atomjoinSource() throws RecognitionException { return gFromClauseParser.atomjoinSource(); }
    public HiveParser_IdentifiersParser.nonReserved_return nonReserved() throws RecognitionException { return gIdentifiersParser.nonReserved(); }
    public HiveParser_IdentifiersParser.timestampLiteral_return timestampLiteral() throws RecognitionException { return gIdentifiersParser.timestampLiteral(); }
    public HiveParser_IdentifiersParser.intervalExpression_return intervalExpression() throws RecognitionException { return gIdentifiersParser.intervalExpression(); }
    public HiveParser_FromClauseParser.fromClause_return fromClause() throws RecognitionException { return gFromClauseParser.fromClause(); }
    public HiveParser_SelectClauseParser.window_range_expression_return window_range_expression() throws RecognitionException { return gSelectClauseParser.window_range_expression(); }
    public HiveParser_IdentifiersParser.floorDateQualifiers_return floorDateQualifiers() throws RecognitionException { return gIdentifiersParser.floorDateQualifiers(); }
    public HiveParser_IdentifiersParser.precedenceConcatenateOperator_return precedenceConcatenateOperator() throws RecognitionException { return gIdentifiersParser.precedenceConcatenateOperator(); }
    public HiveParser_SelectClauseParser.window_frame_start_boundary_return window_frame_start_boundary() throws RecognitionException { return gSelectClauseParser.window_frame_start_boundary(); }
    public HiveParser_IdentifiersParser.subQueryExpression_return subQueryExpression() throws RecognitionException { return gIdentifiersParser.subQueryExpression(); }
    public HiveParser_FromClauseParser.uniqueJoinTableSource_return uniqueJoinTableSource() throws RecognitionException { return gFromClauseParser.uniqueJoinTableSource(); }
    public HiveParser_FromClauseParser.virtualTableSource_return virtualTableSource() throws RecognitionException { return gFromClauseParser.virtualTableSource(); }
    public HiveParser_FromClauseParser.subQuerySource_return subQuerySource() throws RecognitionException { return gFromClauseParser.subQuerySource(); }
    public HiveParser_FromClauseParser.joinSourcePart_return joinSourcePart() throws RecognitionException { return gFromClauseParser.joinSourcePart(); }
    public HiveParser_IdentifiersParser.principalIdentifier_return principalIdentifier() throws RecognitionException { return gIdentifiersParser.principalIdentifier(); }
    public HiveParser_FromClauseParser.tableNameColList_return tableNameColList() throws RecognitionException { return gFromClauseParser.tableNameColList(); }
    public HiveParser_IdentifiersParser.timeQualifiers_return timeQualifiers() throws RecognitionException { return gIdentifiersParser.timeQualifiers(); }
    public HiveParser_IdentifiersParser.precedenceFieldExpression_return precedenceFieldExpression() throws RecognitionException { return gIdentifiersParser.precedenceFieldExpression(); }
    public HiveParser_IdentifiersParser.precedenceNotOperator_return precedenceNotOperator() throws RecognitionException { return gIdentifiersParser.precedenceNotOperator(); }
    public HiveParser_IdentifiersParser.partitionVal_return partitionVal() throws RecognitionException { return gIdentifiersParser.partitionVal(); }
    public HiveParser_SelectClauseParser.trfmClause_return trfmClause() throws RecognitionException { return gSelectClauseParser.trfmClause(); }
    public HiveParser_IdentifiersParser.precedenceAndOperator_return precedenceAndOperator() throws RecognitionException { return gIdentifiersParser.precedenceAndOperator(); }
    public HiveParser_SelectClauseParser.window_defn_return window_defn() throws RecognitionException { return gSelectClauseParser.window_defn(); }
    public HiveParser_IdentifiersParser.expressions_return expressions() throws RecognitionException { return gIdentifiersParser.expressions(); }
    public HiveParser_FromClauseParser.tableBucketSample_return tableBucketSample() throws RecognitionException { return gFromClauseParser.tableBucketSample(); }
    public HiveParser_IdentifiersParser.sql11ReservedKeywordsUsedAsIdentifier_return sql11ReservedKeywordsUsedAsIdentifier() throws RecognitionException { return gIdentifiersParser.sql11ReservedKeywordsUsedAsIdentifier(); }
    public HiveParser_IdentifiersParser.functionName_return functionName() throws RecognitionException { return gIdentifiersParser.functionName(); }
    public HiveParser_FromClauseParser.searchCondition_return searchCondition() throws RecognitionException { return gFromClauseParser.searchCondition(); }
    public HiveParser_IdentifiersParser.precedencePlusOperator_return precedencePlusOperator() throws RecognitionException { return gIdentifiersParser.precedencePlusOperator(); }
    public HiveParser_FromClauseParser.valuesTableConstructor_return valuesTableConstructor() throws RecognitionException { return gFromClauseParser.valuesTableConstructor(); }
    public HiveParser_FromClauseParser.lateralView_return lateralView() throws RecognitionException { return gFromClauseParser.lateralView(); }
    public HiveParser_FromClauseParser.tableAllColumns_return tableAllColumns() throws RecognitionException { return gFromClauseParser.tableAllColumns(); }
    public HiveParser_IdentifiersParser.stringLiteralSequence_return stringLiteralSequence() throws RecognitionException { return gIdentifiersParser.stringLiteralSequence(); }
    public HiveParser_IdentifiersParser.precedenceEqualOperator_return precedenceEqualOperator() throws RecognitionException { return gIdentifiersParser.precedenceEqualOperator(); }
    public HiveParser_IdentifiersParser.precedenceConcatenateExpression_return precedenceConcatenateExpression() throws RecognitionException { return gIdentifiersParser.precedenceConcatenateExpression(); }
    public HiveParser_SelectClauseParser.hintClause_return hintClause() throws RecognitionException { return gSelectClauseParser.hintClause(); }
    public HiveParser_SelectClauseParser.window_specification_return window_specification() throws RecognitionException { return gSelectClauseParser.window_specification(); }
    public HiveParser_IdentifiersParser.precedenceRegexpOperator_return precedenceRegexpOperator() throws RecognitionException { return gIdentifiersParser.precedenceRegexpOperator(); }
    public HiveParser_FromClauseParser.valuesClause_return valuesClause() throws RecognitionException { return gFromClauseParser.valuesClause(); }
    public HiveParser_IdentifiersParser.groupingExpressionSingle_return groupingExpressionSingle() throws RecognitionException { return gIdentifiersParser.groupingExpressionSingle(); }
    public HiveParser_FromClauseParser.partitioningSpec_return partitioningSpec() throws RecognitionException { return gFromClauseParser.partitioningSpec(); }
    public HiveParser_FromClauseParser.whereClause_return whereClause() throws RecognitionException { return gFromClauseParser.whereClause(); }
    public HiveParser_FromClauseParser.valueRowConstructor_return valueRowConstructor() throws RecognitionException { return gFromClauseParser.valueRowConstructor(); }
    public HiveParser_IdentifiersParser.precedenceBitwiseXorExpression_return precedenceBitwiseXorExpression() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseXorExpression(); }
    public HiveParser_SelectClauseParser.selectExpressionList_return selectExpressionList() throws RecognitionException { return gSelectClauseParser.selectExpressionList(); }
    public HiveParser_IdentifiersParser.caseExpression_return caseExpression() throws RecognitionException { return gIdentifiersParser.caseExpression(); }
    public HiveParser_IdentifiersParser.groupby_expression_return groupby_expression() throws RecognitionException { return gIdentifiersParser.groupby_expression(); }
    public HiveParser_FromClauseParser.partitionTableFunctionSource_return partitionTableFunctionSource() throws RecognitionException { return gFromClauseParser.partitionTableFunctionSource(); }
    public HiveParser_IdentifiersParser.precedenceBitwiseOrOperator_return precedenceBitwiseOrOperator() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseOrOperator(); }
    public HiveParser_IdentifiersParser.precedenceSimilarExpressionIn_return precedenceSimilarExpressionIn(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionIn(t); }
    public HiveParser_SelectClauseParser.selectItem_return selectItem() throws RecognitionException { return gSelectClauseParser.selectItem(); }
    public HiveParser_IdentifiersParser.precedenceOrOperator_return precedenceOrOperator() throws RecognitionException { return gIdentifiersParser.precedenceOrOperator(); }
    public HiveParser_IdentifiersParser.precedenceAmpersandOperator_return precedenceAmpersandOperator() throws RecognitionException { return gIdentifiersParser.precedenceAmpersandOperator(); }
    public HiveParser_IdentifiersParser.identifier_return identifier() throws RecognitionException { return gIdentifiersParser.identifier(); }
    public HiveParser_IdentifiersParser.tableOrPartition_return tableOrPartition() throws RecognitionException { return gIdentifiersParser.tableOrPartition(); }
    public HiveParser_IdentifiersParser.sql11ReservedKeywordsUsedAsCastFunctionName_return sql11ReservedKeywordsUsedAsCastFunctionName() throws RecognitionException { return gIdentifiersParser.sql11ReservedKeywordsUsedAsCastFunctionName(); }
    public HiveParser_IdentifiersParser.function_return function() throws RecognitionException { return gIdentifiersParser.function(); }
    public HiveParser_IdentifiersParser.precedenceUnarySuffixExpression_return precedenceUnarySuffixExpression() throws RecognitionException { return gIdentifiersParser.precedenceUnarySuffixExpression(); }
    public HiveParser_IdentifiersParser.precedenceSimilarOperator_return precedenceSimilarOperator() throws RecognitionException { return gIdentifiersParser.precedenceSimilarOperator(); }
    public HiveParser_IdentifiersParser.dateLiteral_return dateLiteral() throws RecognitionException { return gIdentifiersParser.dateLiteral(); }
    public HiveParser_IdentifiersParser.groupingSetExpression_return groupingSetExpression() throws RecognitionException { return gIdentifiersParser.groupingSetExpression(); }
    public HiveParser_SelectClauseParser.window_clause_return window_clause() throws RecognitionException { return gSelectClauseParser.window_clause(); }
    public HiveParser_IdentifiersParser.constant_return constant() throws RecognitionException { return gIdentifiersParser.constant(); }
    public HiveParser_FromClauseParser.uniqueJoinToken_return uniqueJoinToken() throws RecognitionException { return gFromClauseParser.uniqueJoinToken(); }
    public HiveParser_SelectClauseParser.selectExpression_return selectExpression() throws RecognitionException { return gSelectClauseParser.selectExpression(); }
    public HiveParser_FromClauseParser.joinToken_return joinToken() throws RecognitionException { return gFromClauseParser.joinToken(); }
    public HiveParser_FromClauseParser.uniqueJoinSource_return uniqueJoinSource() throws RecognitionException { return gFromClauseParser.uniqueJoinSource(); }
    public HiveParser_IdentifiersParser.intervalValue_return intervalValue() throws RecognitionException { return gIdentifiersParser.intervalValue(); }
    public HiveParser_SelectClauseParser.hintName_return hintName() throws RecognitionException { return gSelectClauseParser.hintName(); }
    public HiveParser_FromClauseParser.fromSource_return fromSource() throws RecognitionException { return gFromClauseParser.fromSource(); }
    public HiveParser_SelectClauseParser.selectTrfmClause_return selectTrfmClause() throws RecognitionException { return gSelectClauseParser.selectTrfmClause(); }
    public HiveParser_IdentifiersParser.precedenceAmpersandExpression_return precedenceAmpersandExpression() throws RecognitionException { return gIdentifiersParser.precedenceAmpersandExpression(); }
    public HiveParser_IdentifiersParser.precedenceEqualExpression_return precedenceEqualExpression() throws RecognitionException { return gIdentifiersParser.precedenceEqualExpression(); }
    public HiveParser_IdentifiersParser.precedenceSimilarExpressionPartNot_return precedenceSimilarExpressionPartNot(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionPartNot(t); }
    public HiveParser_FromClauseParser.aliasList_return aliasList() throws RecognitionException { return gFromClauseParser.aliasList(); }
    public HiveParser_IdentifiersParser.precedenceBitwiseXorOperator_return precedenceBitwiseXorOperator() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseXorOperator(); }
    public HiveParser_IdentifiersParser.whenExpression_return whenExpression() throws RecognitionException { return gIdentifiersParser.whenExpression(); }
    public HiveParser_IdentifiersParser.booleanValueTok_return booleanValueTok() throws RecognitionException { return gIdentifiersParser.booleanValueTok(); }
    public HiveParser_IdentifiersParser.precedenceSimilarExpressionPart_return precedenceSimilarExpressionPart(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionPart(t); }
    public HiveParser_FromClauseParser.joinSource_return joinSource() throws RecognitionException { return gFromClauseParser.joinSource(); }
    public HiveParser_IdentifiersParser.descFuncNames_return descFuncNames() throws RecognitionException { return gIdentifiersParser.descFuncNames(); }
    public HiveParser_IdentifiersParser.havingCondition_return havingCondition() throws RecognitionException { return gIdentifiersParser.havingCondition(); }
    public HiveParser_IdentifiersParser.precedenceOrExpression_return precedenceOrExpression() throws RecognitionException { return gIdentifiersParser.precedenceOrExpression(); }
    public HiveParser_FromClauseParser.tableAlias_return tableAlias() throws RecognitionException { return gFromClauseParser.tableAlias(); }
    public HiveParser_IdentifiersParser.columnRefOrderInParenthesis_return columnRefOrderInParenthesis() throws RecognitionException { return gIdentifiersParser.columnRefOrderInParenthesis(); }
    public HiveParser_FromClauseParser.expressionList_return expressionList() throws RecognitionException { return gFromClauseParser.expressionList(); }
    public HiveParser_IdentifiersParser.intervalQualifiers_return intervalQualifiers() throws RecognitionException { return gIdentifiersParser.intervalQualifiers(); }
    public HiveParser_IdentifiersParser.orderByClause_return orderByClause() throws RecognitionException { return gIdentifiersParser.orderByClause(); }
    public HiveParser_FromClauseParser.viewName_return viewName() throws RecognitionException { return gFromClauseParser.viewName(); }
    public HiveParser_IdentifiersParser.precedenceSimilarExpressionAtom_return precedenceSimilarExpressionAtom(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionAtom(t); }
    public HiveParser_SelectClauseParser.selectList_return selectList() throws RecognitionException { return gSelectClauseParser.selectList(); }
    public HiveParser_FromClauseParser.tableOrColumn_return tableOrColumn() throws RecognitionException { return gFromClauseParser.tableOrColumn(); }
    public HiveParser_IdentifiersParser.floorExpression_return floorExpression() throws RecognitionException { return gIdentifiersParser.floorExpression(); }
    public HiveParser_IdentifiersParser.precedenceSimilarExpressionMain_return precedenceSimilarExpressionMain() throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionMain(); }
    public HiveParser_IdentifiersParser.precedenceNotExpression_return precedenceNotExpression() throws RecognitionException { return gIdentifiersParser.precedenceNotExpression(); }
    public HiveParser_SelectClauseParser.hintArgName_return hintArgName() throws RecognitionException { return gSelectClauseParser.hintArgName(); }
    public HiveParser_FromClauseParser.tableName_return tableName() throws RecognitionException { return gFromClauseParser.tableName(); }
    public HiveParser_IdentifiersParser.charSetStringLiteral_return charSetStringLiteral() throws RecognitionException { return gIdentifiersParser.charSetStringLiteral(); }
    public HiveParser_SelectClauseParser.window_frame_boundary_return window_frame_boundary() throws RecognitionException { return gSelectClauseParser.window_frame_boundary(); }
    public HiveParser_IdentifiersParser.partitionByClause_return partitionByClause() throws RecognitionException { return gIdentifiersParser.partitionByClause(); }
    public HiveParser_IdentifiersParser.precedenceSimilarExpression_return precedenceSimilarExpression() throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpression(); }
    public HiveParser_IdentifiersParser.expressionPart_return expressionPart(CommonTree t, boolean isStruct) throws RecognitionException { return gIdentifiersParser.expressionPart(t, isStruct); }
    public HiveParser_SelectClauseParser.window_frame_return window_frame() throws RecognitionException { return gSelectClauseParser.window_frame(); }
    public HiveParser_IdentifiersParser.expressionsInParenthesis_return expressionsInParenthesis(boolean isStruct) throws RecognitionException { return gIdentifiersParser.expressionsInParenthesis(isStruct); }
    public HiveParser_IdentifiersParser.dropPartitionOperator_return dropPartitionOperator() throws RecognitionException { return gIdentifiersParser.dropPartitionOperator(); }
    public HiveParser_IdentifiersParser.booleanValue_return booleanValue() throws RecognitionException { return gIdentifiersParser.booleanValue(); }
    public HiveParser_IdentifiersParser.sortByClause_return sortByClause() throws RecognitionException { return gIdentifiersParser.sortByClause(); }
    public HiveParser_IdentifiersParser.extractExpression_return extractExpression() throws RecognitionException { return gIdentifiersParser.extractExpression(); }

    public final boolean synpred18_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred18_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred21_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred21_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred7_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred7_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred11_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred11_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred15_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred15_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred13_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred13_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred10_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred10_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred8_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred8_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred4_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred4_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred2_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred2_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred6_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred6_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred19_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred19_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred14_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred14_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred17_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred17_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred20_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred20_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred12_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred12_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred3_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred3_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred9_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred9_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred16_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred16_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred5_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred5_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }
    public final boolean synpred1_HiveParser() {
        state.backtracking++;
        int start = input.mark();
        try {
            synpred1_HiveParser_fragment(); // can never throw exception
        } catch (RecognitionException re) {
            System.err.println("impossible: "+re);
        }
        boolean success = !state.failed;
        input.rewind(start);
        state.backtracking--;
        state.failed=false;
        return success;
    }


    protected DFA2 dfa2 = new DFA2(this);
    protected DFA19 dfa19 = new DFA19(this);
    protected DFA119 dfa119 = new DFA119(this);
    protected DFA210 dfa210 = new DFA210(this);
    protected DFA244 dfa244 = new DFA244(this);
    static final String DFA2_eotS =
        "\110\uffff";
    static final String DFA2_eofS =
        "\110\uffff";
    static final String DFA2_minS =
        "\1\34\25\uffff\1\34\61\uffff";
    static final String DFA2_maxS =
        "\1\u0149\25\uffff\1\u0149\61\uffff";
    static final String DFA2_acceptS =
        "\1\uffff\1\2\41\uffff\1\1\44\uffff";
    static final String DFA2_specialS =
        "\110\uffff}>";
    static final String[] DFA2_transitionS = {
            "\1\1\4\uffff\1\1\1\26\5\uffff\1\43\27\uffff\1\1\7\uffff\1\1"+
            "\20\uffff\1\1\1\uffff\1\43\2\1\7\uffff\1\1\13\uffff\1\1\1\43"+
            "\16\uffff\1\43\1\1\3\uffff\1\1\6\uffff\1\1\7\uffff\1\1\24\uffff"+
            "\1\1\2\uffff\1\1\1\uffff\1\43\2\uffff\1\1\3\uffff\1\1\5\uffff"+
            "\1\1\52\uffff\1\1\2\uffff\1\1\3\uffff\1\1\3\uffff\1\1\5\uffff"+
            "\1\1\6\uffff\1\1\4\uffff\1\1\2\uffff\1\1\7\uffff\1\1\26\uffff"+
            "\1\1\6\uffff\1\1\2\uffff\1\1\1\uffff\1\1\17\uffff\1\1\6\uffff"+
            "\1\1",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "\1\43\4\uffff\2\43\5\uffff\1\43\27\uffff\1\43\7\uffff\1\43"+
            "\20\uffff\1\43\1\uffff\3\43\7\uffff\1\43\13\uffff\2\43\16\uffff"+
            "\2\43\3\uffff\1\43\6\uffff\1\43\7\uffff\1\43\24\uffff\1\43\2"+
            "\uffff\1\43\1\uffff\1\43\2\uffff\1\43\3\uffff\1\43\5\uffff\1"+
            "\43\52\uffff\1\43\2\uffff\1\43\3\uffff\1\43\3\uffff\1\43\5\uffff"+
            "\1\43\6\uffff\1\43\4\uffff\1\43\2\uffff\1\43\7\uffff\1\43\6"+
            "\uffff\1\1\17\uffff\1\43\6\uffff\1\43\2\uffff\1\43\1\uffff\1"+
            "\43\17\uffff\1\43\6\uffff\1\43",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
    };

    static final short[] DFA2_eot = DFA.unpackEncodedString(DFA2_eotS);
    static final short[] DFA2_eof = DFA.unpackEncodedString(DFA2_eofS);
    static final char[] DFA2_min = DFA.unpackEncodedStringToUnsignedChars(DFA2_minS);
    static final char[] DFA2_max = DFA.unpackEncodedStringToUnsignedChars(DFA2_maxS);
    static final short[] DFA2_accept = DFA.unpackEncodedString(DFA2_acceptS);
    static final short[] DFA2_special = DFA.unpackEncodedString(DFA2_specialS);
    static final short[][] DFA2_transition;

    static {
        int numStates = DFA2_transitionS.length;
        DFA2_transition = new short[numStates][];
        for (int i=0; i<numStates; i++) {
            DFA2_transition[i] = DFA.unpackEncodedString(DFA2_transitionS[i]);
        }
    }

    class DFA2 extends DFA {

        public DFA2(BaseRecognizer recognizer) {
            this.recognizer = recognizer;
            this.decisionNumber = 2;
            this.eot = DFA2_eot;
            this.eof = DFA2_eof;
            this.min = DFA2_min;
            this.max = DFA2_max;
            this.accept = DFA2_accept;
            this.special = DFA2_special;
            this.transition = DFA2_transition;
        }
        public String getDescription() {
            return "()* loopback of 730:6: ( explainOption )*";
        }
    }
    static final String DFA19_eotS =
        "\u00b8\uffff";
    static final String DFA19_eofS =
        "\u00b8\uffff";
    static final String DFA19_minS =
        "\1\34\1\120\1\uffff\1\120\4\uffff\1\76\3\uffff\2\120\2\33\2\uffff"+
        "\1\163\14\uffff\1\u0084\37\uffff\7\12\1\uffff\3\12\4\uffff\10\12"+
        "\1\uffff\3\12\14\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1"+
        "\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff"+
        "\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0"+
        "\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\4\uffff"+
        "\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0"+
        "\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff"+
        "\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0"+
        "\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0";
    static final String DFA19_maxS =
        "\1\u0132\1\u013b\1\uffff\1\u013b\4\uffff\1\u0122\3\uffff\2\u0116"+
        "\2\u022e\2\uffff\1\u0116\14\uffff\1\u00b1\37\uffff\7\u0149\1\uffff"+
        "\3\u0149\4\uffff\1\u00c8\7\u0149\1\uffff\3\u0149\14\uffff\1\0\1"+
        "\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff"+
        "\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0"+
        "\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff"+
        "\1\0\1\uffff\1\0\1\uffff\1\0\4\uffff\1\0\1\uffff\1\0\1\uffff\1\0"+
        "\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff"+
        "\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0"+
        "\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff"+
        "\1\0";
    static final String DFA19_acceptS =
        "\2\uffff\1\2\1\uffff\1\6\1\7\1\10\2\uffff\1\12\1\22\1\24\4\uffff"+
        "\1\43\1\45\1\uffff\1\17\1\31\1\1\1\uffff\1\4\1\uffff\1\13\1\uffff"+
        "\1\15\1\5\1\14\1\20\1\uffff\1\32\1\3\1\uffff\1\21\1\11\12\uffff"+
        "\1\35\1\36\1\37\1\40\1\44\5\uffff\1\25\1\27\1\uffff\1\26\1\30\10"+
        "\uffff\1\33\3\uffff\1\41\13\uffff\1\34\3\uffff\1\42\4\uffff\1\16"+
        "\3\uffff\1\23\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33"+
        "\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33"+
        "\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33"+
        "\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33"+
        "\1\uffff\1\33\1\uffff\1\34\2\uffff\1\34\1\uffff\1\34\1\uffff\1\34"+
        "\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34"+
        "\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34"+
        "\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34"+
        "\1\uffff\1\34\1\uffff\1\34\1\uffff";
    static final String DFA19_specialS =
        "\16\uffff\1\0\1\1\57\uffff\1\2\1\3\1\4\1\5\1\6\1\7\1\10\1\uffff"+
        "\1\11\1\12\1\13\4\uffff\1\14\1\15\1\16\1\17\1\20\1\21\1\22\1\23"+
        "\1\uffff\1\24\1\25\1\26\14\uffff\1\27\1\uffff\1\30\1\uffff\1\31"+
        "\1\uffff\1\32\1\uffff\1\33\1\uffff\1\34\1\uffff\1\35\1\uffff\1\36"+
        "\1\uffff\1\37\1\uffff\1\40\1\uffff\1\41\1\uffff\1\42\1\uffff\1\43"+
        "\1\uffff\1\44\1\uffff\1\45\1\uffff\1\46\1\uffff\1\47\1\uffff\1\50"+
        "\1\uffff\1\51\1\uffff\1\52\4\uffff\1\53\1\uffff\1\54\1\uffff\1\55"+
        "\1\uffff\1\56\1\uffff\1\57\1\uffff\1\60\1\uffff\1\61\1\uffff\1\62"+
        "\1\uffff\1\63\1\uffff\1\64\1\uffff\1\65\1\uffff\1\66\1\uffff\1\67"+
        "\1\uffff\1\70\1\uffff\1\71\1\uffff\1\72\1\uffff\1\73\1\uffff\1\74"+
        "\1\uffff\1\75\1\uffff\1\76}>";
    static final String[] DFA19_transitionS = {
            "\1\21\4\uffff\1\5\1\13\45\uffff\1\1\23\uffff\2\6\7\uffff\1\3"+
            "\40\uffff\1\16\46\uffff\1\14\16\uffff\1\11\55\uffff\1\12\7\uffff"+
            "\1\17\21\uffff\1\20\2\uffff\1\10\36\uffff\1\4\6\uffff\1\15\4"+
            "\uffff\1\2",
            "\1\25\42\uffff\1\27\20\uffff\1\33\12\uffff\1\23\71\uffff\1"+
            "\31\54\uffff\1\24\5\uffff\1\25\31\uffff\1\27\3\uffff\1\22\40"+
            "\uffff\1\31",
            "",
            "\1\41\63\uffff\1\43\12\uffff\1\36\146\uffff\1\40\5\uffff\1"+
            "\41\31\uffff\1\34\3\uffff\1\37\40\uffff\1\35",
            "",
            "",
            "",
            "",
            "\1\44\3\uffff\1\44\2\uffff\1\44\2\uffff\1\44\2\uffff\1\63\5"+
            "\uffff\1\44\57\uffff\1\44\3\uffff\1\44\1\57\10\uffff\2\44\35"+
            "\uffff\1\44\46\uffff\1\44\7\uffff\1\61\30\uffff\1\60\1\62\5"+
            "\uffff\1\44\30\uffff\2\44\1\uffff\1\44\10\uffff\1\44",
            "",
            "",
            "",
            "\1\72\u00ab\uffff\1\72\31\uffff\1\71",
            "\1\75\u00ab\uffff\1\75\31\uffff\1\74",
            "\5\112\1\77\1\100\1\112\1\uffff\21\112\2\uffff\1\112\1\uffff"+
            "\4\112\1\uffff\2\112\1\uffff\4\112\1\uffff\2\112\1\102\1\uffff"+
            "\1\112\1\uffff\4\112\1\uffff\10\112\1\111\7\112\1\uffff\3\112"+
            "\1\103\2\112\1\uffff\1\112\1\uffff\1\112\2\uffff\4\112\1\uffff"+
            "\1\112\1\uffff\7\112\2\uffff\4\112\1\uffff\1\112\1\uffff\4\112"+
            "\1\uffff\2\112\1\uffff\2\112\1\104\5\112\1\110\2\112\1\uffff"+
            "\5\112\1\uffff\6\112\1\uffff\7\112\1\105\3\112\2\uffff\5\112"+
            "\1\uffff\2\112\1\uffff\4\112\1\uffff\5\112\2\uffff\1\112\1\uffff"+
            "\5\112\1\uffff\2\112\1\uffff\5\112\3\uffff\14\112\1\uffff\20"+
            "\112\1\uffff\6\112\1\106\10\112\1\107\6\112\1\uffff\10\112\1"+
            "\uffff\3\112\1\uffff\6\112\1\uffff\4\112\1\uffff\3\112\1\uffff"+
            "\3\112\1\101\11\112\1\uffff\3\112\2\uffff\1\112\1\uffff\4\112"+
            "\70\uffff\1\112\46\uffff\1\112\61\uffff\1\112\3\uffff\1\112"+
            "\61\uffff\1\112\3\uffff\1\112\27\uffff\1\112\4\uffff\1\112",
            "\5\132\1\117\1\120\1\132\1\uffff\21\132\2\uffff\1\132\1\uffff"+
            "\4\132\1\uffff\2\132\1\uffff\4\132\1\uffff\2\132\1\122\1\uffff"+
            "\1\132\1\uffff\4\132\1\uffff\10\132\1\131\7\132\1\uffff\3\132"+
            "\1\123\2\132\1\uffff\1\132\1\uffff\1\132\2\uffff\4\132\1\uffff"+
            "\1\132\1\uffff\7\132\2\uffff\4\132\1\uffff\1\132\1\uffff\1\132"+
            "\1\116\2\132\1\uffff\2\132\1\uffff\2\132\1\124\5\132\1\130\2"+
            "\132\1\uffff\5\132\1\uffff\6\132\1\uffff\7\132\1\125\3\132\2"+
            "\uffff\5\132\1\uffff\2\132\1\uffff\4\132\1\uffff\5\132\2\uffff"+
            "\1\132\1\uffff\5\132\1\uffff\2\132\1\uffff\5\132\3\uffff\14"+
            "\132\1\uffff\20\132\1\uffff\6\132\1\126\10\132\1\127\6\132\1"+
            "\uffff\10\132\1\uffff\3\132\1\uffff\6\132\1\uffff\4\132\1\uffff"+
            "\3\132\1\uffff\3\132\1\121\11\132\1\uffff\3\132\2\uffff\1\132"+
            "\1\uffff\4\132\70\uffff\1\132\46\uffff\1\132\61\uffff\1\132"+
            "\3\uffff\1\132\61\uffff\1\132\3\uffff\1\132\27\uffff\1\132\4"+
            "\uffff\1\132",
            "",
            "",
            "\1\27\20\uffff\1\33\54\uffff\1\137\144\uffff\1\27",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "\1\43\54\uffff\1\143",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "\1\146\u00bb\uffff\1\147\130\uffff\1\150\51\uffff\1\145",
            "\1\152\u00bb\uffff\1\153\130\uffff\1\154\51\uffff\1\151",
            "\1\156\u00bb\uffff\1\157\130\uffff\1\160\51\uffff\1\155",
            "\1\162\u00bb\uffff\1\163\130\uffff\1\164\51\uffff\1\161",
            "\1\166\u00bb\uffff\1\167\130\uffff\1\170\51\uffff\1\165",
            "\1\172\u00bb\uffff\1\173\130\uffff\1\174\51\uffff\1\171",
            "\1\176\u00bb\uffff\1\177\130\uffff\1\u0080\51\uffff\1\175",
            "",
            "\1\u0082\u00bb\uffff\1\u0083\130\uffff\1\u0084\51\uffff\1\u0081",
            "\1\u0086\u00bb\uffff\1\u0087\130\uffff\1\u0088\51\uffff\1\u0085",
            "\1\u008a\u00bb\uffff\1\u008b\130\uffff\1\u008c\51\uffff\1\u0089",
            "",
            "",
            "",
            "",
            "\1\132\167\uffff\1\132\105\uffff\1\u008d",
            "\1\u0091\167\uffff\1\u0093\103\uffff\1\u0092\u0082\uffff\1"+
            "\u0090",
            "\1\u0095\167\uffff\1\u0097\103\uffff\1\u0096\u0082\uffff\1"+
            "\u0094",
            "\1\u0099\167\uffff\1\u009b\103\uffff\1\u009a\u0082\uffff\1"+
            "\u0098",
            "\1\u009d\167\uffff\1\u009f\103\uffff\1\u009e\u0082\uffff\1"+
            "\u009c",
            "\1\u00a1\167\uffff\1\u00a3\103\uffff\1\u00a2\u0082\uffff\1"+
            "\u00a0",
            "\1\u00a5\167\uffff\1\u00a7\103\uffff\1\u00a6\u0082\uffff\1"+
            "\u00a4",
            "\1\u00a9\167\uffff\1\u00ab\103\uffff\1\u00aa\u0082\uffff\1"+
            "\u00a8",
            "",
            "\1\u00ad\167\uffff\1\u00af\103\uffff\1\u00ae\u0082\uffff\1"+
            "\u00ac",
            "\1\u00b1\167\uffff\1\u00b3\103\uffff\1\u00b2\u0082\uffff\1"+
            "\u00b0",
            "\1\u00b5\167\uffff\1\u00b7\103\uffff\1\u00b6\u0082\uffff\1"+
            "\u00b4",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "",
            "",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff"
    };

    static final short[] DFA19_eot = DFA.unpackEncodedString(DFA19_eotS);
    static final short[] DFA19_eof = DFA.unpackEncodedString(DFA19_eofS);
    static final char[] DFA19_min = DFA.unpackEncodedStringToUnsignedChars(DFA19_minS);
    static final char[] DFA19_max = DFA.unpackEncodedStringToUnsignedChars(DFA19_maxS);
    static final short[] DFA19_accept = DFA.unpackEncodedString(DFA19_acceptS);
    static final short[] DFA19_special = DFA.unpackEncodedString(DFA19_specialS);
    static final short[][] DFA19_transition;

    static {
        int numStates = DFA19_transitionS.length;
        DFA19_transition = new short[numStates][];
        for (int i=0; i<numStates; i++) {
            DFA19_transition[i] = DFA.unpackEncodedString(DFA19_transitionS[i]);
        }
    }

    class DFA19 extends DFA {

        public DFA19(BaseRecognizer recognizer) {
            this.recognizer = recognizer;
            this.decisionNumber = 19;
            this.eot = DFA19_eot;
            this.eof = DFA19_eof;
            this.min = DFA19_min;
            this.max = DFA19_max;
            this.accept = DFA19_accept;
            this.special = DFA19_special;
            this.transition = DFA19_transition;
        }
        public String getDescription() {
            return "821:1: ddlStatement : ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | dropViewStatement | createFunctionStatement | createMacroStatement | createIndexStatement | dropIndexStatement | dropFunctionStatement | reloadFunctionStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | ( grantPrivileges )=> grantPrivileges | ( revokePrivileges )=> revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole | abortTransactionStatement );";
        }
        public int specialStateTransition(int s, IntStream _input) throws NoViableAltException {
            TokenStream input = (TokenStream)_input;
        	int _s = s;
            switch ( s ) {
                    case 0 : 
                        int LA19_14 = input.LA(1);

                         
                        int index19_14 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_14==KW_ALL) ) {s = 63;}

                        else if ( (LA19_14==KW_ALTER) ) {s = 64;}

                        else if ( (LA19_14==KW_UPDATE) ) {s = 65;}

                        else if ( (LA19_14==KW_CREATE) ) {s = 66;}

                        else if ( (LA19_14==KW_DROP) ) {s = 67;}

                        else if ( (LA19_14==KW_INDEX) ) {s = 68;}

                        else if ( (LA19_14==KW_LOCK) ) {s = 69;}

                        else if ( (LA19_14==KW_SELECT) && (synpred1_HiveParser())) {s = 70;}

                        else if ( (LA19_14==KW_SHOW_DATABASE) ) {s = 71;}

                        else if ( (LA19_14==KW_INSERT) ) {s = 72;}

                        else if ( (LA19_14==KW_DELETE) ) {s = 73;}

                        else if ( ((LA19_14 >= Identifier && LA19_14 <= KW_AFTER)||LA19_14==KW_ANALYZE||(LA19_14 >= KW_ARCHIVE && LA19_14 <= KW_CASCADE)||LA19_14==KW_CHANGE||(LA19_14 >= KW_CLUSTER && LA19_14 <= KW_COLLECTION)||(LA19_14 >= KW_COLUMNS && LA19_14 <= KW_COMMENT)||(LA19_14 >= KW_COMPACT && LA19_14 <= KW_CONCATENATE)||(LA19_14 >= KW_CONSTRAINT && LA19_14 <= KW_CONTINUE)||LA19_14==KW_CUBE||(LA19_14 >= KW_CURRENT_DATE && LA19_14 <= KW_DATA)||(LA19_14 >= KW_DATABASES && LA19_14 <= KW_DEFINED)||(LA19_14 >= KW_DELIMITED && LA19_14 <= KW_DISABLE)||(LA19_14 >= KW_DISTRIBUTE && LA19_14 <= KW_DOW)||(LA19_14 >= KW_DUMP && LA19_14 <= KW_ELEM_TYPE)||LA19_14==KW_ENABLE||LA19_14==KW_ESCAPED||(LA19_14 >= KW_EXCLUSIVE && LA19_14 <= KW_EXPORT)||LA19_14==KW_EXTERNAL||(LA19_14 >= KW_FALSE && LA19_14 <= KW_FLOAT)||(LA19_14 >= KW_FOR && LA19_14 <= KW_FORMATTED)||LA19_14==KW_FULL||(LA19_14 >= KW_FUNCTIONS && LA19_14 <= KW_GROUPING)||(LA19_14 >= KW_HOUR && LA19_14 <= KW_IDXPROPERTIES)||(LA19_14 >= KW_IMPORT && LA19_14 <= KW_IN)||(LA19_14 >= KW_INDEXES && LA19_14 <= KW_INPUTFORMAT)||(LA19_14 >= KW_INT && LA19_14 <= KW_INTERSECT)||(LA19_14 >= KW_INTO && LA19_14 <= KW_JAR)||(LA19_14 >= KW_KEY && LA19_14 <= KW_LEFT)||(LA19_14 >= KW_LEVEL && LA19_14 <= KW_LOCATION)||(LA19_14 >= KW_LOCKS && LA19_14 <= KW_LONG)||(LA19_14 >= KW_MAPJOIN && LA19_14 <= KW_METADATA)||(LA19_14 >= KW_MINUTE && LA19_14 <= KW_MONTH)||(LA19_14 >= KW_MSCK && LA19_14 <= KW_NOSCAN)||(LA19_14 >= KW_NOVALIDATE && LA19_14 <= KW_OFFSET)||LA19_14==KW_OPTION||(LA19_14 >= KW_ORDER && LA19_14 <= KW_OUTPUTFORMAT)||(LA19_14 >= KW_OVERWRITE && LA19_14 <= KW_OWNER)||(LA19_14 >= KW_PARTITION && LA19_14 <= KW_PLUS)||(LA19_14 >= KW_PRETTY && LA19_14 <= KW_RECORDWRITER)||(LA19_14 >= KW_REFERENCES && LA19_14 <= KW_ROLES)||(LA19_14 >= KW_ROLLUP && LA19_14 <= KW_SECOND)||(LA19_14 >= KW_SEMI && LA19_14 <= KW_SHOW)||(LA19_14 >= KW_SKEWED && LA19_14 <= KW_SSL)||(LA19_14 >= KW_STATISTICS && LA19_14 <= KW_TABLES)||(LA19_14 >= KW_TBLPROPERTIES && LA19_14 <= KW_TERMINATED)||(LA19_14 >= KW_TIMESTAMP && LA19_14 <= KW_TRANSACTIONS)||(LA19_14 >= KW_TRIGGER && LA19_14 <= KW_UNARCHIVE)||(LA19_14 >= KW_UNDO && LA19_14 <= KW_UNIONTYPE)||(LA19_14 >= KW_UNLOCK && LA19_14 <= KW_UNSIGNED)||(LA19_14 >= KW_URI && LA19_14 <= KW_VALUE_TYPE)||(LA19_14 >= KW_VIEW && LA19_14 <= KW_WEEK)||LA19_14==KW_WHILE||(LA19_14 >= KW_WITH && LA19_14 <= KW_YEAR)||LA19_14==KW_BATCH||LA19_14==KW_DAYOFWEEK||LA19_14==KW_HOLD_DDLTIME||LA19_14==KW_IGNORE||LA19_14==KW_NO_DROP||LA19_14==KW_OFFLINE||LA19_14==KW_PROTECTION||LA19_14==KW_READONLY) ) {s = 74;}

                         
                        input.seek(index19_14);

                        if ( s>=0 ) return s;
                        break;
                    case 1 : 
                        int LA19_15 = input.LA(1);

                         
                        int index19_15 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_15==KW_GRANT) ) {s = 78;}

                        else if ( (LA19_15==KW_ALL) ) {s = 79;}

                        else if ( (LA19_15==KW_ALTER) ) {s = 80;}

                        else if ( (LA19_15==KW_UPDATE) ) {s = 81;}

                        else if ( (LA19_15==KW_CREATE) ) {s = 82;}

                        else if ( (LA19_15==KW_DROP) ) {s = 83;}

                        else if ( (LA19_15==KW_INDEX) ) {s = 84;}

                        else if ( (LA19_15==KW_LOCK) ) {s = 85;}

                        else if ( (LA19_15==KW_SELECT) && (synpred2_HiveParser())) {s = 86;}

                        else if ( (LA19_15==KW_SHOW_DATABASE) ) {s = 87;}

                        else if ( (LA19_15==KW_INSERT) ) {s = 88;}

                        else if ( (LA19_15==KW_DELETE) ) {s = 89;}

                        else if ( ((LA19_15 >= Identifier && LA19_15 <= KW_AFTER)||LA19_15==KW_ANALYZE||(LA19_15 >= KW_ARCHIVE && LA19_15 <= KW_CASCADE)||LA19_15==KW_CHANGE||(LA19_15 >= KW_CLUSTER && LA19_15 <= KW_COLLECTION)||(LA19_15 >= KW_COLUMNS && LA19_15 <= KW_COMMENT)||(LA19_15 >= KW_COMPACT && LA19_15 <= KW_CONCATENATE)||(LA19_15 >= KW_CONSTRAINT && LA19_15 <= KW_CONTINUE)||LA19_15==KW_CUBE||(LA19_15 >= KW_CURRENT_DATE && LA19_15 <= KW_DATA)||(LA19_15 >= KW_DATABASES && LA19_15 <= KW_DEFINED)||(LA19_15 >= KW_DELIMITED && LA19_15 <= KW_DISABLE)||(LA19_15 >= KW_DISTRIBUTE && LA19_15 <= KW_DOW)||(LA19_15 >= KW_DUMP && LA19_15 <= KW_ELEM_TYPE)||LA19_15==KW_ENABLE||LA19_15==KW_ESCAPED||(LA19_15 >= KW_EXCLUSIVE && LA19_15 <= KW_EXPORT)||LA19_15==KW_EXTERNAL||(LA19_15 >= KW_FALSE && LA19_15 <= KW_FLOAT)||(LA19_15 >= KW_FOR && LA19_15 <= KW_FORMATTED)||LA19_15==KW_FULL||LA19_15==KW_FUNCTIONS||(LA19_15 >= KW_GROUP && LA19_15 <= KW_GROUPING)||(LA19_15 >= KW_HOUR && LA19_15 <= KW_IDXPROPERTIES)||(LA19_15 >= KW_IMPORT && LA19_15 <= KW_IN)||(LA19_15 >= KW_INDEXES && LA19_15 <= KW_INPUTFORMAT)||(LA19_15 >= KW_INT && LA19_15 <= KW_INTERSECT)||(LA19_15 >= KW_INTO && LA19_15 <= KW_JAR)||(LA19_15 >= KW_KEY && LA19_15 <= KW_LEFT)||(LA19_15 >= KW_LEVEL && LA19_15 <= KW_LOCATION)||(LA19_15 >= KW_LOCKS && LA19_15 <= KW_LONG)||(LA19_15 >= KW_MAPJOIN && LA19_15 <= KW_METADATA)||(LA19_15 >= KW_MINUTE && LA19_15 <= KW_MONTH)||(LA19_15 >= KW_MSCK && LA19_15 <= KW_NOSCAN)||(LA19_15 >= KW_NOVALIDATE && LA19_15 <= KW_OFFSET)||LA19_15==KW_OPTION||(LA19_15 >= KW_ORDER && LA19_15 <= KW_OUTPUTFORMAT)||(LA19_15 >= KW_OVERWRITE && LA19_15 <= KW_OWNER)||(LA19_15 >= KW_PARTITION && LA19_15 <= KW_PLUS)||(LA19_15 >= KW_PRETTY && LA19_15 <= KW_RECORDWRITER)||(LA19_15 >= KW_REFERENCES && LA19_15 <= KW_ROLES)||(LA19_15 >= KW_ROLLUP && LA19_15 <= KW_SECOND)||(LA19_15 >= KW_SEMI && LA19_15 <= KW_SHOW)||(LA19_15 >= KW_SKEWED && LA19_15 <= KW_SSL)||(LA19_15 >= KW_STATISTICS && LA19_15 <= KW_TABLES)||(LA19_15 >= KW_TBLPROPERTIES && LA19_15 <= KW_TERMINATED)||(LA19_15 >= KW_TIMESTAMP && LA19_15 <= KW_TRANSACTIONS)||(LA19_15 >= KW_TRIGGER && LA19_15 <= KW_UNARCHIVE)||(LA19_15 >= KW_UNDO && LA19_15 <= KW_UNIONTYPE)||(LA19_15 >= KW_UNLOCK && LA19_15 <= KW_UNSIGNED)||(LA19_15 >= KW_URI && LA19_15 <= KW_VALUE_TYPE)||(LA19_15 >= KW_VIEW && LA19_15 <= KW_WEEK)||LA19_15==KW_WHILE||(LA19_15 >= KW_WITH && LA19_15 <= KW_YEAR)||LA19_15==KW_BATCH||LA19_15==KW_DAYOFWEEK||LA19_15==KW_HOLD_DDLTIME||LA19_15==KW_IGNORE||LA19_15==KW_NO_DROP||LA19_15==KW_OFFLINE||LA19_15==KW_PROTECTION||LA19_15==KW_READONLY) ) {s = 90;}

                         
                        input.seek(index19_15);

                        if ( s>=0 ) return s;
                        break;
                    case 2 : 
                        int LA19_63 = input.LA(1);

                         
                        int index19_63 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_63==LPAREN) && (synpred1_HiveParser())) {s = 101;}

                        else if ( (LA19_63==COMMA) ) {s = 102;}

                        else if ( (LA19_63==KW_ON) && (synpred1_HiveParser())) {s = 103;}

                        else if ( (LA19_63==KW_TO) ) {s = 104;}

                         
                        input.seek(index19_63);

                        if ( s>=0 ) return s;
                        break;
                    case 3 : 
                        int LA19_64 = input.LA(1);

                         
                        int index19_64 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_64==LPAREN) && (synpred1_HiveParser())) {s = 105;}

                        else if ( (LA19_64==COMMA) ) {s = 106;}

                        else if ( (LA19_64==KW_ON) && (synpred1_HiveParser())) {s = 107;}

                        else if ( (LA19_64==KW_TO) ) {s = 108;}

                         
                        input.seek(index19_64);

                        if ( s>=0 ) return s;
                        break;
                    case 4 : 
                        int LA19_65 = input.LA(1);

                         
                        int index19_65 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_65==LPAREN) && (synpred1_HiveParser())) {s = 109;}

                        else if ( (LA19_65==COMMA) ) {s = 110;}

                        else if ( (LA19_65==KW_ON) && (synpred1_HiveParser())) {s = 111;}

                        else if ( (LA19_65==KW_TO) ) {s = 112;}

                         
                        input.seek(index19_65);

                        if ( s>=0 ) return s;
                        break;
                    case 5 : 
                        int LA19_66 = input.LA(1);

                         
                        int index19_66 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_66==LPAREN) && (synpred1_HiveParser())) {s = 113;}

                        else if ( (LA19_66==COMMA) ) {s = 114;}

                        else if ( (LA19_66==KW_ON) && (synpred1_HiveParser())) {s = 115;}

                        else if ( (LA19_66==KW_TO) ) {s = 116;}

                         
                        input.seek(index19_66);

                        if ( s>=0 ) return s;
                        break;
                    case 6 : 
                        int LA19_67 = input.LA(1);

                         
                        int index19_67 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_67==LPAREN) && (synpred1_HiveParser())) {s = 117;}

                        else if ( (LA19_67==COMMA) ) {s = 118;}

                        else if ( (LA19_67==KW_ON) && (synpred1_HiveParser())) {s = 119;}

                        else if ( (LA19_67==KW_TO) ) {s = 120;}

                         
                        input.seek(index19_67);

                        if ( s>=0 ) return s;
                        break;
                    case 7 : 
                        int LA19_68 = input.LA(1);

                         
                        int index19_68 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_68==LPAREN) && (synpred1_HiveParser())) {s = 121;}

                        else if ( (LA19_68==COMMA) ) {s = 122;}

                        else if ( (LA19_68==KW_ON) && (synpred1_HiveParser())) {s = 123;}

                        else if ( (LA19_68==KW_TO) ) {s = 124;}

                         
                        input.seek(index19_68);

                        if ( s>=0 ) return s;
                        break;
                    case 8 : 
                        int LA19_69 = input.LA(1);

                         
                        int index19_69 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_69==LPAREN) && (synpred1_HiveParser())) {s = 125;}

                        else if ( (LA19_69==COMMA) ) {s = 126;}

                        else if ( (LA19_69==KW_ON) && (synpred1_HiveParser())) {s = 127;}

                        else if ( (LA19_69==KW_TO) ) {s = 128;}

                         
                        input.seek(index19_69);

                        if ( s>=0 ) return s;
                        break;
                    case 9 : 
                        int LA19_71 = input.LA(1);

                         
                        int index19_71 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_71==LPAREN) && (synpred1_HiveParser())) {s = 129;}

                        else if ( (LA19_71==COMMA) ) {s = 130;}

                        else if ( (LA19_71==KW_ON) && (synpred1_HiveParser())) {s = 131;}

                        else if ( (LA19_71==KW_TO) ) {s = 132;}

                         
                        input.seek(index19_71);

                        if ( s>=0 ) return s;
                        break;
                    case 10 : 
                        int LA19_72 = input.LA(1);

                         
                        int index19_72 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_72==LPAREN) && (synpred1_HiveParser())) {s = 133;}

                        else if ( (LA19_72==COMMA) ) {s = 134;}

                        else if ( (LA19_72==KW_ON) && (synpred1_HiveParser())) {s = 135;}

                        else if ( (LA19_72==KW_TO) ) {s = 136;}

                         
                        input.seek(index19_72);

                        if ( s>=0 ) return s;
                        break;
                    case 11 : 
                        int LA19_73 = input.LA(1);

                         
                        int index19_73 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_73==LPAREN) && (synpred1_HiveParser())) {s = 137;}

                        else if ( (LA19_73==COMMA) ) {s = 138;}

                        else if ( (LA19_73==KW_ON) && (synpred1_HiveParser())) {s = 139;}

                        else if ( (LA19_73==KW_TO) ) {s = 140;}

                         
                        input.seek(index19_73);

                        if ( s>=0 ) return s;
                        break;
                    case 12 : 
                        int LA19_78 = input.LA(1);

                         
                        int index19_78 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_78==KW_OPTION) && (synpred2_HiveParser())) {s = 141;}

                        else if ( (LA19_78==COMMA||LA19_78==KW_FROM) ) {s = 90;}

                         
                        input.seek(index19_78);

                        if ( s>=0 ) return s;
                        break;
                    case 13 : 
                        int LA19_79 = input.LA(1);

                         
                        int index19_79 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_79==LPAREN) && (synpred2_HiveParser())) {s = 144;}

                        else if ( (LA19_79==COMMA) ) {s = 145;}

                        else if ( (LA19_79==KW_ON) && (synpred2_HiveParser())) {s = 146;}

                        else if ( (LA19_79==KW_FROM) ) {s = 147;}

                         
                        input.seek(index19_79);

                        if ( s>=0 ) return s;
                        break;
                    case 14 : 
                        int LA19_80 = input.LA(1);

                         
                        int index19_80 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_80==LPAREN) && (synpred2_HiveParser())) {s = 148;}

                        else if ( (LA19_80==COMMA) ) {s = 149;}

                        else if ( (LA19_80==KW_ON) && (synpred2_HiveParser())) {s = 150;}

                        else if ( (LA19_80==KW_FROM) ) {s = 151;}

                         
                        input.seek(index19_80);

                        if ( s>=0 ) return s;
                        break;
                    case 15 : 
                        int LA19_81 = input.LA(1);

                         
                        int index19_81 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_81==LPAREN) && (synpred2_HiveParser())) {s = 152;}

                        else if ( (LA19_81==COMMA) ) {s = 153;}

                        else if ( (LA19_81==KW_ON) && (synpred2_HiveParser())) {s = 154;}

                        else if ( (LA19_81==KW_FROM) ) {s = 155;}

                         
                        input.seek(index19_81);

                        if ( s>=0 ) return s;
                        break;
                    case 16 : 
                        int LA19_82 = input.LA(1);

                         
                        int index19_82 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_82==LPAREN) && (synpred2_HiveParser())) {s = 156;}

                        else if ( (LA19_82==COMMA) ) {s = 157;}

                        else if ( (LA19_82==KW_ON) && (synpred2_HiveParser())) {s = 158;}

                        else if ( (LA19_82==KW_FROM) ) {s = 159;}

                         
                        input.seek(index19_82);

                        if ( s>=0 ) return s;
                        break;
                    case 17 : 
                        int LA19_83 = input.LA(1);

                         
                        int index19_83 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_83==LPAREN) && (synpred2_HiveParser())) {s = 160;}

                        else if ( (LA19_83==COMMA) ) {s = 161;}

                        else if ( (LA19_83==KW_ON) && (synpred2_HiveParser())) {s = 162;}

                        else if ( (LA19_83==KW_FROM) ) {s = 163;}

                         
                        input.seek(index19_83);

                        if ( s>=0 ) return s;
                        break;
                    case 18 : 
                        int LA19_84 = input.LA(1);

                         
                        int index19_84 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_84==LPAREN) && (synpred2_HiveParser())) {s = 164;}

                        else if ( (LA19_84==COMMA) ) {s = 165;}

                        else if ( (LA19_84==KW_ON) && (synpred2_HiveParser())) {s = 166;}

                        else if ( (LA19_84==KW_FROM) ) {s = 167;}

                         
                        input.seek(index19_84);

                        if ( s>=0 ) return s;
                        break;
                    case 19 : 
                        int LA19_85 = input.LA(1);

                         
                        int index19_85 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_85==LPAREN) && (synpred2_HiveParser())) {s = 168;}

                        else if ( (LA19_85==COMMA) ) {s = 169;}

                        else if ( (LA19_85==KW_ON) && (synpred2_HiveParser())) {s = 170;}

                        else if ( (LA19_85==KW_FROM) ) {s = 171;}

                         
                        input.seek(index19_85);

                        if ( s>=0 ) return s;
                        break;
                    case 20 : 
                        int LA19_87 = input.LA(1);

                         
                        int index19_87 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_87==LPAREN) && (synpred2_HiveParser())) {s = 172;}

                        else if ( (LA19_87==COMMA) ) {s = 173;}

                        else if ( (LA19_87==KW_ON) && (synpred2_HiveParser())) {s = 174;}

                        else if ( (LA19_87==KW_FROM) ) {s = 175;}

                         
                        input.seek(index19_87);

                        if ( s>=0 ) return s;
                        break;
                    case 21 : 
                        int LA19_88 = input.LA(1);

                         
                        int index19_88 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_88==LPAREN) && (synpred2_HiveParser())) {s = 176;}

                        else if ( (LA19_88==COMMA) ) {s = 177;}

                        else if ( (LA19_88==KW_ON) && (synpred2_HiveParser())) {s = 178;}

                        else if ( (LA19_88==KW_FROM) ) {s = 179;}

                         
                        input.seek(index19_88);

                        if ( s>=0 ) return s;
                        break;
                    case 22 : 
                        int LA19_89 = input.LA(1);

                         
                        int index19_89 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA19_89==LPAREN) && (synpred2_HiveParser())) {s = 180;}

                        else if ( (LA19_89==COMMA) ) {s = 181;}

                        else if ( (LA19_89==KW_ON) && (synpred2_HiveParser())) {s = 182;}

                        else if ( (LA19_89==KW_FROM) ) {s = 183;}

                         
                        input.seek(index19_89);

                        if ( s>=0 ) return s;
                        break;
                    case 23 : 
                        int LA19_102 = input.LA(1);

                         
                        int index19_102 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_102);

                        if ( s>=0 ) return s;
                        break;
                    case 24 : 
                        int LA19_104 = input.LA(1);

                         
                        int index19_104 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_104);

                        if ( s>=0 ) return s;
                        break;
                    case 25 : 
                        int LA19_106 = input.LA(1);

                         
                        int index19_106 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_106);

                        if ( s>=0 ) return s;
                        break;
                    case 26 : 
                        int LA19_108 = input.LA(1);

                         
                        int index19_108 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_108);

                        if ( s>=0 ) return s;
                        break;
                    case 27 : 
                        int LA19_110 = input.LA(1);

                         
                        int index19_110 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_110);

                        if ( s>=0 ) return s;
                        break;
                    case 28 : 
                        int LA19_112 = input.LA(1);

                         
                        int index19_112 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_112);

                        if ( s>=0 ) return s;
                        break;
                    case 29 : 
                        int LA19_114 = input.LA(1);

                         
                        int index19_114 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_114);

                        if ( s>=0 ) return s;
                        break;
                    case 30 : 
                        int LA19_116 = input.LA(1);

                         
                        int index19_116 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_116);

                        if ( s>=0 ) return s;
                        break;
                    case 31 : 
                        int LA19_118 = input.LA(1);

                         
                        int index19_118 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_118);

                        if ( s>=0 ) return s;
                        break;
                    case 32 : 
                        int LA19_120 = input.LA(1);

                         
                        int index19_120 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_120);

                        if ( s>=0 ) return s;
                        break;
                    case 33 : 
                        int LA19_122 = input.LA(1);

                         
                        int index19_122 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_122);

                        if ( s>=0 ) return s;
                        break;
                    case 34 : 
                        int LA19_124 = input.LA(1);

                         
                        int index19_124 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_124);

                        if ( s>=0 ) return s;
                        break;
                    case 35 : 
                        int LA19_126 = input.LA(1);

                         
                        int index19_126 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_126);

                        if ( s>=0 ) return s;
                        break;
                    case 36 : 
                        int LA19_128 = input.LA(1);

                         
                        int index19_128 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_128);

                        if ( s>=0 ) return s;
                        break;
                    case 37 : 
                        int LA19_130 = input.LA(1);

                         
                        int index19_130 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_130);

                        if ( s>=0 ) return s;
                        break;
                    case 38 : 
                        int LA19_132 = input.LA(1);

                         
                        int index19_132 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_132);

                        if ( s>=0 ) return s;
                        break;
                    case 39 : 
                        int LA19_134 = input.LA(1);

                         
                        int index19_134 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_134);

                        if ( s>=0 ) return s;
                        break;
                    case 40 : 
                        int LA19_136 = input.LA(1);

                         
                        int index19_136 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_136);

                        if ( s>=0 ) return s;
                        break;
                    case 41 : 
                        int LA19_138 = input.LA(1);

                         
                        int index19_138 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_138);

                        if ( s>=0 ) return s;
                        break;
                    case 42 : 
                        int LA19_140 = input.LA(1);

                         
                        int index19_140 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred1_HiveParser()) ) {s = 139;}

                        else if ( (true) ) {s = 74;}

                         
                        input.seek(index19_140);

                        if ( s>=0 ) return s;
                        break;
                    case 43 : 
                        int LA19_145 = input.LA(1);

                         
                        int index19_145 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_145);

                        if ( s>=0 ) return s;
                        break;
                    case 44 : 
                        int LA19_147 = input.LA(1);

                         
                        int index19_147 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_147);

                        if ( s>=0 ) return s;
                        break;
                    case 45 : 
                        int LA19_149 = input.LA(1);

                         
                        int index19_149 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_149);

                        if ( s>=0 ) return s;
                        break;
                    case 46 : 
                        int LA19_151 = input.LA(1);

                         
                        int index19_151 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_151);

                        if ( s>=0 ) return s;
                        break;
                    case 47 : 
                        int LA19_153 = input.LA(1);

                         
                        int index19_153 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_153);

                        if ( s>=0 ) return s;
                        break;
                    case 48 : 
                        int LA19_155 = input.LA(1);

                         
                        int index19_155 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_155);

                        if ( s>=0 ) return s;
                        break;
                    case 49 : 
                        int LA19_157 = input.LA(1);

                         
                        int index19_157 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_157);

                        if ( s>=0 ) return s;
                        break;
                    case 50 : 
                        int LA19_159 = input.LA(1);

                         
                        int index19_159 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_159);

                        if ( s>=0 ) return s;
                        break;
                    case 51 : 
                        int LA19_161 = input.LA(1);

                         
                        int index19_161 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_161);

                        if ( s>=0 ) return s;
                        break;
                    case 52 : 
                        int LA19_163 = input.LA(1);

                         
                        int index19_163 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_163);

                        if ( s>=0 ) return s;
                        break;
                    case 53 : 
                        int LA19_165 = input.LA(1);

                         
                        int index19_165 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_165);

                        if ( s>=0 ) return s;
                        break;
                    case 54 : 
                        int LA19_167 = input.LA(1);

                         
                        int index19_167 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_167);

                        if ( s>=0 ) return s;
                        break;
                    case 55 : 
                        int LA19_169 = input.LA(1);

                         
                        int index19_169 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_169);

                        if ( s>=0 ) return s;
                        break;
                    case 56 : 
                        int LA19_171 = input.LA(1);

                         
                        int index19_171 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_171);

                        if ( s>=0 ) return s;
                        break;
                    case 57 : 
                        int LA19_173 = input.LA(1);

                         
                        int index19_173 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_173);

                        if ( s>=0 ) return s;
                        break;
                    case 58 : 
                        int LA19_175 = input.LA(1);

                         
                        int index19_175 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_175);

                        if ( s>=0 ) return s;
                        break;
                    case 59 : 
                        int LA19_177 = input.LA(1);

                         
                        int index19_177 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_177);

                        if ( s>=0 ) return s;
                        break;
                    case 60 : 
                        int LA19_179 = input.LA(1);

                         
                        int index19_179 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_179);

                        if ( s>=0 ) return s;
                        break;
                    case 61 : 
                        int LA19_181 = input.LA(1);

                         
                        int index19_181 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_181);

                        if ( s>=0 ) return s;
                        break;
                    case 62 : 
                        int LA19_183 = input.LA(1);

                         
                        int index19_183 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred2_HiveParser()) ) {s = 182;}

                        else if ( (true) ) {s = 90;}

                         
                        input.seek(index19_183);

                        if ( s>=0 ) return s;
                        break;
            }
            if (state.backtracking>0) {state.failed=true; return -1;}

            NoViableAltException nvae =
                new NoViableAltException(getDescription(), 19, _s, input);
            error(nvae);
            throw nvae;
        }

    }
    static final String DFA119_eotS =
        "\130\uffff";
    static final String DFA119_eofS =
        "\2\uffff\1\7\1\uffff\1\7\1\uffff\1\7\121\uffff";
    static final String DFA119_minS =
        "\1\33\1\uffff\1\22\1\uffff\1\22\1\uffff\1\22\4\uffff\3\0\1\uffff"+
        "\1\0\1\uffff\3\0\1\uffff\1\0\1\uffff\3\0\1\uffff\1\0\74\uffff";
    static final String DFA119_maxS =
        "\1\u022e\1\uffff\1\u022e\1\uffff\1\u022e\1\uffff\1\u022e\4\uffff"+
        "\3\0\1\uffff\1\0\1\uffff\3\0\1\uffff\1\0\1\uffff\3\0\1\uffff\1\0"+
        "\74\uffff";
    static final String DFA119_acceptS =
        "\1\uffff\1\1\1\uffff\1\2\1\uffff\1\3\1\uffff\1\4\2\uffff\1\1\115"+
        "\uffff";
    static final String DFA119_specialS =
        "\1\0\1\uffff\1\1\10\uffff\1\2\1\3\1\4\1\uffff\1\5\1\uffff\1\6\1"+
        "\7\1\10\1\uffff\1\11\1\uffff\1\12\1\13\1\14\1\uffff\1\15\74\uffff}>";
    static final String[] DFA119_transitionS = {
            "\10\7\1\uffff\21\7\2\uffff\1\7\1\uffff\4\7\1\uffff\2\7\1\uffff"+
            "\4\7\1\uffff\3\7\1\uffff\1\7\1\uffff\4\7\1\1\20\7\1\uffff\6"+
            "\7\1\uffff\1\7\1\uffff\1\7\2\uffff\4\7\1\5\1\7\1\uffff\7\7\2"+
            "\uffff\3\7\1\4\1\uffff\1\7\1\3\4\7\1\uffff\2\7\1\uffff\13\7"+
            "\1\uffff\5\7\1\uffff\6\7\1\uffff\13\7\2\uffff\5\7\1\uffff\2"+
            "\7\1\uffff\4\7\1\uffff\5\7\2\uffff\1\7\1\uffff\5\7\1\uffff\2"+
            "\7\1\uffff\5\7\3\uffff\1\6\13\7\1\uffff\20\7\1\uffff\3\7\1\2"+
            "\2\7\1\uffff\17\7\1\uffff\10\7\1\uffff\3\7\1\uffff\6\7\1\uffff"+
            "\4\7\1\uffff\3\7\1\uffff\15\7\1\uffff\3\7\2\uffff\1\7\1\uffff"+
            "\4\7\70\uffff\1\7\46\uffff\1\7\61\uffff\1\7\3\uffff\1\7\61\uffff"+
            "\1\7\3\uffff\1\7\27\uffff\1\7\4\uffff\1\7",
            "",
            "\1\7\10\uffff\1\13\4\14\2\17\1\14\1\uffff\1\14\2\17\1\14\1"+
            "\17\2\14\5\17\2\14\1\17\2\14\2\uffff\1\14\1\uffff\4\14\1\uffff"+
            "\2\14\1\uffff\4\14\1\uffff\1\17\1\14\1\17\1\uffff\1\17\1\uffff"+
            "\3\17\1\14\1\uffff\1\14\1\17\3\14\1\17\2\14\1\17\3\14\1\17\3"+
            "\14\1\uffff\1\14\1\17\1\14\1\17\2\14\1\uffff\1\14\1\uffff\1"+
            "\14\2\uffff\1\14\1\17\2\14\1\12\1\17\1\uffff\2\17\4\14\1\17"+
            "\2\uffff\2\17\2\14\1\uffff\1\17\1\uffff\1\14\3\17\1\uffff\2"+
            "\14\1\uffff\2\17\2\14\1\17\3\14\3\17\1\uffff\2\17\3\14\1\uffff"+
            "\4\14\2\17\1\uffff\1\14\1\17\3\14\1\17\5\14\2\uffff\5\14\1\uffff"+
            "\2\14\1\uffff\1\14\1\17\2\14\1\uffff\1\14\1\17\1\14\1\17\1\14"+
            "\2\uffff\1\14\1\uffff\3\17\2\14\1\uffff\2\14\1\uffff\1\15\2"+
            "\14\1\17\1\14\3\uffff\1\14\1\17\1\14\1\17\2\14\1\17\1\14\1\17"+
            "\3\14\1\uffff\2\17\10\14\1\17\1\14\2\17\2\14\1\uffff\3\17\3"+
            "\14\1\uffff\4\14\1\17\5\14\1\17\4\14\1\uffff\6\14\1\17\1\14"+
            "\1\uffff\3\14\1\uffff\1\17\1\14\1\17\3\14\1\uffff\3\17\1\14"+
            "\1\uffff\1\14\1\17\1\14\1\uffff\3\14\1\17\2\14\2\17\3\14\1\17"+
            "\1\14\1\uffff\3\14\2\uffff\1\14\1\uffff\1\17\3\14\70\uffff\1"+
            "\14\46\uffff\1\14\61\uffff\1\14\3\uffff\1\14\61\uffff\1\14\3"+
            "\uffff\1\14\27\uffff\1\14\4\uffff\1\14",
            "",
            "\1\7\10\uffff\1\21\4\22\2\25\1\22\1\uffff\1\22\2\25\1\22\1"+
            "\25\2\22\5\25\2\22\1\25\2\22\2\uffff\1\22\1\uffff\4\22\1\uffff"+
            "\2\22\1\uffff\4\22\1\uffff\1\25\1\22\1\25\1\uffff\1\25\1\uffff"+
            "\3\25\1\22\1\uffff\1\22\1\25\3\22\1\25\2\22\1\25\3\22\1\25\3"+
            "\22\1\uffff\1\22\1\25\1\22\1\25\2\22\1\uffff\1\22\1\uffff\1"+
            "\22\2\uffff\1\22\1\25\2\22\1\uffff\1\25\1\uffff\2\25\4\22\1"+
            "\25\2\uffff\2\25\2\22\1\uffff\1\25\1\uffff\1\22\3\25\1\uffff"+
            "\2\22\1\uffff\2\25\2\22\1\25\3\22\3\25\1\uffff\2\25\3\22\1\uffff"+
            "\4\22\2\25\1\uffff\1\22\1\25\3\22\1\25\5\22\2\uffff\5\22\1\uffff"+
            "\2\22\1\uffff\1\22\1\25\2\22\1\uffff\1\22\1\25\1\22\1\25\1\22"+
            "\2\uffff\1\22\1\uffff\3\25\2\22\1\uffff\2\22\1\uffff\1\23\2"+
            "\22\1\25\1\22\3\uffff\1\22\1\25\1\22\1\25\2\22\1\25\1\22\1\25"+
            "\3\22\1\uffff\2\25\10\22\1\25\1\22\2\25\2\22\1\uffff\3\25\3"+
            "\22\1\uffff\4\22\1\25\5\22\1\25\4\22\1\uffff\6\22\1\25\1\22"+
            "\1\uffff\3\22\1\uffff\1\25\1\22\1\25\3\22\1\uffff\3\25\1\22"+
            "\1\uffff\1\22\1\25\1\22\1\uffff\3\22\1\25\2\22\2\25\3\22\1\25"+
            "\1\22\1\uffff\3\22\2\uffff\1\22\1\uffff\1\25\3\22\70\uffff\1"+
            "\22\46\uffff\1\22\61\uffff\1\22\3\uffff\1\22\61\uffff\1\22\3"+
            "\uffff\1\22\27\uffff\1\22\4\uffff\1\22",
            "",
            "\1\7\10\uffff\1\27\4\30\2\33\1\30\1\uffff\1\30\2\33\1\30\1"+
            "\33\2\30\5\33\2\30\1\33\2\30\2\uffff\1\30\1\uffff\4\30\1\uffff"+
            "\2\30\1\uffff\4\30\1\uffff\1\33\1\30\1\33\1\uffff\1\33\1\uffff"+
            "\3\33\1\30\1\uffff\1\30\1\33\3\30\1\33\2\30\1\33\3\30\1\33\3"+
            "\30\1\uffff\1\30\1\33\1\30\1\33\2\30\1\uffff\1\30\1\uffff\1"+
            "\30\2\uffff\1\30\1\33\2\30\1\uffff\1\33\1\uffff\2\33\4\30\1"+
            "\33\2\uffff\2\33\2\30\1\uffff\1\33\1\uffff\1\30\3\33\1\uffff"+
            "\2\30\1\uffff\2\33\2\30\1\33\3\30\3\33\1\uffff\2\33\3\30\1\uffff"+
            "\4\30\2\33\1\uffff\1\30\1\33\3\30\1\33\5\30\2\uffff\5\30\1\uffff"+
            "\2\30\1\uffff\1\30\1\33\2\30\1\uffff\1\30\1\33\1\30\1\33\1\30"+
            "\2\uffff\1\30\1\uffff\3\33\2\30\1\uffff\2\30\1\uffff\1\31\2"+
            "\30\1\33\1\30\3\uffff\1\30\1\33\1\30\1\33\2\30\1\33\1\30\1\33"+
            "\3\30\1\uffff\2\33\10\30\1\33\1\30\2\33\2\30\1\uffff\3\33\3"+
            "\30\1\uffff\4\30\1\33\5\30\1\33\4\30\1\uffff\6\30\1\33\1\30"+
            "\1\uffff\3\30\1\uffff\1\33\1\30\1\33\3\30\1\uffff\3\33\1\30"+
            "\1\uffff\1\30\1\33\1\30\1\uffff\3\30\1\33\2\30\2\33\3\30\1\33"+
            "\1\30\1\uffff\3\30\2\uffff\1\30\1\uffff\1\33\3\30\70\uffff\1"+
            "\30\46\uffff\1\30\61\uffff\1\30\3\uffff\1\30\61\uffff\1\30\3"+
            "\uffff\1\30\27\uffff\1\30\4\uffff\1\30",
            "",
            "",
            "",
            "",
            "\1\uffff",
            "\1\uffff",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "\1\uffff",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "\1\uffff",
            "\1\uffff",
            "\1\uffff",
            "",
            "\1\uffff",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
    };

    static final short[] DFA119_eot = DFA.unpackEncodedString(DFA119_eotS);
    static final short[] DFA119_eof = DFA.unpackEncodedString(DFA119_eofS);
    static final char[] DFA119_min = DFA.unpackEncodedStringToUnsignedChars(DFA119_minS);
    static final char[] DFA119_max = DFA.unpackEncodedStringToUnsignedChars(DFA119_maxS);
    static final short[] DFA119_accept = DFA.unpackEncodedString(DFA119_acceptS);
    static final short[] DFA119_special = DFA.unpackEncodedString(DFA119_specialS);
    static final short[][] DFA119_transition;

    static {
        int numStates = DFA119_transitionS.length;
        DFA119_transition = new short[numStates][];
        for (int i=0; i<numStates; i++) {
            DFA119_transition[i] = DFA.unpackEncodedString(DFA119_transitionS[i]);
        }
    }

    class DFA119 extends DFA {

        public DFA119(BaseRecognizer recognizer) {
            this.recognizer = recognizer;
            this.decisionNumber = 119;
            this.eot = DFA119_eot;
            this.eof = DFA119_eof;
            this.min = DFA119_min;
            this.max = DFA119_max;
            this.accept = DFA119_accept;
            this.special = DFA119_special;
            this.transition = DFA119_transition;
        }
        public String getDescription() {
            return "1461:5: ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED | KW_PRETTY )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) )";
        }
        public int specialStateTransition(int s, IntStream _input) throws NoViableAltException {
            TokenStream input = (TokenStream)_input;
        	int _s = s;
            switch ( s ) {
                    case 0 : 
                        int LA119_0 = input.LA(1);

                         
                        int index119_0 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA119_0==KW_DATABASE) && (synpred7_HiveParser())) {s = 1;}

                        else if ( (LA119_0==KW_SCHEMA) ) {s = 2;}

                        else if ( (LA119_0==KW_FUNCTION) && (synpred8_HiveParser())) {s = 3;}

                        else if ( (LA119_0==KW_FORMATTED) ) {s = 4;}

                        else if ( (LA119_0==KW_EXTENDED) && (synpred9_HiveParser())) {s = 5;}

                        else if ( (LA119_0==KW_PRETTY) ) {s = 6;}

                        else if ( ((LA119_0 >= Identifier && LA119_0 <= KW_ANALYZE)||(LA119_0 >= KW_ARCHIVE && LA119_0 <= KW_CASCADE)||LA119_0==KW_CHANGE||(LA119_0 >= KW_CLUSTER && LA119_0 <= KW_COLLECTION)||(LA119_0 >= KW_COLUMNS && LA119_0 <= KW_COMMENT)||(LA119_0 >= KW_COMPACT && LA119_0 <= KW_CONCATENATE)||(LA119_0 >= KW_CONSTRAINT && LA119_0 <= KW_CREATE)||LA119_0==KW_CUBE||(LA119_0 >= KW_CURRENT_DATE && LA119_0 <= KW_DATA)||(LA119_0 >= KW_DATABASES && LA119_0 <= KW_DISABLE)||(LA119_0 >= KW_DISTRIBUTE && LA119_0 <= KW_ELEM_TYPE)||LA119_0==KW_ENABLE||LA119_0==KW_ESCAPED||(LA119_0 >= KW_EXCLUSIVE && LA119_0 <= KW_EXPORT)||LA119_0==KW_EXTERNAL||(LA119_0 >= KW_FALSE && LA119_0 <= KW_FLOAT)||(LA119_0 >= KW_FOR && LA119_0 <= KW_FORMAT)||LA119_0==KW_FULL||(LA119_0 >= KW_FUNCTIONS && LA119_0 <= KW_GROUPING)||(LA119_0 >= KW_HOUR && LA119_0 <= KW_IDXPROPERTIES)||(LA119_0 >= KW_IMPORT && LA119_0 <= KW_INTERSECT)||(LA119_0 >= KW_INTO && LA119_0 <= KW_JAR)||(LA119_0 >= KW_KEY && LA119_0 <= KW_LEFT)||(LA119_0 >= KW_LEVEL && LA119_0 <= KW_LONG)||(LA119_0 >= KW_MAPJOIN && LA119_0 <= KW_METADATA)||(LA119_0 >= KW_MINUTE && LA119_0 <= KW_MONTH)||(LA119_0 >= KW_MSCK && LA119_0 <= KW_NOSCAN)||(LA119_0 >= KW_NOVALIDATE && LA119_0 <= KW_OFFSET)||LA119_0==KW_OPTION||(LA119_0 >= KW_ORDER && LA119_0 <= KW_OUTPUTFORMAT)||(LA119_0 >= KW_OVERWRITE && LA119_0 <= KW_OWNER)||(LA119_0 >= KW_PARTITION && LA119_0 <= KW_PLUS)||(LA119_0 >= KW_PRIMARY && LA119_0 <= KW_RECORDWRITER)||(LA119_0 >= KW_REFERENCES && LA119_0 <= KW_ROLES)||(LA119_0 >= KW_ROLLUP && LA119_0 <= KW_ROWS)||(LA119_0 >= KW_SCHEMAS && LA119_0 <= KW_SECOND)||(LA119_0 >= KW_SEMI && LA119_0 <= KW_SSL)||(LA119_0 >= KW_STATISTICS && LA119_0 <= KW_TABLES)||(LA119_0 >= KW_TBLPROPERTIES && LA119_0 <= KW_TERMINATED)||(LA119_0 >= KW_TIMESTAMP && LA119_0 <= KW_TRANSACTIONS)||(LA119_0 >= KW_TRIGGER && LA119_0 <= KW_UNARCHIVE)||(LA119_0 >= KW_UNDO && LA119_0 <= KW_UNIONTYPE)||(LA119_0 >= KW_UNLOCK && LA119_0 <= KW_VALUE_TYPE)||(LA119_0 >= KW_VIEW && LA119_0 <= KW_WEEK)||LA119_0==KW_WHILE||(LA119_0 >= KW_WITH && LA119_0 <= KW_YEAR)||LA119_0==KW_BATCH||LA119_0==KW_DAYOFWEEK||LA119_0==KW_HOLD_DDLTIME||LA119_0==KW_IGNORE||LA119_0==KW_NO_DROP||LA119_0==KW_OFFLINE||LA119_0==KW_PROTECTION||LA119_0==KW_READONLY) ) {s = 7;}

                         
                        input.seek(index119_0);

                        if ( s>=0 ) return s;
                        break;
                    case 1 : 
                        int LA119_2 = input.LA(1);

                         
                        int index119_2 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (LA119_2==KW_EXTENDED) && (synpred7_HiveParser())) {s = 10;}

                        else if ( (LA119_2==Identifier) ) {s = 11;}

                        else if ( ((LA119_2 >= KW_ABORT && LA119_2 <= KW_AFTER)||LA119_2==KW_ANALYZE||LA119_2==KW_ARCHIVE||LA119_2==KW_ASC||(LA119_2 >= KW_AUTOCOMMIT && LA119_2 <= KW_BEFORE)||(LA119_2 >= KW_BUCKET && LA119_2 <= KW_BUCKETS)||(LA119_2 >= KW_CACHE && LA119_2 <= KW_CASCADE)||LA119_2==KW_CHANGE||(LA119_2 >= KW_CLUSTER && LA119_2 <= KW_COLLECTION)||(LA119_2 >= KW_COLUMNS && LA119_2 <= KW_COMMENT)||(LA119_2 >= KW_COMPACT && LA119_2 <= KW_CONCATENATE)||LA119_2==KW_CONTINUE||LA119_2==KW_DATA||LA119_2==KW_DATABASES||(LA119_2 >= KW_DATETIME && LA119_2 <= KW_DBPROPERTIES)||(LA119_2 >= KW_DEFERRED && LA119_2 <= KW_DEFINED)||(LA119_2 >= KW_DELIMITED && LA119_2 <= KW_DESC)||(LA119_2 >= KW_DIRECTORIES && LA119_2 <= KW_DISABLE)||LA119_2==KW_DISTRIBUTE||LA119_2==KW_DOW||(LA119_2 >= KW_DUMP && LA119_2 <= KW_ELEM_TYPE)||LA119_2==KW_ENABLE||LA119_2==KW_ESCAPED||LA119_2==KW_EXCLUSIVE||(LA119_2 >= KW_EXPLAIN && LA119_2 <= KW_EXPORT)||(LA119_2 >= KW_FIELDS && LA119_2 <= KW_FIRST)||(LA119_2 >= KW_FORMAT && LA119_2 <= KW_FORMATTED)||LA119_2==KW_FUNCTIONS||(LA119_2 >= KW_HOUR && LA119_2 <= KW_IDXPROPERTIES)||(LA119_2 >= KW_INDEX && LA119_2 <= KW_INDEXES)||(LA119_2 >= KW_INPATH && LA119_2 <= KW_INPUTFORMAT)||(LA119_2 >= KW_ISOLATION && LA119_2 <= KW_JAR)||(LA119_2 >= KW_KEY && LA119_2 <= KW_LAST)||LA119_2==KW_LEVEL||(LA119_2 >= KW_LIMIT && LA119_2 <= KW_LOAD)||(LA119_2 >= KW_LOCATION && LA119_2 <= KW_LONG)||(LA119_2 >= KW_MAPJOIN && LA119_2 <= KW_METADATA)||(LA119_2 >= KW_MINUTE && LA119_2 <= KW_MONTH)||LA119_2==KW_MSCK||(LA119_2 >= KW_NORELY && LA119_2 <= KW_NOSCAN)||LA119_2==KW_NOVALIDATE||LA119_2==KW_NULLS||LA119_2==KW_OFFSET||LA119_2==KW_OPTION||(LA119_2 >= KW_OUTPUTDRIVER && LA119_2 <= KW_OUTPUTFORMAT)||(LA119_2 >= KW_OVERWRITE && LA119_2 <= KW_OWNER)||(LA119_2 >= KW_PARTITIONED && LA119_2 <= KW_PARTITIONS)||LA119_2==KW_PLUS||LA119_2==KW_PRETTY||LA119_2==KW_PRINCIPALS||(LA119_2 >= KW_PURGE && LA119_2 <= KW_QUARTER)||LA119_2==KW_READ||(LA119_2 >= KW_REBUILD && LA119_2 <= KW_RECORDWRITER)||(LA119_2 >= KW_RELOAD && LA119_2 <= KW_RESTRICT)||LA119_2==KW_REWRITE||(LA119_2 >= KW_ROLE && LA119_2 <= KW_ROLES)||(LA119_2 >= KW_SCHEMA && LA119_2 <= KW_SECOND)||(LA119_2 >= KW_SEMI && LA119_2 <= KW_SERVER)||(LA119_2 >= KW_SETS && LA119_2 <= KW_SKEWED)||(LA119_2 >= KW_SNAPSHOT && LA119_2 <= KW_SSL)||(LA119_2 >= KW_STATISTICS && LA119_2 <= KW_STRUCT)||LA119_2==KW_TABLES||(LA119_2 >= KW_TBLPROPERTIES && LA119_2 <= KW_TERMINATED)||LA119_2==KW_TINYINT||(LA119_2 >= KW_TOUCH && LA119_2 <= KW_TRANSACTIONS)||LA119_2==KW_UNARCHIVE||LA119_2==KW_UNDO||LA119_2==KW_UNIONTYPE||(LA119_2 >= KW_UNLOCK && LA119_2 <= KW_UNSIGNED)||(LA119_2 >= KW_URI && LA119_2 <= KW_USE)||(LA119_2 >= KW_UTC && LA119_2 <= KW_VALIDATE)||LA119_2==KW_VALUE_TYPE||(LA119_2 >= KW_VIEW && LA119_2 <= KW_WEEK)||LA119_2==KW_WHILE||(LA119_2 >= KW_WORK && LA119_2 <= KW_YEAR)||LA119_2==KW_BATCH||LA119_2==KW_DAYOFWEEK||LA119_2==KW_HOLD_DDLTIME||LA119_2==KW_IGNORE||LA119_2==KW_NO_DROP||LA119_2==KW_OFFLINE||LA119_2==KW_PROTECTION||LA119_2==KW_READONLY) ) {s = 12;}

                        else if ( (LA119_2==KW_PARTITION) ) {s = 13;}

                        else if ( (LA119_2==EOF||LA119_2==DOT) ) {s = 7;}

                        else if ( ((LA119_2 >= KW_ALL && LA119_2 <= KW_ALTER)||(LA119_2 >= KW_ARRAY && LA119_2 <= KW_AS)||LA119_2==KW_AUTHORIZATION||(LA119_2 >= KW_BETWEEN && LA119_2 <= KW_BOTH)||LA119_2==KW_BY||LA119_2==KW_CONSTRAINT||LA119_2==KW_CREATE||LA119_2==KW_CUBE||(LA119_2 >= KW_CURRENT_DATE && LA119_2 <= KW_CURSOR)||LA119_2==KW_DATE||LA119_2==KW_DECIMAL||LA119_2==KW_DELETE||LA119_2==KW_DESCRIBE||LA119_2==KW_DOUBLE||LA119_2==KW_DROP||LA119_2==KW_EXISTS||LA119_2==KW_EXTERNAL||(LA119_2 >= KW_FALSE && LA119_2 <= KW_FETCH)||LA119_2==KW_FLOAT||(LA119_2 >= KW_FOR && LA119_2 <= KW_FOREIGN)||LA119_2==KW_FULL||(LA119_2 >= KW_GRANT && LA119_2 <= KW_GROUPING)||(LA119_2 >= KW_IMPORT && LA119_2 <= KW_IN)||LA119_2==KW_INNER||(LA119_2 >= KW_INSERT && LA119_2 <= KW_INTERSECT)||(LA119_2 >= KW_INTO && LA119_2 <= KW_IS)||(LA119_2 >= KW_LATERAL && LA119_2 <= KW_LEFT)||LA119_2==KW_LIKE||LA119_2==KW_LOCAL||LA119_2==KW_NONE||LA119_2==KW_NULL||LA119_2==KW_OF||(LA119_2 >= KW_ORDER && LA119_2 <= KW_OUTER)||LA119_2==KW_PERCENT||LA119_2==KW_PRIMARY||LA119_2==KW_PROCEDURE||LA119_2==KW_RANGE||LA119_2==KW_READS||(LA119_2 >= KW_REFERENCES && LA119_2 <= KW_REGEXP)||LA119_2==KW_REVOKE||(LA119_2 >= KW_RIGHT && LA119_2 <= KW_RLIKE)||(LA119_2 >= KW_ROLLUP && LA119_2 <= KW_ROWS)||LA119_2==KW_SET||LA119_2==KW_SMALLINT||LA119_2==KW_TABLE||LA119_2==KW_TIMESTAMP||LA119_2==KW_TO||(LA119_2 >= KW_TRIGGER && LA119_2 <= KW_TRUNCATE)||LA119_2==KW_UNION||LA119_2==KW_UPDATE||(LA119_2 >= KW_USER && LA119_2 <= KW_USING)||LA119_2==KW_VALUES||LA119_2==KW_WITH) ) {s = 15;}

                         
                        input.seek(index119_2);

                        if ( s>=0 ) return s;
                        break;
                    case 2 : 
                        int LA119_11 = input.LA(1);

                         
                        int index119_11 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred7_HiveParser()) ) {s = 10;}

                        else if ( (true) ) {s = 7;}

                         
                        input.seek(index119_11);

                        if ( s>=0 ) return s;
                        break;
                    case 3 : 
                        int LA119_12 = input.LA(1);

                         
                        int index119_12 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred7_HiveParser()) ) {s = 10;}

                        else if ( (true) ) {s = 7;}

                         
                        input.seek(index119_12);

                        if ( s>=0 ) return s;
                        break;
                    case 4 : 
                        int LA119_13 = input.LA(1);

                         
                        int index119_13 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred7_HiveParser()) ) {s = 10;}

                        else if ( (true) ) {s = 7;}

                         
                        input.seek(index119_13);

                        if ( s>=0 ) return s;
                        break;
                    case 5 : 
                        int LA119_15 = input.LA(1);

                         
                        int index119_15 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred7_HiveParser()) ) {s = 10;}

                        else if ( (true) ) {s = 7;}

                         
                        input.seek(index119_15);

                        if ( s>=0 ) return s;
                        break;
                    case 6 : 
                        int LA119_17 = input.LA(1);

                         
                        int index119_17 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred9_HiveParser()) ) {s = 5;}

                        else if ( (true) ) {s = 7;}

                         
                        input.seek(index119_17);

                        if ( s>=0 ) return s;
                        break;
                    case 7 : 
                        int LA119_18 = input.LA(1);

                         
                        int index119_18 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred9_HiveParser()) ) {s = 5;}

                        else if ( (true) ) {s = 7;}

                         
                        input.seek(index119_18);

                        if ( s>=0 ) return s;
                        break;
                    case 8 : 
                        int LA119_19 = input.LA(1);

                         
                        int index119_19 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred9_HiveParser()) ) {s = 5;}

                        else if ( (true) ) {s = 7;}

                         
                        input.seek(index119_19);

                        if ( s>=0 ) return s;
                        break;
                    case 9 : 
                        int LA119_21 = input.LA(1);

                         
                        int index119_21 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred9_HiveParser()) ) {s = 5;}

                        else if ( (true) ) {s = 7;}

                         
                        input.seek(index119_21);

                        if ( s>=0 ) return s;
                        break;
                    case 10 : 
                        int LA119_23 = input.LA(1);

                         
                        int index119_23 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred9_HiveParser()) ) {s = 5;}

                        else if ( (true) ) {s = 7;}

                         
                        input.seek(index119_23);

                        if ( s>=0 ) return s;
                        break;
                    case 11 : 
                        int LA119_24 = input.LA(1);

                         
                        int index119_24 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred9_HiveParser()) ) {s = 5;}

                        else if ( (true) ) {s = 7;}

                         
                        input.seek(index119_24);

                        if ( s>=0 ) return s;
                        break;
                    case 12 : 
                        int LA119_25 = input.LA(1);

                         
                        int index119_25 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred9_HiveParser()) ) {s = 5;}

                        else if ( (true) ) {s = 7;}

                         
                        input.seek(index119_25);

                        if ( s>=0 ) return s;
                        break;
                    case 13 : 
                        int LA119_27 = input.LA(1);

                         
                        int index119_27 = input.index();
                        input.rewind();

                        s = -1;
                        if ( (synpred9_HiveParser()) ) {s = 5;}

                        else if ( (true) ) {s = 7;}

                         
                        input.seek(index119_27);

                        if ( s>=0 ) return s;
                        break;
            }
            if (state.backtracking>0) {state.failed=true; return -1;}

            NoViableAltException nvae =
                new NoViableAltException(getDescription(), 119, _s, input);
            error(nvae);
            throw nvae;
        }

    }
    static final String DFA210_eotS =
        "\136\uffff";
    static final String DFA210_eofS =
        "\1\2\135\uffff";
    static final String DFA210_minS =
        "\1\46\1\7\41\uffff\1\4\72\uffff";
    static final String DFA210_maxS =
        "\1\u0154\1\u022e\41\uffff\1\u0158\72\uffff";
    static final String DFA210_acceptS =
        "\2\uffff\1\2\100\uffff\1\1\32\uffff";
    static final String DFA210_specialS =
        "\136\uffff}>";
    static final String[] DFA210_transitionS = {
            "\1\2\22\uffff\1\2\5\uffff\1\2\42\uffff\1\2\11\uffff\1\2\25\uffff"+
            "\1\2\4\uffff\1\2\1\uffff\1\2\2\uffff\1\2\10\uffff\1\2\1\uffff"+
            "\1\2\13\uffff\1\2\4\uffff\2\2\2\uffff\1\2\5\uffff\1\1\5\uffff"+
            "\1\2\11\uffff\1\2\7\uffff\1\2\32\uffff\3\2\27\uffff\1\2\14\uffff"+
            "\1\2\5\uffff\1\2\6\uffff\1\2\20\uffff\1\2\11\uffff\1\2\3\uffff"+
            "\1\2\6\uffff\1\2\1\uffff\1\2\7\uffff\1\2\12\uffff\1\2",
            "\1\2\6\uffff\1\2\4\uffff\1\2\7\uffff\10\2\1\uffff\24\2\1\uffff"+
            "\4\2\1\uffff\2\2\1\uffff\4\2\1\uffff\3\2\1\uffff\1\2\1\uffff"+
            "\4\2\1\uffff\20\2\1\uffff\6\2\1\uffff\1\2\1\uffff\1\2\2\uffff"+
            "\4\2\1\uffff\12\2\1\uffff\4\2\1\uffff\1\2\1\uffff\4\2\1\uffff"+
            "\24\2\1\uffff\1\2\1\43\4\2\1\uffff\13\2\1\uffff\6\2\1\uffff"+
            "\2\2\1\uffff\12\2\2\uffff\1\2\1\uffff\5\2\1\uffff\2\2\1\uffff"+
            "\5\2\3\uffff\14\2\1\uffff\20\2\1\uffff\6\2\1\uffff\17\2\1\uffff"+
            "\10\2\1\uffff\3\2\1\uffff\6\2\1\uffff\4\2\1\uffff\3\2\1\uffff"+
            "\15\2\1\uffff\3\2\2\uffff\1\2\1\uffff\4\2\3\uffff\1\2\2\uffff"+
            "\1\2\2\uffff\2\2\7\uffff\5\2\41\uffff\1\2\46\uffff\1\2\61\uffff"+
            "\1\2\3\uffff\1\2\61\uffff\1\2\3\uffff\1\2\27\uffff\1\2\4\uffff"+
            "\1\2",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "\3\2\3\uffff\1\2\1\uffff\1\2\2\uffff\2\2\1\uffff\1\2\2\uffff"+
            "\2\2\1\uffff\2\2\11\uffff\1\2\7\uffff\1\2\142\uffff\1\2\13\uffff"+
            "\1\2\14\uffff\1\2\30\uffff\1\2\10\uffff\1\2\34\uffff\1\2\2\uffff"+
            "\1\2\13\uffff\1\2\4\uffff\1\2\40\uffff\1\103\30\uffff\1\2\22"+
            "\uffff\4\2\1\uffff\3\2\1\uffff\1\2\7\uffff\1\2",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
    };

    static final short[] DFA210_eot = DFA.unpackEncodedString(DFA210_eotS);
    static final short[] DFA210_eof = DFA.unpackEncodedString(DFA210_eofS);
    static final char[] DFA210_min = DFA.unpackEncodedStringToUnsignedChars(DFA210_minS);
    static final char[] DFA210_max = DFA.unpackEncodedStringToUnsignedChars(DFA210_maxS);
    static final short[] DFA210_accept = DFA.unpackEncodedString(DFA210_acceptS);
    static final short[] DFA210_special = DFA.unpackEncodedString(DFA210_specialS);
    static final short[][] DFA210_transition;

    static {
        int numStates = DFA210_transitionS.length;
        DFA210_transition = new short[numStates][];
        for (int i=0; i<numStates; i++) {
            DFA210_transition[i] = DFA.unpackEncodedString(DFA210_transitionS[i]);
        }
    }

    class DFA210 extends DFA {

        public DFA210(BaseRecognizer recognizer) {
            this.recognizer = recognizer;
            this.decisionNumber = 210;
            this.eot = DFA210_eot;
            this.eof = DFA210_eof;
            this.min = DFA210_min;
            this.max = DFA210_max;
            this.accept = DFA210_accept;
            this.special = DFA210_special;
            this.transition = DFA210_transition;
        }
        public String getDescription() {
            return "1919:103: ( tableRowFormatMapKeysIdentifier )?";
        }
    }
    static final String DFA244_eotS =
        "\u0096\uffff";
    static final String DFA244_eofS =
        "\u0096\uffff";
    static final String DFA244_minS =
        "\2\33\2\45\3\uffff\1\177\14\12\1\177\1\12\1\177\2\uffff\2\177\1"+
        "\uffff\1\177\171\uffff";
    static final String DFA244_maxS =
        "\2\u022e\2\u013a\3\uffff\1\u00dc\14\u0154\1\u0147\1\u0154\1\u0147"+
        "\2\uffff\1\u00dc\1\u0147\1\uffff\1\u00dc\171\uffff";
    static final String DFA244_acceptS =
        "\4\uffff\1\5\30\uffff\1\3\23\uffff\1\4\23\uffff\1\1\1\2\117\uffff";
    static final String DFA244_specialS =
        "\u0096\uffff}>";
    static final String[] DFA244_transitionS = {
            "\10\4\1\uffff\21\4\2\uffff\1\4\1\uffff\4\4\1\uffff\2\4\1\uffff"+
            "\4\4\1\uffff\1\1\2\4\1\uffff\1\4\1\uffff\4\4\1\uffff\20\4\1"+
            "\uffff\6\4\1\uffff\1\4\1\uffff\1\4\2\uffff\4\4\1\uffff\1\4\1"+
            "\uffff\7\4\2\uffff\1\4\1\3\2\4\1\uffff\1\4\1\uffff\4\4\1\uffff"+
            "\2\4\1\uffff\13\4\1\uffff\5\4\1\uffff\6\4\1\uffff\13\4\2\uffff"+
            "\5\4\1\uffff\2\4\1\uffff\4\4\1\uffff\5\4\2\uffff\1\4\1\uffff"+
            "\5\4\1\uffff\2\4\1\uffff\5\4\3\uffff\1\4\1\2\12\4\1\uffff\20"+
            "\4\1\uffff\6\4\1\uffff\17\4\1\uffff\10\4\1\uffff\3\4\1\uffff"+
            "\6\4\1\uffff\4\4\1\uffff\3\4\1\uffff\15\4\1\uffff\3\4\2\uffff"+
            "\1\4\1\uffff\4\4\70\uffff\1\4\46\uffff\1\4\61\uffff\1\4\3\uffff"+
            "\1\4\61\uffff\1\4\3\uffff\1\4\27\uffff\1\4\4\uffff\1\4",
            "\1\7\4\34\2\31\1\34\1\uffff\1\34\1\26\1\31\1\34\1\31\2\34\1"+
            "\31\1\14\1\23\1\15\1\31\2\34\1\31\2\34\2\uffff\1\34\1\4\4\34"+
            "\1\uffff\2\34\1\uffff\4\34\1\uffff\1\31\1\34\1\31\1\uffff\1"+
            "\31\1\uffff\3\31\1\34\1\uffff\1\34\1\20\1\12\2\34\1\25\2\34"+
            "\1\31\3\34\1\31\3\34\1\uffff\1\34\1\17\1\34\1\31\2\34\1\uffff"+
            "\1\34\1\uffff\1\34\2\uffff\1\34\1\31\2\34\1\uffff\1\31\1\uffff"+
            "\2\31\4\34\1\16\2\uffff\2\31\2\34\1\uffff\1\31\1\uffff\1\34"+
            "\3\31\1\uffff\2\34\1\uffff\2\31\2\34\1\31\3\34\1\31\1\13\1\31"+
            "\1\uffff\2\31\3\34\1\uffff\4\34\2\31\1\uffff\1\34\1\31\3\34"+
            "\1\31\5\34\1\uffff\1\4\5\34\1\uffff\2\34\1\uffff\1\34\1\31\2"+
            "\34\1\uffff\1\34\1\31\1\34\1\31\1\34\2\uffff\1\34\1\uffff\3"+
            "\31\2\34\1\uffff\2\34\1\uffff\1\31\2\34\1\31\1\34\3\uffff\1"+
            "\34\1\31\1\34\1\31\2\34\1\31\1\34\1\31\3\34\1\uffff\2\31\10"+
            "\34\1\31\1\34\2\31\2\34\1\uffff\3\31\3\34\1\uffff\4\34\1\31"+
            "\5\34\1\11\4\34\1\uffff\4\34\1\22\1\24\1\31\1\34\1\uffff\3\34"+
            "\1\uffff\1\21\1\10\1\31\3\34\1\uffff\3\31\1\34\1\uffff\1\34"+
            "\1\31\1\32\1\uffff\3\34\1\31\2\34\2\31\3\34\1\31\1\34\1\4\3"+
            "\34\2\uffff\1\34\1\uffff\1\31\3\34\70\uffff\1\34\46\uffff\1"+
            "\34\61\uffff\1\34\3\uffff\1\34\61\uffff\1\34\3\uffff\1\34\27"+
            "\uffff\1\34\4\uffff\1\34",
            "\1\4\6\uffff\3\4\11\uffff\1\4\31\uffff\2\4\2\uffff\1\4\14\uffff"+
            "\1\4\27\uffff\1\4\32\uffff\1\4\10\uffff\1\35\22\uffff\1\4\127"+
            "\uffff\1\4\11\uffff\2\4\7\uffff\2\4\14\uffff\1\4\16\uffff\1"+
            "\4",
            "\1\4\6\uffff\3\4\11\uffff\1\4\31\uffff\2\4\2\uffff\1\4\14\uffff"+
            "\1\4\27\uffff\1\4\32\uffff\1\4\10\uffff\1\61\22\uffff\1\4\127"+
            "\uffff\1\4\11\uffff\2\4\7\uffff\2\4\14\uffff\1\4\16\uffff\1"+
            "\4",
            "",
            "",
            "",
            "\1\105\134\uffff\1\106",
            "\1\4\64\uffff\1\4\77\uffff\1\105\134\uffff\1\106\167\uffff"+
            "\1\4",
            "\1\4\64\uffff\1\4\77\uffff\1\105\134\uffff\1\106\167\uffff"+
            "\1\4",
            "\1\4\64\uffff\1\4\77\uffff\1\105\134\uffff\1\106\167\uffff"+
            "\1\4",
            "\1\4\64\uffff\1\4\77\uffff\1\105\134\uffff\1\106\167\uffff"+
            "\1\4",
            "\1\4\64\uffff\1\4\77\uffff\1\105\134\uffff\1\106\167\uffff"+
            "\1\4",
            "\1\4\64\uffff\1\4\77\uffff\1\105\134\uffff\1\106\167\uffff"+
            "\1\4",
            "\1\4\64\uffff\1\4\77\uffff\1\105\134\uffff\1\106\167\uffff"+
            "\1\4",
            "\1\4\64\uffff\1\4\77\uffff\1\105\134\uffff\1\106\167\uffff"+
            "\1\4",
            "\1\4\64\uffff\1\4\77\uffff\1\105\134\uffff\1\106\167\uffff"+
            "\1\4",
            "\1\4\64\uffff\1\4\77\uffff\1\105\134\uffff\1\106\167\uffff"+
            "\1\4",
            "\1\4\64\uffff\1\4\77\uffff\1\105\134\uffff\1\106\167\uffff"+
            "\1\4",
            "\1\4\64\uffff\1\4\77\uffff\1\105\134\uffff\1\106\167\uffff"+
            "\1\4",
            "\1\105\134\uffff\1\106\152\uffff\1\4",
            "\1\4\64\uffff\1\4\77\uffff\1\105\134\uffff\1\106\154\uffff"+
            "\1\4\12\uffff\1\4",
            "\1\105\134\uffff\1\106\152\uffff\1\4",
            "",
            "",
            "\1\105\134\uffff\1\106",
            "\1\105\134\uffff\1\106\152\uffff\1\4",
            "",
            "\1\105\134\uffff\1\106",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
    };

    static final short[] DFA244_eot = DFA.unpackEncodedString(DFA244_eotS);
    static final short[] DFA244_eof = DFA.unpackEncodedString(DFA244_eofS);
    static final char[] DFA244_min = DFA.unpackEncodedStringToUnsignedChars(DFA244_minS);
    static final char[] DFA244_max = DFA.unpackEncodedStringToUnsignedChars(DFA244_maxS);
    static final short[] DFA244_accept = DFA.unpackEncodedString(DFA244_acceptS);
    static final short[] DFA244_special = DFA.unpackEncodedString(DFA244_specialS);
    static final short[][] DFA244_transition;

    static {
        int numStates = DFA244_transitionS.length;
        DFA244_transition = new short[numStates][];
        for (int i=0; i<numStates; i++) {
            DFA244_transition[i] = DFA.unpackEncodedString(DFA244_transitionS[i]);
        }
    }

    class DFA244 extends DFA {

        public DFA244(BaseRecognizer recognizer) {
            this.recognizer = recognizer;
            this.decisionNumber = 244;
            this.eot = DFA244_eot;
            this.eof = DFA244_eof;
            this.min = DFA244_min;
            this.max = DFA244_max;
            this.accept = DFA244_accept;
            this.special = DFA244_special;
            this.transition = DFA244_transition;
        }
        public String getDescription() {
            return "2238:1: columnNameTypeOrPKOrFK : ( ( foreignKeyWithName ) | ( primaryKeyWithName ) | ( primaryKeyWithoutName ) | ( foreignKeyWithoutName ) | ( columnNameType ) );";
        }
    }
 

    public static final BitSet FOLLOW_explainStatement_in_statement1175 = new BitSet(new long[]{0x0000000000000000L});
    public static final BitSet FOLLOW_EOF_in_statement1177 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_execStatement_in_statement1182 = new BitSet(new long[]{0x0000000000000000L});
    public static final BitSet FOLLOW_EOF_in_statement1184 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_EXPLAIN_in_explainStatement1205 = new BitSet(new long[]{0x0000010610000000L,0x000600203A000101L,0x1044A40000202046L,0x810C448000000000L,0x0005204000008090L,0x0000000000000204L});
    public static final BitSet FOLLOW_explainOption_in_explainStatement1214 = new BitSet(new long[]{0x0000010610000000L,0x000600203A000101L,0x1044A40000202046L,0x8104448000000000L,0x0005204000008090L,0x0000000000000204L});
    public static final BitSet FOLLOW_execStatement_in_explainStatement1217 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_REWRITE_in_explainStatement1248 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0004000000200004L,0x8000008000000000L,0x0000000000000000L,0x0000000000000204L});
    public static final BitSet FOLLOW_queryStatementExpression_in_explainStatement1250 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_queryStatementExpression_in_execStatement1320 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_loadStatement_in_execStatement1328 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_exportStatement_in_execStatement1336 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_importStatement_in_execStatement1344 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_replDumpStatement_in_execStatement1352 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_replLoadStatement_in_execStatement1360 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_replStatusStatement_in_execStatement1368 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_ddlStatement_in_execStatement1376 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_deleteStatement_in_execStatement1384 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_updateStatement_in_execStatement1392 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_sqlTransactionStatement_in_execStatement1400 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_mergeStatement_in_execStatement1408 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LOAD_in_loadStatement1435 = new BitSet(new long[]{0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_KW_DATA_in_loadStatement1437 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000080000040000L});
    public static final BitSet FOLLOW_KW_LOCAL_in_loadStatement1442 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
    public static final BitSet FOLLOW_KW_INPATH_in_loadStatement1446 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_loadStatement1451 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000002000000L,0x0000000000010000L});
    public static final BitSet FOLLOW_KW_OVERWRITE_in_loadStatement1457 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_KW_INTO_in_loadStatement1461 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_TABLE_in_loadStatement1463 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableOrPartition_in_loadStatement1468 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_FOR_in_replicationClause1520 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0080000000000000L,0x0001000000000000L});
    public static final BitSet FOLLOW_KW_METADATA_in_replicationClause1525 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
    public static final BitSet FOLLOW_KW_REPLICATION_in_replicationClause1529 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_replicationClause1531 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_replicationClause1536 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_replicationClause1539 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_EXPORT_in_exportStatement1583 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_TABLE_in_exportStatement1591 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableOrPartition_in_exportStatement1596 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_KW_TO_in_exportStatement1605 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_exportStatement1610 = new BitSet(new long[]{0x0000000000000002L,0x4000000000000000L});
    public static final BitSet FOLLOW_replicationClause_in_exportStatement1619 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_IMPORT_in_importStatement1669 = new BitSet(new long[]{0x0000000000000000L,0x0008000000000000L,0x0000000000000004L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_EXTERNAL_in_importStatement1684 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_TABLE_in_importStatement1688 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableOrPartition_in_importStatement1693 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_FROM_in_importStatement1707 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_importStatement1712 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000100000000000L});
    public static final BitSet FOLLOW_tableLocation_in_importStatement1724 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_REPL_in_replDumpStatement1778 = new BitSet(new long[]{0x0000000000000000L,0x0000004000000000L});
    public static final BitSet FOLLOW_KW_DUMP_in_replDumpStatement1780 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_replDumpStatement1793 = new BitSet(new long[]{0x0000000000040002L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_DOT_in_replDumpStatement1797 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_replDumpStatement1801 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_FROM_in_replDumpStatement1814 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_Number_in_replDumpStatement1819 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000010000000000L,0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_KW_TO_in_replDumpStatement1833 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_Number_in_replDumpStatement1838 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000010000000000L});
    public static final BitSet FOLLOW_KW_LIMIT_in_replDumpStatement1854 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_Number_in_replDumpStatement1859 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_REPL_in_replLoadStatement1944 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000040000000000L});
    public static final BitSet FOLLOW_KW_LOAD_in_replLoadStatement1946 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEFL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_replLoadStatement1960 = new BitSet(new long[]{0x0000000000040000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_DOT_in_replLoadStatement1964 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_replLoadStatement1968 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_FROM_in_replLoadStatement1982 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_replLoadStatement1987 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_REPL_in_replStatusStatement2042 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
    public static final BitSet FOLLOW_KW_STATUS_in_replStatusStatement2044 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_replStatusStatement2057 = new BitSet(new long[]{0x0000000000040002L});
    public static final BitSet FOLLOW_DOT_in_replStatusStatement2061 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_replStatusStatement2065 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_createDatabaseStatement_in_ddlStatement2115 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_switchDatabaseStatement_in_ddlStatement2123 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_dropDatabaseStatement_in_ddlStatement2131 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_createTableStatement_in_ddlStatement2139 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_dropTableStatement_in_ddlStatement2147 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_truncateTableStatement_in_ddlStatement2155 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatement_in_ddlStatement2163 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_descStatement_in_ddlStatement2171 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_showStatement_in_ddlStatement2179 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_metastoreCheck_in_ddlStatement2187 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_createViewStatement_in_ddlStatement2195 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_dropViewStatement_in_ddlStatement2203 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_createFunctionStatement_in_ddlStatement2211 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_createMacroStatement_in_ddlStatement2219 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_createIndexStatement_in_ddlStatement2227 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_dropIndexStatement_in_ddlStatement2235 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_dropFunctionStatement_in_ddlStatement2243 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_reloadFunctionStatement_in_ddlStatement2251 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_dropMacroStatement_in_ddlStatement2259 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_analyzeStatement_in_ddlStatement2267 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_lockStatement_in_ddlStatement2275 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_unlockStatement_in_ddlStatement2283 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_lockDatabase_in_ddlStatement2291 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_unlockDatabase_in_ddlStatement2299 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_createRoleStatement_in_ddlStatement2307 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_dropRoleStatement_in_ddlStatement2315 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_grantPrivileges_in_ddlStatement2329 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_revokePrivileges_in_ddlStatement2343 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_showGrants_in_ddlStatement2351 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_showRoleGrants_in_ddlStatement2359 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_showRolePrincipals_in_ddlStatement2367 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_showRoles_in_ddlStatement2375 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_grantRole_in_ddlStatement2383 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_revokeRole_in_ddlStatement2391 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_setRole_in_ddlStatement2399 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_showCurrentRole_in_ddlStatement2407 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_abortTransactionStatement_in_ddlStatement2415 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_IF_in_ifExists2442 = new BitSet(new long[]{0x0000000000000000L,0x0000800000000000L});
    public static final BitSet FOLLOW_KW_EXISTS_in_ifExists2444 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_RESTRICT_in_restrictOrCascade2481 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CASCADE_in_restrictOrCascade2499 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_IF_in_ifNotExists2536 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
    public static final BitSet FOLLOW_KW_NOT_in_ifNotExists2538 = new BitSet(new long[]{0x0000000000000000L,0x0000800000000000L});
    public static final BitSet FOLLOW_KW_EXISTS_in_ifNotExists2540 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STORED_in_storedAsDirs2577 = new BitSet(new long[]{0x0000004000000000L});
    public static final BitSet FOLLOW_KW_AS_in_storedAsDirs2579 = new BitSet(new long[]{0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_KW_DIRECTORIES_in_storedAsDirs2581 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_OR_in_orReplace2618 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000800000000000L});
    public static final BitSet FOLLOW_KW_REPLACE_in_orReplace2620 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CREATE_in_createDatabaseStatement2657 = new BitSet(new long[]{0x0000000000000000L,0x0000000000010000L,0x0000000000000000L,0x1000000000000000L});
    public static final BitSet FOLLOW_KW_DATABASE_in_createDatabaseStatement2660 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFFDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_SCHEMA_in_createDatabaseStatement2662 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFFDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_ifNotExists_in_createDatabaseStatement2673 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_createDatabaseStatement2686 = new BitSet(new long[]{0x8000000000000002L,0x0000000000000000L,0x0000100000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_databaseComment_in_createDatabaseStatement2696 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000100000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_dbLocation_in_createDatabaseStatement2707 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_WITH_in_createDatabaseStatement2719 = new BitSet(new long[]{0x0000000000000000L,0x0000000000200000L});
    public static final BitSet FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement2721 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_dbProperties_in_createDatabaseStatement2725 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LOCATION_in_dbLocation2786 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_dbLocation2790 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_LPAREN_in_dbProperties2832 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_dbPropertiesList_in_dbProperties2834 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_dbProperties2836 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_keyValueProperty_in_dbPropertiesList2877 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_dbPropertiesList2880 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_keyValueProperty_in_dbPropertiesList2882 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_KW_USE_in_switchDatabaseStatement2921 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_switchDatabaseStatement2923 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DROP_in_dropDatabaseStatement2962 = new BitSet(new long[]{0x0000000000000000L,0x0000000000010000L,0x0000000000000000L,0x1000000000000000L});
    public static final BitSet FOLLOW_KW_DATABASE_in_dropDatabaseStatement2965 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFFDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_SCHEMA_in_dropDatabaseStatement2967 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFFDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_ifExists_in_dropDatabaseStatement2970 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_dropDatabaseStatement2973 = new BitSet(new long[]{0x0010000000000002L,0x0000000000000000L,0x0000000000000000L,0x0002000000000000L});
    public static final BitSet FOLLOW_restrictOrCascade_in_dropDatabaseStatement2975 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_COMMENT_in_databaseComment3021 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_databaseComment3025 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CREATE_in_createTableStatement3065 = new BitSet(new long[]{0x0000000000000000L,0x0008000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004400000L});
    public static final BitSet FOLLOW_KW_TEMPORARY_in_createTableStatement3070 = new BitSet(new long[]{0x0000000000000000L,0x0008000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_EXTERNAL_in_createTableStatement3077 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_TABLE_in_createTableStatement3081 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFFDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_ifNotExists_in_createTableStatement3083 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_createTableStatement3088 = new BitSet(new long[]{0x8400004000000002L,0x0000000000000000L,0x0000108000000000L,0x0400000000100000L,0x0000000002040200L,0x0000000000000200L});
    public static final BitSet FOLLOW_KW_LIKE_in_createTableStatement3101 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_createTableStatement3105 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000100000000000L,0x0400000000000000L,0x0000000002040000L});
    public static final BitSet FOLLOW_tableRowFormat_in_createTableStatement3116 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000100000000000L,0x0000000000000000L,0x0000000002040000L});
    public static final BitSet FOLLOW_tableFileFormat_in_createTableStatement3128 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000100000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_tableLocation_in_createTableStatement3140 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createTableStatement3152 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_LPAREN_in_createTableStatement3165 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameTypeOrPKOrFKList_in_createTableStatement3167 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_createTableStatement3169 = new BitSet(new long[]{0x8400004000000002L,0x0000000000000000L,0x0000100000000000L,0x0400000000100000L,0x0000000002040200L});
    public static final BitSet FOLLOW_tableComment_in_createTableStatement3182 = new BitSet(new long[]{0x0400004000000002L,0x0000000000000000L,0x0000100000000000L,0x0400000000100000L,0x0000000002040200L});
    public static final BitSet FOLLOW_tablePartition_in_createTableStatement3194 = new BitSet(new long[]{0x0400004000000002L,0x0000000000000000L,0x0000100000000000L,0x0400000000000000L,0x0000000002040200L});
    public static final BitSet FOLLOW_tableBuckets_in_createTableStatement3206 = new BitSet(new long[]{0x0000004000000002L,0x0000000000000000L,0x0000100000000000L,0x0400000000000000L,0x0000000002040200L});
    public static final BitSet FOLLOW_tableSkewed_in_createTableStatement3218 = new BitSet(new long[]{0x0000004000000002L,0x0000000000000000L,0x0000100000000000L,0x0400000000000000L,0x0000000002040000L});
    public static final BitSet FOLLOW_tableRowFormat_in_createTableStatement3230 = new BitSet(new long[]{0x0000004000000002L,0x0000000000000000L,0x0000100000000000L,0x0000000000000000L,0x0000000002040000L});
    public static final BitSet FOLLOW_tableFileFormat_in_createTableStatement3242 = new BitSet(new long[]{0x0000004000000002L,0x0000000000000000L,0x0000100000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_tableLocation_in_createTableStatement3254 = new BitSet(new long[]{0x0000004000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createTableStatement3266 = new BitSet(new long[]{0x0000004000000002L});
    public static final BitSet FOLLOW_KW_AS_in_createTableStatement3279 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0004000000000000L,0x8000008000000000L,0x0000000000000000L,0x0000000000000204L});
    public static final BitSet FOLLOW_selectStatementWithCTE_in_createTableStatement3281 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_TRUNCATE_in_truncateTableStatement3488 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_TABLE_in_truncateTableStatement3490 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tablePartitionPrefix_in_truncateTableStatement3492 = new BitSet(new long[]{0x4000000000000002L});
    public static final BitSet FOLLOW_KW_COLUMNS_in_truncateTableStatement3495 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_truncateTableStatement3497 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameList_in_truncateTableStatement3499 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_truncateTableStatement3501 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CREATE_in_createIndexStatement3536 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_KW_INDEX_in_createIndexStatement3538 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_createIndexStatement3542 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_KW_ON_in_createIndexStatement3550 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_TABLE_in_createIndexStatement3552 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_createIndexStatement3556 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_createIndexStatement3558 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameList_in_createIndexStatement3562 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_createIndexStatement3564 = new BitSet(new long[]{0x0000004000000000L});
    public static final BitSet FOLLOW_KW_AS_in_createIndexStatement3572 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_createIndexStatement3576 = new BitSet(new long[]{0x8000000000000002L,0x0000000000000000L,0x0000100000004800L,0x0400000000000000L,0x0000000002040000L,0x0000000000000004L});
    public static final BitSet FOLLOW_autoRebuild_in_createIndexStatement3584 = new BitSet(new long[]{0x8000000000000002L,0x0000000000000000L,0x0000100000004800L,0x0400000000000000L,0x0000000002040000L});
    public static final BitSet FOLLOW_indexPropertiesPrefixed_in_createIndexStatement3593 = new BitSet(new long[]{0x8000000000000002L,0x0000000000000000L,0x0000100000004000L,0x0400000000000000L,0x0000000002040000L});
    public static final BitSet FOLLOW_indexTblName_in_createIndexStatement3602 = new BitSet(new long[]{0x8000000000000002L,0x0000000000000000L,0x0000100000000000L,0x0400000000000000L,0x0000000002040000L});
    public static final BitSet FOLLOW_tableRowFormat_in_createIndexStatement3611 = new BitSet(new long[]{0x8000000000000002L,0x0000000000000000L,0x0000100000000000L,0x0000000000000000L,0x0000000002040000L});
    public static final BitSet FOLLOW_tableFileFormat_in_createIndexStatement3620 = new BitSet(new long[]{0x8000000000000002L,0x0000000000000000L,0x0000100000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_tableLocation_in_createIndexStatement3629 = new BitSet(new long[]{0x8000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createIndexStatement3638 = new BitSet(new long[]{0x8000000000000002L});
    public static final BitSet FOLLOW_indexComment_in_createIndexStatement3647 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_COMMENT_in_indexComment3804 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_indexComment3808 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_WITH_in_autoRebuild3849 = new BitSet(new long[]{0x0000000000000000L,0x0000000000800000L});
    public static final BitSet FOLLOW_KW_DEFERRED_in_autoRebuild3851 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_REBUILD_in_autoRebuild3853 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_IN_in_indexTblName3889 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_TABLE_in_indexTblName3891 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_indexTblName3895 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_IDXPROPERTIES_in_indexPropertiesPrefixed3942 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_indexProperties_in_indexPropertiesPrefixed3945 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_LPAREN_in_indexProperties3978 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_indexPropertiesList_in_indexProperties3980 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_indexProperties3982 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_keyValueProperty_in_indexPropertiesList4023 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_indexPropertiesList4026 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_keyValueProperty_in_indexPropertiesList4028 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_KW_DROP_in_dropIndexStatement4066 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_KW_INDEX_in_dropIndexStatement4068 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFFDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_ifExists_in_dropIndexStatement4070 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_dropIndexStatement4075 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_KW_ON_in_dropIndexStatement4077 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_dropIndexStatement4081 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DROP_in_dropTableStatement4126 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_TABLE_in_dropTableStatement4128 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFFDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_ifExists_in_dropTableStatement4130 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_dropTableStatement4133 = new BitSet(new long[]{0x0000000000000002L,0x4000000000000000L,0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_KW_PURGE_in_dropTableStatement4135 = new BitSet(new long[]{0x0000000000000002L,0x4000000000000000L});
    public static final BitSet FOLLOW_replicationClause_in_dropTableStatement4138 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ALTER_in_alterStatement4187 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_TABLE_in_alterStatement4189 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_alterStatement4191 = new BitSet(new long[]{0x0480001020000000L,0x0000202000000012L,0x0000000002000000L,0x0000900000080001L,0x0001408100000210L});
    public static final BitSet FOLLOW_alterTableStatementSuffix_in_alterStatement4193 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ALTER_in_alterStatement4211 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0800000000000000L});
    public static final BitSet FOLLOW_KW_VIEW_in_alterStatement4213 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_alterStatement4215 = new BitSet(new long[]{0x0000004020000000L,0x0000002000000000L,0x0004000000000000L,0x8000108000000000L,0x0000400000000010L,0x0000000000000204L});
    public static final BitSet FOLLOW_KW_AS_in_alterStatement4217 = new BitSet(new long[]{0x0000000020000000L,0x0000002000000000L,0x0004000000000000L,0x8000108000000000L,0x0000400000000010L,0x0000000000000204L});
    public static final BitSet FOLLOW_alterViewStatementSuffix_in_alterStatement4220 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ALTER_in_alterStatement4238 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_KW_INDEX_in_alterStatement4240 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_alterIndexStatementSuffix_in_alterStatement4242 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ALTER_in_alterStatement4254 = new BitSet(new long[]{0x0000000000000000L,0x0000000000010000L,0x0000000000000000L,0x1000000000000000L});
    public static final BitSet FOLLOW_KW_DATABASE_in_alterStatement4257 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_SCHEMA_in_alterStatement4259 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_alterDatabaseStatementSuffix_in_alterStatement4262 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixRename_in_alterTableStatementSuffix4300 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixDropPartitions_in_alterTableStatementSuffix4309 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixAddPartitions_in_alterTableStatementSuffix4318 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixTouch_in_alterTableStatementSuffix4327 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixArchive_in_alterTableStatementSuffix4335 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixUnArchive_in_alterTableStatementSuffix4343 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixProperties_in_alterTableStatementSuffix4351 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixSkewedby_in_alterTableStatementSuffix4359 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixExchangePartition_in_alterTableStatementSuffix4367 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementPartitionKeyType_in_alterTableStatementSuffix4375 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixDropConstraint_in_alterTableStatementSuffix4383 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixAddConstraint_in_alterTableStatementSuffix4391 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_partitionSpec_in_alterTableStatementSuffix4399 = new BitSet(new long[]{0x0480000020000000L,0x0000000000000012L,0x0000000002000000L,0x0000900000000001L,0x0001000000000010L});
    public static final BitSet FOLLOW_alterTblPartitionStatementSuffix_in_alterTableStatementSuffix4402 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixFileFormat_in_alterTblPartitionStatementSuffix4434 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixLocation_in_alterTblPartitionStatementSuffix4440 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixMergeFiles_in_alterTblPartitionStatementSuffix4446 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixSerdeProperties_in_alterTblPartitionStatementSuffix4452 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixRenamePart_in_alterTblPartitionStatementSuffix4458 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixBucketNum_in_alterTblPartitionStatementSuffix4464 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterTblPartitionStatementSuffixSkewedLocation_in_alterTblPartitionStatementSuffix4470 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixClusterbySortby_in_alterTblPartitionStatementSuffix4476 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixCompact_in_alterTblPartitionStatementSuffix4482 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixUpdateStatsCol_in_alterTblPartitionStatementSuffix4488 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixUpdateStats_in_alterTblPartitionStatementSuffix4494 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixRenameCol_in_alterTblPartitionStatementSuffix4500 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixAddCol_in_alterTblPartitionStatementSuffix4506 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_PARTITION_in_alterStatementPartitionKeyType4528 = new BitSet(new long[]{0x2000000000000000L});
    public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementPartitionKeyType4530 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_alterStatementPartitionKeyType4532 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameType_in_alterStatementPartitionKeyType4534 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_alterStatementPartitionKeyType4536 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterViewSuffixProperties_in_alterViewStatementSuffix4569 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixRename_in_alterViewStatementSuffix4577 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixAddPartitions_in_alterViewStatementSuffix4586 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixDropPartitions_in_alterViewStatementSuffix4595 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_selectStatementWithCTE_in_alterViewStatementSuffix4604 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterIndexStatementSuffix4633 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_KW_ON_in_alterIndexStatementSuffix4635 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_alterIndexStatementSuffix4637 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000080000L,0x0000000000000010L});
    public static final BitSet FOLLOW_partitionSpec_in_alterIndexStatementSuffix4639 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_KW_REBUILD_in_alterIndexStatementSuffix4654 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_alterIndexStatementSuffix4687 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000800L});
    public static final BitSet FOLLOW_KW_IDXPROPERTIES_in_alterIndexStatementSuffix4689 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_indexProperties_in_alterIndexStatementSuffix4697 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterDatabaseSuffixProperties_in_alterDatabaseStatementSuffix4748 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterDatabaseSuffixSetOwner_in_alterDatabaseStatementSuffix4756 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterDatabaseSuffixProperties4785 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_KW_SET_in_alterDatabaseSuffixProperties4787 = new BitSet(new long[]{0x0000000000000000L,0x0000000000200000L});
    public static final BitSet FOLLOW_KW_DBPROPERTIES_in_alterDatabaseSuffixProperties4789 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_dbProperties_in_alterDatabaseSuffixProperties4791 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterDatabaseSuffixSetOwner4835 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_KW_SET_in_alterDatabaseSuffixSetOwner4837 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
    public static final BitSet FOLLOW_KW_OWNER_in_alterDatabaseSuffixSetOwner4839 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000080L,0x0040000000000000L,0x0008000000000000L});
    public static final BitSet FOLLOW_principalName_in_alterDatabaseSuffixSetOwner4841 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_RENAME_in_alterStatementSuffixRename4884 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_KW_TO_in_alterStatementSuffixRename4886 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_alterStatementSuffixRename4888 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ADD_in_alterStatementSuffixAddCol4955 = new BitSet(new long[]{0x4000000000000000L});
    public static final BitSet FOLLOW_KW_REPLACE_in_alterStatementSuffixAddCol4961 = new BitSet(new long[]{0x4000000000000000L});
    public static final BitSet FOLLOW_KW_COLUMNS_in_alterStatementSuffixAddCol4964 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_alterStatementSuffixAddCol4966 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameTypeList_in_alterStatementSuffixAddCol4968 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_alterStatementSuffixAddCol4970 = new BitSet(new long[]{0x0010000000000002L,0x0000000000000000L,0x0000000000000000L,0x0002000000000000L});
    public static final BitSet FOLLOW_restrictOrCascade_in_alterStatementSuffixAddCol4972 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ADD_in_alterStatementSuffixAddConstraint5048 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_foreignKeyWithName_in_alterStatementSuffixAddConstraint5053 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_primaryKeyWithName_in_alterStatementSuffixAddConstraint5057 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DROP_in_alterStatementSuffixDropConstraint5121 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_KW_CONSTRAINT_in_alterStatementSuffixDropConstraint5123 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixDropConstraint5127 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CHANGE_in_alterStatementSuffixRenameCol5164 = new BitSet(new long[]{0xFE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementSuffixRenameCol5166 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixRenameCol5171 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixRenameCol5175 = new BitSet(new long[]{0x0100702000000000L,0x08000008004C0000L,0x0004000000400000L,0x0000000000000000L,0x0400080060300400L});
    public static final BitSet FOLLOW_colType_in_alterStatementSuffixRenameCol5177 = new BitSet(new long[]{0x8010000080000002L,0x0400000000000000L,0x0000000000000000L,0x0002000000000000L});
    public static final BitSet FOLLOW_KW_COMMENT_in_alterStatementSuffixRenameCol5180 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixRenameCol5184 = new BitSet(new long[]{0x0010000080000002L,0x0400000000000000L,0x0000000000000000L,0x0002000000000000L});
    public static final BitSet FOLLOW_alterStatementChangeColPosition_in_alterStatementSuffixRenameCol5188 = new BitSet(new long[]{0x0010000000000002L,0x0000000000000000L,0x0000000000000000L,0x0002000000000000L});
    public static final BitSet FOLLOW_restrictOrCascade_in_alterStatementSuffixRenameCol5191 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateStatsCol5246 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
    public static final BitSet FOLLOW_KW_STATISTICS_in_alterStatementSuffixUpdateStatsCol5248 = new BitSet(new long[]{0x0000000000000000L,0x4000000000000000L});
    public static final BitSet FOLLOW_KW_FOR_in_alterStatementSuffixUpdateStatsCol5250 = new BitSet(new long[]{0xFE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementSuffixUpdateStatsCol5252 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixUpdateStatsCol5257 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixUpdateStatsCol5259 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixUpdateStatsCol5261 = new BitSet(new long[]{0x8000000000000002L});
    public static final BitSet FOLLOW_KW_COMMENT_in_alterStatementSuffixUpdateStatsCol5264 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixUpdateStatsCol5268 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateStats5315 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
    public static final BitSet FOLLOW_KW_STATISTICS_in_alterStatementSuffixUpdateStats5317 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixUpdateStats5319 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixUpdateStats5321 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_FIRST_in_alterStatementChangeColPosition5351 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_AFTER_in_alterStatementChangeColPosition5353 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_alterStatementChangeColPosition5357 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ADD_in_alterStatementSuffixAddPartitions5410 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000001000L,0x0000000000080000L});
    public static final BitSet FOLLOW_ifNotExists_in_alterStatementSuffixAddPartitions5412 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_alterStatementSuffixAddPartitionsElement_in_alterStatementSuffixAddPartitions5415 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixAddPartitionsElement5478 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000100000000000L});
    public static final BitSet FOLLOW_partitionLocation_in_alterStatementSuffixAddPartitionsElement5480 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_TOUCH_in_alterStatementSuffixTouch5508 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixTouch5511 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_KW_ARCHIVE_in_alterStatementSuffixArchive5555 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixArchive5558 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_KW_UNARCHIVE_in_alterStatementSuffixUnArchive5602 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixUnArchive5605 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_KW_LOCATION_in_partitionLocation5655 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_partitionLocation5659 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DROP_in_alterStatementSuffixDropPartitions5696 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000001000L,0x0000000000080000L});
    public static final BitSet FOLLOW_ifExists_in_alterStatementSuffixDropPartitions5698 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions5701 = new BitSet(new long[]{0x0000000000000402L,0x4000000000000000L,0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_COMMA_in_alterStatementSuffixDropPartitions5704 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions5706 = new BitSet(new long[]{0x0000000000000402L,0x4000000000000000L,0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_KW_PURGE_in_alterStatementSuffixDropPartitions5710 = new BitSet(new long[]{0x0000000000000002L,0x4000000000000000L});
    public static final BitSet FOLLOW_replicationClause_in_alterStatementSuffixDropPartitions5713 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixProperties5795 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties5797 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixProperties5799 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_UNSET_in_alterStatementSuffixProperties5819 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties5821 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000001000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_ifExists_in_alterStatementSuffixProperties5823 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixProperties5826 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_alterViewSuffixProperties5868 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties5870 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_tableProperties_in_alterViewSuffixProperties5872 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_UNSET_in_alterViewSuffixProperties5892 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties5894 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000001000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_ifExists_in_alterViewSuffixProperties5896 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_tableProperties_in_alterViewSuffixProperties5899 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties5941 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SERDE_in_alterStatementSuffixSerdeProperties5943 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixSerdeProperties5947 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_WITH_in_alterStatementSuffixSerdeProperties5950 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties5952 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties5954 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties5980 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties5982 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties5984 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_tableName_in_tablePartitionPrefix6021 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_partitionSpec_in_tablePartitionPrefix6023 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixFileFormat6058 = new BitSet(new long[]{0x0000000000000000L,0x0200000000000000L});
    public static final BitSet FOLLOW_KW_FILEFORMAT_in_alterStatementSuffixFileFormat6060 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_fileFormat_in_alterStatementSuffixFileFormat6062 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby6093 = new BitSet(new long[]{0x0400000000000000L});
    public static final BitSet FOLLOW_KW_CLUSTERED_in_alterStatementSuffixClusterbySortby6095 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby6109 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000002000L});
    public static final BitSet FOLLOW_KW_SORTED_in_alterStatementSuffixClusterbySortby6111 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_tableBuckets_in_alterStatementSuffixClusterbySortby6125 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_alterTblPartitionStatementSuffixSkewedLocation6156 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_KW_SKEWED_in_alterTblPartitionStatementSuffixSkewedLocation6158 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
    public static final BitSet FOLLOW_KW_LOCATION_in_alterTblPartitionStatementSuffixSkewedLocation6160 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_skewedLocations_in_alterTblPartitionStatementSuffixSkewedLocation6162 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_LPAREN_in_skewedLocations6205 = new BitSet(new long[]{0x0000000000084080L,0x0020000000043000L,0x0000000000000000L,0x0000000000000004L,0x0000002020000000L,0x0000000016008200L});
    public static final BitSet FOLLOW_skewedLocationsList_in_skewedLocations6207 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_skewedLocations6209 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_skewedLocationMap_in_skewedLocationsList6250 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_skewedLocationsList6253 = new BitSet(new long[]{0x0000000000084080L,0x0020000000043000L,0x0000000000000000L,0x0000000000000004L,0x0000002020000000L,0x0000000016008200L});
    public static final BitSet FOLLOW_skewedLocationMap_in_skewedLocationsList6255 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_skewedValueLocationElement_in_skewedLocationMap6301 = new BitSet(new long[]{0x0000000000200000L});
    public static final BitSet FOLLOW_EQUAL_in_skewedLocationMap6303 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_skewedLocationMap6307 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixLocation6344 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
    public static final BitSet FOLLOW_KW_LOCATION_in_alterStatementSuffixLocation6346 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixLocation6350 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_tableSkewed_in_alterStatementSuffixSkewedby6384 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby6399 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_KW_SKEWED_in_alterStatementSuffixSkewedby6401 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby6414 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
    public static final BitSet FOLLOW_storedAsDirs_in_alterStatementSuffixSkewedby6416 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_EXCHANGE_in_alterStatementSuffixExchangePartition6447 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixExchangePartition6449 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_WITH_in_alterStatementSuffixExchangePartition6451 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_TABLE_in_alterStatementSuffixExchangePartition6453 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_alterStatementSuffixExchangePartition6457 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_RENAME_in_alterStatementSuffixRenamePart6499 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_KW_TO_in_alterStatementSuffixRenamePart6501 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixRenamePart6503 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_UPDATE_in_alterStatementSuffixStatsPart6541 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
    public static final BitSet FOLLOW_KW_STATISTICS_in_alterStatementSuffixStatsPart6543 = new BitSet(new long[]{0x0000000000000000L,0x4000000000000000L});
    public static final BitSet FOLLOW_KW_FOR_in_alterStatementSuffixStatsPart6545 = new BitSet(new long[]{0xFE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementSuffixStatsPart6547 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixStatsPart6552 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixStatsPart6554 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixStatsPart6556 = new BitSet(new long[]{0x8000000000000002L});
    public static final BitSet FOLLOW_KW_COMMENT_in_alterStatementSuffixStatsPart6559 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixStatsPart6563 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CONCATENATE_in_alterStatementSuffixMergeFiles6610 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_INTO_in_alterStatementSuffixBucketNum6647 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_Number_in_alterStatementSuffixBucketNum6651 = new BitSet(new long[]{0x0002000000000000L});
    public static final BitSet FOLLOW_KW_BUCKETS_in_alterStatementSuffixBucketNum6653 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_COMPACT_in_alterStatementSuffixCompact6693 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixCompact6697 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_WITH_in_alterStatementSuffixCompact6700 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
    public static final BitSet FOLLOW_KW_OVERWRITE_in_alterStatementSuffixCompact6702 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixCompact6704 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixCompact6706 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_INPUTFORMAT_in_fileFormat6752 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_fileFormat6756 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_KW_OUTPUTFORMAT_in_fileFormat6758 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_fileFormat6762 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SERDE_in_fileFormat6764 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_fileFormat6768 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_KW_INPUTDRIVER_in_fileFormat6771 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_fileFormat6775 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000002000L});
    public static final BitSet FOLLOW_KW_OUTPUTDRIVER_in_fileFormat6777 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_fileFormat6781 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_fileFormat6822 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_tabTypeExpr6857 = new BitSet(new long[]{0xDE9FFFF7F8040002L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_DOT_in_tabTypeExpr6860 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_tabTypeExpr6863 = new BitSet(new long[]{0xDE9FFFF7F8000002L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_tabTypeExpr6871 = new BitSet(new long[]{0x0000000000040002L});
    public static final BitSet FOLLOW_DOT_in_tabTypeExpr6874 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_ELEM_TYPE_in_tabTypeExpr6891 = new BitSet(new long[]{0x0000000000040002L});
    public static final BitSet FOLLOW_KW_KEY_TYPE_in_tabTypeExpr6908 = new BitSet(new long[]{0x0000000000040002L});
    public static final BitSet FOLLOW_KW_VALUE_TYPE_in_tabTypeExpr6925 = new BitSet(new long[]{0x0000000000040002L});
    public static final BitSet FOLLOW_identifier_in_tabTypeExpr6933 = new BitSet(new long[]{0x0000000000040002L});
    public static final BitSet FOLLOW_tabTypeExpr_in_partTypeExpr6973 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_partitionSpec_in_partTypeExpr6975 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_tableName_in_tabPartColTypeExpr7015 = new BitSet(new long[]{0xDE9FFFF7F8000002L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_partitionSpec_in_tabPartColTypeExpr7017 = new BitSet(new long[]{0xDE9FFFF7F8000002L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_extColumnName_in_tabPartColTypeExpr7020 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DESCRIBE_in_descStatement7067 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEFCAFDFFFFF5DEL,0xF6F9FFDFBEFFEDFBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_DESC_in_descStatement7069 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEFCAFDFFFFF5DEL,0xF6F9FFDFBEFFEDFBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_DATABASE_in_descStatement7091 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEFCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_SCHEMA_in_descStatement7093 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEFCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement7096 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_descStatement7102 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_FUNCTION_in_descStatement7133 = new BitSet(new long[]{0xDEBFFFFFFB618070L,0xDFEFCAFDFFFEF5DEL,0xF6FDFFDFBEFFFDEBL,0x7EFFFF7FF8FB7F3FL,0x7BFFEEF7EEFF7FFFL,0x400000000D0171BDL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement7135 = new BitSet(new long[]{0xDEBFFFFFFB618070L,0xDFEBCAFDFFFEF5DEL,0xF6FDFFDFBEFFFDEBL,0x7EFFFF7FF8FB7F3FL,0x7BFFEEF7EEFF7FFFL,0x400000000D0171BDL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_descFuncNames_in_descStatement7141 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_FORMATTED_in_descStatement7180 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement7184 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_PRETTY_in_descStatement7188 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tabPartColTypeExpr_in_descStatement7193 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_tabPartColTypeExpr_in_descStatement7220 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ANALYZE_in_analyzeStatement7262 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_TABLE_in_analyzeStatement7264 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableOrPartition_in_analyzeStatement7269 = new BitSet(new long[]{0x0008000000000000L,0x0000000000000008L});
    public static final BitSet FOLLOW_KW_COMPUTE_in_analyzeStatement7292 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
    public static final BitSet FOLLOW_KW_STATISTICS_in_analyzeStatement7294 = new BitSet(new long[]{0x0000000000000002L,0x4000000000000000L,0x8000000000000000L,0x0000000000040000L});
    public static final BitSet FOLLOW_KW_NOSCAN_in_analyzeStatement7300 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_PARTIALSCAN_in_analyzeStatement7308 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_FOR_in_analyzeStatement7368 = new BitSet(new long[]{0x4000000000000000L});
    public static final BitSet FOLLOW_KW_COLUMNS_in_analyzeStatement7370 = new BitSet(new long[]{0xDE9FFFF7F8000002L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameList_in_analyzeStatement7375 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CACHE_in_analyzeStatement7432 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
    public static final BitSet FOLLOW_KW_METADATA_in_analyzeStatement7434 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement7478 = new BitSet(new long[]{0x0000000000000000L,0x0000000000020000L,0x0000000000000000L,0x2000000000000000L});
    public static final BitSet FOLLOW_KW_DATABASES_in_showStatement7481 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000008000000000L});
    public static final BitSet FOLLOW_KW_SCHEMAS_in_showStatement7483 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000008000000000L});
    public static final BitSet FOLLOW_KW_LIKE_in_showStatement7487 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000400003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement7489 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement7508 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
    public static final BitSet FOLLOW_KW_TABLES_in_showStatement7510 = new BitSet(new long[]{0xDE9FFFF7F8000002L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEFL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000400003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_FROM_in_showStatement7514 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_IN_in_showStatement7516 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_showStatement7521 = new BitSet(new long[]{0xDE9FFFF7F8000002L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000400003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_LIKE_in_showStatement7526 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000400003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement7528 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement7530 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement7558 = new BitSet(new long[]{0x4000000000000000L});
    public static final BitSet FOLLOW_KW_COLUMNS_in_showStatement7560 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000004004L});
    public static final BitSet FOLLOW_KW_FROM_in_showStatement7563 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_IN_in_showStatement7565 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_showStatement7568 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000004004L});
    public static final BitSet FOLLOW_KW_FROM_in_showStatement7572 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_IN_in_showStatement7574 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_showStatement7579 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement7605 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
    public static final BitSet FOLLOW_KW_FUNCTIONS_in_showStatement7607 = new BitSet(new long[]{0xDE9FFFF7F8000002L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000400003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_LIKE_in_showStatement7610 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000400003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_showFunctionIdentifier_in_showStatement7612 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_showFunctionIdentifier_in_showStatement7614 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement7637 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000200000L});
    public static final BitSet FOLLOW_KW_PARTITIONS_in_showStatement7639 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_showStatement7643 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_partitionSpec_in_showStatement7645 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement7667 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000100L});
    public static final BitSet FOLLOW_KW_CREATE_in_showStatement7669 = new BitSet(new long[]{0x0000000000000000L,0x0000000000010000L,0x0000000000000000L,0x1000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_DATABASE_in_showStatement7690 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_SCHEMA_in_showStatement7692 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_showStatement7697 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_TABLE_in_showStatement7726 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_showStatement7730 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement7755 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_TABLE_in_showStatement7757 = new BitSet(new long[]{0x0000000000000000L,0x0004000000000000L});
    public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement7759 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000008000004004L});
    public static final BitSet FOLLOW_KW_FROM_in_showStatement7763 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_IN_in_showStatement7765 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_showStatement7770 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
    public static final BitSet FOLLOW_KW_LIKE_in_showStatement7774 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000400003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement7776 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_partitionSpec_in_showStatement7778 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement7806 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_showStatement7808 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_showStatement7810 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_showStatement7813 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_showStatement7817 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_showStatement7819 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement7841 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_KW_LOCKS_in_showStatement7843 = new BitSet(new long[]{0xDE9FFFF7F8000002L,0xCFEFCAFDFFFFF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_DATABASE_in_showStatement7869 = new BitSet(new long[]{0x0000000008000000L});
    public static final BitSet FOLLOW_KW_SCHEMA_in_showStatement7871 = new BitSet(new long[]{0x0000000008000000L});
    public static final BitSet FOLLOW_Identifier_in_showStatement7877 = new BitSet(new long[]{0x0000000000000002L,0x0004000000000000L});
    public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement7883 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_partTypeExpr_in_showStatement7917 = new BitSet(new long[]{0x0000000000000002L,0x0004000000000000L});
    public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement7924 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement7956 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000018002L});
    public static final BitSet FOLLOW_KW_FORMATTED_in_showStatement7961 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000018000L});
    public static final BitSet FOLLOW_KW_INDEX_in_showStatement7966 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_KW_INDEXES_in_showStatement7968 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_KW_ON_in_showStatement7971 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000400003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement7973 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000004004L});
    public static final BitSet FOLLOW_KW_FROM_in_showStatement7977 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_IN_in_showStatement7979 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_showStatement7984 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement8014 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_COMPACTIONS_in_showStatement8016 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement8030 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
    public static final BitSet FOLLOW_KW_TRANSACTIONS_in_showStatement8032 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement8046 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000020L});
    public static final BitSet FOLLOW_KW_CONF_in_showStatement8048 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_showStatement8050 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LOCK_in_lockStatement8085 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_TABLE_in_lockStatement8087 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_lockStatement8089 = new BitSet(new long[]{0x0000000000000000L,0x0000400000000000L,0x0000000000000000L,0x0000000000080000L,0x0000000000000040L});
    public static final BitSet FOLLOW_partitionSpec_in_lockStatement8091 = new BitSet(new long[]{0x0000000000000000L,0x0000400000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_lockMode_in_lockStatement8094 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LOCK_in_lockDatabase8134 = new BitSet(new long[]{0x0000000000000000L,0x0000000000010000L,0x0000000000000000L,0x1000000000000000L});
    public static final BitSet FOLLOW_KW_DATABASE_in_lockDatabase8137 = new BitSet(new long[]{0x0000000008000000L});
    public static final BitSet FOLLOW_KW_SCHEMA_in_lockDatabase8139 = new BitSet(new long[]{0x0000000008000000L});
    public static final BitSet FOLLOW_Identifier_in_lockDatabase8145 = new BitSet(new long[]{0x0000000000000000L,0x0000400000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_lockMode_in_lockDatabase8148 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_UNLOCK_in_unlockStatement8217 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_TABLE_in_unlockStatement8219 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_unlockStatement8221 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_partitionSpec_in_unlockStatement8223 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_UNLOCK_in_unlockDatabase8263 = new BitSet(new long[]{0x0000000000000000L,0x0000000000010000L,0x0000000000000000L,0x1000000000000000L});
    public static final BitSet FOLLOW_KW_DATABASE_in_unlockDatabase8266 = new BitSet(new long[]{0x0000000008000000L});
    public static final BitSet FOLLOW_KW_SCHEMA_in_unlockDatabase8268 = new BitSet(new long[]{0x0000000008000000L});
    public static final BitSet FOLLOW_Identifier_in_unlockDatabase8274 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CREATE_in_createRoleStatement8311 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
    public static final BitSet FOLLOW_KW_ROLE_in_createRoleStatement8313 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_createRoleStatement8317 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DROP_in_dropRoleStatement8357 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
    public static final BitSet FOLLOW_KW_ROLE_in_dropRoleStatement8359 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_dropRoleStatement8363 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_GRANT_in_grantPrivileges8403 = new BitSet(new long[]{0x0000000300000000L,0x0000002002000100L,0x0000200000208000L,0x8000000000000000L,0x0001000000000100L});
    public static final BitSet FOLLOW_privilegeList_in_grantPrivileges8407 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L,0x0000000080000000L});
    public static final BitSet FOLLOW_privilegeObject_in_grantPrivileges8415 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_KW_TO_in_grantPrivileges8424 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000080L,0x0040000000000000L,0x0008000000000000L});
    public static final BitSet FOLLOW_principalSpecification_in_grantPrivileges8426 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_withGrantOption_in_grantPrivileges8434 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_REVOKE_in_revokePrivileges8483 = new BitSet(new long[]{0x0000000300000000L,0x0000002002000100L,0x0000200000208040L,0x8000000000000000L,0x0001000000000100L});
    public static final BitSet FOLLOW_grantOptionFor_in_revokePrivileges8485 = new BitSet(new long[]{0x0000000300000000L,0x0000002002000100L,0x0000200000208000L,0x8000000000000000L,0x0001000000000100L});
    public static final BitSet FOLLOW_privilegeList_in_revokePrivileges8488 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000004L,0x0000000000000040L});
    public static final BitSet FOLLOW_privilegeObject_in_revokePrivileges8490 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_FROM_in_revokePrivileges8493 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000080L,0x0040000000000000L,0x0008000000000000L});
    public static final BitSet FOLLOW_principalSpecification_in_revokePrivileges8495 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_GRANT_in_grantRole8542 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_ROLE_in_grantRole8544 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_grantRole8547 = new BitSet(new long[]{0x0000000000000400L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_COMMA_in_grantRole8550 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_grantRole8552 = new BitSet(new long[]{0x0000000000000400L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_KW_TO_in_grantRole8556 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000080L,0x0040000000000000L,0x0008000000000000L});
    public static final BitSet FOLLOW_principalSpecification_in_grantRole8558 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_withAdminOption_in_grantRole8560 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_REVOKE_in_revokeRole8606 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_adminOptionFor_in_revokeRole8608 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_ROLE_in_revokeRole8611 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_revokeRole8614 = new BitSet(new long[]{0x0000000000000400L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_COMMA_in_revokeRole8617 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_revokeRole8619 = new BitSet(new long[]{0x0000000000000400L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_FROM_in_revokeRole8623 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000080L,0x0040000000000000L,0x0008000000000000L});
    public static final BitSet FOLLOW_principalSpecification_in_revokeRole8625 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showRoleGrants8670 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
    public static final BitSet FOLLOW_KW_ROLE_in_showRoleGrants8672 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_KW_GRANT_in_showRoleGrants8674 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000080L,0x0040000000000000L,0x0008000000000000L});
    public static final BitSet FOLLOW_principalName_in_showRoleGrants8676 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showRoles8716 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
    public static final BitSet FOLLOW_KW_ROLES_in_showRoles8718 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showCurrentRole8755 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000800L});
    public static final BitSet FOLLOW_KW_CURRENT_in_showCurrentRole8757 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
    public static final BitSet FOLLOW_KW_ROLES_in_showCurrentRole8759 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_setRole8796 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
    public static final BitSet FOLLOW_KW_ROLE_in_setRole8798 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_ALL_in_setRole8820 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_NONE_in_setRole8851 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_setRole8873 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showGrants8914 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_KW_GRANT_in_showGrants8916 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000080L,0x0040000000000040L,0x0008000000000000L});
    public static final BitSet FOLLOW_principalName_in_showGrants8918 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_KW_ON_in_showGrants8922 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFFF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_privilegeIncludeColObject_in_showGrants8924 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showRolePrincipals8969 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000020000000L});
    public static final BitSet FOLLOW_KW_PRINCIPALS_in_showRolePrincipals8971 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_showRolePrincipals8975 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ALL_in_privilegeIncludeColObject9022 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_privObjectCols_in_privilegeIncludeColObject9036 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ON_in_privilegeObject9071 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFFF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_privObject_in_privilegeObject9073 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DATABASE_in_privObject9100 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_SCHEMA_in_privObject9102 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_privObject9105 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_TABLE_in_privObject9121 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_privObject9124 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_partitionSpec_in_privObject9126 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_URI_in_privObject9146 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_privObject9151 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SERVER_in_privObject9170 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_privObject9172 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DATABASE_in_privObjectCols9198 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_SCHEMA_in_privObjectCols9200 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_privObjectCols9203 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_TABLE_in_privObjectCols9219 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_privObjectCols9222 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_privObjectCols9225 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameList_in_privObjectCols9229 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_privObjectCols9231 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_partitionSpec_in_privObjectCols9235 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_URI_in_privObjectCols9259 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_privObjectCols9264 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SERVER_in_privObjectCols9283 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_privObjectCols9285 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_privlegeDef_in_privilegeList9320 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_privilegeList9323 = new BitSet(new long[]{0x0000000300000000L,0x0000002002000100L,0x0000200000208000L,0x8000000000000000L,0x0001000000000100L});
    public static final BitSet FOLLOW_privlegeDef_in_privilegeList9325 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_privilegeType_in_privlegeDef9367 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_privlegeDef9370 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameList_in_privlegeDef9374 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_privlegeDef9376 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ALL_in_privilegeType9421 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ALTER_in_privilegeType9435 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_UPDATE_in_privilegeType9449 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CREATE_in_privilegeType9463 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DROP_in_privilegeType9477 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_INDEX_in_privilegeType9491 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LOCK_in_privilegeType9505 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SELECT_in_privilegeType9519 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_DATABASE_in_privilegeType9533 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_INSERT_in_privilegeType9547 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DELETE_in_privilegeType9561 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_principalName_in_principalSpecification9594 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_principalSpecification9597 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000080L,0x0040000000000000L,0x0008000000000000L});
    public static final BitSet FOLLOW_principalName_in_principalSpecification9599 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_KW_USER_in_principalName9637 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000004003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_principalIdentifier_in_principalName9639 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_GROUP_in_principalName9655 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000004003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_principalIdentifier_in_principalName9657 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ROLE_in_principalName9673 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_principalName9675 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_WITH_in_withGrantOption9710 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_KW_GRANT_in_withGrantOption9712 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000100L});
    public static final BitSet FOLLOW_KW_OPTION_in_withGrantOption9714 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_GRANT_in_grantOptionFor9751 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000100L});
    public static final BitSet FOLLOW_KW_OPTION_in_grantOptionFor9753 = new BitSet(new long[]{0x0000000000000000L,0x4000000000000000L});
    public static final BitSet FOLLOW_KW_FOR_in_grantOptionFor9755 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ADMIN_in_adminOptionFor9788 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000100L});
    public static final BitSet FOLLOW_KW_OPTION_in_adminOptionFor9790 = new BitSet(new long[]{0x0000000000000000L,0x4000000000000000L});
    public static final BitSet FOLLOW_KW_FOR_in_adminOptionFor9792 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_WITH_in_withAdminOption9825 = new BitSet(new long[]{0x0000000040000000L});
    public static final BitSet FOLLOW_KW_ADMIN_in_withAdminOption9827 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000100L});
    public static final BitSet FOLLOW_KW_OPTION_in_withAdminOption9829 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_MSCK_in_metastoreCheck9866 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_REPAIR_in_metastoreCheck9871 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_KW_TABLE_in_metastoreCheck9876 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_metastoreCheck9878 = new BitSet(new long[]{0x0000000000000402L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_partitionSpec_in_metastoreCheck9880 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_metastoreCheck9884 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_partitionSpec_in_metastoreCheck9886 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_resource_in_resourceList9939 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_resourceList9942 = new BitSet(new long[]{0x0000001000000000L,0x0100000000000000L,0x0000000020000000L});
    public static final BitSet FOLLOW_resource_in_resourceList9944 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_resourceType_in_resource9982 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_resource9986 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_JAR_in_resourceType10023 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_FILE_in_resourceType10037 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ARCHIVE_in_resourceType10051 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CREATE_in_createFunctionStatement10082 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000010L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_KW_TEMPORARY_in_createFunctionStatement10087 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_KW_FUNCTION_in_createFunctionStatement10091 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_functionIdentifier_in_createFunctionStatement10093 = new BitSet(new long[]{0x0000004000000000L});
    public static final BitSet FOLLOW_KW_AS_in_createFunctionStatement10095 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_createFunctionStatement10097 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
    public static final BitSet FOLLOW_KW_USING_in_createFunctionStatement10106 = new BitSet(new long[]{0x0000001000000000L,0x0100000000000000L,0x0000000020000000L});
    public static final BitSet FOLLOW_resourceList_in_createFunctionStatement10110 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DROP_in_dropFunctionStatement10196 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000010L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_KW_TEMPORARY_in_dropFunctionStatement10201 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_KW_FUNCTION_in_dropFunctionStatement10205 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFFDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_ifExists_in_dropFunctionStatement10207 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_functionIdentifier_in_dropFunctionStatement10210 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_RELOAD_in_reloadFunctionStatement10288 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_KW_FUNCTION_in_reloadFunctionStatement10290 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CREATE_in_createMacroStatement10318 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_KW_TEMPORARY_in_createMacroStatement10320 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0002000000000000L});
    public static final BitSet FOLLOW_KW_MACRO_in_createMacroStatement10322 = new BitSet(new long[]{0x0000000008000000L});
    public static final BitSet FOLLOW_Identifier_in_createMacroStatement10324 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_createMacroStatement10332 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000010003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameTypeList_in_createMacroStatement10334 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_createMacroStatement10337 = new BitSet(new long[]{0xDEFFFFF7F8084080L,0xDFFBCAFDFFFEF5DEL,0xF6FDFFDFBFFFFDEBL,0x7EFFFF7FF8FB7D3FL,0x3BFFEEF7EEFF7FFFL,0x400000001E01923DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_expression_in_createMacroStatement10339 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DROP_in_dropMacroStatement10383 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_KW_TEMPORARY_in_dropMacroStatement10385 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0002000000000000L});
    public static final BitSet FOLLOW_KW_MACRO_in_dropMacroStatement10387 = new BitSet(new long[]{0x0000000008000000L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_ifExists_in_dropMacroStatement10389 = new BitSet(new long[]{0x0000000008000000L});
    public static final BitSet FOLLOW_Identifier_in_dropMacroStatement10392 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CREATE_in_createViewStatement10434 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L,0x0800000000000000L});
    public static final BitSet FOLLOW_orReplace_in_createViewStatement10437 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0800000000000000L});
    public static final BitSet FOLLOW_KW_VIEW_in_createViewStatement10441 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFFDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_ifNotExists_in_createViewStatement10444 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_createViewStatement10450 = new BitSet(new long[]{0x8000004000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L,0x0000000002000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_createViewStatement10461 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameCommentList_in_createViewStatement10463 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_createViewStatement10465 = new BitSet(new long[]{0x8000004000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L,0x0000000002000000L});
    public static final BitSet FOLLOW_tableComment_in_createViewStatement10469 = new BitSet(new long[]{0x0000004000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L,0x0000000002000000L});
    public static final BitSet FOLLOW_viewPartition_in_createViewStatement10472 = new BitSet(new long[]{0x0000004000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createViewStatement10483 = new BitSet(new long[]{0x0000004000000000L});
    public static final BitSet FOLLOW_KW_AS_in_createViewStatement10494 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0004000000000000L,0x8000008000000000L,0x0000000000000000L,0x0000000000000204L});
    public static final BitSet FOLLOW_selectStatementWithCTE_in_createViewStatement10504 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_PARTITIONED_in_viewPartition10627 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_KW_ON_in_viewPartition10629 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_viewPartition10631 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameList_in_viewPartition10633 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_viewPartition10635 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DROP_in_dropViewStatement10674 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0800000000000000L});
    public static final BitSet FOLLOW_KW_VIEW_in_dropViewStatement10676 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFFDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_ifExists_in_dropViewStatement10678 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_viewName_in_dropViewStatement10681 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_functionIdentifier_in_showFunctionIdentifier10719 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_StringLiteral_in_showFunctionIdentifier10727 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_showStmtIdentifier10754 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_StringLiteral_in_showStmtIdentifier10762 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_COMMENT_in_tableComment10795 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableComment10799 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_PARTITIONED_in_tablePartition10836 = new BitSet(new long[]{0x0004000000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tablePartition10838 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_tablePartition10840 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameTypeList_in_tablePartition10842 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_tablePartition10844 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CLUSTERED_in_tableBuckets10889 = new BitSet(new long[]{0x0004000000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableBuckets10891 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_tableBuckets10893 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameList_in_tableBuckets10897 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_tableBuckets10899 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000002000000L,0x0000000000000000L,0x0000000000002000L});
    public static final BitSet FOLLOW_KW_SORTED_in_tableBuckets10902 = new BitSet(new long[]{0x0004000000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableBuckets10904 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_tableBuckets10906 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameOrderList_in_tableBuckets10910 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_tableBuckets10912 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_KW_INTO_in_tableBuckets10916 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_Number_in_tableBuckets10920 = new BitSet(new long[]{0x0002000000000000L});
    public static final BitSet FOLLOW_KW_BUCKETS_in_tableBuckets10922 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SKEWED_in_tableSkewed10974 = new BitSet(new long[]{0x0004000000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableSkewed10976 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_tableSkewed10978 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameList_in_tableSkewed10982 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_tableSkewed10984 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_KW_ON_in_tableSkewed10986 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_tableSkewed10988 = new BitSet(new long[]{0x0000000000084080L,0x0020000000043000L,0x0000000000000000L,0x0000000000000004L,0x0000002020000000L,0x0000000016008200L});
    public static final BitSet FOLLOW_skewedValueElement_in_tableSkewed10993 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_tableSkewed10996 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
    public static final BitSet FOLLOW_storedAsDirs_in_tableSkewed11005 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_rowFormatSerde_in_rowFormat11053 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_rowFormatDelimited_in_rowFormat11069 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_RECORDREADER_in_recordReader11118 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_recordReader11120 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_RECORDWRITER_in_recordWriter11169 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_recordWriter11171 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ROW_in_rowFormatSerde11220 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
    public static final BitSet FOLLOW_KW_FORMAT_in_rowFormatSerde11222 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SERDE_in_rowFormatSerde11224 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_rowFormatSerde11228 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_WITH_in_rowFormatSerde11231 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_rowFormatSerde11233 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_tableProperties_in_rowFormatSerde11237 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ROW_in_rowFormatDelimited11289 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
    public static final BitSet FOLLOW_KW_FORMAT_in_rowFormatDelimited11291 = new BitSet(new long[]{0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_KW_DELIMITED_in_rowFormatDelimited11293 = new BitSet(new long[]{0x1000000000000002L,0x0080000000000000L,0x0004020000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_tableRowFormatFieldIdentifier_in_rowFormatDelimited11295 = new BitSet(new long[]{0x1000000000000002L,0x0000000000000000L,0x0004020000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_tableRowFormatCollItemsIdentifier_in_rowFormatDelimited11298 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0004020000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_tableRowFormatMapKeysIdentifier_in_rowFormatDelimited11301 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000020000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_tableRowFormatLinesIdentifier_in_rowFormatDelimited11304 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_tableRowNullFormat_in_rowFormatDelimited11307 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_rowFormatDelimited_in_tableRowFormat11366 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_rowFormatSerde_in_tableRowFormat11386 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_tablePropertiesPrefixed11433 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_tableProperties_in_tablePropertiesPrefixed11436 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_LPAREN_in_tableProperties11469 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_tablePropertiesList_in_tableProperties11471 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_tableProperties11473 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_keyValueProperty_in_tablePropertiesList11514 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_tablePropertiesList11517 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_keyValueProperty_in_tablePropertiesList11519 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_keyProperty_in_tablePropertiesList11544 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_tablePropertiesList11547 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_keyProperty_in_tablePropertiesList11549 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_StringLiteral_in_keyValueProperty11595 = new BitSet(new long[]{0x0000000000200000L});
    public static final BitSet FOLLOW_EQUAL_in_keyValueProperty11597 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_keyValueProperty11601 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_StringLiteral_in_keyProperty11648 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_FIELDS_in_tableRowFormatFieldIdentifier11692 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000008000000L});
    public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatFieldIdentifier11694 = new BitSet(new long[]{0x0004000000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier11696 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier11700 = new BitSet(new long[]{0x0000000000000002L,0x0000080000000000L});
    public static final BitSet FOLLOW_KW_ESCAPED_in_tableRowFormatFieldIdentifier11703 = new BitSet(new long[]{0x0004000000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier11705 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier11709 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_COLLECTION_in_tableRowFormatCollItemsIdentifier11761 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
    public static final BitSet FOLLOW_KW_ITEMS_in_tableRowFormatCollItemsIdentifier11763 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000008000000L});
    public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatCollItemsIdentifier11765 = new BitSet(new long[]{0x0004000000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableRowFormatCollItemsIdentifier11767 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatCollItemsIdentifier11771 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_MAP_in_tableRowFormatMapKeysIdentifier11817 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000100000000L});
    public static final BitSet FOLLOW_KW_KEYS_in_tableRowFormatMapKeysIdentifier11819 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000008000000L});
    public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatMapKeysIdentifier11821 = new BitSet(new long[]{0x0004000000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableRowFormatMapKeysIdentifier11823 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatMapKeysIdentifier11827 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LINES_in_tableRowFormatLinesIdentifier11873 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000008000000L});
    public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatLinesIdentifier11875 = new BitSet(new long[]{0x0004000000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableRowFormatLinesIdentifier11877 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatLinesIdentifier11881 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_NULL_in_tableRowNullFormat11927 = new BitSet(new long[]{0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_KW_DEFINED_in_tableRowNullFormat11929 = new BitSet(new long[]{0x0000004000000000L});
    public static final BitSet FOLLOW_KW_AS_in_tableRowNullFormat11931 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableRowNullFormat11935 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat11990 = new BitSet(new long[]{0x0000004000000000L});
    public static final BitSet FOLLOW_KW_AS_in_tableFileFormat11992 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_KW_INPUTFORMAT_in_tableFileFormat11994 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat11998 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_KW_OUTPUTFORMAT_in_tableFileFormat12000 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat12004 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_KW_INPUTDRIVER_in_tableFileFormat12007 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat12011 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000002000L});
    public static final BitSet FOLLOW_KW_OUTPUTDRIVER_in_tableFileFormat12013 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat12017 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat12055 = new BitSet(new long[]{0x0004000000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableFileFormat12057 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat12061 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_WITH_in_tableFileFormat12073 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat12075 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_tableProperties_in_tableFileFormat12079 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat12110 = new BitSet(new long[]{0x0000004000000000L});
    public static final BitSet FOLLOW_KW_AS_in_tableFileFormat12112 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_tableFileFormat12116 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LOCATION_in_tableLocation12164 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableLocation12168 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_columnNameType_in_columnNameTypeList12204 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_columnNameTypeList12207 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameType_in_columnNameTypeList12209 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_columnNameTypeOrPKOrFK_in_columnNameTypeOrPKOrFKList12246 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_columnNameTypeOrPKOrFKList12249 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameTypeOrPKOrFK_in_columnNameTypeOrPKOrFKList12251 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_columnNameColonType_in_columnNameColonTypeList12289 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_columnNameColonTypeList12292 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameColonType_in_columnNameColonTypeList12294 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_columnName_in_columnNameList12332 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_columnNameList12335 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnName_in_columnNameList12337 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_identifier_in_columnName12381 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_extColumnName12414 = new BitSet(new long[]{0x0000000000040002L});
    public static final BitSet FOLLOW_DOT_in_extColumnName12417 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_ELEM_TYPE_in_extColumnName12427 = new BitSet(new long[]{0x0000000000040002L});
    public static final BitSet FOLLOW_KW_KEY_TYPE_in_extColumnName12437 = new BitSet(new long[]{0x0000000000040002L});
    public static final BitSet FOLLOW_KW_VALUE_TYPE_in_extColumnName12447 = new BitSet(new long[]{0x0000000000040002L});
    public static final BitSet FOLLOW_identifier_in_extColumnName12451 = new BitSet(new long[]{0x0000000000040002L});
    public static final BitSet FOLLOW_columnNameOrder_in_columnNameOrderList12481 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_columnNameOrderList12484 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameOrder_in_columnNameOrderList12486 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_LPAREN_in_columnParenthesesList12524 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameList_in_columnParenthesesList12526 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_columnParenthesesList12528 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ENABLE_in_enableSpecification12555 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DISABLE_in_enableSpecification12569 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_VALIDATE_in_validateSpecification12602 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_NOVALIDATE_in_validateSpecification12616 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_RELY_in_relySpecification12650 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_NORELY_in_relySpecification12666 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_PRIMARY_in_primaryKeyWithoutName12701 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_KW_KEY_in_primaryKeyWithoutName12703 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_columnParenthesesList_in_primaryKeyWithoutName12705 = new BitSet(new long[]{0x0000000000000000L,0x0000020100000000L});
    public static final BitSet FOLLOW_enableSpecification_in_primaryKeyWithoutName12709 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L,0x0080000000000000L});
    public static final BitSet FOLLOW_validateSpecification_in_primaryKeyWithoutName12713 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x4000000000000000L,0x0000080000000000L});
    public static final BitSet FOLLOW_relySpecification_in_primaryKeyWithoutName12717 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CONSTRAINT_in_primaryKeyWithName12765 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_primaryKeyWithName12769 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
    public static final BitSet FOLLOW_KW_PRIMARY_in_primaryKeyWithName12771 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_KW_KEY_in_primaryKeyWithName12773 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_columnParenthesesList_in_primaryKeyWithName12777 = new BitSet(new long[]{0x0000000000000000L,0x0000020100000000L});
    public static final BitSet FOLLOW_enableSpecification_in_primaryKeyWithName12781 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L,0x0080000000000000L});
    public static final BitSet FOLLOW_validateSpecification_in_primaryKeyWithName12785 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x4000000000000000L,0x0000080000000000L});
    public static final BitSet FOLLOW_relySpecification_in_primaryKeyWithName12789 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CONSTRAINT_in_foreignKeyWithName12841 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_foreignKeyWithName12845 = new BitSet(new long[]{0x0000000000000000L,0x8000000000000000L});
    public static final BitSet FOLLOW_KW_FOREIGN_in_foreignKeyWithName12847 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_KW_KEY_in_foreignKeyWithName12849 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_columnParenthesesList_in_foreignKeyWithName12853 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
    public static final BitSet FOLLOW_KW_REFERENCES_in_foreignKeyWithName12856 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_foreignKeyWithName12860 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_columnParenthesesList_in_foreignKeyWithName12864 = new BitSet(new long[]{0x0000000000000000L,0x0000020100000000L});
    public static final BitSet FOLLOW_enableSpecification_in_foreignKeyWithName12868 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L,0x0080000000000000L});
    public static final BitSet FOLLOW_validateSpecification_in_foreignKeyWithName12872 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x4000000000000000L,0x0000080000000000L});
    public static final BitSet FOLLOW_relySpecification_in_foreignKeyWithName12876 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_FOREIGN_in_foreignKeyWithoutName12934 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_KW_KEY_in_foreignKeyWithoutName12936 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_columnParenthesesList_in_foreignKeyWithoutName12940 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
    public static final BitSet FOLLOW_KW_REFERENCES_in_foreignKeyWithoutName12943 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_foreignKeyWithoutName12947 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_columnParenthesesList_in_foreignKeyWithoutName12951 = new BitSet(new long[]{0x0000000000000000L,0x0000020100000000L});
    public static final BitSet FOLLOW_enableSpecification_in_foreignKeyWithoutName12955 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L,0x0080000000000000L});
    public static final BitSet FOLLOW_validateSpecification_in_foreignKeyWithoutName12959 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x4000000000000000L,0x0000080000000000L});
    public static final BitSet FOLLOW_relySpecification_in_foreignKeyWithoutName12963 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_skewedColumnValues_in_skewedValueElement13026 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_skewedColumnValuePairList_in_skewedValueElement13035 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList13062 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_skewedColumnValuePairList13065 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList13067 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_LPAREN_in_skewedColumnValuePair13112 = new BitSet(new long[]{0x0000000000084080L,0x0020000000043000L,0x0000000000000000L,0x0000000000000004L,0x0000002020000000L,0x0000000016008000L});
    public static final BitSet FOLLOW_skewedColumnValues_in_skewedColumnValuePair13116 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_skewedColumnValuePair13118 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_skewedColumnValue_in_skewedColumnValues13161 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_skewedColumnValues13164 = new BitSet(new long[]{0x0000000000084080L,0x0020000000043000L,0x0000000000000000L,0x0000000000000004L,0x0000002020000000L,0x0000000016008000L});
    public static final BitSet FOLLOW_skewedColumnValue_in_skewedColumnValues13166 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_constant_in_skewedColumnValue13210 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_skewedColumnValue_in_skewedValueLocationElement13244 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedValueLocationElement13253 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_NULLS_in_nullOrdering13307 = new BitSet(new long[]{0x0000000000000000L,0x0400000000000000L});
    public static final BitSet FOLLOW_KW_FIRST_in_nullOrdering13309 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_NULLS_in_nullOrdering13323 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
    public static final BitSet FOLLOW_KW_LAST_in_nullOrdering13325 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_columnNameOrder13358 = new BitSet(new long[]{0x0000008000000002L,0x0000000010000000L,0x0000000000000000L,0x0000000000000008L});
    public static final BitSet FOLLOW_orderSpecification_in_columnNameOrder13362 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000008L});
    public static final BitSet FOLLOW_nullOrdering_in_columnNameOrder13367 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_columnNameComment_in_columnNameCommentList13564 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_columnNameCommentList13567 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameComment_in_columnNameCommentList13569 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_identifier_in_columnNameComment13609 = new BitSet(new long[]{0x8000000000000002L});
    public static final BitSet FOLLOW_KW_COMMENT_in_columnNameComment13612 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_columnNameComment13616 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_expression_in_columnRefOrder13664 = new BitSet(new long[]{0x0000008000000002L,0x0000000010000000L,0x0000000000000000L,0x0000000000000008L});
    public static final BitSet FOLLOW_orderSpecification_in_columnRefOrder13668 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000008L});
    public static final BitSet FOLLOW_nullOrdering_in_columnRefOrder13673 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_columnNameType13872 = new BitSet(new long[]{0x0100702000000000L,0x08000008004C0000L,0x0004000000400000L,0x0000000000000000L,0x0400080060300400L});
    public static final BitSet FOLLOW_colType_in_columnNameType13874 = new BitSet(new long[]{0x8000000000000002L});
    public static final BitSet FOLLOW_KW_COMMENT_in_columnNameType13877 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_columnNameType13881 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_foreignKeyWithName_in_columnNameTypeOrPKOrFK13977 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_primaryKeyWithName_in_columnNameTypeOrPKOrFK13989 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_primaryKeyWithoutName_in_columnNameTypeOrPKOrFK14001 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_foreignKeyWithoutName_in_columnNameTypeOrPKOrFK14013 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_columnNameType_in_columnNameTypeOrPKOrFK14025 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_columnNameColonType14056 = new BitSet(new long[]{0x0000000000000200L});
    public static final BitSet FOLLOW_COLON_in_columnNameColonType14058 = new BitSet(new long[]{0x0100702000000000L,0x08000008004C0000L,0x0004000000400000L,0x0000000000000000L,0x0400080060300400L});
    public static final BitSet FOLLOW_colType_in_columnNameColonType14060 = new BitSet(new long[]{0x8000000000000002L});
    public static final BitSet FOLLOW_KW_COMMENT_in_columnNameColonType14063 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_columnNameColonType14067 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_type_in_colType14151 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_colType_in_colTypeList14178 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_colTypeList14181 = new BitSet(new long[]{0x0100702000000000L,0x08000008004C0000L,0x0004000000400000L,0x0000000000000000L,0x0400080060300400L});
    public static final BitSet FOLLOW_colType_in_colTypeList14183 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_primitiveType_in_type14211 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_listType_in_type14219 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_structType_in_type14227 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_mapType_in_type14235 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_unionType_in_type14243 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_TINYINT_in_primitiveType14265 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SMALLINT_in_primitiveType14286 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_INT_in_primitiveType14306 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_BIGINT_in_primitiveType14331 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_BOOLEAN_in_primitiveType14353 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_FLOAT_in_primitiveType14374 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DOUBLE_in_primitiveType14397 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DATE_in_primitiveType14419 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DATETIME_in_primitiveType14443 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_TIMESTAMP_in_primitiveType14463 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STRING_in_primitiveType14497 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_BINARY_in_primitiveType14519 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DECIMAL_in_primitiveType14541 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_primitiveType14544 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_Number_in_primitiveType14548 = new BitSet(new long[]{0x0000000000000400L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_COMMA_in_primitiveType14551 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_Number_in_primitiveType14555 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_primitiveType14559 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_VARCHAR_in_primitiveType14583 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_primitiveType14585 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_Number_in_primitiveType14589 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_primitiveType14591 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CHAR_in_primitiveType14616 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_primitiveType14618 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_Number_in_primitiveType14622 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_primitiveType14624 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ARRAY_in_listType14668 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000080L});
    public static final BitSet FOLLOW_LESSTHAN_in_listType14670 = new BitSet(new long[]{0x0100702000000000L,0x08000008004C0000L,0x0004000000400000L,0x0000000000000000L,0x0400080060300400L});
    public static final BitSet FOLLOW_type_in_listType14672 = new BitSet(new long[]{0x0000000001000000L});
    public static final BitSet FOLLOW_GREATERTHAN_in_listType14674 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STRUCT_in_structType14711 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000080L});
    public static final BitSet FOLLOW_LESSTHAN_in_structType14713 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameColonTypeList_in_structType14715 = new BitSet(new long[]{0x0000000001000000L});
    public static final BitSet FOLLOW_GREATERTHAN_in_structType14717 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_MAP_in_mapType14752 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000080L});
    public static final BitSet FOLLOW_LESSTHAN_in_mapType14754 = new BitSet(new long[]{0x0100700000000000L,0x08000008004C0000L,0x0000000000400000L,0x0000000000000000L,0x0400000060100400L});
    public static final BitSet FOLLOW_primitiveType_in_mapType14758 = new BitSet(new long[]{0x0000000000000400L});
    public static final BitSet FOLLOW_COMMA_in_mapType14760 = new BitSet(new long[]{0x0100702000000000L,0x08000008004C0000L,0x0004000000400000L,0x0000000000000000L,0x0400080060300400L});
    public static final BitSet FOLLOW_type_in_mapType14764 = new BitSet(new long[]{0x0000000001000000L});
    public static final BitSet FOLLOW_GREATERTHAN_in_mapType14766 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_UNIONTYPE_in_unionType14809 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000080L});
    public static final BitSet FOLLOW_LESSTHAN_in_unionType14811 = new BitSet(new long[]{0x0100702000000000L,0x08000008004C0000L,0x0004000000400000L,0x0000000000000000L,0x0400080060300400L});
    public static final BitSet FOLLOW_colTypeList_in_unionType14813 = new BitSet(new long[]{0x0000000001000000L});
    public static final BitSet FOLLOW_GREATERTHAN_in_unionType14815 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_UNION_in_setOperator14850 = new BitSet(new long[]{0x0000000100000000L});
    public static final BitSet FOLLOW_KW_ALL_in_setOperator14852 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_UNION_in_setOperator14866 = new BitSet(new long[]{0x0000000000000002L,0x0000000200000000L});
    public static final BitSet FOLLOW_KW_DISTINCT_in_setOperator14868 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_INTERSECT_in_setOperator14883 = new BitSet(new long[]{0x0000000100000000L});
    public static final BitSet FOLLOW_KW_ALL_in_setOperator14885 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_INTERSECT_in_setOperator14899 = new BitSet(new long[]{0x0000000000000002L,0x0000000200000000L});
    public static final BitSet FOLLOW_KW_DISTINCT_in_setOperator14901 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_EXCEPT_in_setOperator14916 = new BitSet(new long[]{0x0000000100000000L});
    public static final BitSet FOLLOW_KW_ALL_in_setOperator14918 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_EXCEPT_in_setOperator14932 = new BitSet(new long[]{0x0000000000000002L,0x0000000200000000L});
    public static final BitSet FOLLOW_KW_DISTINCT_in_setOperator14934 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_MINUS_in_setOperator14949 = new BitSet(new long[]{0x0000000100000000L});
    public static final BitSet FOLLOW_KW_ALL_in_setOperator14951 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_MINUS_in_setOperator14965 = new BitSet(new long[]{0x0000000000000002L,0x0000000200000000L});
    public static final BitSet FOLLOW_KW_DISTINCT_in_setOperator14967 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_withClause_in_queryStatementExpression15004 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0004000000200004L,0x8000008000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_queryStatementExpressionBody_in_queryStatementExpression15012 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_fromStatement_in_queryStatementExpressionBody15044 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_regularBody_in_queryStatementExpressionBody15052 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_WITH_in_withClause15069 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_cteStatement_in_withClause15071 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_withClause15074 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_cteStatement_in_withClause15076 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_identifier_in_cteStatement15102 = new BitSet(new long[]{0x0000004000000000L});
    public static final BitSet FOLLOW_KW_AS_in_cteStatement15104 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_cteStatement15106 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0004000000200004L,0x8000008000000000L,0x0000000000000000L,0x0000000000000204L});
    public static final BitSet FOLLOW_queryStatementExpression_in_cteStatement15108 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_cteStatement15110 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_singleFromStatement_in_fromStatement15133 = new BitSet(new long[]{0x0000000000000002L,0x0000100000000000L,0x0100000000800000L,0x0000000000000000L,0x0000040000000000L});
    public static final BitSet FOLLOW_setOperator_in_fromStatement15145 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_singleFromStatement_in_fromStatement15149 = new BitSet(new long[]{0x0000000000000002L,0x0000100000000000L,0x0100000000800000L,0x0000000000000000L,0x0000040000000000L});
    public static final BitSet FOLLOW_fromClause_in_singleFromStatement15356 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0004000000200000L,0x8000008000000000L});
    public static final BitSet FOLLOW_body_in_singleFromStatement15366 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0004000000200000L,0x8000008000000000L});
    public static final BitSet FOLLOW_insertClause_in_regularBody15403 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0004000000000000L,0x8000008000000000L,0x0100000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_selectStatement_in_regularBody15415 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_valuesClause_in_regularBody15440 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_selectStatement_in_regularBody15564 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_selectClause_in_atomSelectStatement15584 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000284L,0x0000000000000000L,0x8000000000000000L,0x0000000000000002L});
    public static final BitSet FOLLOW_fromClause_in_atomSelectStatement15591 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000280L,0x0000000000000000L,0x8000000000000000L,0x0000000000000002L});
    public static final BitSet FOLLOW_whereClause_in_atomSelectStatement15599 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000280L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L});
    public static final BitSet FOLLOW_groupByClause_in_atomSelectStatement15607 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000200L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L});
    public static final BitSet FOLLOW_havingClause_in_atomSelectStatement15615 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L});
    public static final BitSet FOLLOW_window_clause_in_atomSelectStatement15623 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_LPAREN_in_atomSelectStatement15701 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0004000000000000L,0x8000008000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_selectStatement_in_atomSelectStatement15704 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_atomSelectStatement15706 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_atomSelectStatement_in_selectStatement15727 = new BitSet(new long[]{0x0200000000000002L,0x0000100400000000L,0x0100010000800000L,0x0000000000000400L,0x0000040000001000L});
    public static final BitSet FOLLOW_setOpSelectStatement_in_selectStatement15734 = new BitSet(new long[]{0x0200000000000002L,0x0000000400000000L,0x0000010000000000L,0x0000000000000400L,0x0000000000001000L});
    public static final BitSet FOLLOW_orderByClause_in_selectStatement15743 = new BitSet(new long[]{0x0200000000000002L,0x0000000400000000L,0x0000010000000000L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_clusterByClause_in_selectStatement15751 = new BitSet(new long[]{0x0000000000000002L,0x0000000400000000L,0x0000010000000000L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_distributeByClause_in_selectStatement15759 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000010000000000L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_sortByClause_in_selectStatement15767 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000010000000000L});
    public static final BitSet FOLLOW_limitClause_in_selectStatement15775 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_setOperator_in_setOpSelectStatement16040 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0004000000000000L,0x8000008000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_atomSelectStatement_in_setOpSelectStatement16044 = new BitSet(new long[]{0x0000000000000002L,0x0000100000000000L,0x0100000000800000L,0x0000000000000000L,0x0000040000000000L});
    public static final BitSet FOLLOW_withClause_in_selectStatementWithCTE16679 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0004000000000000L,0x8000008000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_selectStatement_in_selectStatementWithCTE16687 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_insertClause_in_body16717 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0004000000000000L,0x8000008000000000L});
    public static final BitSet FOLLOW_selectClause_in_body16722 = new BitSet(new long[]{0x0200000000000002L,0x0000000400000000L,0x0000010800000280L,0x0000000000000400L,0x8000000000001000L,0x0000000000000002L});
    public static final BitSet FOLLOW_lateralView_in_body16727 = new BitSet(new long[]{0x0200000000000002L,0x0000000400000000L,0x0000010000000280L,0x0000000000000400L,0x8000000000001000L,0x0000000000000002L});
    public static final BitSet FOLLOW_whereClause_in_body16733 = new BitSet(new long[]{0x0200000000000002L,0x0000000400000000L,0x0000010000000280L,0x0000000000000400L,0x0000000000001000L,0x0000000000000002L});
    public static final BitSet FOLLOW_groupByClause_in_body16739 = new BitSet(new long[]{0x0200000000000002L,0x0000000400000000L,0x0000010000000200L,0x0000000000000400L,0x0000000000001000L,0x0000000000000002L});
    public static final BitSet FOLLOW_havingClause_in_body16745 = new BitSet(new long[]{0x0200000000000002L,0x0000000400000000L,0x0000010000000000L,0x0000000000000400L,0x0000000000001000L,0x0000000000000002L});
    public static final BitSet FOLLOW_window_clause_in_body16751 = new BitSet(new long[]{0x0200000000000002L,0x0000000400000000L,0x0000010000000000L,0x0000000000000400L,0x0000000000001000L});
    public static final BitSet FOLLOW_orderByClause_in_body16757 = new BitSet(new long[]{0x0200000000000002L,0x0000000400000000L,0x0000010000000000L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_clusterByClause_in_body16763 = new BitSet(new long[]{0x0000000000000002L,0x0000000400000000L,0x0000010000000000L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_distributeByClause_in_body16769 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000010000000000L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_sortByClause_in_body16775 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000010000000000L});
    public static final BitSet FOLLOW_limitClause_in_body16781 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_selectClause_in_body16874 = new BitSet(new long[]{0x0200000000000002L,0x0000000400000000L,0x0000010800000280L,0x0000000000000400L,0x8000000000001000L,0x0000000000000002L});
    public static final BitSet FOLLOW_lateralView_in_body16879 = new BitSet(new long[]{0x0200000000000002L,0x0000000400000000L,0x0000010000000280L,0x0000000000000400L,0x8000000000001000L,0x0000000000000002L});
    public static final BitSet FOLLOW_whereClause_in_body16885 = new BitSet(new long[]{0x0200000000000002L,0x0000000400000000L,0x0000010000000280L,0x0000000000000400L,0x0000000000001000L,0x0000000000000002L});
    public static final BitSet FOLLOW_groupByClause_in_body16891 = new BitSet(new long[]{0x0200000000000002L,0x0000000400000000L,0x0000010000000200L,0x0000000000000400L,0x0000000000001000L,0x0000000000000002L});
    public static final BitSet FOLLOW_havingClause_in_body16897 = new BitSet(new long[]{0x0200000000000002L,0x0000000400000000L,0x0000010000000000L,0x0000000000000400L,0x0000000000001000L,0x0000000000000002L});
    public static final BitSet FOLLOW_window_clause_in_body16903 = new BitSet(new long[]{0x0200000000000002L,0x0000000400000000L,0x0000010000000000L,0x0000000000000400L,0x0000000000001000L});
    public static final BitSet FOLLOW_orderByClause_in_body16909 = new BitSet(new long[]{0x0200000000000002L,0x0000000400000000L,0x0000010000000000L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_clusterByClause_in_body16915 = new BitSet(new long[]{0x0000000000000002L,0x0000000400000000L,0x0000010000000000L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_distributeByClause_in_body16921 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000010000000000L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_sortByClause_in_body16927 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000010000000000L});
    public static final BitSet FOLLOW_limitClause_in_body16933 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_INSERT_in_insertClause17054 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
    public static final BitSet FOLLOW_KW_OVERWRITE_in_insertClause17056 = new BitSet(new long[]{0x0000000000000000L,0x0000000080000000L,0x0000080000000000L,0x0000000000000000L,0x0000000000400000L});
    public static final BitSet FOLLOW_destination_in_insertClause17058 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_ifNotExists_in_insertClause17060 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_INSERT_in_insertClause17079 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_KW_INTO_in_insertClause17081 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_TABLE_in_insertClause17083 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableOrPartition_in_insertClause17086 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_LPAREN_in_insertClause17089 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnNameList_in_insertClause17093 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_RPAREN_in_insertClause17095 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LOCAL_in_destination17151 = new BitSet(new long[]{0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_KW_DIRECTORY_in_destination17155 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_StringLiteral_in_destination17157 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0400000000000000L,0x0000000000040000L});
    public static final BitSet FOLLOW_tableRowFormat_in_destination17159 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
    public static final BitSet FOLLOW_tableFileFormat_in_destination17162 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_TABLE_in_destination17195 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableOrPartition_in_destination17197 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LIMIT_in_limitClause17229 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_Number_in_limitClause17235 = new BitSet(new long[]{0x0000000000000400L});
    public static final BitSet FOLLOW_COMMA_in_limitClause17237 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_Number_in_limitClause17243 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LIMIT_in_limitClause17266 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_Number_in_limitClause17270 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
    public static final BitSet FOLLOW_KW_OFFSET_in_limitClause17272 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_Number_in_limitClause17276 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DELETE_in_deleteStatement17320 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_FROM_in_deleteStatement17322 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_deleteStatement17324 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x8000000000000000L});
    public static final BitSet FOLLOW_whereClause_in_deleteStatement17327 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_tableOrColumn_in_columnAssignmentClause17360 = new BitSet(new long[]{0x0000000000200000L});
    public static final BitSet FOLLOW_EQUAL_in_columnAssignmentClause17362 = new BitSet(new long[]{0xDEFFFFF7F8084080L,0xDFFBCAFDFFFEF5DEL,0xF6FDFFDFBFFFFDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000001E01923DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_precedencePlusExpression_in_columnAssignmentClause17365 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_setColumnsClause17385 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnAssignmentClause_in_setColumnsClause17387 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_setColumnsClause17390 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_columnAssignmentClause_in_setColumnsClause17392 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_KW_UPDATE_in_updateStatement17434 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_updateStatement17436 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_setColumnsClause_in_updateStatement17438 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x8000000000000000L});
    public static final BitSet FOLLOW_whereClause_in_updateStatement17440 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_startTransactionStatement_in_sqlTransactionStatement17482 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_commitStatement_in_sqlTransactionStatement17487 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_rollbackStatement_in_sqlTransactionStatement17492 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_setAutoCommitStatement_in_sqlTransactionStatement17497 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_START_in_startTransactionStatement17511 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000200000000L});
    public static final BitSet FOLLOW_KW_TRANSACTION_in_startTransactionStatement17513 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000008000000L,0x0000000400000000L});
    public static final BitSet FOLLOW_transactionMode_in_startTransactionStatement17517 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_startTransactionStatement17522 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000008000000L,0x0000000400000000L});
    public static final BitSet FOLLOW_transactionMode_in_startTransactionStatement17524 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_isolationLevel_in_transactionMode17555 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_transactionAccessMode_in_transactionMode17561 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_READ_in_transactionAccessMode17584 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000080L});
    public static final BitSet FOLLOW_KW_ONLY_in_transactionAccessMode17586 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_READ_in_transactionAccessMode17596 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_KW_WRITE_in_transactionAccessMode17598 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ISOLATION_in_isolationLevel17617 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
    public static final BitSet FOLLOW_KW_LEVEL_in_isolationLevel17619 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000800L});
    public static final BitSet FOLLOW_levelOfIsolation_in_isolationLevel17621 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SNAPSHOT_in_levelOfIsolation17646 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_COMMIT_in_commitStatement17665 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000008L});
    public static final BitSet FOLLOW_KW_WORK_in_commitStatement17669 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ROLLBACK_in_rollbackStatement17691 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000008L});
    public static final BitSet FOLLOW_KW_WORK_in_rollbackStatement17695 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_setAutoCommitStatement17716 = new BitSet(new long[]{0x0000020000000000L});
    public static final BitSet FOLLOW_KW_AUTOCOMMIT_in_setAutoCommitStatement17718 = new BitSet(new long[]{0x0000000000000000L,0x0020000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
    public static final BitSet FOLLOW_booleanValueTok_in_setAutoCommitStatement17720 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ABORT_in_abortTransactionStatement17755 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
    public static final BitSet FOLLOW_KW_TRANSACTIONS_in_abortTransactionStatement17757 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_Number_in_abortTransactionStatement17761 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_KW_MERGE_in_mergeStatement17807 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
    public static final BitSet FOLLOW_KW_INTO_in_mergeStatement17809 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_tableName_in_mergeStatement17811 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_KW_AS_in_mergeStatement17814 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000003DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_identifier_in_mergeStatement17817 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
    public static final BitSet FOLLOW_KW_USING_in_mergeStatement17821 = new BitSet(new long[]{0xDE9FFFF7F8000000L,0xCFEBCAFDFFFEF5DEL,0xF6F9FFDFBEFFEDEBL,0x7EFFFF7FF8FB7D3EL,0x3BFFEEF7EEFF7FFFL,0x400000000000023DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_joinSourcePart_in_mergeStatement17823 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_KW_ON_in_mergeStatement17825 = new BitSet(new long[]{0xDEFFFFF7F8084080L,0xDFFBCAFDFFFEF5DEL,0xF6FDFFDFBFFFFDEBL,0x7EFFFF7FF8FB7D3FL,0x3BFFEEF7EEFF7FFFL,0x400000001E01923DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_expression_in_mergeStatement17827 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
    public static final BitSet FOLLOW_whenClauses_in_mergeStatement17829 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_whenMatchedAndClause_in_whenClauses17874 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
    public static final BitSet FOLLOW_whenMatchedThenClause_in_whenClauses17876 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
    public static final BitSet FOLLOW_whenNotMatchedClause_in_whenClauses17880 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_WHEN_in_whenNotMatchedClause17907 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
    public static final BitSet FOLLOW_KW_NOT_in_whenNotMatchedClause17909 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
    public static final BitSet FOLLOW_KW_MATCHED_in_whenNotMatchedClause17911 = new BitSet(new long[]{0x0000000800000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
    public static final BitSet FOLLOW_KW_AND_in_whenNotMatchedClause17914 = new BitSet(new long[]{0xDEFFFFF7F8084080L,0xDFFBCAFDFFFEF5DEL,0xF6FDFFDFBFFFFDEBL,0x7EFFFF7FF8FB7D3FL,0x3BFFEEF7EEFF7FFFL,0x400000001E01923DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_expression_in_whenNotMatchedClause17916 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
    public static final BitSet FOLLOW_KW_THEN_in_whenNotMatchedClause17920 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L});
    public static final BitSet FOLLOW_KW_INSERT_in_whenNotMatchedClause17922 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0100000000000000L});
    public static final BitSet FOLLOW_KW_VALUES_in_whenNotMatchedClause17924 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_valueRowConstructor_in_whenNotMatchedClause17926 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_WHEN_in_whenMatchedAndClause17969 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
    public static final BitSet FOLLOW_KW_MATCHED_in_whenMatchedAndClause17971 = new BitSet(new long[]{0x0000000800000000L});
    public static final BitSet FOLLOW_KW_AND_in_whenMatchedAndClause17973 = new BitSet(new long[]{0xDEFFFFF7F8084080L,0xDFFBCAFDFFFEF5DEL,0xF6FDFFDFBFFFFDEBL,0x7EFFFF7FF8FB7D3FL,0x3BFFEEF7EEFF7FFFL,0x400000001E01923DL,0x0000002000000000L,0x0000000008800000L,0x0000420000022000L});
    public static final BitSet FOLLOW_expression_in_whenMatchedAndClause17975 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
    public static final BitSet FOLLOW_KW_THEN_in_whenMatchedAndClause17977 = new BitSet(new long[]{0x0000000000000000L,0x0000000002000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
    public static final BitSet FOLLOW_updateOrDelete_in_whenMatchedAndClause17979 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_WHEN_in_whenMatchedThenClause18017 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
    public static final BitSet FOLLOW_KW_MATCHED_in_whenMatchedThenClause18019 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
    public static final BitSet FOLLOW_KW_THEN_in_whenMatchedThenClause18021 = new BitSet(new long[]{0x0000000000000000L,0x0000000002000000L,0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
    public static final BitSet FOLLOW_updateOrDelete_in_whenMatchedThenClause18023 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_UPDATE_in_updateOrDelete18052 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_setColumnsClause_in_updateOrDelete18054 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DELETE_in_updateOrDelete18072 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_grantPrivileges_in_synpred1_HiveParser2324 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_revokePrivileges_in_synpred2_HiveParser2338 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixRename_in_synpred3_HiveParser4294 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ELEM_TYPE_in_synpred4_HiveParser6886 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_KEY_TYPE_in_synpred5_HiveParser6903 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_VALUE_TYPE_in_synpred6_HiveParser6920 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_FUNCTION_in_synpred8_HiveParser7128 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_COMPUTE_in_synpred10_HiveParser7287 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CACHE_in_synpred11_HiveParser7427 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ALL_in_synpred14_HiveParser8812 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_NONE_in_synpred15_HiveParser8843 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ALL_in_synpred16_HiveParser9017 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_storedAsDirs_in_synpred17_HiveParser11000 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STORED_in_synpred18_HiveParser11981 = new BitSet(new long[]{0x0000004000000000L});
    public static final BitSet FOLLOW_KW_AS_in_synpred18_HiveParser11983 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_KW_INPUTFORMAT_in_synpred18_HiveParser11985 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ELEM_TYPE_in_synpred19_HiveParser12422 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_KEY_TYPE_in_synpred20_HiveParser12432 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_VALUE_TYPE_in_synpred21_HiveParser12442 = new BitSet(new long[]{0x0000000000000002L});

}